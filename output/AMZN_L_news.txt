List of news related to Layoffs Amazon:

Title: AI Book Club recording and notes for The Singularity is Nearer, by Ray Kurzweil
URL: https://idratherbewriting.com/blog/kurzweil-singularity-ai-book-club-recording-notes
Time Published: 2025-06-15T07:00:00Z
Full Content:
by Tom Johnson on Jun 15, 2025 categories: ai • ai-book-club • podcasts Here’s a recording of the AI Book Club: A Human in the Loop meeting, held June 15, 2025: If you just want the audio, here it is: Listen here: Here are some of the high-level topics we discussed during the book club. (These are pulled and summarized from the transcript using AI.) Here are some discussion questions I prepared for the book club. We didn’t discuss many of these, but they nonetheless reflect some of the themes and issues that stood out to me. AGI by 2029? Do you really think that by 2029 we’ll reach AGI? That’s really close – just 4 years away. If it happens, how will that change our profession? Accelerating returns cycle? How do some of the information assets we produce create accelerating returns? AI leads to producing more content with greater depth and accuracy. This information then leads to more abundant and rapid use of the technology, as it helps AI tools more quickly implement APIs and other tools/assets, which in turn leads to the development of more technologies. Is this a virtuous cycle of technological advancement? Discuss unprovable futurism? Is there merit in getting so invested or antagonistic in a futurist position that seems so far-fetched as to be unprovable? For example, nanobots rearranging our molecular DNA to create immune responses from virus-type nanobots, or grey-goo scenarios. If something isn’t provable, is it worth truly discussing? Or, due to the Law of Accelerating Returns (LOAR), will these scenarios become near-immediate realities much faster than we realize, catching us unprepared? LOAR and AI? I’m most persuaded by the Law of Accelerating Returns (LOAR). I think there’s merit to this idea. I had a discussion this morning about how AI is similar to the dot-com boom/hype of the early 2000s. The dot-com boom did lead to a crash, but the internet eventually turned out to be deeply transformative. AI isn’t just potentially similar; it can build on the existing innovation of the web to accelerate even faster, as the web enables better information sharing and distribution. Additionally, the web itself (all the content) provided much of the data needed to train and power LLMs. So I can see a case where these technologies build on each other and, in so doing, accelerate faster and faster. Do you agree with this assessment? Radical life extension? Are we on the verge of radical life extension? If we can just hold out another 10-15 years, will we hit a point of “longevity escape velocity” with our health? What would that mean? Could a technical writer be 250 years old? Singularity, new identity? If we hit a point of the singularity, we will no longer be “tech writers” because we’ll have so much knowledge at our disposal that we could be engineers, doctors, or rocket scientists, etc? The infusion of this knowledge will allow us to transcend this role and move into any other. Do we need to start thinking beyond our current identity to be more ambitious in what we want to undertake? Your singularity age? How old will you be when the singularity (predicted in 2045) takes place? What will society be like when this happens? What if it only partially happens? Acceleration already here? In what sense are we already seeing this rate of acceleration taking place? I feel like every day someone is sharing some new AI-related tool, link, or news with me. It’s certainly coming at an accelerated pace. Will this pace keep up? Workplace acceleration impact? What happens when acceleration starts to become more apparent in the workplace? Technical writers (TWs) will be bombarded with documentation requests, potentially just requests to review documents engineers have already written, etc. TWs will either use AI to keep up or start outsourcing the documentation work to those using AI to build. How are you / will you deal with acceleration? AI divide growing? Do you see a growing divide between those who can access and use AI tools versus those who don’t have access to them, or who have access but don’t know how to use them successfully? For example, if users have access to the top tiers of Gemini, Claude, or ChatGPT in their work (tiers costing $200+/month), will this separation start to create a divide between the AI-haves and AI-have-nots? What could you do with access to a top-tier model? What if a model is released at $5,000 a month, such as a powerful agentic model that lets you accomplish all your work while you sleep, or which reduces your existing workload by half, freeing up more of your time to pursue or accelerate other work? Perhaps we’ll start to see more acceleration in individuals, widening the divide. This is a new type of technological divide: not just people who have computers and know how to use them, but people who can access and successfully use advanced AI models. Merging with AI? Kurzweil has said that in many ways, we’re already merging with AI. We carry smartphones in our pockets, and the documents we produce are collaborations with AI (helping us brainstorm, refine our thoughts, articulate our ideas, etc.). As others incorporate these human/machine collaborative products, the AI-based content proliferates and becomes embedded into even more parts of society. As a result, the distinction between human and machine is blurring. Will our close relationship with smartphones, all of which now offer AI in our pockets, accelerate our convergence with AI? AI catastrophe risk? It seems that AI advancements present many new and novel ways for humanity to destroy itself. The grey-goo scenario, where nanobots out of control consume the biosphere in a matter of days, or where rogue actors bioengineer toxins (perhaps tailored to specific DNA profiles) present new avenues for annihilation. We’re lucky that so far, nuclear winter hasn’t happened. But what are the chances that some AI-engineered catastrophe won’t occur, given its increased accessibility and the variety of available scenarios that could lead to many possible attack vectors? Complexity brakes and self-driving cars. Critics mention possible “complexity brakes” interfering with the projected timeline. I think self-driving cars are a good example. A lot of people anticipated that we would have fully autonomous vehicles several years ago, but it didn’t really happen. Only in controlled areas in select cities do we see AVs like Waymo operating. Autonomous driving turned out to be much harder than anything anticipated (for example, Elon keeps saying Tesla Robotaxis are just around the corner). It’s probably the same with many of Kurzweil’s predictions. The Law of Accelerating Returns (LOAR) will hit many complexity snags that slow acceleration down. Figuratively speaking, maybe accelerating a technology from 0 to 70 mph is somewhat easy, then from 70 - 90 mph much harder, and then from 90-95 mph the most difficult, and 95-100 almost impossible. I’m not sure if the LOAR curve is always exponential. Brain-cloud interface? Connecting our brains to the cloud reminds me of a Black Mirror episode, specifically Season 7, episode 1: “Common People.” A woman has part of her brain removed due to a tumor, but a cloud service can provide similar functionality, connected to online services that stream data to her brain. It’s a pretty compelling episode. Of course, as with nearly every Black Mirror episode, the plot goes dark when the company starts showing ads and upselling services through the person (taking over their brain), and then amplifying her sensory experiences for even more upselling. But the larger point of this episode is to contemplate our merging with AI. Is it likely that an AI service, running on massive cloud computing, could provide a service that in some way connects to a biological component in a human? Utopian or dystopian? Kurzweil’s vision of the future is a techno-utopian one, where technology eliminates disease, economic hardship, and more. It’s an era of abundance and opportunity. In contrast, many others perceive the future as much more dystopian and see many concerns about bleak futures. Do you perceive a techno-utopian future or techno-dystopian future, and why? Hollywood romanticizes the dystopian future for a more compelling storyline, but Kurzweil’s evidence showing advancements during the past 200 years presents a compelling case for continued and accelerating improvements (we live longer, have greater wealth, etc.). Are we overlooking these improvements? If we were to teleport back in time, would our current progress be much more apparent to us? Book’s overall effect? Overall, this book is a refreshing argument in favor of techno-utopianism at a time when we’re seeing more anti-AI books come out. It makes me think we’re only going to see more acceleration, technological innovation, and advancements in the years to come. More readily available expert knowledge will be available. I think we’ll see a growing divide between those who can harness AI for their work and those who can’t. So it makes me want to double down on my AI learning and incorporation, as I think this will position me to ride the wave and learn to navigate what’s to come. What was the overall effect of this book on your perspective? For notes summarizing the book, along with discussion questions, see this Google Doc. The Google Doc organizes information into various tabs (Book summary, Discussion questions, etc.) that appear on the left. I uploaded the summary and discussion questions into NotebookLM and created a “Deep Dive” podcast from it. You can listen here: Listen here: Here’s a transcript of the meeting, with the conversation made more readable through AI: Tom: This is a recording of the AI book club, “A Human in the Loop.” Specifically, we are discussing Ray Kurzweil’s The Singularity is Nearer. This is a discussion among around five people for about an hour where we talk about different topics. A lot of us are tech writers, and some of us are in other roles, but this is basically a recording of a book club discussion. It’s not super focused thematically; it’s a lot of different perspectives, takeaways, and thoughts on Kurzweil’s book. So, enjoy. Tom: Well, let me just go ahead and kick things off here. Welcome to this AI book club. We’ll be talking about Ray Kurzweil’s The Singularity is Nearer. And like the other book club sessions, this is being recorded, and I’ll distribute it afterwards. So just make sure you don’t say anything you don’t want to be heard by other people. That usually doesn’t happen. We have about four people today. Last time, we had probably two or three times that. Unfortunately, I have a bad track record of picking holidays for this. I try to just do a regular, predictable cadence—the third Sunday of the month—and already I’ve hit Easter and Father’s Day. So anyway, Happy Father’s Day to anybody who’s a father out there. Nathan: And you’re a father. Tom: Yeah, I am. Happy Father’s Day to you. I’ve got plans right after this, going to a baseball game with my kids. I don’t even really watch baseball, but it’s kind of fun to go with my kids to a sporting event. So anyway, all right, let’s get into this book. I did share a document. If you didn’t see it, let me just share my screen real quick so you know where all these notes go. I usually provide a notes document right before the book club, and the notes document just has—you can find the link right next to the book in the schedule. And this time, I created a few different things. First of all, I just drafted a big summary because I wanted to make sure I was understanding things. If you’ve never used Gemini Deep Research, or even ChatGPT’s deep research capabilities, it’s probably highly similar. It’s great, and it does a nice job of just summarizing all the main things. And with a book like this that’s so popular, there’s a lot of information online, so you could probably have more confidence in its accuracy. But I mean, if you’ve read the book too, you would know what’s on target and what’s not, and it surprisingly looks good to me. I also added some discussion questions and invited people to add to them if they wanted. These are kind of long and different thoughts, and we can hit them or not. I don’t think anybody added one, but maybe I’m wrong. And then finally, I just added this this morning, but if you haven’t played around with NotebookLM, this is a tremendous amount of fun. It’s notebooklm.google.com. You just upload—in this example, I uploaded the book summary into it—and it generated a 28-minute podcast. And then I just downloaded and uploaded this. But it’s a good way to sort of ramp up on any subject. Now, as people pointed out last time, none of these resources are really what people want, which is they want to know what others think about the book. What do you make of it? Do you agree? Did you like the book? How do you see this sort of applying and playing out in your life or not? So, why don’t we jump into that high-level topic? What did you think of the book? Did you enjoy it? Did you have strong reactions against it? What was your general reception? Mette: I can start with the opening shot. Tom: Go for it. Mette: I liked the book. I didn’t like it as much as the last book by Mustafa Suleyman. I thought he was more—he talked more to an audience that was here and now. It seemed that—and I don’t know how to really pronounce his name, Ray Kurzweil, is that his name? Tom: I actually don’t know either. Kurzweil is my understanding. Mette: Yeah. His book was really centered on maybe not the people right now on Earth, but people maybe, I don’t know, 20, 30 years from now, or 50 years. So I kept on finding myself going, “Okay, buddy, what about us now?” He seemed to do a lot of—his argument often was, “Here’s all the wonderful things that AI is going to do for humanity. Oh, but it’s not going to be so great in the short term.” And I found that to be a continuing theme. Maybe I was in a pessimistic mood. But that said, he could certainly crunch the numbers, and I found that interesting. I don’t know where he got all that information. It’s a whole lot of research he did, certainly very optimistic research. I found the most interesting part of the book to be the bio part because that’s something Suleyman didn’t really go into in great detail, but he went into it in a lot of detail. I’m like, “Oh, okay, that’s what’s going to happen.” Okay. So, what astounded me was that it was all going to be happening pretty much in the 2030s by his predictions. And then on several occasions, he pointed out that he’s always been kind of correct on his predictions. Tom: Yeah, I, wow, you brought up so many great points here. Let’s jump into some of these. The first one you mentioned about the audience: who is he really talking to? And you’re right that he seems to be addressing more of a future audience or not really talking to the people here and now. And yet, his AGI (Artificial General Intelligence) prediction is supposed to land around 2029, which is four years away. I’m like, “Oh my god, that’s, you know, really just a stone’s throw away.” Mette: Yeah. Tom: But I mean, there’s definitely an element of science fiction, it feels, especially when you get into Epoch 6 where the universe wakes up and so on. It’s like, very creative and imaginative, and it’s kind of like, wow, I mean, who knows what that time will look like? But you also brought up the Law of Accelerating Returns, and I agree. I’m kind of taken by that as well. And this whole topic of acceleration is one that I find probably most applicable and most immediate. I know critics have said that he mostly cherry-picks examples from technology as proof, and we don’t really have that same kind of Law of Accelerating Returns in biology and other domains, or even just like airplane travel. So people say we’re hitting complexity brakes in those other areas. But I mean, do you—this is a question I asked my colleagues the other day—do you feel like things are accelerating in your own work? Mette: Yes. Tom: In what ways? Mette: The expectations that are placed on me as a technical writer. It’s, you know, my company is kind but firm. It’s like, if you’re not using AI to show us how you can be twice as efficient or more, then, gee, there might be a different future for you that doesn’t include us. Tom: Wow. Mette: So I mean, it’s very subtle, but it’s there. And they’ve really gotten on the AI bandwagon. So I feel it every day, definitely. Of course, you know, just on my cell phone, I notice all sorts of things. So just apart from work, I see it happening every single day. Tom: It’s interesting to hear feedback from people in other companies about AI momentum and pressure and encouragement. So yeah, that’s really, really fascinating. Do you feel like the work itself has doubled yet? Like if you’re being asked to do twice as much, do you also have twice as many doc requests and projects and things to do as before? Mette: Yeah, and that’s probably because we laid off 40% of our department. Tom: Oh, okay. Mette: Because of AI. Tom: Because of AI, initially? Wow. Wow, you’re really in the—you’re right in this stuff. That’s crazy. Okay. Wow. So they really, they really doubled down on people being twice as productive by laying off— Mette: They really have. Tom: Wow, that’s a trend that I don’t think has really caught on. I mean, I don’t see massive companies laying off half their staff and telling them to just use AI to pick up the slack, but I see it here and there and wonder how much speed it will pick up. Anybody else have any thoughts? Nathan? Nathan: I think, just about companies and the choices they might make, I think AI gives them almost an excuse to shrink their workforce, right? I mean, so whether or not AI is actually making gains in any productivity for a company’s workers, a company can use that as an excuse to shrink their workforce. And there is, you know, I mean, there’s a benefit to the hype of AI, you know, in the way that those companies have said it needs to be regulated, it’s going to get out of control. I mean, there’s some marketing angle to that, I would say. So, you know, for friends of mine who have been laid off for reasons of AI, I definitely sympathize with all those folks, and I think in some cases it’s definitely true, but in some cases as well, there might be some, you know, kind of marketing spin to workforce reductions underneath this AI era. So I just wanted to throw that out there. Tom: That’s a really good point. And I think another point on understanding why companies might be using AI as an excuse to lay people off is also just to justify the massive capital expenditure on all the AI infrastructure and tooling and resources. I mean, you can’t spend billions of dollars and not have a return on investment. So maybe the quickest way to show that is by saying we were able to cut our workforce in half. You have to satisfy Wall Street. Nathan: True. Tom: Anybody else have—go ahead, Liam. Liam: Yeah, well, nice to meet y’all. I work at AWS, and obviously, whatever I share is basically my perspective; working there has nothing to do with my actual work. But we do a lot of work with GenAI, and I think what I was surprised by was how little the phrase “GenAI,” like generative artificial intelligence, was brought up. Ray talks about AI a lot, or AI superintelligence, or artificial general intelligence like you said, Tom. For me, when I think about where it goes in my work, how I feel like things are accelerating—I’m in sales, and so we’re working with a lot of SMB companies. I’m not a technical writer, but I thought what y’all were talking about was fascinating, so I wanted to join. We’re trying to sell the future, kind of. And so there are expectations put on us about what level of adoption and usage customers should be using GenAI for, whether that’s a concrete manufacturer or a digitally native business. And it feels like whether it’s Azure, GCP, Oracle, or AWS, a lot of people are guessing about what level of adoption will be like in day-to-day business. And I would say for me, what’s accelerating is that we’re not seeing agents do my day-to-day work, even though we see Service Now commercials or Salesforce commercials show that. We’re still seeing a lot of manual tasks done by individuals like myself and still trying to find ways, like, how do we move this from—interestingly, it’s commercialized so people use it day-to-day, but it’s not in the actual business. Like, it’s not seeing real business value being driven, at least when I’m working with my customers, other than like chatbots and intelligent document processing, which might have been started 5-10 years ago and is not a GenAI topic. It’s something that can be structured and responsive. Suparna: Hey, oh, go ahead. Tom: Super—I was just going to ask a follow-up question to Liam, really, but totally okay if you can’t answer. I was just wondering if you could give an example of one of those manual tasks that hasn’t yet been… that you haven’t been able to transition to AI? Liam: Yeah, great question. I think the phrase wouldn’t be “can’t transition to AI.” I think what I’m seeing right now is, is the organization investing in doing that? So, for example, Salesforce is a great tool to track how you interact well with your customers. And so we use that to track who our customers are and how we interact with them, whether we had a meeting, like a billion other organizations do. And that could be a very agentic thing, I believe, where I have a meeting on my calendar, and let’s say a live meeting assistant takes the notes and then imports that into Salesforce, and then identifies the notes and then gives suggestions, writes emails for next steps, sends it out, sends the new meeting invite, or submits a ticket for a special request to meet with a technical advisor, like a solutions architect, about Amazon Rekognition to be able to recognize images on documents. Rekognition is an AWS AI tool, which you probably know. And so it’s not that it can’t be done; we’re just seeing a lot of these businesses that I’m working with are not implementing it at the speed at which I think a lot of leadership in the tech world think they would have by this time. Tom: Speaking of agents and how much can be automated and accelerated, I was playing around with something the other day called Jules. I’m not sure if you’ve heard of this, but this is one of these agents that is somewhat experimental, I think. It’s an experimental coding agent that helps you fix bugs, add documentation, and so on. It integrates with GitHub. This is a Google experimental agent. And I was really trying to make it work. I was like, “Oh, this looks awesome.” You give it some tasks and it just goes to work, and you come back later and it’s all done. But it was really hard to figure out what tasks to give it that it would be successful with. What I wanted it to do, basically, is first just to check all the links of something and make sure all the links were valid. And instead, it built me a link parser out of Python. You know, I was like, “Whoa, that wasn’t what I expected.” And then I thought, “Okay, let me just update the information on this page. I know that’s somewhat outdated.” And I wanted it to go out and get all the information necessary and pull it down and unpack it and update the topic. But it’s a lot harder to pull that off. I think there’s so much glue between the tasks we do. I feel like I have to set up AI so that it will be successful—give it all the info it needs, give it a very concrete task, give it access to a specific page, tell it what to do. And setting all that up, it’s hard, right? That’s all the meta-information between tasks that AI can’t really do—all that context, even prioritizing what page, where to start. So I don’t know, the agent thing is, I think, definitely the next level of AI. The ability for these tools to just update pages across a doc set in a very autonomous way is pretty amazing, but still hard to implement. Suparna, have you done anything—have you made progress with agents and getting significantly long tasks going with them? Suparna: I haven’t, no. I used to work as a software engineer, and I’m currently laid off, with some thoughts of going into something slightly different. I am volunteering in literacy right now, and the only way that I’m using AI is—I used to try to take articles, for example, from BBC Features, and try to summarize them in ESL-friendly language. And then I think I heard from one of the tech-savvy staff members, he was like, “You should be doing this with AI.” And then I finally started just feeding those articles into ChatGPT, with a slight worry about, “Is this ethical for me to do this?” But it’s actually been really great using that because the ways in which the summaries have been generated allow me to focus on interacting with the content more and thinking about how the people I’m doing the article with can engage with the content. So I’m focusing more on discussion questions, which also could be generated by the chatbot, but I think I’m enjoying the questions that I think of and that they think of more. So I guess I kind of save that pleasure for myself. And so that’s the only way I’m really using it in a context that is more of a public setting, since I’m not working right now. Tom: Yeah, well, that’s cool. That sounds like a worthwhile use. I’m just thinking back to the whole acceleration topic and how this might fit in. Let’s say you have 30 different articles that you’re trying to make more readable or more understandable. If you used an agent and you gave it the task of going through each one of these articles and applying certain style rules, it would probably do a decent job at it, and you could review it at the end. This speaks to this larger goal that many tech writers have, where you might have a whole doc set and you want to make sure that your style guide rules apply to every one of the 100 pages in the doc set, as well as other rules. And you give it this task, and then in the morning, you come back and you review the changes and you hit accept or reject. That kind of acceleration could be interesting. I haven’t achieved anything like that, but I think that is the promise. And I think many people do think that agents will be a key ingredient in the acceleration equation. But Kurzweil doesn’t really talk about agents so much, unless I missed that part. He’s very high-level. Nathan: I’m searching a PDF of the book right now, and the word “agent” only appears a few times in the body of the book and a few more times in the endnotes. So yeah, it does appear. Tom: I think at a more high level, what he says is that one innovation gives rise to another. He says we’re now using—like, before we had computers, people had to develop computers. But now computers are being used to develop more computer chips. So one invention leads to another. And I see this pretty regularly. I was thinking about just all the docs we produce or the information we produce will then accelerate the creation of other tools and APIs, which will then create more innovation. It does seem commonsensical or logical that things would accelerate because the tools we’re creating can be used to create more things more quickly. I was trying to think of an example of this. Nathan: How about in the book? Yeah, sure. Or elsewhere outside of it? Tom: Could you even say something that creates code automatically leads to greater creations? Nathan: Oh yeah, yeah, yeah, that’s a great example. The Cursor AI code editor and just the whole integration now making it faster to create additional code. Tom: Yeah, good example. All right, any other themes? Maybe we should move off of acceleration unless people have any more thoughts on that. Mette: Towards the end of the book, he was talking about the Asilomar conference and how they came up with sort of some guideline bylaws by which humanity could use AI. And I guess my thought was, are we really dependent on this one thing to keep everything in check? Otherwise, bad actors are going to intervene. There’s so much vulnerability there. When I read that part, I was like, “Okay, that sounds great.” He read some of the bylaws, and I thought, “Sounds really great.” You know, why aren’t we hearing about this more? What’s going to happen? Because if they’re not followed, there are some really bad things that can happen. Tom: I think that is a major criticism Kurzweil has received—that he’s very much a techno-utopian optimist. And especially in contrast to the last book we read with Suleyman—Suleyman devoted half of the book to containment strategies and theories. Mette: I know. Tom: And Kurzweil basically just says, “Well, the way to get past these problems is just to build better defense.” He doesn’t want to slow down the rate of development or put a bunch of regulation on it. He just wants to build better defensive mechanisms and that requires all of the man-made democratic tools that humanity has in terms of governance, which is threatened by AI, you know, according to Suleyman. So I’m like, okay, you’re placing greater weight on a foundation that is kind of crumbling. I don’t know. Yeah, it really perplexes me, the just variety of attitudes around AI. I also listened to a podcast, This Week in Tech with Leo Laporte. He’s very much embracing AI. He really wants to accelerate things. I can’t help but think, is Kurzweil really so fully embracing of AI because he wants things to move faster to achieve the whole longevity escape velocity? Like, does he want things to get in motion before he has to, you know, take his exit off this planet? Because he’s—I don’t know how old he is, but he’s been around since going to MIT in 1965. Nathan: So he’s getting up there. And I know there was a documentary on him, I don’t know, 10 or 15 years ago, that detailed some of his kind of vitamin life extension regimen, which he is on that train for sure. And he really does want to—and I can understand this—he wants to get to the next paradigm of life extension. And speaking of Father’s Day, I know he’s had a preoccupation with kind of reviving the image of his dad, who is deceased. He brings it up maybe once or twice in this book, and he definitely has elsewhere. But I feel like that really deep psychological thing that human beings have, and Ray Kurzweil in particular has, is kind of informing this techno-optimism. And, you know, I don’t know that Ray Kurzweil is looking at it from maybe just an average person’s perspective in terms of workers’ rights and environmental wellness and, you know, those sorts of things. He’s very much in his kind of ivory tower, it seems like, dreaming up these phases, kind of beyond the edge of reality. So he’s definitely an optimist. I want to be an optimist. Tom: I would love that. That sounds great. Mette: He certainly seems to be relegating all these threats to just, “Oh, details to be worked out.” Tom: Yeah, yeah, for sure. Go ahead. Liam: Yeah, just on—I totally agree with y’all. I was speaking to someone because I didn’t know who Ray Kurzweil was, and they were like, “Oh, you’re reading that book?” I was like, “Oh, is he actually a famous person?” When I was like 50 pages in, it was my perception, like, this guy’s kind of a wild writer. Like, some of these predictions are pretty nuts. Meta—and I might be pronouncing that wrong, so please… Mette: Meta. Liam: One thing that stood out to me on page 421, on the very last chapter before the 200-page appendix, which was nuts, Tom—I was very afraid you assigned a 600-page book—he says at the very end of 421, talking about being cautiously optimistic, he says at the very end, “We should thus focus work towards a world where the powers of AI are broadly distributed so that it reflects the values of humanity as a whole.” And I like that he compared that to when we had 64,000 active nuclear warheads, and now we have 9,000. How he practiced nuclear fallout drills, and then we didn’t have a nuclear fallout, and then how maybe as a world, or the way we use nukes, is actually more reflective of our values of peace than we actually think. I’m coming up with these ideas on the fly. But just how AI could, if broadly distributed instead of just kept in the hands of the few, if it’s put in the hands of the many, it will reflect the values of humanity as a whole, is something as a concept I can definitely get behind. Tom: Yeah, that’s a great debate that has opened up, right? Do you open source and broadly distribute this technology so that everybody has access and you get maybe more checks and balances? Or does it become a tool within the hands of the elite that they keep out of bad actors’ hands, or they try to? Nathan: I have a question or kind of a thought forming on that. “We should thus work toward a world where the powers of AI are broadly distributed so that its effects reflect the values of humanity as a whole.” I think that sounds great, and I would not argue for the techno-elite to only have AI. But if we think about another technology that is broadly distributed, so let’s just say the internet. Does that reflect the values of humanity as a whole? I don’t know. Tom: Good comparison. Mette: I’m sorry, could you repeat that? It’s a good comparison. Nathan: Yeah, and I mean, maybe it’s a glass-half-empty, glass-half-full kind of conversation, but I use the internet all the time. I love it, of course. But it does seem to reflect not values or virtues, but whatever the opposite of that is, you know, some really kind of negative traits of humanity. And in a lot of ways, it’s very corrosive to democracy; it’s very corrosive to mental health. Mette: Yes. And you know, that’s really, I would think even kind of beyond a debate. So, but he doesn’t bring that up. When he does all his comparisons, he really doesn’t bring up the internet, but it’s a really good one because it was all wonderful, especially in the beginning. And I’m old, so I remember the beginning. And you know, more recently, we’ve seen the corrosive effects of the internet, particularly on really young people, children who grew up with it, and, you know, cyberbullying, all this stuff that is having a pretty great effect on society. And that’s worrying and something that he doesn’t seem to be dealing with. That’s his “details.” Tom: I agree, that’s a great analogy. I mean, if you think about the truly transformative things that have been rolled out and unleashed, as you pointed out, the internet was believed to be a democratizing force that would lead to things like the Arab Spring and awareness and just greater collaboration and knowledge sharing, breaking down the walls between countries and cultures. And yeah, and now it’s like people are realizing that that was kind of a dream and the reality is much more corrosive and toxic and polarizing and radicalizing and fragmenting. Yeah, not what people had hoped. I think that’s totally right on. Nathan: I, just in trying to be critical of my own thoughts, I do recognize that this conversation is made possible by the internet, and I think it’s very awesome. It’s very cool. And so maybe if it’s a question of optimism or pessimism, the answer is “yes,” you know? It’s both of these things, right? We can have billionaires basically censoring huge chunks of the internet to fit their kind of personal narratives, right? And we can have an Arab Spring. And, you know, maybe… I don’t know. But if AI is, you know, if we can make an analogy between AI and a broadly distributed technology like the internet, there is an optimistic world and a pessimistic world, and they’re happening at the exact same time. Mette: Or the better angels of our nature and the more evil demons of our nature are all together. Tom: He does spend a lot of time trying to make the case that technology has pretty much improved our lives, even if we don’t recognize it at the time. Go back a hundred years, and you might be surprised at the level of poverty and disease and so on. But I wanted to make a comment about the growing divide because this is also something that I’ve been thinking about. Yes, a lot of these technologies are being broadly distributed for $20 a month—which maybe that’s prohibitive, maybe it’s not. People can get access to a lot of these tools and have an immense amount of knowledge in their pocket. But we’ve also seen a tier of tools that cost $200 a month where you can get a lot more power. And what if we just turned up the dial a little bit and said, “Okay, well, for $500 a month, now you’ve really got the AI that is game-changing.” Suddenly, you’ve got a group of people who have access to game-changing AI that they then use to maybe cut their workday in half and take another job or just do three times as much. For example, I would like to take and implement one of these AI agents on my API doc course to continuously update it and make it accurate and current in every way on a continual basis. And that becomes a little asset that I can also sell if people want to download the PDF and whatever. You know, like, what if AI enabled just the automation of little side businesses like that and larger ones? You get this growing divide between, yeah, people can access AI, but they get the cheap, crappy, free version. If you really want to have an impact, you’re going to have to have some money. I don’t know. Nathan: That’s a really interesting idea. I wonder, like, why wouldn’t that happen, you know what I mean? For any company who’s monetizing AI, why wouldn’t they do that? I mean, yeah, obviously the $200 a month version, that’s for content creators, for people who have monetized their YouTube channel. It’s pretty much what you describe. And then, yeah, why wouldn’t the more luxury brands of AI kind of come out of that? And then, yeah, what about, you know, $2,000 a month? It seems like that’s the road we’re on. Tom: I mean, if you paid $2,000 a month for an AI and it did something that gave you a return on the investment of $4,000, I mean, that would be pretty impressive. I don’t really know how that would play out, right? But you know, give it a couple of years and maybe we’ll figure out how. You could sketch this out. Like, I can think of one thing I want to do. I want to create a whole course on how to use AI for tech docs, something that I keep thinking I should do, but it’s a lot of time. It’s a lot of time outside of work that I don’t really have. So, but let’s say I figure… anyway, I’m sort of getting off track. But what capabilities will evolve? And this book also made me think that there’s probably going to be a growing divide between people who can use AI to expand and augment their capabilities versus people who have rejected it. I think you mentioned, Mette, that the message among some employees is that they have to start using AI to double their productivity or find a different company. And yeah, I can see that same sentiment expanding. It’s like, you want to have the tech writers and the other workers who have figured out how to augment their capabilities five times or more. And all the people who haven’t are going to be turning to other sorts of lines of work. This growing divide. Mette: Yes, yeah, yeah. Tom: Reading these last two books really makes me feel a sense of urgency to up my skills and knowledge about AI. And even though I am experimenting and using AI heavily and I’m leading initiatives at my work, like the education initiative for tech writers and AI and so on, I still feel like there’s just so much I don’t know and I still feel behind, you know? Mette: And every week it feels like there’s something new. Tom: Yeah, yeah, people are always sharing new tools. They’re like, “Check this out, Tom.” You know, I’m like, “Oh my gosh, I, you know, this new paper, this, that.” And yeah, that pace of acceleration is really rotating fast. The wheel is going faster. And maybe I have to figure out how to leverage the AI tools to keep up. Or maybe that’s just part of the new reality, is like, there’s new stuff every day, you will never absorb it. I don’t know. Nathan: I think that that’s true. And I honestly think that that’s been true for a long time. You know, I remember being a kid and going into the bookstore and then just really being blown away by how many books there are. There’s not enough time to read. It’s a thing I struggle with. And, like I said at the beginning, you know, how many book clubs I would love to join. There is always going to be more to know and more to learn. But it has been that way for a really long time. I mean, whenever the printing press came out, right? And now, just in this realm of AI, I mean, we could have GenAI write a book for us right now, you know? And there’s some kind of… the graph of that is… I mean, there’s just so much content now, you know, more than there are hours of human existence available to consume that content. So I just want to say, I think you’re doing a great job, Tom. Tom: Well, the scenario that you’re describing is what Kurzweil is trying to say is that next epoch where biology and machine merge, and you’ll be able to process every book in the bookstore, right? This is where when our brains basically take on these computer-like capabilities through nanobots that are rearranging molecules—who knows what’s happening—but then, yeah, his argument is that you will be able to consume a library in a day or an hour or whatever, and you’ll be super intelligent. What are your thoughts on that? I mean, this feels very science-fictiony because I don’t work in biology. I haven’t seen, I’ve never experienced Neuralink. I don’t really see how we’re going to have this merger between machine and biology. But what are your thoughts on that? Mette: That was the most optimistic part of the book. You know, we don’t know a lot about the human body. We know even less about the human brain specifically. And we’re already making these predictions. I don’t know, I just think there’s a lot of surprises out there. I kind of had the same reaction as you. For that kind of certainty that Kurzweil seems to have, I don’t know. Nathan: Yeah, I mean, they haven’t been able to tame the issues of fully automated driving yet. Mette: They don’t have an air traffic control system that is running on AI. They barely have one that’s working off computer software, really. Nathan: It’s a great point. Liam: I would say, I read an article or a post, like, “There will be two people in the coming age.” How much validity this has, who knows. “One will be the builders and one will be the learners,” like those who build the software and those who learn about it. And I think that’s one of the first things that drew me to this book club. Hey, I don’t think I was built to be a builder. I’m intellectually curious and I love to read. I’m clearly not a technical writer, however, I really enjoy the gift of learning. And so I think there will be a lot of good that will come out of just people that learn and don’t build, because you’re always going to have people that need to run the ship, and so they need to run the business or make the decisions. And Meta, I agree with you about the cars. I thought his examples about Waymo from Google DeepMind and their ability to simulate 20 million miles from their actual car driving were interesting. And I liked his point at the end of the book that talks about Neuralink. I don’t understand what the back-and-forth between him and Cassandra was in the very last chapter. I don’t know who Cassandra is. But he says, “Hey, what if regulatory policy prevents us from the Neuralink happening for our neocortex for 10 years?” And that kind of feels like what’s happened a little bit for Waymo, from the tiny bit that I know of it. It probably drives a lot safer than I drive. And if regulation opens up for just allowing that, we’d probably not have 40,000 deaths a year on the roads. But regulation is such a huge part of it as well. Tom: Interesting comments about the builder versus learner. That’s a point I was thinking about in other contexts. And I think that the promise of this massive merger of machine and biology and this ability to learn at such faster, accelerated scales means that you basically will be able to perform both roles. “Builder” won’t just be the super-detailed engineer-type roles. I mean, we’ve seen this now with “vibe coding,” where if you just can describe something, the application or whatever—Gemini, whatever you’re using—will try to build it. And it’s certainly interesting. I was vibe coding something—I’m not an engineer—and I was just like, I don’t even understand what this Go code is doing, but it seems to be working for a very small, little, tiny use case. I realize that if I had more engineering knowledge, I’d be a lot more dangerous. But yeah, this idea that whatever our role is—tech writer, salesperson, whatever role you have—the tools could easily allow us to expand beyond what these roles are. If you can consume a library in a day, I mean, then you could be a rocket scientist or a surgeon or whatever. You would have that knowledge that other roles have, perhaps. So I think maybe—I mean, this is the optimistic side—but in 2029, when AGI is here, maybe tech writers won’t exist, but you can do many other roles very capably. I don’t know. Liam: The concept of… please, go ahead. I’m going to say what I thought so I don’t forget it. Just the augmentation and what that brought, and the lack of learning. Like, we need to learn less for each role. Before, you needed someone who could build shoes as a cobbler, and now you just need someone to be able to run a conveyor belt and pull the shoes down. So just the concept of augmentation, Tom. But Nathan, pass it to you, please. Nathan: Oh, I was going to ask about AGI. So, you know, that’s a really important milestone on the Law of Accelerating Returns roadmap, as is the merging of biology with nanobots. I wondered about the AGI thing because I’ve heard it said by kind of contemporary or present-day technologists like Sam Altman, he says, “By one measure, we already have AGI.” And my understanding is that AGI just means that the AI can perform basically as well as a human in any number of tasks. Is there a hard test for that? Because I feel like we could probably say that with most human tasks right now. Or the point Sam Altman was making is that the goalposts kind of keep getting shifted for AGI. Because if we were to show ChatGPT in its current state to someone from five years ago, it would completely blow their mind, right? It blew my mind two years ago when I asked it to describe a technical procedure in the style of Edgar Allan Poe, and it did it like that. Wow. And now that seems a bit quaint. But yeah, in this conversation, is there any way to kind of refine my understanding of AGI? Would anybody push back on us having AGI right now? Tom: I think the nuances that you’re bringing up are right on target. And yeah, Kurzweil doesn’t really get into AGI and define it, and it’s a subject that is highly contentious and variable depending on who’s talking. Like you said, the goalpost keeps shifting, and how do you define it? I mean, right now you could ask an AI tool pretty much anything you want, and it’s probably going to be fairly smart and capable. But what I don’t see happening is, let’s say that the AI takes over the controls at my computer, and now I want it to figure out what it should work on, evaluate the bugs in my queue, figure out which ones it should prioritize, who it should contact, whether there’s enough information to be actionable. Like, there’s a ton of contextual information that it would need to absorb to do the task of a human in that sense. That makes sense. So anyway, I don’t know, does anybody have any other thoughts on AGI? Liam? Liam: I would say the Turing test—I think I first heard of the Turing test when I watched The Imitation Game with Benedict Cumberbatch a few years ago. And then the example of AlphaGo beating the world leader in Go, and then IBM Watson beating Jeopardy, but then Watson showing the three levels of its guesses. It’s like, its first guess was “the European Union,” like “What is the Parliament?” and then it guessed “women’s suffrage” and then “African safari.” And so what I found fascinating was Ray Kurzweil’s commenting on this—and this was kind of… it comes from the Ship of Theseus, the Greek philosophy of, as I remove one plank, when does it become a new ship? And so, AGI being—Watson thinks totally different. And if we make a brain out of brain matter or silicon, it doesn’t really matter if it has consciousness. That stuff I got a little bit lost in, just the philosophical part of it. But I would say the Turing test comes back to what you said, Tom, about setting AI up. When you were talking about Jules, like setting AI up to do something that has context and can prioritize and doing that in ways that are contextual to human interactions or to everyday tasks. The reason I don’t think it’s passed the Turing test is because AGI might—I mean, AGI has to be really general. It has to be able to talk about the Renaissance and then also empathize with a child who stubs their toe, or be able to discuss with a human something irrational but really important to their mind. Because the reason economics is not an exact science is because humans are irrational. And so I think there is a bunch of stuff that wouldn’t really make sense to a robot, that wouldn’t make sense, that could pass the Turing test. So while it might be super intelligent, human-level at building code or creating APIs, it might be really hard to create a therapist AI that helps with a teenage girl or boy that is struggling with bullying or social media issues and with self-image in middle school. And so AI’s ability to—and by the way, this confused me—AI’s ability to deceive a human that it is a human, I just don’t think it’s there yet for all the niche parameters. Tom: Yeah, and it seems like a lot of the AI tools are becoming more specialized. Like, you might have a medical AI and you might have a coding AI. We already have that with things like Codex and other things. And yeah, whereas AGI is supposed to operate across domains and be able to absorb this context. I don’t know how a tool can really pull in all the context that it would need to have awareness. Like, it would have to consume my whole bug queue, all my documentation, all my Gmail, understand who’s around me, where I am organizationally, and what the releases are coming up just to even operate in a documentation role, let alone, I don’t know, build rapport with colleagues and so on. Nathan: I feel like that piece, you know, I’ve heard it suggested by some journalists that AI can synthesize different news articles, but it can’t actually go out there in the world and start talking to people. And to your point about context, I mean, that’s kind of it, right? It’s going and just kind of finding out little bits of information about who knows what or who’s on vacation and who else you have to ask. You know, those kinds of details escape AI right now. But even if it was able to say, “Hey Tom, I need to find out X. Where do I go to find that?” That would, I guess, be a start. But yeah, right now it’s like an artificial general sophist or something like that, you know, almost pretending that it’s smart. Tom: Well, hey, before we wrap this up, I wanted to promote the next book just to put it on your radar. So this next book is— Nathan: Perfect. Wait, what, I missed that. Tom: Oh, the next book. I bought it because I was worried I wasn’t going to have enough time. Nathan: Oh, you held it up. Got it. Okay. Tom: Yeah, so we’ve got Supremacy: AI, ChatGPT, and the Race That Will Change the World by Parmy Olson. I thought this might be interesting because there does seem to be a tangible sense of the race toward AGI, to build it first. I mean, I’ve heard this in many different contexts where people really want to have their workers double down and move towards this. And I thought it might be interesting to see what this book is about. So I haven’t read it, but it does seem to get decent reviews. Nathan: It did get an Editor’s Pick, whatever that—I don’t know how that’s decided. Financial Times Business Book of the Year 2024. Tom: So it can’t be that bad with 739 reviews. Nathan: Was it decided by AI? Was it a pick by AI? Tom: I don’t know. We’ll find out. But usually when books have hundreds of reviews, they’re going to be substantial. And even this book that we read, despite its flaws, it was thought-provoking and interesting. And gosh, it gave me a lot to think about, and for that, I thought it was worthwhile. But thank you so much for coming to this. I appreciate it. This is kind of nice to have a smaller group today. You’re able to get to know each other a little more, and you all are very sharp and insightful. So I appreciate your comments and thoughts. Nathan: Yeah, thank you. It’s been great. Appreciate it. Liam: These are really fun. Suparna: Thanks, everyone. This is great. Tom: Thank you. Have a good rest of your weekend, and I’ll see you next month. All: Bye-bye. I'm an API technical writer based in the Seattle area. On this blog, I write about topics related to technical writing and communication — such as software documentation, API documentation, AI, information architecture, content strategy, writing processes, plain language, tech comm careers, and more. Check out my API documentation course if you're looking for more info about documenting APIs. Or see my posts on AI and AI course section for more on the latest in AI and tech comm. If you're a technical writer and want to keep on top of the latest trends in the tech comm, be sure to subscribe to email updates below. You can also learn more about me or contact me. Finally, note that the opinions I express on my blog are my own points of view, not that of my employer. Technical writing blog and API documentation course by Tom Johnson. © 2025 Tom Johnson
--------------------------------------------------

Title: John Larroquette's Night Court Thanks, The Daily LITG, 14th June 2025
URL: https://bleedingcool.com/tv/john-larroquettes-night-court-thanks-the-daily-litg-14th-june-2025/
Time Published: 2025-06-14T10:37:03Z
Full Content:
Posted in: TV | Tagged: newlitg, Night Court Night Court thanks from John Larroquette was the most-read story on Bleeding Cool yesterday. Lying In The Gutters is the daily runaround. Night Court thanks from John Larroquette was the most-read story on Bleeding Cool yesterday. Lying In The Gutters is the daily runaround for the most-read stories the day before, as well as over the past six years. Founded sixteen years ago and steeped in a history of comic book industry gossip for a further eighteen years before that, Bleeding Cool has become one of the longest-standing and most well-known pop culture websites around. The Daily Lying In The Gutters remains a long-running run around the day before and possibly the day ahead. You can sign up to receive it as an email here. And maybe you just have. The top ten traffic on all stories on Bleeding Cool yesterday LITG Image: Shutterstock.com To be fair, I would not have been surprised by hundreds of comic book stores having closed at this point. That four years ago, five had chosen to close is very sad, but it was good news that it was comparatively so few. We were reminded of when Rob Liefeld was predicting the imminent fall of DC Comics… There may not be much of a party atmosphere right now. It all depends on which state you are living in. But comic folk are still getting older and still celebrating that special date with twelve years for us as well. If you are in comics and have a birthday coming up – or you know someone who has – get in touch at richjohnston@bleedingcool.com. Interested in more LITG discussion about what this all means? Subscribe to our LitG Daily Mailing List. And we'll see you here tomorrow. Erik Per Sullivan, Erik Per Sullivan, Erik Per Sullivan, Erik Per Sullivan, Erik Per Sullivan, Erik Per Sullivan Enjoyed this? Please share on social media!
--------------------------------------------------

Title: The Tech Job Meltdown
URL: https://www.professoraxelrod.com/p/the-tech-job-meltdown
Time Published: 2025-06-14T02:22:54Z
Full Content:
He wrote me a prescription; he said “You are depressedI'm glad you came to see me to get this off your chestCome back and see me later, next patient pleaseSend in another victim of industrial disease”Industrial Disease, Dire Straits Since the start of 2023, more than half-a-million tech workers have been laid off. This isn’t the impact of COVID, this isn’t a sudden realization that tech workers are under-performing, this isn’t (much) a wave of AI making tech workers more efficient, and the other usual shibboleths like “it was overhiring during the pandemic” or “it’s a wave of H1B workers” or “all knowledge worker jobs are being replaced by LLMs” are only vaguely correct. You could make a pretty reasonable case that it was the end of Zero Interest Rate Policy (ZIRP) and the corresponding impact of cost of capital - that the cost of borrowing went up, thus venture capital became a less attractive investment class than other areas, so less money went to building new companies and it was harder for existing firms to borrow, as investors went elsewhere for better returns. That is correct - and it would have had its impact - though that impact would have basically been the slowdown of new venture backed firms, not layoffs at the Big Tech Giants - and that did in fact happen. (There is definitely a knock-on effect at the Big Tech Giants where a lack of tech startups does bad things to the large parts of the ecosystem - but that effect is not as immediate as it was back in in the 2000 dot com crash.) But there’s a much more immediate bottom line reason. Section 174 of the Internal Revenue Code governs the tax treatment of research and development (R&D) expenditures. For roughly 70 years, American companies could deduct 100% of “qualified research and development spending” in the year they incurred the costs, and this was generally interpreted pretty liberally. Salaries, software, contractor payments… if it contributed to creating or improving a product, it could be deducted “off the top” of a firm’s taxable income. The deduction was originally codified by Section 174 of the IRS Code of 1954, and under the provision, R&D flourished in the U.S. It gave us the dominance of Bell Labs, Microsoft, Apple, Google, Facebook - pretty much all the US technology booms you’ve lived through unless you’re quire venerable. So the way these regs are written: These expenditures must be for activities intended to discover information that eliminates uncertainty about the development or improvement of a product. (Kind of open-ended.) Prior to 2022, taxpayers could immediately deduct R&D expenditures in the year they were incurred, providing a significant tax benefit for businesses investing in innovation. Alternatively, taxpayers could capitalize these costs and amortize them over a period (e.g., at least 60 months) if they chose to defer the deduction. But it was pretty rare to do this, because you could directly manage your R&D payroll costs versus income to mitigate the tax hit. And societally, we accepted that - we were investing in growing the American economy. But, the Tax Cuts and Jobs Act (TCJA) of 2017 amended Section 174, effective for tax years beginning after December 31, 2021. Starting in 2022, R&D expenditures must be capitalized and amortized over 5 years for domestic research (and 15 years for foreign research… which is pretty untenable.) This change eliminated the option to immediately deduct R&D costs, increasing tax liability for companies with significant research budgets in the short term. Even more annoying, amortization begins at the midpoint of the taxable year in which the expenses are incurred, using a straight-line method. The short version is: this rule change has increased taxable income for businesses in the short term, as they can no longer deduct R&D costs immediately. Now, there is actually a category of tax law which you can still use (IRS Section 41 Research and Development Tax Credits) which are different - if you think I’m about to advocate tax reform, yes, but I’m always doing that and I feel like I’m talking to a brick wall. But it’s not as broadly useful, and it’s not a simple recategorization, or we’d all have done it. Anyway, let me see if I can summarize how it works today. A U.S. company incurs $1 million in domestic R&D (Section 174) expenses in 2025 and let’s assume they can’t reasonably reclassify any of it under Section 41. Under Section 174, it must capitalize these costs and amortize them over 5 years. Amortization begins mid-year, so in 2025, the company can deduct $100,000 (1/10th of $1 million, since you only get to count half the first year. The remaining $900,000 is deducted evenly over the next 4.5 years ($200,000 per year). These are basically “tax credits”. So in some respects, they may be long term beneficial - but they are a short term drag, which is why you see layoffs at the moment. Also they create a lot more compliance paperwork (and potentially you’ll see companies change hands just for their accumulated tax credits, which is a little… unhelpful.) And of course, this hit the “real world” of companies focused on building tomorrow’s products in some pretty obvious ways. The inability to immediately deduct R&D costs reduced cash flow, particularly for cash-strapped startups and small tech firms reliant on R&D. Companies had to either take out high-interest loans - since of course, interest rates have recently gone up, cut costs, or face bankruptcy. Many chose layoffs to free up cash to cover these tax liabilities. For instance, a small company might lay off a software engineer earning $200,000 to cover a $189,000 tax bill. Now, you might think the 15-year amortization period for foreign R&E expenditures would make hiring non-U.S. engineers less tax-advantageous and help bring jobs back to the US, but this mostly did not actually work out this way. You see, larger companies responded by offshoring R&D to countries with more favorable tax regimes, leading to U.S. job losses. For example, Google reportedly shifted some work to Germany, and Microsoft moved a bunch of research work to China - both because pay rates were better and because the local subsidiary company in that jurisdiction operated under the national laws for that nation, which … were not the US tax laws. They were much more like the previous US tax laws, because the rest of the world had realized “hey, we also want to encourage people to invest in R&D and grow the next trillion dollar company here!” And this new tax ruling doesn’t precisely say “we don’t want to do that” but it does say “we don’t want you to be quick about it” - which everyone who believes in the Amazing Growth Story thinks is anathema to their strategy. Anyway, the impact of this tax strategy turned out to be: layoffs of U.S.-based engineers while companies restructured operations abroad. Now back in 2017, when Congress passed the Tax Cuts and Jobs Act (TCJA), the signature legislative achievement of President Donald Trump’s first term, it slashed the corporate tax rate from 35% to 21%, which looked like a massive revenue loss “on paper” for the federal government. So in order to make the 2017 bill comply with Senate budget rules, lawmakers had to offset the cost… therefore, they put in a future tax hike (well, several) that wouldn’t kick in right away, wouldn’t provoke immediate backlash from businesses, and could, in theory, be quietly repealed later. The delayed change to Section 174, from immediate expensing of R&D to “mandatory amortization”, meaning that companies must spread the deduction out in smaller chunks over five or even 15-year periods… that’s one of them, as I’m sure you’ve figured out. The delayyed start meant that it would not begin affecting the budget until 2022, but it helped the TCJA appear “deficit neutral” over the 10-year window used for legislative “scoring”. The delay wasn’t legally required, mind you, it was a way to game the system. These kind of political tactics are commononplace in tax legislation. Phase-ins and or delayed-start provisions let lawmakers game how the Congressional Budget Office (CBO) - Congress’ nonpartisan analyst of how bills impact budgets and deficits - “grades” legislation, because it kicks the costs down the road, outside the “official” forecasting windows. Those of you who play table-top games or RPGs would call this a way to “cheese the system” or the traditional euphemism used to be something along the lines of “robbing Peter to pay Paul”. Many businesses expected Congress to repeal or delay the Section 174 changes before they took effect in 2022, as there definitely was bipartisan support for immediate expensing. However, inaction led to a “shock” when 2022 tax bills arrived in 2023, forcing rapid cost-cutting, including layoffs. Small software firms, in particular, faced “extinction-level” tax bills, with some reporting taxable income tripling overnight, prompting layoffs or salary cuts. And bigger firms - Amazon, Meta/Facebook, Alphabet/Google, etc, Microsoft, Salesforce, etc - have had widespread layoffs in the US and have moved jobs overseas. Twilio cut 22% of its domestic workforce in 2023. Shopify cut 30% (they’re based in Canada, but much of their R&D was in the US - guess what, it isn’t anymore). Coinbase cut 36% of their team and there are still a heck of a lot of crypto bros, so I think they are probably not in a doomsday situation. Now, I don’t want to say this was the only thing in 2023 that did this. There was a lot of economic turmoil on the horizon then: rising interest rates, reduced venture capital funding, supply chain problems, and post-pandemic over-hiring corrections, all amplifying financial pressures at the time. Companies like Meta announced layoffs during their “Year of Efficiency” in 2023, partly due to these tax changes and corresponding changes in ad spending. While not the sole cause, the Section 174 change drove (or accelerated) layoffs that otherwise would probably have been unnecessary. Congress has made noise previously about a bipartisan reversal of this tax code change, and I rather hope they do - it would be a welcome boost to many sectors of the American economy, from manufacturing to pharmaceutical to technology to education to electrnics to scientific research and consulting. Don’t think of this as just a problem for the tech space. I mean, the tech sector is ridiculously dominant for the S&P 500, the “Magnificent Seven” are a third of the value of the S&P 500. (That’s Alphabet, Amazon, Apple, Nvidia, Microsoft, Meta, and Tesla.) But if this does get repealed - it will be very good for those seven stocks - this is not an official stock tip, shush, you SEC guys. Throughout the 2010s, a broad swath of startups, direct-to-consumer brands, and internet-first firms… heck, basically every company that you would recognize from Instagram or Facebook ads… built their growth models around a kind of synthetic carefully engineered break-even. Lot of online firms, a lot of handheld or wearable tech firms, personal entertainment devices, ride-hailing firms, anything self-driving, all the recent buzzy things. The tax code allowed them to spend aggressively on product and engineering, then write it all off as R&D, keeping their taxable income close to zero by design. It worked because taxable income and actual cash flow were often not quite the same thing under what’s known as GAAP accounting practices. Basically, as long as spending counted as R&D, companies could report losses to investors while owing almost nothing to the IRS. In short, it costs a lot to invent - and market - the future. Building a better tomorrow can be expensive! Investors generally bought into this, gave them another round of venture capital, and let them defer a public offering. (This is actually another problem with this model - companies have stayed private far too long - but I’ll address that at some other point.) But the Section 174 tax change absolutely cratered that model. Once those same expenses had to be spread out, or amortized, over multiple years, suddenly you couldn’t write these off - basically, the tax shield vanished or the accounting rules changed, depending on how politely you want to phrase it. But the mechanics of it are the same: companies that were still burning cash suddenly looked profitable on paper, triggering real tax bills on imaginary gains. (If this reminds you of some of the past economic crises - it should - this is one of the things that burned people back in the dotcom crash of 2000 amongst other mark-to-market problems in 2008, though the 2008 crisis mostly wasn’t this.) The logic that once fueled a generation of digital-first research-focused growth ran straight into a IRS-shaped brick wall and put a mighty dent in the work force. If you were already public and profitable - well, your management team wasn’t going let you suddenly become unprofitable just because of a tax law change, so the answer was “cut expenses” and that mostly became “slow CapEx on data centers - servers are expensive - and lay off employees” so as to preserve profit margins and keep the stock price high. After all, reasoned management, if we had to put up with these crazy new rules, we basically just had to bank up R&D credits for a few years and then we were back to par. It was a couple of years of drag on the economy - and a particularly bad time to fall behind on technology leadership or a chance to reshore manufacturing or stabilize the American economy. One suspects that the current administration, if they had noticed that, might have kicked out a repeal or other clever plan as part of their new budget package (what’s currently being bundled together under the slightly goofy name of the Big Beautiful Bill) to juice economic recovery. So it wasn’t just tech experiencing effects. From 1954 until 2022, the U.S. tax code had encouraged businesses of all stripes to behave at least a little bit like we think of tech companies behaving, by which I mean “investing in R&D” and more generally “investing in software” for the latter half of that. From retail to logistics, healthcare to media, if firms built internal tools, customized a software stack, or invested in business intelligence and data-driven product development, they could expense those costs - and the IRS generally agreed, which is slightly miraculous. The write-off incentivized in-house builds and fast growth well outside what people generally call the “tech sector”. For comparison, check the OECD research showing that immediate deductions foster innovation more than spread-out ones. And American companies loved that logic and invested according to it. According to government data, U.S. businesses reported about $500 billion in R&D expenditures in 2019 alone, and almost half of that came from industries outside traditional tech. The Bureau of Economic Analysis estimates that this sector, the broader digital economy, accounts for another 10% of GDP. Probably 20% if you count Big Tech. And there’s a secondary market - all the people who support and are downstream from those workers and those industries (see below); we’re actually introducing relatively-avoidable friction into about a quarter of the American economy here with this particular tax change. The result? A tax policy aimed at raising short-term revenue basically defined the growth engine for a huge chunk of American companies. But when that rug got pulled out, it also yanked out the incentive for hiring American engineers or investing in American-made tech and digital products. It made building tech companies in America suddenly not economically viable, and the last time we did this with a stupid policy change (Fed policy tightening “to defeat the Wealth Effect” and cool down speculative fervor … yup, it sure did! Lots of wealth went away, was that a good idea?) caused the big Dot Com Crash in 2000. It would probably be a good idea to put this tax credit back in place (or some facsimile thereof) before it continues to strip jobs out of the American economy - let alone all the folks (realtors, contractors, restaurants, nannies, tutors, personal trainers, et al) that are one step downstream from the tech sector jobs. Thanks for reading! Subscribe for free to receive new posts and support my work. This entire tech-layoff wave is about more than AI or plummeting demand. It’s the delayed bomb Congress planted in Section 174 (a stealth tax that reclassified every developer’s salary as R&D amortized over years, not the quick write-off it used to be). People inside big firms are collateral damage in a tax strategy. The policy also shoved engineers’ families onto the payroll chopping block. Until lawmakers reverse course, U.S. tech is bleeding talent - nail in coffin for innovation here while other countries scoop up the scraps. This needs to be shouted from every rooftop. Everyone needs to write, call, and email their representatives and senators to address this issue. No posts Ready for more?
--------------------------------------------------

Title: Amazon Reorganizes Health Business to ‘Move Faster’
URL: http://www.pymnts.com/amazon/2025/amazon-reorganizes-health-business-to-move-faster/
Time Published: 2025-06-13T22:33:59Z
Full Content:
Amazon reportedly aims to boost its efforts in the healthcare field by simplifying the structure of its health business. Complete the form to unlock this article and enjoy unlimited free access to all PYMNTS content — no additional logins required. yesSubscribe to our daily newsletter, PYMNTS Today. By completing this form, you agree to receive marketing communications from PYMNTS and to the sharing of your information with our sponsor, if applicable, in accordance with our Privacy Policy and Terms and Conditions. Δ The company is reorganizing Amazon Health Services into six units, CNBC reported Friday (June 13), citing its interview with Neil Lindsay, senior vice president of Amazon Health Services. “Our leadership team has been focused on simplifying our structure to move faster and continue to innovate effectively,” Lindsay told CNBC. “One of the problems we’re trying to solve is the fragmented experience for patients and customers that’s common in healthcare.” Some of the new units will be headed by longtime Amazon leaders, while others will be led by executives from Amazon’s primary care chain, One Medical, according to the report. The changes do not include broad layoffs, the report said. The restructuring follows the departure of some health leaders in 2025, including the chief medical officer of Amazon Pharmacy, the CEO of One Medical and the chief medical officer of Amazon, per the report. Lindsay said that the departures were part of the natural evolution of the business and that the organization has “no shortage of depth of talent,” according to the report. The six new divisions of Amazon Health Services include One Medical Clinical Care Delivery; One Medical Clinical Operations and Performance; AHS Strategic Growth and Network Development; AHS Store, Tech and Marketing; AHS Compliance; and AHS Pharmacy Services, per the report. Both Amazon and its rival Walmart are competing for not only retail dollars but also other infrastructure of daily living, including healthcare, media and cloud services, PYMNTS reported in May. The company has been expanding its healthcare offerings such as virtual care and chronic condition management by forming strategic partnerships with companies like Teladoc and mental health providers, PYMNTS reported in January. By integrating these services into its larger ecosystem, Amazon seeks to redefine healthcare access and challenge Walmart’s established position in the industry. In November, Amazon added new health and beauty-related services to its healthcare offering by extending the Amazon One Medical Pay-per-visit telehealth service, which offers care on a range of different conditions and the option of on-demand messaging visits with clinicians. Amazon Reorganizes Health Business to ‘Move Faster’ Consumer Sentiment Rebounds but Remains Below Pre-Tariff Levels Payment Assist Adopts Groov’s Embedded Finance Offering in UK PairSoft Adds AI Agents to Accounts Payable Automation Solutions We’re always on the lookout for opportunities to partner with innovators and disruptors.
--------------------------------------------------

Title: Amazon reorganises healthcare business: Report
URL: https://economictimes.indiatimes.com/tech/technology/amazon-reorganises-healthcare-business-report/articleshow/121834826.cms
Time Published: 2025-06-13T17:19:44Z
Full Content:
5 Stories 7 Stories 9 Stories 9 Stories 8 Stories 6 Stories INR1,300 crore loans for INR100? Stamp duty notice to ArcelorMittal, banks. Why failed small businessmen die by suicide when those behind big blow-ups bounce back? Explainer: The RBI’s LAF corridor and its role in rate transmission Yet another battle over neem; this time it’s a startup vs. Procter & Gamble Everything ‘e’ won’t make you a millionaire. Just look at e-pharmacies Stock Radar: Breakout from falling trendline makes Glenmark an attractive buy; check target & stop loss Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Prime Articles Top Commodities Top Definitions Private Companies Top Story Listing Top Slideshow Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Worry not. You’re just a step away. It seems like you're already an ETPrime member with Login using your ET Prime credentials to enjoy all member benefits Log out of your current logged-in account and log in again using your ET Prime credentials to enjoy all member benefits. Offer Exclusively For You Save up to Rs. 700/- ON ET PRIME MEMBERSHIP Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get Flat 40% Off Then ₹ 1749 for 1 year Offer Exclusively For You ET Prime at ₹ 49 for 1 month Then ₹ 1749 for 1 year Special Offer Get flat 40% off on ETPrime What’s Included with ETPrime Membership Trump temper on H-1B visas is forcing Indians to do these things to stay put in US What Adani’s US indictment means for India Inc’s overseas fundraising Why veterans like Reliance, L&T are on acquisition spree? Aswath Damodaran has an answer. Will China’s dollar bond sale in Saudi Arabia trump the US in financial world? Huawei launches its own OS to compete with Google and Apple. But can it win beyond China? The problem with lab grown diamonds Why a falling rupee is a better option for the economy A list of top 20 momentum stocks that have delivered massive returns in one year Investment Ideas Grow your wealth with stock ideas & sectoral trends. Stock Reports Plus Buy low & sell high with access to Stock Score, Upside potential & more. BigBull Porfolio Get to know where the market bulls are investing to identify the right stocks. Stock Analyzer Check the score based on the company's fundamentals, solvency, growth, risk & ownership to decide the right stocks. Market Mood Analyze the market sentiments & identify the trend reversal for strategic decisions. Stock Talk Live at 9 AM Daily Ask your stock queries & get assured replies by ET appointed, SEBI registered experts. ePaper - Print View Read the PDF version of ET newspaper. Download & access it offline anytime. ePaper - Digital View Read your daily newspaper in Digital View & get it delivered to your inbox everyday. Wealth Edition Manage your money efficiently with this weekly money management guide. TOI ePaper Read the PDF version of TOI newspaper. Download & access it offline anytime. Deep Explainers Explore the In-depth explanation of complex topics for everyday life decisions. Health+ Stories Get fitter with daily health insights committed to your well-being. Personal Finance+ Stories Manage your wealth better with in-depth insights & updates on finance. New York Times Exclusives Stay globally informed with exclusive story from New York Times. TimesPrime Subscription Access 20+ premium subscriptions like Spotify, Youtube & more. Docubay Subscription Stream new documentaries from all across the world every day. Leadership | Entrepreneurship People | Culture Leadership | Entrepreneurship People | Culture Leadership | Entrepreneurship People | Culture Leadership | Entrepreneurship People | Culture Leadership | Entrepreneurship People | Culture Stories you might be interested in
--------------------------------------------------

Title: Amazon reorganizes health-care business in latest bid to crack multitrillion-dollar market
URL: https://www.cnbc.com/2025/06/13/amazon-reorganizes-its-health-care-business-after-executive-departures.html
Time Published: 2025-06-13T16:30:01Z
Description: Amazon is reorganizing its health-care business into six "pillars" to simplify its structure in a market where it's spent billions of dollars on acquisitions.
--------------------------------------------------

Title: Job search going nowhere? Try this.
URL: https://www.businessinsider.com/job-search-tips-flexibility-career-advancement-2025-6
Time Published: 2025-06-13T15:28:49Z
Full Content:
If you're trying to find a job, it's time to get scrappy. While the job market hasn't fallen off a cliff and layoffs remain low, stiffer competition for roles, surging use of artificial intelligence, and some employers' hesitation to hire are scrambling some job searches. That means some job seekers might have to pivot — potentially to an entirely new industry — or find other ways to stand out if they're set on a certain field. In some cases, you might have to adjust your goals. "Maybe put aside for the moment that dream to work for Amazon and Google, and maybe think about a different company that's more mid-cap," Angie Kamath, dean of the School of Professional Studies at New York University, told Business Insider. Kamath said the need to stay open to various options if you're looking for a role reflects the rapid change in many industries, especially as employers and employees alike try to understand what AI will mean for many aspects of work. "That's here to stay," she said, referring to the need for job seekers to understand how technology might remake jobs. To keep up, Kamath said, you should find ways to build your skills. That doesn't only mean getting a degree in a field, she said. Kamath said you might look to freebie or low-cost classes, for example, on AI from Amazon, Google, or online learning platforms like Udemy. "That's my No. 1 advice. Try something out. See if you like it. See if you hate it. See if you're energized by it," she said. If you don't want to shift to a different field or job type, you might simply have to work harder to stand out. Ryan McManus, a vice president at the recruitment firm Selby Jennings, told BI that some employers have become more selective in who they hire. "It might just be a bit more competitive in the sense that we're looking to check more boxes," he said, referring to finding candidates for the company's employer clients. For those who don't necessarily have every part of a job description nailed down, intangibles like being personable and a strong communicator can make a difference, McManus said. While finding ways to be flexible and try to stand out in a job search can help, it doesn't necessarily mean it will be easy to land a role. Some employers are slow-walking hiring, and some workers' confidence about business prospects is slipping. In the Glassdoor Employee Confidence Index released Tuesday, the share of employees who expect a positive six-month business outlook fell to 44.1% in May from 45.8% in April. The May reading was the lowest since 2016, when Glassdoor began collecting predictions from tens of thousands of US workers. To navigate an uncertain landscape, NYU's Kamath said job seekers might think of themselves as entrepreneurs who generate more than one idea for a business. "That's what we should do as we're looking for jobs. We should come up with a couple of versions of success, or what's interesting," she said. To know which option might be best, Kamath said it can help to ask friends what they think. She said that might mean having a conversation with a connection on LinkedIn who's in the line of work you're considering. Or it could involve visiting an employer that has public events or conferences. That manner of thinking, Kamath said, helps you avoid putting much pressure on yourself to land a certain role, and the thinking that "anything other than being successful in that one path equals failure." "It widens out what you might do and where you might do it," she said. Ultimately, Kamath said, job seekers often benefit when they step back and consider alternatives. "That's been very eye-opening for our students and our alumni to say there's more out there than the singular path to success," she said. June 13, 2025: The story was updated to refer to Selby Jennings as a recruitment firm. Do you have a story to share about your job hunt or interview process? Contact this reporter at tparadis@businessinsider.com. Where Big Tech secrets go public — unfiltered in your inbox weekly. Sign up chevron down icon An icon in the shape of an angle pointing down. Jump to
--------------------------------------------------

Title: Ticker: Data centers drive up power demand forecast; Jobless claims stick at 8-month high
URL: https://www.bostonherald.com/2025/06/12/ticker-data-centers-drive-up-power-demand-forecast-jobless-claims-stick-at-8-month-high/
Time Published: 2025-06-12T20:14:11Z
Full Content:
U.S. data centers are rapidly driving up demand for power, with the official forecast for electricity consumption next year almost doubling in the past month. Total power usage in the U.S. is expected to climb 2.15% in 2026, spurred largely by a 5% spike from commercial users because of the expansion of data centers, according to a U.S. Energy Department report released this week. That’s up sharply from a month ago, when the agency expected commercial demand to rise by 2% and total consumption to gain by 1.12%. Amazon said Monday that it will spend $20 billion on two data center complexes in Pennsylvania, including one it is building alongside a nuclear power plant. U.S. filings for jobless benefits were unchanged last week, remaining at the higher end of recent ranges as uncertainty over the impact of trade wars lingers. New applications for jobless benefits numbered 248,000 for the week ending June 7, the Labor Department said Thursday. Analysts had forecast 244,000 new applications. A week ago, there were 248,000 jobless claim applications, which was the most since early October and a sign that layoffs could be trending higher. “There are early warning signs in the labor market,” said Navy Federal Credit Union’s chief economist, Heather Long. “If layoffs worsen this summer, it will heighten fears of a recession and consumer spending pullback.” On Wednesday, Google confirmed that it had offered buyouts to a swath of its workforce in a fresh round of cost-cutting ahead of a court decision that could order a breakup of its internet empire. Other companies that have announced job cuts this year include Procter & Gamble, Workday, Dow, CNN, Starbucks, Southwest Airlines, Microsoft and Facebook parent company Meta.
--------------------------------------------------

Title: Carbon Capture Comes Crashing Down (Again): A Comedy in Subsidies
URL: https://wattsupwiththat.com/2025/06/11/carbon-capture-comes-crashing-down-again-a-comedy-in-subsidies/
Time Published: 2025-06-11T21:00:00Z
Full Content:
The world's most viewed site on global warming and climate change If you heard a distant wailing this week, don’t worry—it was just The New York Times realizing their beloved carbon capture techno-fantasy is, once again, face-planting in the real world. In a recent Climate Forward newsletter piece titled “Carbon Capture Comes Back Down to Earth”, Times writer David Gelles practically had to mop his keyboard with tears over the news that the carbon removal market—once projected to be a trillion-dollar juggernaut—is now wheezing toward irrelevance. Not that we mind. After all, here at Watts Up With That, we never bought into the carbon panic to begin with. CO2 isn’t a pollutant—it’s plant food. But watching the climate-industrial complex flop around trying to vacuum molecules out of the sky is pure entertainment. From “The Next Big Thing” to Layoff Bingo Just a few months ago, the hype machine was at full throttle. Bill Gates was investing. Google, Amazon, and Airbus were snapping up “carbon credits” like trendy NFTs. McKinsey—ever the oracle of bad ideas—declared carbon capture a $1.2 trillion market by 2050. One venture capitalist even called it “the single greatest opportunity I’ve seen in 20 years.” You almost have to admire the brazenness of the grift. Fast-forward to now: 24 government grants worth $3.7 billion have been scrapped, Climeworks axed 22% of its staff, and permit applications have tanked. The “market” is imploding because—brace yourself—no one wants to fund something that doesn’t work. Meanwhile, Climeworks’ headline-grabbing Iceland plant managed to remove only a sliver of its projected CO2. Naturally, the execs blame “ramp-up issues.” Of course they do. It’s never the technology’s fault—it’s always “early days” or “transitional challenges.” You’d think they were launching a moon mission, not running industrial shop vacs for the atmosphere. The Laws of Physics Want a Word Let’s be crystal clear: carbon capture is a thermodynamic clown show. Pulling CO2 from ambient air—where it exists at a wispy 0.04%—is like trying to find a particular grain of sand on a beach… using tweezers… while blindfolded. It takes more energy to remove CO2 from the air than was released burning the fossil fuel in the first place. And even then, you still have to compress it, transport it, inject it underground, and pray it doesn’t leak back out. This isn’t cutting-edge climate tech. It’s an energy-intensive Rube Goldberg machine designed to appease green investors, virtue-signaling corporations, and bureaucrats allergic to basic physics. Bonus: It Boosts Oil Production! Now here’s the kicker: the CO2 some of these companies do manage to capture is often used for enhanced oil recovery. That’s right—after spending billions to “fight climate change,” the carbon is injected into wells to squeeze out even more oil. And yes, Occidental Petroleum—the same company running a giant DAC project in Texas—openly touts this as a feature, not a bug. The Times, ever reverent, quotes CEO Vicki Hollub promising that the project will help achieve “energy security” and “produce vital resources and fuels.” Translation: we’re going to burn more hydrocarbons and call it green. The NYT’s Tiny Violin Section What really makes this article sing is the melodramatic tone. The author laments layoffs, canceled subsidies, and a “retrenchment” in the industry like it’s some noble cause under siege. And when the DOE finally did something rational—canceling $3.7 billion in vaporware grants—the Carbon Capture Coalition, which is about as unbiased as a pharma lobby, called it a “major step backward.” For whom? Rent-seeking climatepreneurs? Even Climeworks now admits they’re going into “consolidation mode” and focusing on “efficiency.” Translation: the gravy train is slowing, so it’s time to pretend we’re tightening belts while keeping the PR spigot open. Final Thoughts: Not Our Problem Let’s be honest: the entire carbon capture craze was never about saving the planet. It was about: The NYT can whimper all it wants about Trump pulling the plug, but the real villain here is reality. Physics doesn’t care about good intentions, ESG scores, or narrative arcs. It just keeps tallying the kilowatt-hours. So while The Times continues wringing its hands over CO2 removal dreams deferred, we’ll be here pointing, laughing, and perhaps warming ourselves with the comforting glow of all that wasted taxpayer cash being vaporized in yet another doomed climate gimmick. Coming Soon: Subscribe to get the latest posts sent to your email. Type your email… Subscribe Sequestering CO2 also sequesters Oxygen. Why would anyone want to do that? News to me. What do you think the O2 part of CO2 stands for? Be more curious, George Plant Trees and market them as Natural Carbon Capture Machines Please stop buying into their imaginary CO2 problem. There are lots of reasons why planting trees is a good idea, but capturing CO2 isn’t one of them. But it works. And gives us oxygen in return The oxygen is the important factor. Shade is nice. I like trees. Canada’s disgraced / dumped ex prime minister Justine Trudeau promised to plant 2 billion trees to save the planet. Turned out that all the spare land in Canada was already covered in trees, so nowhere left to plant another 2 billion of the buggers. That darn reality / rationality just keeps smacking ideology down. (Just as it always has) Somebody pointed out that some study said the permafrost line was moving northward 75 km per year causing CO2 and methane release…probable Climageddon. Someone else pointed out that they knew where the permafrost line was because the boreal forest was advancing northwards in unfrozen ground…someone else calculated how many trees must have sprouted to cover the area…Someone else calculated that Canada’s 300 billion trees only had to grow by 1.2 Kg of cellulose and lignin per year per tree to completely offset Canada’s entire anthropogenic CO2 emissions. Pretty soon the room went silent, and they changed the topic to how they could further greenwash getting more carbon taxes out of the oil and gas industry in Western Canada and rewarding their voter base in Ontario and Quebec for using electric heat pumps, and subsidizing electric cars. “Oh what a tangled web we weave When first we practice to deceive” Sounds like some of our democrats have migrated up north. We have plenty of our own greenie weenies, thank you. Our new PM (Carney) is going to sell “decarbonized oil” to Asia. Forests are carbon (dioxide) neutral of course (trees die/burn/rot) It is really hard to come up with a worse idea than downgrading perfectly good electricity into hydrogen through electrolysis, but DAC and CCS (as “climate” mitigation) take the prize. This article is far too kind to CCUS schemes and purposes. There is NO good feature, period. Engineered and built a few AGI systems (acid gas injection) …if you are producing sour natural gas, containing H2S and CO2, sequestering it underground is very good solution in most cases compared to the expense of building and operating a sulfur plant. The earth is geologically active. How do you prevent leaks? Long term. Despite the hype, there is no real evidence that CO2 has any meaursable effect on our global climate system. The AGW hypothesis has been falsified by science. Spending money trying to fight climate change is just a big waste of funds. Climeworks Very close to Slimeworks, home of the famous Slimeburger, the ubiquitous ever miltipling fast food chain in the Craig Shaw Gardner’s Neatherhell novels. I think they knew all along. Every time I see the name, I think Crimeworks. Ha! In the enviro case Crimeworks does. It lines there pockets I just saw an article that exposed the Obama EPA’s refusal to introduce their study on carbon capture and storage because it concluded that process was not a viable technology. The policies implemented required a proven process to mitigate the “pollution” they controlled. This could be a story tip if I could find the article. Dilbert Dude, Scott Adams loves the idea of carbon capture. He’s proud of his economics training. What a tard. Nobody’s perfect. Doesn’t sound like him, either. Story tip. Consider my comments on carbon capture from a Wall Street Journal article below: Subject: Occidental Petroleum’s CO2 Reduction Plan In the April 11, 2023 edition of the Wall Street Journal, an article by Benoit Morenne described a plan by Occidental Petroleum to extract massive amounts of CO2 out of the air. Occidental is spending more than $1 billion to build the first of a planned fleet of plants. The plant will remove 500,000 metric tons of CO2 from the air per year. Occidental intends to build up to 135 more of these plants by the year 2035. Occidental claims that its initial cost to remove a metric tonne of CO2 would be between $400 and $500. Using $400 a metric ton, the total cost by 2035 would be $2,400,000,000, excluding possible cost reductions due to efficiencies of scale, for removing 810,000,000 metric tons of CO2. Tax incentives will subsidize 45% of the initial costs, thanks to Bidens’ climate package that was signed into law last year. Consider how this plan will cut global CO2 levels from now to the year 2035. Assume that all 135 plants are on line and operating today. By 2035, these plants will have removed 810,000,000 metric tons of CO2. The atmosphere weighs 5,500,000,000,000,000 (5.5 quadrillion) metric tons. 810,000,000 metric tons of removed CO2 is 0.0000147% of the atmosphere. CO2 currently constitutes about 0.04 % of the atmosphere. Removing 0.0000147 % of CO2 would reduce atmospheric CO2 levels to 0.03999%, which when rounded to two decimal places yields 0.04%. Ergo, there will be no significant percentage reduction in CO2 levels. Occidental expects to generate between $400 and $630 in revenue per metric ton, which includes a $180 per metric ton tax credit. So, even without the tax credits, Occidental expects to earn between $220 and $450 a metric ton. It should be noted that cost estimates for untested new technologies tend to escalate. Occidental’s projections of costs and potential revenues may be a bit too rosy in my opinion. Time will tell. At 2.4 billion dollars, Occidental’s project may or may not be a technical or financial success. But the anticipated removal of 810,000,000 metric tons of CO2 by 2035 from the atmosphere will not measurably change the global percentage of atmospheric CO2. I don’t know what the current price is but in 2022 the water plant I worked at paid $140.60 a ton for Liquid CO2. Unless the price has skyrocketed, $400 to $630 a metric ton doesn’t sound like a bargain. (Our supplier got the CO2 from ethanol production.) How does one generate a revenue from such a system without government funding? “Pulling CO2 from ambient air—where it exists at a wispy 0.04%—is like trying to find a particular grain of sand on a beach… using tweezers… while blindfolded. It takes more energy to remove CO2 from the air than was released burning the fossil fuel in the first place.” Sounds thermodynamic. But as often, emphasis rather than quantitative. And wrong. The free energy difference between CO2 at 0.04% and 100% is RT*log(.0004)=8,3*290*log(.0004)=-18832 J/mol The heat of combustion of carbon is 393,500 J/mol. Are you talking about the heat of combustion of Carbon Dioxide molecules (CO2), or the heat of combustion of the Carbon (C) element here Nick? CO2 does not burn. It will burn with Fl2 or O3, won’t it? Yeah I get that – fire extinguishers. but why mention anything about Carbon when the subject is Carbon Dioxide? The claim was “It takes more energy to remove CO2 from the air than was released burning the fossil fuel in the first place.” OK, but the whole exercise was / is an idiotic pursuit in the first place, yes? And a flagrant waste of taxpayers’ dough. Nick, I think you win the battle but not the war. It does take less energy to sequester carbon than is produced by burning fossil fuels. But it takes so much energy, e.g., as a parasitical load in a coal-burning power plant, that sequestration becomes uneconomical. That is how I understood the article. Here in West Virginia AEP did a pilot CO2 sequestration project a decade or so ago and found it just won’t work. Actually, it did work. But the Virginia utility regulators refused to put their share of the costs into the rate base (AEP serves western Virginia). They also refused to pay the for the engineering study for the new 240 MW demonstration project (the pilot was 20 MW). So AEP shut down the project and wiped all of the pilot equipment off the site. What does the free energy difference have to do with extracting the molecules from the atmosphere? It’s the “basic physics” that this WUWT article says people are allergic to, but which WUWT doesn’t seem to have any idea about. So, instead of answering a legitimate question you chose to go with insults. Nick, Your argument will not convince anyone that plucking CO2 molecules from the atmosphere is a great idea. You might better spend your time planting trees. Meanwhile, I have some to cut** and dry for next year’s firewood. Just keeping up with their growth, dying, and decay is exhausting – – growth is relentless. **when I’m not planting little ones Just responding to “Let’s be crystal clear: carbon capture is a thermodynamic clown show.” It is Gelles who can’t get the thermodynamics right. Confusion there – it wasn’t Gelles (NYT), it was the WUWT writer. Your figures seem to assume that the removal process is 100% efficient. What is the actual energy consumption involved in the process? You are correct, Nick. 18.8 kJ/mol is much less than 393,500 J/mol. Billions have been invested wasted in technologies schemes to remove carbon dioxide from the sky in recent years. But Trump’s policies have clouded the outlook ended the farce. There, I fixed it. Very nice, more good news. If CO2 is removed from the air, CO2 will bubble out of all bodies of water, especially the cold polar oceans, to replace the captured CO2 molecules. What were the OXY chemical engineers thinking? Remove CO2 from the atmosphere, all other factors being equal, the oceans and earth will emit CO2 to replace it to maintain equilibrium of the partial pressure. Shoveling against the tide. Comedy is the wrong word. Tragedy is more appropriate. Direct Air Capture vs. a Leaf: Guess Which One Works Better This a loaded question. One works and one doesn’t. To my knowledge, no one has developed technology that has captured more carbon than was released in making the facility to capture the carbon. It is the same thing with wind turbines and solar panels. They do no more than shift the location where the carbon gets burnt. They do not reduce it. HOW? How could anybody be so stupid as to think such a scheme could work? How? Stupid? Maybe. Greedy? Definitely. Correction: “carbon is injected into wells to squeeze out even more oil” No. CO2 is injected. The Iceland plant did not extract even one gram of molecular carbon. It did manage a pissant amount of CO2. MIT researchers a while back came up with a very interesting process. Similar to photosynthesis, they passed are over a chemical element and in the presence of sunlight produced methane. I lost the link. Typo: they passed CO2 over a chemical element…. All of this nonsense is no different than Solyndra. It’s an unsophisticated money laundering operation where left wing politicians use taxpayer money to fund obviously non-viable projects coincidentally run by their friends. Eventually all the taxpayer money vanishes into the pockets of the politicians and their friends. There is no accountability or oversight, just a bunch of truly terrible people getting rich off the taxpayers. How much CO2 “needs” to be captured for “carbon capture” to work? What will be done with it? How much space will all that CO2 take up? Where will it be put? Some of this may have been addressed in posts I’ve missed, but they’re questions I’ve had for a while about this approach. Leaving aside whether it’s actually needed, it seems quite impractical to do at any scale that would make a difference globally. I lived in Iceland where the pictured scrubbers are. I find this very odd. They have geothermal heat everywhere. The Blue Lagoon is a tourist attraction driven by geothermal heat. If the scrubbers aren’t next to a volcano they are useless. I was lucky enough to visit Hekla when it erupted in the early 70’s. An awesome sight. There are lots of volcanoes that spew lots of CO2 in Iceland. Login Sign up to comment or become a paid supporter: Click Here “Walk toward the fire. Don’t worry about what they call you.” – Andrew Breitbart | read more “…the world’s most viewed climate website” – Fred Pearce The Climate Files: The Battle for the Truth about Global Warming “…invaluable” – Steven F. Hayward, The Weekly Standard “…changed the world and is one of the most influential resources on global warming. – Jonathon Moseley, American Thinker “…flashy (apparently widely distributed)”– Michael E. Mann RSS - Posts RSS - Comments Material on this website is copyright © 2006-2024, by Anthony Watts, and may not be stored or archived separately, rebroadcast, or republished without written permission. For permission, contact us. See the About>Contact menu under the header. All rights reserved worldwide. Some material from contributors may contain additional copyrights of their respective company or organization. You must be logged in to post a comment.
--------------------------------------------------

Title: Trump administration AI plans apparently leaked on GitHub
URL: https://www.techradar.com/pro/trump-administration-ai-plans-apparently-leaked-on-github
Time Published: 2025-06-11T12:27:00Z
Full Content:
AI.gov site was discovered by researchers When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. An apparently leaked GitHub page has revealed the Trump administration is working on a website called ai.gov, set to launch on July 4 with the aim of trying to, “accelerate government innovation with AI” The site was uncovered by 404Media researchers after an early version of the website was posted on GitHub by the General Services Administration (GSA), The Register reports. Now taken down, the page was aimed at serving as a hub for government agencies to enable AI integration into their processes. The GSA department responsible for the website looks to be the Technology Transformation Service (TTS). Headed up by Thomas Shedd, a close associate of Elon Musk, the TTS will seemingly launch the AI website with three key components; a chatbot, an “all-in-one” API that enables connections between existing systems and AI models from Anthropic, Google, or OpenAI, and ‘CONSOLE’ - a "groundbreaking tool to analyze agency-wide implementation," according to the page. The initial staging site suggests that the ai.gov site will serve AI models through Amazon Bedrock, and most of the models listed in the API documentation on the GitHub page are FedRAMP certified for government usage, the researchers confirmed. However, they note that one model identified and listed from AI firm Cohere is not FedRamp certified. Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! The fact the US government is planning to leverage AI or increase its connections with AI companies probably won’t come as much of a surprise to anyone - with the Trump administration pushing hard for widespread government adoption. Earlier in 2025 it was announced that the IRS could use AI to replace fired workers following mass layoffs at the hands of Elon Musk’s Department of Government Efficiency. Other departments like the SEC and VA are reportedly bracing for ‘restructuring’ as the department investigated whether AI can be used to replace human workers across a range of government departments. Ellen has been writing for almost four years, with a focus on post-COVID policy whilst studying for BA Politics and International Relations at the University of Cardiff, followed by an MA in Political Communication. Before joining TechRadar Pro as a Junior Writer, she worked for Future Publishing’s MVC content team, working with merchants and retailers to upload content. Please logout and then login again, you will then be prompted to enter your display name. TechRadar is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036.
--------------------------------------------------

Title: Customer-Obsessed Innovation
URL: https://hbr.org/podcast/2025/06/customer-obsessed-innovation
Time Published: 2025-06-11T12:02:00Z
Full Content:
A conversation with Lyft CEO David Risher on how listening can lead to breakthrough ideas. This month, we’re highlighting some of the best conversations from the 2025 HBR Leadership Summit held in April. In this episode, David Risher, CEO of Lyft, shares how he’s driving a turnaround at the rideshare company by anchoring everything in customer obsession. Since Risher took the wheel in 2023, Lyft reached record bookings and a 31% increase in annual revenue and its first full year of profitability. Risher shares how his own experience behind the wheel as a Lyft driver informs product innovation. And why listening deeply—whether to a single passenger or a room of drivers—can lead to breakthrough ideas. He also opens up about navigating layoffs, launching inclusive features, and preparing for an autonomous future while keeping human dignity front and center. Key episode topics include: customer experience, innovation, technology and analytics, listening skills, change management, employee engagement, competitive advantage, strategy • Learn more about the HBR Leadership Summit (April 2025) • Find more Harvard Business Review live events • Discover 100 years of Harvard Business Review articles, case studies, podcasts, and more at HBR.org ALISON BEARD: Welcome to HBR On Leadership, case studies and conversations with the world’s top business and management experts—hand-selected to help you unlock the best in those around you. I’m HBR executive editor Alison Beard filling in for Hannah Bates. This month, we’re highlighting some of the best conversations from the 2025 HBR Leadership Summit held in April. In today’s episode, we hear from David Risher, the CEO of Lyft. Since taking the wheel in 2023, figuratively and literally, Risher has led the company through a bold transformation—focusing on customer obsession, technological innovation, and a renewed commitment to drivers and riders alike. Lyft recently reached record bookings and a 31% increase in annual revenue and its first full year of profitability. In this conversation with me, Risher shares how his own experience behind the wheel as a Lyft driver informs product innovation. And why listening deeply—whether to a single passenger or a room of drivers—can lead to breakthrough ideas. He also opens up about navigating layoffs, launching inclusive features, and preparing for an autonomous future while keeping human dignity front and center. If you care about service, leadership, or what it takes to revive a brand in a hyper-competitive space, this episode is for you. Here it is. ALISON BEARD: I want to hear how Lyft evaluates and anticipates what customers want and need. Is it analytic surveys, focus groups, all of the above? DAVID RISHER: It’s kind of all of the above, but in maybe a different order. So I would actually say analytics are the least important, and I’m going to tell you why in a second. The most important, for sure, is lived experience. So we’re really lucky. Lyft gives two million rides a day, obviously a huge volume, 800 million rides a year. And every one of us– we have 3,000 people who work for us. Every one of us can be a rider or a driver. And I actually am a huge, huge believer in lived experiences, one of the best ways to– because then you’re literally putting yourself in the driver’s seat or in the passenger seat. You don’t even have to imagine it. We also do round tables pretty often with drivers in particular where we’ll bring groups of drivers together. I’ve done them in New York. I’ve done them in DC, in Boston, in Seattle, here in San Francisco because people’s interests vary a little bit in different parts of the country, so for sure. Social media is also really important. Of course, you have to filter things out a little bit, but there is a lot of wisdom out there if you can see through the noise and through some of the frustration and extreme stuff that you get. I get email every day and texts all the time from friends and from random people who find my email address online. And so it’s all that. And then analytics is– the reason I say it’s the least important is because it’s so tempting, I think, to sit at your desk and look at the numbers. And while you can use that to size opportunities and maybe prioritize, but you very rarely get the real insight that leads to the breakthrough just by looking at the analytics. ALISON BEARD: I know that you’ve done some Lyft-driving yourself, so is that standard process for all managers so you can better understand the situation on the ground? DAVID RISHER: Yeah, I’d like to say that it is. This sounds maybe a little braggy, but I think I’ve driven more than– I think this is true– than just about anyone else at the company. So we have 1.5 million drivers on the platform. They’re all independent contractors. But in terms of Lyft employees, I might be the first. I’m not sure. I drive about every six weeks, and I never tell people when I’m going to do it. I don’t tell the social media team or anything like that. I do post about it afterwards just with the pictures and experiences I’ve had, and you can see that on LinkedIn. But I take it really seriously, really seriously. And I listen very carefully. I ask, tell me why you chose Lyft today, and also very interested in other things going on in people’s lives. I’ve had these great conversations with people who, for example– I’ll give you an example. So I picked a woman– I live in San Francisco. I picked a woman up– this was last year– in Sausalito. And I said, why did you choose Lyft? And she said, well, look, every day I wake up in the morning at, like, 6 or 7 o’clock in the morning. And I said, why? And she said, well, to check the pricing because sometimes it’s $20. Sometimes it’s $30. Sometimes it’s $40. And it kind of drives me crazy because when it’s $40, that’s too expensive for me, but when it’s $20, I’ll take it. $30, maybe I’ll check the competition. But today is a colleague’s birthday, and so I really wanted to be there. So I was so glad that it was inexpensive. So just that conversation really got me understanding how frustrating what’s called surge pricing is to people. And I can tell you all about this, but we have a feature called Price Lock that really tries to get rid of it. And it was really developed or it was catalyzed because of that conversation I had with her. ALISON BEARD: So when you get these new ideas for features or services, how do you make a decision about which will be worthwhile and value-creating to pursue? And then how quickly can you move to execution? DAVID RISHER: So two very different questions. The answer to the second is it’s never quickly enough, so this is a source of constant– it turns out, as a CEO, you can have all sorts of ideas about how fast things can go, and then just brutal reality gets in your way. I’ll come back to that in a second. The prioritization is– so we have a pretty rigorous process because, again, of course, there are always more ideas than you can possibly do. And so broadly, broadly speaking, we’re always– OK, Lyft’s business model, very simply, is the more people we have taking rides, the better we do. It’s kind of that simple. If our fixed costs are more or less fixed, which they are, then the incremental contribution of every ride– it might be $1, or it might be $2, might be $3, whatever it is– is a certain number. And the more of those we can drive across the platform, the more money we make. We’re now profitable, as you said in your introduction. We spun off about $760 million in cash over the last 12 months. That was up from negative $300 million the year before. So once you really understand the basics of the business model, everything else is just execution. And so that helps you understand then how you evaluate new ideas is, can it– is the product market fit– is the potential for product market fit so good that it could potentially drive hundreds of thousands or millions of more rides on the platform? Now, the economics of them might be different. So for example, with Price Lock, it’s actually a subscription product. You pay $2.99 a month, and then you lock in a price, a cheap price so it doesn’t bounce around. And then we have to do a lot of math to try to figure out whether we can make money on that or not. So you then have to figure out whether you can do it profitably. But the first question is, is it compelling? Is it interesting? Can it touch either, I’ll say– let’s call it millions of people. Or is it something that maybe a smaller group of people care about, but they care about it so much that the impact is outsized? And I think those are two different cases, but they both come up. And I’ll give you just very quickly an example of the latter. This actually came out of another– I mentioned this idea of driver roundtables. We were talking to about 12 different people. This is in New York City. And we were talking about things that they like about the platform and things they don’t, and one of the women said almost offhand– she said, you know, I have a tough time taking breaks to go to the bathroom. And I said, why? And she said, well, some bathrooms– they feel unsafe, or they’re dirty, or whatever. And then she said, the thing that struck with me– that stuck with me the most. She said, and I can’t just pull out a bottle and pee in it. It’s like, OK, that’s a good point. And so we developed as a result of that and some other things we’re doing something called a restroom finder now that allows drivers to indicate where there are safe restrooms and easy-to-access restrooms and maybe what the restroom code is. So anyway, so it might only affect a– it affects all drivers at some point, but it probably only affects a small number of drivers in a deep way. But for those drivers, it’s really important. ALISON BEARD: I love that example because it illustrates how you have customers that are riders, but then your drivers are also your customers. So you have to be equally obsessed with their experience. DAVID RISHER: That’s right. ALISON BEARD: So talk about that execution piece. And sorry for jamming two questions together, but when you decide that that’s a great thing to implement, the restroom finder, how do you ensure that your teams can get it out there quickly enough that it makes an impact? DAVID RISHER: Yeah, so it’s such a– it’s a simple question, and there are multitudes within it because of course you have an annual plan that you’ve done. You have certain themes you really want to work through over the course of the year. So as an example, one of the themes we’ve been working on for quite a long time is, how can we increase driver earnings? How can we increase driver earnings? As you say, there are two customers in every car. The rider has a certain price that they’re willing to pay. The driver has a certain price that they’re willing to accept. And we have to figure out how to make those lines cross millions of times every single day. Drivers get very frustrated if they feel that they’re not getting rides that meet a certain threshold for them. In some cases, there’s work we can do at the user interface level to help a driver see how much they’re going to make. This is something we’ve done a lot of work on to make it very clear every time they accept a ride how much money they can expect to make on that on a per-hour basis so it’s easy for them to compare. But we’ve also put in minimum standards. So we used to have no minimum. Now we have a 70% earnings guarantee. That means that at the end of every week a rider will always get– excuse me, a driver will always get at least 70% of what riders pay after insurance and some other fees are taken out. And that’s been a game-changer, very expensive– it costs us millions of dollars to do– very technically complex. And so it took us months and months of work to do. This was last year. But because it fit in a thematic piece that we’d already put out for ourselves over the year, how can we increase driver earnings, we had space for it. So it was a lot of work, but it was kind of straightforward. The trickier ones are ideas that come along the way that you hadn’t necessarily anticipated, or you realize, we’re kind of missing the boat here, or whatever it is. And then, frankly, it’s a lot of my job as CEO– you think of it as an allocation question. Like, how do I reallocate resources periodically in a way that focuses on a combination of what we thought was important at the beginning of the year and what we think is important now without being so disruptive? I know that’s of a generic answer, but it’s the way it goes. ALISON BEARD: No, I think that’s useful. So I’m on the same note, when you discover that there are problems, how do you fix them? I hear you have something called Falcon Mode. DAVID RISHER: I do. [CHUCKLES] I do. I do. Yeah, I do. So Falcon Mode refers to the idea that– so Falcons are unbelievable animals. And I’m not a falconer, by the way. I don’t know that much about them. But what I do know is that they can fly at very, very high altitude for a very long period of time. But then they get hungry, and so they’ve got to dive. And they got to dive 2,000 feet or whatever it is and then pick a fish out of the ocean or whatever it is they actually eat. As I say, I’m not really a falconer. So as a metaphor, I use it sometimes to help people understand, there are going to be times where even I at the level that I operate need to go deep, and I need to go deep fast. I need to understand some problem at some level of detail so that I’m assured myself that I’m making good calls on whether or not to put energy over here or energy over here or what have you. Now, the problem, of course, is that generally people who work for you don’t like this very much. [CHUCKLES] And there’s this word, “micromanagement,” that comes up from time to time. I don’t think I’m that person, but maybe some people have a different opinion. But my point is I’m not trying to solve necessarily the problem. That’s generally not my job. But I do believe that sometimes you have to go very deep to understand the problem and to hang out in that problem space for a while and really get it. So let’s go back to driver earnings for a second. It’s very easy to detect that drivers want to be paid more like anyone who’s doing a job. That’s not complicated. The question becomes then, how do you do it in an economic way? But I think what becomes more interesting is, well, hold on. What else are drivers telling us about their goals and their life besides the obvious, besides the loud thing, which is earnings? And one of the things that we know is that– so the vast majority of people who drive on the Lyft platform do it part time. They’ll do it 20 hours a week or less. Often it’s supplemental income. Sometimes it’s a bridge. They’ve just lost their job, and they need to earn quick money, whatever it is. But it’s always– most of the time– let’s call this 85% of the time– it’s part of a bigger plan. Call it 15% of the time a person might want to be a professional driver. 85% it’s a bigger plan. So how can we support them? How can we– how can we support them in a way that’s going to be economically good for us? So we put together this thing called the driver accomplishment letter, which allows the driver to push a button and get a readout of their accomplishments, an AI-generated readout so they can use that, for example, as a reference letter for another service-oriented job. That’s an example– sorry for going on at some length with this, but that’s an example of moving beyond the transactional and the obvious stuff and trying to understand deeply enough, what do drivers really care about? Not just making more money but setting themselves up for maybe longer-term financial success in a way that if you don’t do those social media readings or focus-groupy-type things– you might not get to. But once you get there, you realize, oh, yeah, this really matters too. ALISON BEARD: Yeah. So in your recent shareholder letter, you recently wrote about a different kind of problem. You have a term for it that I’ll let you share yourself. But it’s basically the slow degradation of a product, of a service that happens over such a long period of time that you’re not really aware of it, until the problem is so bad that it’s more difficult to fix. So how do you protect against that? DAVID RISHER: Yeah, so I think you’re referring to enshittification. I appreciate your– [CHUCKLES] I understand. I wrote this letter myself, but of course I have other people who look at it. And I got a lot of– some pushback on the term. But I said, look, this is it’s first of all, it’s not mine. It’s Cory Doctorow’s term. You might know him. He’s an author and a thinker. And one of the things that he recognized some period of time ago is that ideas and businesses, let’s say– they start often with a high-quality, high-bar mode but then over time tend to get worse. And you can see this even within rideshare. Rideshare, for those of you who’ve been paying attention for, let’s say, the last decade– you might remember when you first got in the car it was kind of a magical experience. The driver treated you super well, and maybe it was a very nice car. And it kind of felt amazing. I push a button, and three minutes later, someone pulls up. They take me where I want to go. I don’t have to pay at the end. It seems like magic, all this stuff. Well, rideshare, like many other things– but I’ll use the industry I know the best. I would say, looking at it objectively, it’s gotten worse over time, not better. And we’re in the service industry. That’s crazy. So one of the, let’s say, responsibilities I feel, as a leader in this industry, is to push against that and to say, let’s not just let that be the way. Let’s not let quarterly earnings or what I call additive bias– again, not my term. But there’s always a general mode of, just add more and more stuff to a thing, and make it better, which sometimes is exactly the wrong thing to do. Anyway, let’s actively fight against some of this. And again– I should zoom out– my basic premise in the last two years has been– customer obsession is what’s going to drive profitable growth. Customer obsession will drive profitable growth. And it’s worked right. We used to be not profitable. Now we’re profitable, full stop. And we used to be not growing so much, and now we’re growing a lot. So anyway, so I think all the questions you’re asking get at the same fundamental premise, which is, can you really be a customer-obsessed organization and grow as a result profitably? And we’re trying to demonstrate the answer is yes. ALISON BEARD: So on that note, Shazab is asking, how do you ensure that your 1.5 million driver contractors, who are gig workers– they’re not employed by Lyft– live and embrace your customer experience obsession? DAVID RISHER: Ah, this is a very cool question. This is a very cool question. And I’m going to answer the question, but I’m going to give you– I’m going to tell you you’re in good company for asking this question. So first of all, let me say this– service, of course, doesn’t just mean, what happens when you’re in the car. It means, for example, after I open up the app, what’s the estimate I’m going to get? How fast am I going to get picked up? Let’s start with that. So right now we pick you up about a minute faster, on average, than we did a year ago. That’s about 40 faster than our biggest competitor, which is actually quite an accomplishment. So before I get to the answer, I will just note that “service” means a whole lot of different things. It can mean, for example, does your driver cancel on you, which is quite irritating? And you might– interestingly enough, it’s actually hard to detect in the data how irritating it is because people tend to get rematched, and a car eventually picks them up. But people find it very frustrating. They don’t like the idea of– and you’ve probably seen this yourself. It says, oh, we’re finding a new ride. It’s not a great experience. So anyway, that service experience starts from the second you pick up the app. But now to the center of your question, now you get in the car. The car pulls up, and you get in the car. And I find this a very, very interesting question of how can– we do all kinds of things today. Let’s just start with level set. So we have what’s called a driver education center, a coaching center. I’m a driver myself, as I said. I just got a prompt yesterday to go in and review some videos and stuff. In a week– actually, we haven’t said this publicly yet, but I’ll say it now because why not– we’re actually starting a new driver podcast, which I think will be very cool because drivers, of course, spend time in the car. And it’s actually not– it’s produced by Lyft, but it’s actually drivers talking to– its two drivers, a man and a woman, talking to each other about how to deliver great service and how that connects to great tips. So that’s cool. And then we also have various incentive programs and bonuses and so forth and so on if you do certain things and don’t do certain things. So there’s a whole, as you can imagine, machine behind it. But I still think the question is even more interesting because– and I’ve asked this very same question. I happen to have had the very lucky experience of getting to talk to Thomas Keller a couple months ago, who runs The French Laundry and then just completely coincidentally to Eric Ripert, who runs Le Bernardin in New York, so two three-star Michelin restaurants. And I asked both of them exactly the question you’re asking me. I said, how can we, as a company, coach, cajole, encourage, whatever it is but create a service culture, a service ethic among the 1.5 million drivers that drive on our platform that’s at the same level, same consistency, maybe not five-star, three-star level but a consistent level, that you do in your restaurants? And both of them– it was so interesting. You know the difference in a question you ask, and the person is– they give you a rote answer and like, whatever. But this was the opposite. In both cases, they leaned into this and spent another five or 10 minutes saying, that’s a mind-blowing, mind-blowing idea. Like, how can you get at that level the type of service that we get? So that was a very, very long way of not answering a question. I don’t actually know yet. I can tell you some of the things we’re working on, and some of them I’ve already mentioned. But I think it’s one of the things that’s going to, I hope, set us apart and make us an industry leader in this group, in this area. ALISON BEARD: I’m sure that driver experience, customer experience is going to play a big role in your answer to the next question. But it is a really good one, and it’s certainly one on everyone’s mind. Two people are asking it. Jordan asks, how does Lyft differentiate itself from its biggest competitor to encourage consumers to switch? And an anonymous viewer asks, how did you position your company to compete so well against a robust, name-recognized competitor? And kudos to our very polite audience for not mentioning the name of the competitor. But that’s the question for you. How are you battling this dominant force in your industry? DAVID RISHER: Sure. So again, it is a good question, and it’s quite hard. It’s quite hard, particularly when some of our drivers drive on both platforms. The car is the same. So it’s quite an interesting problem. I’ll go back to the same thesis. So you mentioned also that I was on the board of Lyft for a couple of years before joining the CEO. And it’s quite interesting and, of course, a separate issue of the perception you have of as a company– of a company as a board member versus inside. I will say, as a board member, I believed the company was customer-obsessed, and I was asked to be on the board to push that idea at the board level because boards often think about finance and strategy, not so much customers. But I came to believe over the course of the two years I was on the board before joining as CEO that customers– and then when I joined the company as CEO, I realized, no. Not that we were not but that, gosh, we were a bunch of different things. We were many– we were trying to do too many things all at the same time and maybe not– not maybe not. I’m sorry– definitively not really obsessing over our customers. We were pricing too high. We were paying too little. Our reliability wasn’t so great, on and on and on. And so the answer to your question– again, it comes to the same. Our purpose is to serve and connect. Let me start with those two words, “serve” and “connect.” And I want to serve riders and drivers better than they’ve ever been served before, and I want to connect them with the people and places they love. That’s big, big picture, what I want to do. And that’s what we’re doing. So I’ll give you some evidence that we’re beginning to make some inroads against those other guys. When I joined– let’s look at two statistics. When I joined, our share was about a 26, maybe 27, now, most recent, about a 30, 31. That might not seem like a big change, but it’s a big change. In Canada, we’ve gone from being irrelevant to having our ride volume double and double again. That’s been 100% a street fight against the other guys because we weren’t really there, and then we entered seriously about a year ago. And now we’ve been– And again, so some of it comes from differentiated service, things like Price Lock, Women+ Connect, a product I started, actually, on the first day I was here that lets women drivers and riders choose each other, a product that’s coming out next week. I’ll give you an early preview. It’s called Lyft Silver, which allows old people to have a simplified version of the app, and you can invite them to be part of the app and even pay for their ride if you’re maybe a son or daughter, caregiver. So some of it’s product differentiation. Some of it’s partnerships. We have partnerships with a company called Bilt, for example, or a company called, well, Chase Sapphire Reserve. Many people probably have their credit card or– in the audience. So some of it’s that. We have these sorts of partnerships that give us exclusive or preferential access to certain customer sets in return for certain things. Some of it’s brand, an area, actually, we haven’t actually invested that much in recently, but you’ll see more of that later this year and next year. So again, maybe a little bit of an “all of the above” thing, but the through line through all this is we want to level up the service that you get by far, by far and really redefine it. And here’s where I’ll end. On the driver’s side– and this is probably the area where we’ve made the most progress– because of things like earnings guarantee, because of– and this earnings commitment and a set of tools around that and various other things we’ve done, we now have a 20-point advantage, 20-point advantage over the other guys when drivers are asked the question, which company would you prefer to drive from, 20 points. So step by step by step, by treating them well, by obsessing over drivers and riders, that’s how we’re getting there. ALISON BEARD: So you’ve been a change agent in the company. When you took over as CEO, you wanted to execute a turnaround that included layoffs at the start. How did you make the very difficult decisions in that scenario and then communicate them to the workforce? DAVID RISHER: Yeah, so it was very difficult but in a weird way kind of straightforward. And this is what I mean. So my first day was April 17, 2023, and I had actually been coming in for the prior– call it two months, on Thursdays and Fridays. So that my first full-time day. And within the first, say, six weeks, we had announced a couple of very significant things. The first, as you mentioned, was quite a significant layoff. It was 26% of the workforce. Now, that’s devastating. That’s devastating. But– or and, I guess I should say– the framing that I gave was, this is the only way, only way that I know how to pay for the things that we are going to do for our customers, for our riders and drivers, which is to say, lower prices to be competitive and raise pay to be competitive. And I was– and of course it was devastating, of course, for the company and particularly because the company had gone through layoffs in the past. But I will say– and I don’t think this is just people telling me what they thought I wanted to hear– even some people who left the company, who were asked to leave the company or told to leave the company, said, I hate it, but I get it. But I get it. If we want this company to survive, you got to make these types of choices, and it’s the type of choice that maybe we needed to have made in the past that we didn’t make with such clarity of purpose, which was so that we could provide better service to riders and drivers. The second thing, just to walk down that path for a couple more steps, I said is– and remember, you have to put yourself back in 2023. We’re all coming back to work three days a week. Now, this was an interesting decision because at the time it was not obvious that that was maybe the right thing to do. And in fact, the company had in the past said, we’re going to be remote first, as many companies did. Now, obviously, a lot of companies since have also done the same. But I bring this up because I thought of it as a very important cultural moment for us as well, to say, if our purpose is to serve and connect and we’re about getting people out of the house and dealing– all these sorts of things, we can’t just do it remotely, and we’re not going to come up with our best ideas. And we’re not going to– it’s very hard for that– again, you can look at the data screens. But to get that real feel of what drivers and riders really will respond to without the whiteboard sessions and all the rest, so that was a very important second thing. And then the third thing that we announced– it was all right in these first couple of weeks– was a new product called Women+ Connect. This– I mentioned this before briefly– allows women riders and drivers to choose each other. And this was something I actually started on the first day. It was actually 10 o’clock in the morning the first day I was here. And the reason I thought it was so important is because it was an idea that had been kind of floating around for a while, and people had always come up with a way to say no to it. Ah, it’s complicated, or there’s legal issues, or this or that, all sorts of things. And I’m like, yeah, but on the other hand, 25%– excuse me, 50% of our riders are women, roughly, and 25% of our drivers are women. And they’re telling us guys, when we listen, that they’re not always comfortable, particularly late at night or particularly in a new city. They’re not always comfortable. So what are we doing here? So anyway, we pushed through some of those objections and talked about the risks and characterized them in certain ways and did the technical work. And I think it was six months later, in August, they came out with a– came out with the product. And it’s been very popular. It’s actually one of our most popular products, particularly for drivers. Once they turn it on, they never turn it off I go into detail on this because I wanted to say from the beginning, it’s not just about cost-cutting. It’s cost-cutting for a reason– we can do better for riders and drivers as a result. And we’re going to grow too. We’re going to innovate. We’re not going to let this stall us, and we’re going to do it together. ALISON BEARD: That’s good advice for anyone who’s trying to lead a change effort in any-size organization or team. So Martin asked, would you consider onboarding autonomous drivers, i.e., cars without driver, and Wendy asks, how does Lyft view the Waymo disruption, continuing to innovate toward that future trend, while balancing your current business model and offering and assuring support to your current drivers? [00:28:23.75] DAVID RISHER: Yeah, so great questions. So the answer to the first is yes, we will absolutely welcome autonomous vehicles onto our platform. In fact, we’ve already announced an agreement with a company called– with a company called May Mobility that operates or will operate in Atlanta later this year, actually this summer. They operate Toyota Siennas in self-driving mode. And we’ve announced an agreement with Mobileye, which is a technology company that produces autonomous technology that will be installed in a to-be-named OEM, to-be-named car that will also be on our platform. And I think, if I zoom out for just one click, autonomous vehicles, self-driving vehicles are absolutely going to happen. In some places, it’ll happen fast. Here in San Francisco, they’re happening quite quickly. In other places, it’ll be slower. But it’s going to happen. So then the question is, well, how do you really embrace it? How do you bring them onto your platform in a way that hopefully expands the market, which– we’ve actually seen some evidence of that, which is great– is respectful and acknowledges the fact that you’ve got millions of people driving on the platform too? So how do you work with them through this transition period? And then how do you make sure that you’re not accidentally being disrupted out of business? Waymo is a very interesting company. Perhaps at some point they’ll be a partner of ours. Right now you might see them as a competitor, a small-scale competitor. But still, they’re doing stuff that competes directly with us in some of our markets. So it’s no exaggeration to say it’s probably the thing that I’m thinking about the most and our board is the most engaged with, but I’m quite optimistic that under 99 scenarios out of 100 it turns out to be actually quite accretive for the industry because it gets– remember, people take 160 billion rides a year in their own private cars. Rideshare is only three billion between us and the other guys. So there’s so much opportunity for other people driving you and that experience being part of people’s lives that I tend to be much more focused on how to take advantage of that market share expansion than I am about fighting a particular battle with a particular competitor or something like that. ALISON BEARD: OK. This is another anonymous viewer asking. He’s clearly done his research. He says, from your wiki page, an impressive career advancement, Microsoft, Amazon, and now Lyft. It’s clear that your bosses have loved you. What characteristics do you think set you apart from others? DAVID RISHER: Wow. That’s like a– it’s like an Oprah Winfrey-style question. ALISON BEARD: I know. I love it when they get personal. I do love it when they get personal. DAVID RISHER: Honestly, it’s maybe easier for me to turn the question around just a little bit and say what I learned at those places. What I learned from working at Microsoft– and I didn’t work directly for Bill Gates, of course, but I did have enough interaction with him to get a sense of who he was and what his values and focus was. He was a very competitive person, and so I learned how to compete hard. I really did. And that was very important learning. And then I also learned a lot about taking technology, from a guy named Todd Nelson, actually, my boss for a long time at Microsoft, taking technology which can feel a little obscure, particularly back in the ’90s, and making it personal and trying to understand it at a personal level, not just at a technology level. I think I did work directly for Jeff Bezos for quite a long time at Amazon, and customer obsession really did come from him. He understood early on the internet everyone’s a click away from everyone else, and so if you don’t– there’s no such thing as an undifferentiated competition. You have to differentiate in order to compete. Otherwise, people go to something else that’s better, so anyway, that real focus on customer obsession. And then I ran Worldreader for a long time, the nonprofit I founded, and there I was my own boss. I was my– well, my board was boss. But really what I learned there is this idea of leading with purpose and that you can get people– you have so few tools in the nonprofit world. You have small salaries. You don’t have stock. But you do have purpose, and if you lead with purpose, gosh, people are willing to do amazing things. So maybe those are some things I’ve learned over the years. ALISON BEARD: I really like that you turned a question asking about why you’re so amazing to talk about why your bosses were so amazing and what they taught you. And so I think maybe what characteristic is most salient for you is that you’re a learner. You’re curious, and you’re picking up lessons from other people. OK, this last question– and it’s just a one-word answer– what’s your Lyft driver rating? DAVID RISHER: 5. [CHUCKLES] ALISON BEARD: I’m not surprised. All right, David, I’m sorry that we’re out of time. It’s really been a pleasure talking with you today. Thank you so much. DAVID RISHER: Alison, I’ve had a ton of fun. Thanks for the great questions from you and from the whole audience. It was great. ALISON BEARD: That was Lyft CEO David Risher in conversation with me at the 2025 HBR Leadership Summit. We’ll be back next Wednesday with another hand-picked conversation about leadership from Harvard Business Review. If you found this episode helpful, share it with your friends and colleagues, and follow our show on Apple Podcasts, Spotify, or wherever you get your podcasts. While you’re there, be sure to leave us a review. When you’re ready for more podcasts, articles, case studies, books, and videos with the world’s top business and management experts, find it all at HBR.org. This episode was produced by Dave Di Ulio, Elie Honein, Curt Nickisch, and me. Music by Coma Media. Special thanks to Julia Butler, Scott LaPierre, Simona Sparane, Maureen Hoch, Amy Poftak, Alex Kephart, Rob Eckhardt, Erica Truxler, Ramsey Khabbaz, Nicole Smith, Anne Bartholomew, and you – our listener. See you next week.
--------------------------------------------------

Title: Despite $2M salaries, Meta can't keep AI staff — talent flocks to rivals like OpenAI and Anthropic
URL: https://www.tomshardware.com/tech-industry/artificial-intelligence/despite-usd2m-salaries-meta-cant-keep-ai-staff-talent-flocks-to-rivals-like-openai-and-anthropic
Time Published: 2025-06-11T11:07:13Z
Full Content:
I think we're in the wrong industry. When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. As companies pour billions of dollars into AI infrastructure, demand for AI talent to program and run these AI data centers is also greatly increasing. Deedy Das, a Venture Capitalist at Menlo Ventures and a former Google Search staff member, posted on X that Meta has an over $2 million annual pay package for AI talent, but still keeps losing its people to OpenAI and Anthropic. He said that he’s personally heard three such cases this week alone, which is major news given the size of Meta’s compensation. Statistics say that for every 10.6 from DeepMind, 8.2 from OpenAI, and 2 from Hugging Face that move to Anthropic, it only loses one employee for each company. This movement shows that the startup is quickly growing and that many people from competing AI labs want to work for it. We don’t know how much the company offers, though, but we can safely assume that it’s at least on par or, more likely, substantially larger than what the competition pays. According to the SignalFire research, beyond salary, Anthropic's edge is a unique culture that embraces "unconventional thinkers" and gives employees true autonomy, as well as flexible work options, a lack of title politics and forced management tracks. Furthermore, employees report an embrace of intellectual discourse and researcher autonomy, compared to bureaucracy elsewhere. Meta is currently offering $2M+/yr in offers for AI talent and still losing them to OpenAI and Anthropic. Heard ~3 such cases this week.The AI talent wars are absolutely ridiculous.Today, Anthropic has the highest ~80% retention 2 years in and is the #1 (large) company top AI… pic.twitter.com/YSv5UNV5H2June 10, 2025 Aside from this, Das also mentioned that Anthropic has an unusually high two-year employee retention rate. The tech industry average is around 40% to 50%, with the retention rate dropping over the past couple of years due to layoffs. However, many AI startups’ two-year retention rates vary between 63% and 80%, with Anthropic holding the top spot. Next to it is Google’s DeepMind, which has a retention rate of 78%. Many new employees who work in AI labs also come from major tech giants. It’s estimated that 5.4% of new hires come from Google’s non-AI divisions, while 4.3% are former Meta staffers. A further 3.2% used to work with Microsoft, and another 2.7% are ex-Amazon employees, while 2.1% were previously affiliated with Stripe, and 1.7% came from Apple. This accounts for nearly 20% of new employees in AI labs that have come from tech giants. Massive tech companies used to be the dream job for many people, especially as they offered competitive pay, strong career growth, many opportunities within the industry, and prestige. However, 2024 was a bad year for the tech sector, with many companies laying off thousands of people. Intel was one of the biggest losers, with the company laying off 15% of its workforce (roughly 15,000 employees) after its disastrous August 2024 financial report. However, other companies like Amazon, Meta, Microsoft, Dell, and AMD were also hit with workforce reductions. On the other hand, the continued growth in the AI sector is pushing many talented individuals towards these startups, as shown by the data. This will likely continue in the near future, as companies and nations continuously build more and more AI data centers. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Follow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button. Jowi Morales is a tech enthusiast with years of experience working in the industry. He’s been writing with several tech publications since 2021, where he’s been interested in tech hardware and consumer electronics. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036.
--------------------------------------------------