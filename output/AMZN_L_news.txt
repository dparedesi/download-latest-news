List of news related to Layoffs Amazon:

Title: Front-End Developer Technical Interview Preparation Course - Google Amazon Meta Apple Front-End Engineer Jobs 2025 Update
URL: https://www.globenewswire.com/news-release/2025/04/15/3062200/0/en/Front-End-Developer-Technical-Interview-Preparation-Course-Google-Amazon-Meta-Apple-Front-End-Engineer-Jobs-2025-Update.html
Time Published: 2025-04-15T22:33:00Z
Full Content:
April 15, 2025 18:33 ET | Source: Interview Kickstart Interview Kickstart Santa Clara, April 15, 2025 (GLOBE NEWSWIRE) -- Santa Clara, California - In February 2025, Meta made headlines by increasing its hiring of engineers, with interview requests surging in that period. As Meta and other top-tier tech companies continue to invest in user experiences, front-end engineering has become a critical area of hiring. Engineers who specialize in crafting fast, responsive, and accessible interfaces are more essential than ever. To learn more visit https://interviewkickstart.com/courses/front-end-engineering-interview-masterclass This hiring spike comes at a time when the broader tech industry is recovering and recalibrating after a wave of layoffs in 2023 and 2024. Against this backdrop, Interview Kickstart has updated its Front-End Engineering course for professionals aiming to break into FAANG and other top-tier companies. Designed and taught by current engineers and hiring managers at FAANG+ companies, the course provides a rigorous, structured path to mastering the technical and interview skills that top employers demand. The demand for engineers with front-end expertise is rising steadily, especially for those skilled in modern frameworks like React, Vue, and Angular. According to a 2024 report from the Burning Glass Institute, front-end developer job postings have grown at an average rate of 15% per year since 2020. Companies are prioritizing candidates who not only know JavaScript and CSS inside out but also understand system design, user performance optimization, and cross-platform delivery. Interview Kickstart Front-end Engineering course covers core fundamentals with an emphasis on data structures and algorithms, a must-have for technical interviews at any elite tech company. Over 5 weeks, learners engage in live classes focused on solving algorithmic challenges, understanding time and space complexity, and approaching problems with optimal solutions. This forms the technical backbone required for any engineer, regardless of specialization. Beyond that foundation, the program includes a dedicated three-week system design module. While many front-end engineers often overlook system design, it is increasingly tested in interviews, particularly for mid-level and senior candidates. The course teaches how to design scalable front-end systems, from rendering pipelines to caching strategies and distributed UI components, which are essential for roles at companies like Meta where products operate at a massive scale. The four-week front-end domain segment focuses on the exact tools, frameworks, and architectures used in modern front-end development. Topics include virtual DOM, component-based design, state management with Redux or Context API, performance optimization, testing, and accessibility, which are all covered through real-world case studies and problems modeled after actual interview questions. Classes are structured around open-ended problems and live feedback, helping participants understand not just how to solve a problem, but how to communicate their thought process effectively during an interview. What sets the Interview Kickstart Front-end Engineering course apart is its career-focused layer. Interview Kickstart provides 6 months of post-program support, including mock interviews with experienced engineers from companies like Google and Apple. These interviews are tailored to front-end roles and simulate the pressure and structure of actual technical interviews. Participants receive detailed feedback on both technical and behavioral performance. There are also dedicated sessions for resume building, personal branding, and LinkedIn optimization to ensure candidates stand out to recruiters and hiring managers. The course is built with working professionals in mind. Each week includes asynchronous foundational content, a timed test and review session, and a four-hour live class on Sundays. Between Monday and Wednesday, learners work on practice problems and attend doubt-clearing sessions, with continuous access to instructors for 1:1 coaching. The program recommends 10–12 hours per week for full participation, balancing structure with flexibility. As companies like Meta increase hiring for engineering teams, and as user experience becomes an even bigger differentiator in product strategy, the need for well-prepared, technically sharp front-end engineers is only going to grow. Interview Kickstart's Front-End Engineering Interview Masterclass offers a direct path to capitalize on this demand. By combining top-tier instruction, real-world practice, and structured interview coaching, the program helps engineers not only improve their skills but translate them into high-paying roles at the companies shaping the future of tech. To learn more visit https://interviewkickstart.com/ About Interview Kickstart Founded in 2014, Interview Kickstart is a premier upskilling platform empowering aspiring tech professionals to secure roles at FAANG and top tech companies. With a proven track record and over 20,000 successful learners, the platform stands out with its team of 700+ FAANG instructors—hiring managers and tech leads—who deliver a comprehensive curriculum, practical insights, and targeted interview prep strategies. https://youtu.be/2-nBzwf3Oaw?si=gmMfsDMazR9YDe4O Offering live classes, 100,000+ hours of pre-recorded video lessons, and 1:1 sessions, Interview Kickstart ensures flexible, in-depth learning along with personalized guidance for resume building and LinkedIn profile optimization. The holistic support, spanning 6 to 10 months with mock interviews, ongoing mentorship, and industry-aligned projects, equips learners to excel in technical interviews and on the job. ### For more information about Interview Kickstart, contact the company here:Interview KickstartBurhanuddin Pithawala+1 (209) 899-1463aiml@interviewkickstart.com4701 Patrick Henry Dr Bldg 25, Santa Clara, CA 95054, United States Santa Clara, April 16, 2025 (GLOBE NEWSWIRE) -- Santa Clara, California - In an era where AI decisions can impact everything from medical diagnoses to financial lending, the "black box" problem... Santa Clara, April 16, 2025 (GLOBE NEWSWIRE) -- Santa Clara, California - As hyperautomation reshapes the landscape of data science and analytics, Interview Kickstart today announced the launch...
--------------------------------------------------

Title: What To Buy Before Tariffs Make Everything More Expensive
URL: https://www.forbes.com/sites/forbes-personal-shopper/2025/04/15/what-to-buy-before-tariffs-1/
Time Published: 2025-04-15T19:03:53Z
Full Content:
Since the second Trump administration announced sweeping global tariffs on April 2, 2025, it has been a dizzying process trying to track what duties are actually active and on what nations, goods and resources. What is clear, according to numerous experts we consulted, is that the prices Americans will soon be paying on all sorts of products—from sofas to washing machines—are going to rise; that’s because tariffs, often positioned as taxes levied on foreign countries and companies, are, in fact, paid by American businesses importing the goods, with some level of elevated consumer prices following on. Prices are going to rise on products ranging from washing machines to bath towels to chocolate bars. ... More We spoke to the experts to find out what to expect and when. To better understand what the effects of these policies will be and how our readers’ lives may change, we spoke with multiple economists and finance researchers to find out what developments we can expect to see across the many products we test and recommend at Forbes Vetted. These experts also shared their advice on how to think about consumer purchasing in the short term, and gave guidance on how to navigate this tricky and uncertain time. Currently, there is a 10% baseline tariff on everything imported to the United States, with higher tariffs imposed on various industries based abroad. Many of these tariffs are nearly as high as 50%, per data sourced from the government. “A baseline tariff is a tariff rate set by our government on all countries,” says Professor Albert Williams, Ph.D, Finance Chair of the Wayne Huizenga College of Business at Nova Southeastern University. On the other hand, he explains that a reciprocal tariff is a further elevated duty imposed as either a retaliation or a punitive measure implemented based on perceived unfair trade practices. Few of those elevated reciprocal tariffs are currently in place, though, as the White House granted a 90-day freeze on April 9, temporarily keeping things at that baseline 10%. (Some industries, like automobiles, steel and aluminum, and as of April 14, semiconductors and pharmaceuticals, might see levies go into effect despite this.) One other—and quite notable—exception to this reprieve is on imports from China, who has the world’s second-largest economy. “The entire menu of tariffs currently in effect is well over 100% on China,” says Professor Jason Miller, Ph.D, with Michigan State University’s Eli Broad College of Business. He adds: “There are tariffs on [almost everything] except for carveouts for [products like] lumber and wood products and copper,” Miller says. “A great many products are affected,” he adds. What won’t be affected, at least for now, is a selection of tech products. Scarcely a week after imposing wide-ranging blanket tariffs on China, the Trump Administration announced exemptions on smartphones, computers, computer chips and several other high-tech product categories, making them subject to much lower duties than the rest of China’s imports. This is seen as a direct but short-term assist to American tech giants, chiefly Apple. But it might be a short-term gift, as the White House has said tariffs on these items are “coming soon.” According to Professor Babak Hafezi, who teaches International Business at American University, “How these tariffs have been imposed will cause nearly everything to increase in price.” He adds that “We have to understand that we have a globalized supply chain with parts being made all over the world and [products] assembled in other countries.” While the exemption of many high-tech devices might keep the price of iPhones, laptops, and other hardware stabler than previously expected—at least for now—you can expect higher price tags for things like appliances, TVs and other complex manufactured goods. Imported foods, apparel, luxury items and more will become pricier, including everything from French wine to Italian leather. And coffee and chocolate will no doubt be more expensive, too. Ironically, tariffs levied on foreign goods often prompt an increase on domestically produced goods as well. If a retailer raises the price on a pound of French cheese by five dollars, for example, they may well elevate the cost of a comparable American product by two or three dollars, since it will still seem like the better bargain. The same is true for other domestically produced products, from apparel to technology to toys. And in addition to higher prices for the consumer, tariffs may lead to supply chain disruptions for both internationally and domestically produced products. This is, in part, because China has vastly limited its exports to the United States in response to the reciprocal tariffs placed on its manufacturers. As an example, our recommendation for one of the best couches, the Rose Sofa from Chicago-based custom sofa maker Interior Define is temporarily unavailable due to trade fluctuations borne by the tariffs. We may see more brands and items follow suit as raw materials become prohibitively expensive or altogether unavailable. While we may see some price increases immediately in anticipation of tariffs, the majority of these will take place a few months after they fully go into effect, “once existing inventories are cycled through and the tariffed items are now being sold,” says professor Miller. That means that with the White House’s current delays, we should see an impact by the summer. And as for whether to stock up before that time, professor Miller advises proceeding with some nuance: “Given all the uncertainty about what tariffs will actually be, I would tell folks only to go forward on purchases for something like a smartphone if they were planning on replacing that phone anyway in the next few months. The same applies with items like laptops.” Long story short, if you were about to buy something you need, go ahead and make the purchase, especially for already pricey items that may be subject to additional price hikes soon. Also shop for those intentional items when you see a meaningful discount; while it’s still too early to tell how shopping events later in the year, like Amazon Prime Day, Black Friday and Cyber Monday will ultimately be affected, it’s smart to pick up what you truly need if you can get it for a good deal. (We’ll continue to track these savings in our ongoing sale coverage.) That said, if you’re not actively in the market for a given product, don’t panic buy early—even if it’s currently discounted. While we’re still waiting to see how drastic and widespread price increases may be in coming months, here are some of the items we’re keeping an eye on, and that you may want to consider purchasing now if they need to be replaced: The back-and-forth over whether smartphones, computers and other technology will be impacted by tariffs means nothing is certain; if you are in the market for a new device, such as the iPhone 15 Pro Max or a new Android phone, you may want to buy it. The same goes for laptops, printers and other electronics like our top-recommended TVs. Apple According to the Alliance for American Manufacturing, about 75% of all furniture sold in America is produced overseas. If you’re in the market for a new desk, bedroom set or living room seating, such as one of the best sofas Forbes Vetted team spent more than a year testing, this is a good time to go for it. Sundays The vast majority of shoes, such as Forbes Vetted reader-favorite Hoka walking shoes, are made overseas, and the price on shoes of all types is likely to rise when tariffs hit and new designs come out. This is also the case for things like men’s shorts, crossbody bags, bath towels and other clothing, accessories and textiles we test and recommend. Frontgate We regularly cover home appliances, such as whole-house humidifiers, stackable washers and dryers, and other hardware that can be quite expensive even without tariff-induced price hikes. If you have already budgeted for a home appliance, it could be a good idea to buy now before prices rise further. You can all but count on higher prices on numerous foods and beverages, such as the aforementioned chocolate, coffee and wine subscriptions, but also on other imports like olive oil and flowers. Maeve Chocolate Contrary to common misconception, tariffs are not paid by foreign countries or foreign companies; they are paid by the company importing goods from overseas or by an agent for the domestic company. In other words, in the case of these recent tariffs, they will be paid for by American businesses. The money raised goes through the United States Custom and Border Protection agency and becomes federal government revenue. “Tariff taxes collected are added to the government’s revenues, which are then used for education, social programs, military, healthcare spending and more,” says professor Williams. Some of the costs incurred by those importers are absorbed by the companies affected, but the rest are largely passed on to consumers in the form of higher prices. In effect, everyday consumers eventually shoulder some burden of increased prices triggered by tariffs. A “recession” is defined as two or more consecutive quarters of decline in economic activity significant enough that the nation’s gross domestic product (GDP) shrinks. The types of economic activity tracked include a higher unemployment rate, a slowdown in industrial production, reduced consumer spending and reduced business investment and profit. Some economists warn that the current tariff program may lead to a recession. “This is what most economists are worried about,” says professor Hafezi. “If we have rising prices because of tariffs and enter a recession, we could enter a timeframe of stagflation. This is a staggering economy that cannot rebalance because tariffs impose an artificially high rate on prices, and discounting will be minimal because the supply chain will have taken all discounts possible to keep prices down as much as possible. This staggering economy is happening while you have further inflationary elements that dampen economic activity. Furthermore, companies will take multiple quarters to move their supply chains to rebalance production to countries that are not tariffed or are less so. This will take time.” Bottom line: During times of recession, consumer spending tends to drop, which further slows the economy. As a result, merchandise prices often drop to accommodate that lowered demand, and while cheaper phones, toilet paper and office chairs might seem like a good thing, reduced prices also often mean less profits for retailers, which can cause hiring freezes and layoffs. These only make a potential recession worse and more protracted.
--------------------------------------------------

Title: What To Buy Before Tariffs Make Everything More Expensive
URL: https://www.forbes.com/sites/forbes-personal-shopper/2025/04/15/what-to-buy-before-tariffs/
Time Published: 2025-04-15T19:03:53Z
Full Content:
Since the second Trump administration announced sweeping global tariffs on April 2, 2025, it has been a dizzying process trying to track what duties are actually active and on what nations, goods and resources. What is clear, according to numerous experts we consulted, is that the prices Americans will soon be paying on all sorts of products—from sofas to washing machines—are going to rise; that’s because tariffs, often positioned as taxes levied on foreign countries and companies, are, in fact, paid by American businesses importing the goods, with some level of elevated consumer prices following on. Prices are going to rise on products ranging from washing machines to bath towels to chocolate bars. ... More We spoke to the experts to find out what to expect and when. To better understand what the effects of these policies will be and how our readers’ lives may change, we spoke with multiple economists and finance researchers to find out what developments we can expect to see across the many products we test and recommend at Forbes Vetted. These experts also shared their advice on how to think about consumer purchasing in the short term, and gave guidance on how to navigate this tricky and uncertain time. Currently, there is a 10% baseline tariff on everything imported to the United States, with higher tariffs imposed on various industries based abroad. Many of these tariffs are nearly as high as 50%, per data sourced from the government. “A baseline tariff is a tariff rate set by our government on all countries,” says Professor Albert Williams, Ph.D, Finance Chair of the Wayne Huizenga College of Business at Nova Southeastern University. On the other hand, he explains that a reciprocal tariff is a further elevated duty imposed as either a retaliation or a punitive measure implemented based on perceived unfair trade practices. Few of those elevated reciprocal tariffs are currently in place, though, as the White House granted a 90-day freeze on April 9, temporarily keeping things at that baseline 10%. (Some industries, like automobiles, steel and aluminum, and as of April 14, semiconductors and pharmaceuticals, might see levies go into effect despite this.) One other—and quite notable—exception to this reprieve is on imports from China, who has the world’s second-largest economy. “The entire menu of tariffs currently in effect is well over 100% on China,” says Professor Jason Miller, Ph.D, with Michigan State University’s Eli Broad College of Business. He adds: “There are tariffs on [almost everything] except for carveouts for [products like] lumber and wood products and copper,” Miller says. “A great many products are affected,” he adds. What won’t be affected, at least for now, is a selection of tech products. Scarcely a week after imposing wide-ranging blanket tariffs on China, the Trump Administration announced exemptions on smartphones, computers, computer chips and several other high-tech product categories, making them subject to much lower duties than the rest of China’s imports. This is seen as a direct but short-term assist to American tech giants, chiefly Apple. But it might be a short-term gift, as the White House has said tariffs on these items are “coming soon.” According to Professor Babak Hafezi, who teaches International Business at American University, “How these tariffs have been imposed will cause nearly everything to increase in price.” He adds that “We have to understand that we have a globalized supply chain with parts being made all over the world and [products] assembled in other countries.” While the exemption of many high-tech devices might keep the price of iPhones, laptops, and other hardware stabler than previously expected—at least for now—you can expect higher price tags for things like appliances, TVs and other complex manufactured goods. Imported foods, apparel, luxury items and more will become pricier, including everything from French wine to Italian leather. And coffee and chocolate will no doubt be more expensive, too. Ironically, tariffs levied on foreign goods often prompt an increase on domestically produced goods as well. If a retailer raises the price on a pound of French cheese by five dollars, for example, they may well elevate the cost of a comparable American product by two or three dollars, since it will still seem like the better bargain. The same is true for other domestically produced products, from apparel to technology to toys. And in addition to higher prices for the consumer, tariffs may lead to supply chain disruptions for both internationally and domestically produced products. This is, in part, because China has vastly limited its exports to the United States in response to the reciprocal tariffs placed on its manufacturers. As an example, our recommendation for one of the best couches, the Rose Sofa from Chicago-based custom sofa maker Interior Define is temporarily unavailable due to trade fluctuations borne by the tariffs. We may see more brands and items follow suit as raw materials become prohibitively expensive or altogether unavailable. While we may see some price increases immediately in anticipation of tariffs, the majority of these will take place a few months after they fully go into effect, “once existing inventories are cycled through and the tariffed items are now being sold,” says professor Miller. That means that with the White House’s current delays, we should see an impact by the summer. And as for whether to stock up before that time, professor Miller advises proceeding with some nuance: “Given all the uncertainty about what tariffs will actually be, I would tell folks only to go forward on purchases for something like a smartphone if they were planning on replacing that phone anyway in the next few months. The same applies with items like laptops.” Long story short, if you were about to buy something you need, go ahead and make the purchase, especially for already pricey items that may be subject to additional price hikes soon. Also shop for those intentional items when you see a meaningful discount; while it’s still too early to tell how shopping events later in the year, like Amazon Prime Day, Black Friday and Cyber Monday will ultimately be affected, it’s smart to pick up what you truly need if you can get it for a good deal. (We’ll continue to track these savings in our ongoing sale coverage.) That said, if you’re not actively in the market for a given product, don’t panic buy early—even if it’s currently discounted. While we’re still waiting to see how drastic and widespread price increases may be in coming months, here are some of the items we’re keeping an eye on, and that you may want to consider purchasing now if they need to be replaced: The back-and-forth over whether smartphones, computers and other technology will be impacted by tariffs means nothing is certain; if you are in the market for a new device, such as the iPhone 15 Pro Max or a new Android phone, you may want to buy it. The same goes for laptops, printers and other electronics like our top-recommended TVs. Apple According to the Alliance for American Manufacturing, about 75% of all furniture sold in America is produced overseas. If you’re in the market for a new desk, bedroom set or living room seating, such as one of the best sofas Forbes Vetted team spent more than a year testing, this is a good time to go for it. Sundays The vast majority of shoes, such as Forbes Vetted reader-favorite Hoka walking shoes, are made overseas, and the price on shoes of all types is likely to rise when tariffs hit and new designs come out. This is also the case for things like men’s shorts, crossbody bags, bath towels and other clothing, accessories and textiles we test and recommend. Frontgate We regularly cover home appliances, such as whole-house humidifiers, stackable washers and dryers, and other hardware that can be quite expensive even without tariff-induced price hikes. If you have already budgeted for a home appliance, it could be a good idea to buy now before prices rise further. You can all but count on higher prices on numerous foods and beverages, such as the aforementioned chocolate, coffee and wine subscriptions, but also on other imports like olive oil and flowers. Maeve Chocolate Contrary to common misconception, tariffs are not paid by foreign countries or foreign companies; they are paid by the company importing goods from overseas or by an agent for the domestic company. In other words, in the case of these recent tariffs, they will be paid for by American businesses. The money raised goes through the United States Custom and Border Protection agency and becomes federal government revenue. “Tariff taxes collected are added to the government’s revenues, which are then used for education, social programs, military, healthcare spending and more,” says professor Williams. Some of the costs incurred by those importers are absorbed by the companies affected, but the rest are largely passed on to consumers in the form of higher prices. In effect, everyday consumers eventually shoulder some burden of increased prices triggered by tariffs. A “recession” is defined as two or more consecutive quarters of decline in economic activity significant enough that the nation’s gross domestic product (GDP) shrinks. The types of economic activity tracked include a higher unemployment rate, a slowdown in industrial production, reduced consumer spending and reduced business investment and profit. Some economists warn that the current tariff program may lead to a recession. “This is what most economists are worried about,” says professor Hafezi. “If we have rising prices because of tariffs and enter a recession, we could enter a timeframe of stagflation. This is a staggering economy that cannot rebalance because tariffs impose an artificially high rate on prices, and discounting will be minimal because the supply chain will have taken all discounts possible to keep prices down as much as possible. This staggering economy is happening while you have further inflationary elements that dampen economic activity. Furthermore, companies will take multiple quarters to move their supply chains to rebalance production to countries that are not tariffed or are less so. This will take time.” Bottom line: During times of recession, consumer spending tends to drop, which further slows the economy. As a result, merchandise prices often drop to accommodate that lowered demand, and while cheaper phones, toilet paper and office chairs might seem like a good thing, reduced prices also often mean less profits for retailers, which can cause hiring freezes and layoffs. These only make a potential recession worse and more protracted.
--------------------------------------------------

Title: VMware closing a door opens up new VDI possibilities
URL: https://www.techradar.com/pro/vmware-closing-a-door-opens-up-new-vdi-possibilities
Time Published: 2025-04-15T14:05:50Z
Full Content:
VMware's fall is leading organizations to explore alternative VDI When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. There has been increasing attention on open and closed technologies in relation to the development of AI and large language models (LLMs) in the past few years. Meta released Llama as open source, XAI released GROK-1 and, of course, the open source release of China’s DeepSeek model in recent months has been widely publicized. It’s evident that open source technology benefits from community adoption and development, enabling faster iteration, greater security testing and the contributions of many more active minds, experiences and skill sets. Whether the recent LLM releases are driven by such beliefs or by commercial instincts (likely both), it certainly helps in preventing a single player from dominating the market. This perspective was highlighted by the ironically named OpenAI trying to stifle DeepSeek adoption in recent weeks. Co-Founder at Inevidesk. The tensions of open versus closed technologies have long existed in less sensitive, yet still important, areas. Closed technologies tend to be much more widely adopted as they are more easily packaged and deployed and require less depth of expertise. This can lead to monopolies of the type exemplified by Microsoft or Adobe, whose dominance stifles any real competition; the sheer weight of users and finances might preclude serious challenges. In other areas there might not be monopolies, but still a general market domination by a handful of vendors. Virtual Desktop Infrastructure (VDI) is a good example, where VMware and Citrix have shared the spoils for many years. And if their dominance has been challenged in recent years, this has been due to the growth of cloud hyperscalers which, for the most part, were extensions of existing global, powerful big tech such as Microsoft, Google and Amazon. This state of play is starting to shift somewhat, driven in part by dissatisfaction and distrust of the cloud giants (almost certainly concentrated further by their involvement in AI). This is causing many organizations to ‘reshore’ on-premises or cloud hosted in their own private data center. This dissatisfaction has been fueled by the slow collapse of VMware - perhaps the most well known and widely used of the legacy VDI vendors. VMware was purchased by Broadcom in November 2023, who almost immediately announced several changes including the divestment of their end user computing (EUC) which included Horizon VDI services. The EUC business was subsequently purchased by KKR, a global investment firm, that now offers VDI services under the ‘Omnissa’ brand. The lack of interest shown by Broadcom in the EUC service is a huge knock in confidence for the continued viability of this model, which is not profitable enough for them. It’s uncertain whether the software can be revived under new ownership and there have been worrying indications. Last year, Gartner warned of uncertainty regarding Omnissa’s roadmap and continued semi-dependence for many users on other VMware products. Concerns are currently compounded by recent large-scale layoffs which in one sense should be expected as a post-sale reconstruction, but of course could easily result in the loss of critical internal expertise and a drop in service levels. The recent upheaval has also caused issues concerning price increases and significantly lengthy waits for renewal quotations. Such concerns are driving customers towards other options and, with Citrix remaining complex and expensive and certainly out of the reach of many SMEs, we are seeing a rise of open source related solutions starting to emerge. Many organizations are now offering KVM-based solutions which both avoid the increasing risks and expense associated with the legacy vendors to offer more accessible, flexible and cost-efficient VDI services. Changes in Microsoft virtualization access licensing in recent years helped open possibilities in the space, which has allowed for more efficient use of hardware and more bespoke options. There are industry specific services arising to serve architecture, engineering and construction (AEC), media production and other compute heavy sectors as well as more generalist, knowledge worker options for finance, law and similar businesses. As VDI offers the potential for higher levels of security, more efficient estate management and greater flexibility in our continuing challenging economic climate, this is to be welcomed. Innovation is critical for a healthy technical ecosystem and the ability to address specific industry requirements, whilst also continuing to focus on lowering carbon impacts and creating greater resilience. Businesses and channel operators should be open to such possibilities and actively engage with potential future partners to support development and mitigate the likelihood of monopolies and big tech dominance. We can see the overreach of some of these players in the news every day; supporting independent innovators is a proactive means of preventing an overgeneralization of power and its associated risks. An open world, rather than a closed one. We've featured the best productivity tool. This article was produced as part of TechRadarPro's Expert Insights channel where we feature the best and brightest minds in the technology industry today. The views expressed here are those of the author and are not necessarily those of TechRadarPro or Future plc. If you are interested in contributing find out more here: https://www.techradar.com/news/submit-your-story-to-techradar-pro Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Co-founder of Inevidesk. Please logout and then login again, you will then be prompted to enter your display name. TechRadar is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036.
--------------------------------------------------

Title: Reliance eyes Flipkart veteran; Small towns seek wealth
URL: https://economictimes.indiatimes.com/tech/newsletters/morning-dispatch/reliance-eyes-flipkart-veteran-small-towns-seek-wealth/articleshow/120294329.cms
Time Published: 2025-04-15T01:32:16Z
Full Content:
Want this newsletter delivered to your inbox? Updated On Apr 15, 2025, 07:09 AM IST Want this newsletter delivered to your inbox? Thank you for subscribing to Morning DispatchWe'll soon meet in your inbox. Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Definitions Top Commodities Top Prime Articles Top Slideshow Top Story Listing Top Market Pages Latest News Follow us on:
--------------------------------------------------

Title: Small businesses take it on chin in Trump’s tariff war — here’s how they’re trying to weather storm
URL: https://nypost.com/2025/04/14/business/small-businesses-take-it-on-chin-in-trumps-tariff-war-heres-how-theyre-trying-to-weather-storm/
Time Published: 2025-04-14T22:23:54Z
Description: Nearly one in five small-to-midsize firms are pessimistic about their chances of survival over the next five years, according to a new report from PYMNTS Intelligence report.
--------------------------------------------------

Title: OpenAI Is a Systemic Risk to the Tech Industry
URL: https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/
Time Published: 2025-04-14T16:28:53Z
Full Content:
Before we go any further: I hate to ask you to do this, but I need your help — I'm up for this year's Webbys for the best business podcast award. I know it's a pain in the ass, but can you sign up and vote for Better Offline? I have never won an award in my life, so help me win this one. Soundtrack: Mastodon - High Road I wanted to start this newsletter with a pithy anecdote about chaos, both that caused by Donald Trump's tariffs and the brittle state of the generative AI bubble. Instead, I am going to write down some questions, and make an attempt to answer them. Last week, OpenAI closed "the largest private tech funding round in history," where it "raised" an astonishing "$40 billion," and the reason that I've put quotation marks around it is that OpenAI has only raised $10 billion of the $40 billion, with the rest arriving by "the end of the year." The remaining $30 billion — $20 billion of which will (allegedly) be provided by SoftBank — is partially contingent on OpenAI's conversion from a non-profit to a for-profit by the end of 2025, and if it fails, SoftBank will only give OpenAI a further $20 billion. The round also valued OpenAI at $300 billion. To put that in context, OpenAI had revenues of $4bn in 2024. This deal values OpenAI at 75 times its revenue. That’s a bigger gulf than Tesla at its peak market cap — a company that was, in fact, worth more than all other legacy car manufacturers combined, despite making far less than them, and shipping a fraction of their vehicles. I also want to add that, as of writing this sentence, this money is yet to arrive. SoftBank's filings say that the money will arrive mid-April — and that SoftBank would be borrowing as much as $10 billion to finance the round, with the option to syndicate part of it to other investors. For the sake of argument, I'm going to assume this money actually arrives. Filings also suggest that "in certain circumstances" the second ($30 billion) tranche could arrive "in early 2026." This isn't great. It also seems that SoftBank's $10 billion commitment is contingent on getting a loan, "...financed through borrowings from Mizuho Bank, Ltd., among other financial institutions." OpenAI also revealed it now has 20 million paying subscribers and over 500 million weekly active users. If you're wondering why it doesn’t talk about monthly active users, it's because they'd likely be much higher than 500 million, which would reveal exactly how poorly OpenAI converts free ChatGPT users to paying ones, and how few people use ChatGPT in their day-to-day lives. The Information reported back in January that OpenAI was generating $25 million in revenue a month from its $200-a-month "Pro" subscribers (it still loses money on every one of them), suggesting around 125,000 ChatGPT Pro subscribers. Assuming the other 19,875,000 users are paying $20 a month, that puts its revenue at about $423 million a month, or about $5 billion a year, from ChatGPT subscriptions. This is what reporters mean when they say "annualized revenue" by the way — it's literally the monthly revenue multiplied by 12. Bloomberg reported recently that OpenAI expects its 2025 revenue to "triple" to $12.7 billion this year. Assuming a similar split of revenue to 2024, this would require OpenAI to nearly double its annualized subscription revenue from Q1 2025 (from $5 billion to around $9.27 billion) and nearly quadruple API revenue (from 2024's revenue of $1 billion, which includes Microsoft's 20% payment for access to OpenAI's models, to $3.43 billion). While these are messy numbers, it's unclear how OpenAI intends to pull this off. The Information reported in February that it planned to do so by making $3 billion a year selling "agents," with ChatGPT subscriptions ($7.9 billion) and API calls ($1.8 billion) making up the rest. This, of course, is utter bollocks. OpenAI's "agents" can't do even the simplest tasks, and three billion dollars of the $12.7 billion figure appears to be a commitment made by SoftBank to purchase OpenAI's tech for its various subsidiaries and business units. Let's say out the numbers precisely: We can assume, in this case, that OpenAI likely has, in the best case scenario, access to roughly $16 billion in liquidity at any given time. It's reasonable to believe that OpenAI will raise more debt this year, and I'd estimate it does so to the tune of around $5 billion or $6 billion. Without it, I am not sure what it’s going to do. As a reminder: OpenAI loses money on every single user. When I wrote "How Does OpenAI Survive?" and "OpenAI Is A Bad Business," I used reported information to explain how this company was, at its core, unsustainable. Let's refresh our memories. It seems, from even a cursory glance, that OpenAI's costs are increasing dramatically. The Information reported earlier in the year that OpenAI projects to spend $13 billion on compute with Microsoft alone in 2025, nearly tripling what it spent in total on compute in 2024 ($5 billion). This suggests that OpenAI's costs are skyrocketing, and that was before the launch of its new image generator which led to multiple complaints from Altman about a lack of available GPUs, leading to OpenAI's CEO saying to expect "stuff to break" and delays in new products. Nevertheless, even if we assume OpenAI factored in the compute increases into its projections, it still expects to pay Microsoft $13 billion for compute this year. This number, however, doesn't include the $12.9 billion five-year-long compute deal signed with CoreWeave, a deal that was a result of Microsoft declining to pick up the option to buy said compute itself. Payments for this deal, according to The Information, start in October 2025, and assuming that it's evenly paid (the terms of these contracts are generally secret, even in the case of public companies), this would still amount to roughly $2.38 billion a year. However, for the sake of argument, let's consider the payments are around $198 million a month, though there are scenarios — such as, say, CoreWeave's buildout partner not being able to build the data centers or CoreWeave not having the money to pay to build them — where OpenAI might pay less. To be clear, and I’ll explain in greater detail later, this wouldn’t be a good thing, either. While it would be off the hook for some of its payments, it would also be without the compute that’s essential for it to continue growing, serving existing customers, and building new AI models. Cash and compute are both essential to OpenAI’s survival. OpenAI has dedicated somewhere in the region of $19 billion to the Stargate data center project, along with another $19 billion provided by SoftBank and an indeterminate amount by other providers. Based on reporting from Bloomberg, OpenAI plans to have 64,000 Blackwell GPUs running "by the end of 2026," or roughly $3.84 billion worth of them. I should also note that Bloomberg said that 16,000 of these chips would be operational by Summer 2025, though it's unclear if that will actually happen. Though it's unclear who actually pays for what parts of Stargate, it's safe to assume that OpenAI will have to, at the very least, put a billion dollars into a project that is meant to be up and running by the end of 2026, if not more. As of now, Stargate has exactly one data center under development in Abilene, Texas, and as above, it's unclear how that's going, though a recent piece from The Information reported that it was currently "empty and incomplete," and that if it stays that way, "OpenAI could walk away from the deal, which would cost Oracle billions of dollars." Though the article takes pains to assure the reader that won't be likely, even an inkling of such a possibility is a bad sign. Business Insider's reporting on the site in Abilene calls it a "$3.4 billion data center development" (as did the press release from site developer Crusoe), though these numbers don't include GPUs, hardware, or the labor necessary to run them. Right now, Crusoe is (according to Business Insider) building "six new data centers, each with a minimum square footage...[which will] join the two it is already constructing for Oracle." Oracle has signed, according to The Information, a 15-year-long lease with Crusoe for its data centers, all of which will be rented to OpenAI. In any case, OpenAI’s exposure could be much, much higher than the $1bn posited at the start of this section (and I’ll explain in greater depth how I reached that figure at the bottom of this section). If OpenAI has to contribute significantly to the costs associated with building Stargate, it could be on the hook for billions. Data Center Dynamics reports that the Abilene site is meant to have 200MW of compute capacity in the first half of 2025, and then as much as 1.2GW by "mid-2026." To give you a sense of total costs for this project, former Microsoft VP of Energy Brian Janous said in January that it costs about $25 million a megawatt (or $25 billion a gigawatt), meaning that the initial capital expenditures for Stargate to spin up its first 200MW data center will be around $5 billion, spiraling to $30 billion for the entire project. Or perhaps even more. The Information has reported that the site, which could be "...potentially one of the world's biggest AI data centers," could cost "$50 billion to $100 billion in the coming years." Assuming we stick with the lower end of the cost estimates, it’s likely that OpenAI is on the hook for over $5 billion for the Abilene site based on the $19 billion it has agreed to contribute to the entire Stargate project, the (often disagreeing) cost projections of the facility), and the contributions of other partners. This expenditure won’t come all at once, and will be spread across several years. Still, assuming even the rosiest numbers, it's hard to see how OpenAI doesn't have to pony up $1 billion in 2025, with similar annual payments going forward until its completion, and that is likely because the development of this site is going to be heavily delayed by both tariffs, labor shortages, and Oracle's (as reported by The Information) trust in "scrappy but unproven startups to develop the project." Based on reporting from The Information last year, OpenAI will spend at least $2.5 billion across salaries, "data" (referring to buying data from other companies), hosting and other cost of sales, and sales and marketing, and then another billion on what infrastructure OpenAI owns. I expect the latter cost to balloon with OpenAI's investment in physical infrastructure for Stargate. Based on previous estimates, OpenAI spends about $2.25 to make $1. At that rate, it's likely that OpenAI's costs in its rosiest revenue projections of $12.7 billion are at least $28 billion — meaning that it’s on course to burn at least $14 billion in 2025. Assuming that OpenAI has all of its liquidity from last year (it doesn't, but for sake of argument, let’s pretend it still has the full $10 billion), as well as the $10 billion from SoftBank, it is still unclear how it meets its obligations. While OpenAI likely has preferential payment structures with all vendors, such as its discounted rates with Microsoft for Azure cloud services, it will still have to pay them, especially in the case of costs related to Stargate, many of which will be up-front costs. In the event that its costs are as severe as reporting suggests, it’s likely the company will find itself needing to raise more capital — whether through equity (or the weird sort-of equity that it issues) or through debt. And yes, while OpenAI has some revenue, it comes at a terrible cost, and anything that isn’t committed to paying for salaries and construction fees will likely be immediately funnelled directly into funding the obscene costs behind inference and training models like GPT 4.5 — a "giant expensive model" to run that the company has nevertheless pushed to every user. Worse still, OpenAI has, while delaying its next model (GPT-5), promised to launch its o3 reasoning model after saying it wouldn't do so, which is strange, because it turns out that o3 is actually way more expensive to run than people thought. Reasoning models are almost always more expensive to operate, as they involve the model “checking” its work, which, in turn, requires more calculations and more computation. Still, o3 is ludicrously expensive even for this category, with the Arc Prize Foundation (a non-profit that makes the ARC-AGI test for benchmarking models) estimating that it will cost $30,000 a task. As of right now, SoftBank has committed to the following: SoftBank's exposure to OpenAI is materially harming the company. To quote the Wall Street Journal: While one might argue that SoftBank has a good amount of cash, the Journal also adds that it’s somewhat hamstrung in its use as a result of CEO Masayoshi Son's reckless gambles: Worse still, it seems, as mentioned before, that SoftBank will be financing the entirety of the first $10 billion — or $7.5 billion, assuming it finds investors to syndicate the first tranche, and they follow through right until the moment Masayoshi Son hits ‘send’ on the wire transfer . As a result, SoftBank will likely have to start selling off parts of its valuable holdings in companies like Alibaba and ARM, or, worse still, parts of its ailing investments from its Vision Fund, resulting in a material loss on its underwater deals. This is an untenable strategy, and I'll explain why. While we do not have much transparency into OpenAI's actual day-to-day finances, we can make the educated guess that its costs are increasing based on the amount of capital it’s raising. If OpenAI’s costs were flat, or only mildly increasing, we’d expect to see raises roughly the same size as previous ones. Its $40bn raise is nearly six times the previous funding round. Admittedly, multiples like that aren’t particularly unusual. If a company raises $300,000 in a pre-seed round, and $3m in a Series A round, that’s a tenfold increase. But we’re not talking about hundreds of thousands of dollars, or even millions of dollars. We’re talking about billions of dollars. If OpenAI’s funding round with Softbank goes as planned, it’ll raise the equivalent of the entire GDP of Estonia — a fairly wealthy country itself, and one that’s also a member of Nato and the European Union. That alone should give you a sense of the truly insane scale of this. Insane, sure, but undoubtedly necessary. Per The Information, OpenAI expects to spend as much as $28 billion in compute on Microsoft's Azure cloud in 2028. Over a third of OpenAI's revenue, per the same article, will come from SoftBank's (alleged) spend.It's reasonable to believe that OpenAI will, as a result, need to raise in excess of $40 billion in funding a year, though it's reasonable to believe that it will need to raise more along the lines of $50 billion or more a year until it reaches profitability. This is due to both its growing cost of business, as well as its various infrastructure commitments, both in terms of Stargate, as well as with third-party suppliers like CoreWeave and Microsoft. OpenAI CEO Sam Altman's statements around costs also suggest that they're increasing. In late February, Altman claimed that OpenAI was "out of GPUs." While this suggests that there’s demand for some products — like its image-generating tech, which enjoyed a viral day in the sun in March — it also means that to meet the demand it needs to spend more. And, at the risk of repeating myself, that demand doesn’t necessarily translate into profitability. As discussed above, SoftBank has to overcome significant challenges to fund both OpenAI and Stargate, and when I say "fund," I mean fund the current state of both projects, assuming no further obligations. The Information reports that OpenAI forecasts that it will spend $28 billion on compute with Microsoft alone in 2028. The same article also reports that OpenAI "would turn profitable by the end of the decade after the buildout of Stargate," suggesting that OpenAI's operating expenses will grow exponentially year-over-year. These costs, per The Information, are astronomical: SoftBank has had to (and will continue having to) go to remarkable lengths to fund OpenAI's current ($40 billion) round, lengths so significant that it may lead to its credit rating being further downgraded. Even if we assume the best case scenario — OpenAI successfully converts to a for-profit entity by the end of the year, and receives the full $30 billion — it seems unlikely (if not impossible) for it to continue raising the amount of capital they need to continue operations. As I’ve argued in previous newsletters, there are only a few entities that can provide the kinds of funding that OpenAI needs. These include big tech-focused investment firms like Softbank, sovereign wealth funds (like those of Saudi Arabia and the United Emirates), and perhaps the largest tech companies. These entities can meet OpenAI’s needs, but not all the time. It’s not realistic to expect Softbank, or Microsoft, or the Saudis, or Oracle, or whoever, to provide $40bn every year for the foreseeable future. This is especially true for Softbank. Based on its current promise to not borrow more than 25% of its holdings, it is near-impossible that SoftBank will be able to continue funding OpenAI at this rate ($40 billion a year), and $40 billion a year may not actually be enough. Based on its last reported equity value of holdings, SoftBank's investments and other assets are worth around $229 billion, meaning that it can borrow just over $57bn while remaining compliant with these guidelines. In any case, it is unclear how SoftBank can fund OpenAI, but it's far clearer that nobody else is willing to. Before we go any further, it's important to note that OpenAI does not really have its own compute infrastructure. The majority of its compute is provided by Microsoft, though, as mentioned above, OpenAI now has a deal with CoreWeave to take over Microsoft's future options for more capacity. Anyway, in the last 90 days, Sam Altman has complained about a lack of GPUs and pressure on OpenAI's servers multiple times. Forgive me for repeating stuff from above, but this is necessary. These statements, in a bubble, seem either harmless or like OpenAI's growth is skyrocketing — the latter of which might indeed be true, but bodes ill for a company that burns money on every single user. Any mention of rate limits or performance issues suggests that OpenAI is having significant capacity issues, and at this point it's unclear what further capacity it can actually expand to outside of that currently available. Remember, Microsoft has now pulled out of as much as 2GW of data center projects, walked away from a $1 billion data center development in Ohio, and declined the option on $12bn of compute from CoreWeave that OpenAI had to pick up — meaning that it may be pushing up against the limits of what is physically available. While the total available capacity of GPUs at many providers like Lambda and Crusoe is unknown, we know that CoreWeave has approximately 360MWavailable, compared to Microsoft's 6.5 to 7.5 Gigawatts, a large chunk of which already powers OpenAI. If OpenAI is running into capacity issues, it could be one of the following: Per The Information's reporting, Microsoft "promised OpenAI 300,000 NVIDIA GB200 (Blackwell) chips by the end of 2025," or roughly $18 billion of chips. It's unclear if this has changed since Microsoft allowed OpenAI to seek other compute in late January 2025. I also don't believe that OpenAI has any other viable options for existing compute infrastructure outside of Microsoft. CoreWeave's current data centers mostly feature NVIDIA's aging "Hopper" GPUs, and while it could — and likely is! — retrofitting its current infrastructure with Blackwell chips, doing so is not easy. Blackwell chips require far more powerful cooling and server infrastructure to make them run smoothly (a problem which led to a delay in their delivery to most customers), and even if CoreWeave was able to replace every last Hopper GPU with Blackwell (it won't), it still wouldn't match what OpenAI needs to expand. One might argue that it simply needs to wait for the construction of the Stargate data center, or for CoreWeave to finish the gigawatt or so of construction it’s working on. As I've previously written, I have serious concerns over the viability of CoreWeave ever completing its (alleged) contracted 1.3 Gigawatts of capacity. Per my article: However, even if I were to humour the idea, it is impossible that any of this project is done by the end of the year, or even in 2026. I can find no commitments to any timescale, other than the fact that OpenAI will allegedly start paying CoreWeave in October (per The Information), which could very well be using current capacity. I can also find no evidence that Crusoe, the company building the Stargate data center, has any compute available. Lambda, a GPU compute company that raised $320 million earlier in this year, and according to Data Center Dynamics "operates out of colocation data centers in San Francisco, California, and Allen, Texas, and is backed by more than $820 million in funds raised just this year," suggesting that it may not have their own data centers at all. Its ability to scale is entirely contingent on the availability of whatever data center providers it has relationships with. In any case, this means that OpenAI's only real choice for GPUs is CoreWeave or Microsoft. While it's hard to calculate precisely, OpenAI's best case scenario is that 16,000 GPUs come online in the summer of 2025 as part of the Stargate data center project. That's a drop in the bucket compared to the 300,000 Blackwell GPUs that Microsoft had previously promised. OpenAI is, regardless of how you or I may feel about generative AI, one of the fastest-growing companies of all time. It currently has, according to its own statements, 500 million weekly active users. Putting aside that each user is unprofitable, such remarkable growth — especially as it's partially a result of its extremely resource-intensive image generator — is also a strain on its infrastructure. The vast majority of OpenAI's users are free customers using ChatGPT, with only around 20 million paying subscribers, and the vast majority on the cheapest $20 plan. OpenAI's services — even in the case of image generation — are relatively commoditized, meaning that users can, if they really care, go and use any number of other different Large Language Model services. They can switch to Bing Image Creator, or Grok, or Stable Diffusion, or whatever. Free users are also a burden on the company — especially with such a piss-poor conversion rate — losing it money with each prompt (which is also the case with paying customers), and the remarkable popularity of its image generation service only threatens to bring more burdensome one-off customers that will generate a few abominable Studio Ghibli pictures and then never return. If OpenAI's growth continues at this rate, it will run into capacity issues, and it does not have much room to expand. While we do not know how much capacity it’s taking up with Microsoft, or indeed whether Microsoft is approaching capacity or otherwise limiting how much of it OpenAI can take, we do know that OpenAI has seen reason to beg for access to more GPUs. In simpler terms, even if OpenAI wasn’t running out of money, even if OpenAI wasn’t horrifyingly unprofitable, it also may not have enough GPUs to continue providing its services in a reliable manner. If that's the case, there really isn't much that can be done to fix it other than: The problem is that these measures, even if they succeed in generating more money for the company, also need to reduce the burden on OpenAI's available infrastructure. Remember: data centers can take three to six years to build, and even with the Stargate's accelerated (and I'd argue unrealistic) timelines, OpenAI isn't even unlocking a tenth of Microsoft's promised compute (16,000 GPUs online this year versus the 300,000 GPUs promised by Microsoft). Though downtime might be an obvious choice, capacity issues at OpenAI will likely manifest in hard limits on what free users can do, some of which I've documented above. Nevertheless, I believe the real pale horses of capacity issues come from arbitrary limits on any given user group, meaning both free and paid users. Sudden limits on what a user can do — a reduction in the number of generations of images of videos for paid users, any introduction of "peak hours," or any increases in prices are a sign that OpenAI is running out of GPUs, which it has already publicly said is happening. However, the really obvious one would be service degradation — delays in generations of any kind, 500 status code errors, or ChatGPT failing to fully produce an answer. OpenAI has, up until this point, had fairly impressive uptime. Still, if it is running up against a wall, this streak will end. The consequences depend on how often these issues occur, and to whom they occur. If free users face service degradation, they will bounce off the product, as their use is likely far more fleeting than a paid user, which will begin to erode OpenAI's growth. Ironically, rapid (and especially unprecedented) growth in one of OpenAI’s competitors, like xAI or Anthropic, could also represent a pale horse for OpenAI. If paid users face service degradation, it's likely this will cause the most harm to the company, as while paid users still lose OpenAI money in the end, it at least receives some money in exchange. OpenAI has effectively one choice here: getting more GPUs from Microsoft, and its future depends heavily both on its generosity and there being enough of them at a time when Microsoft has pulled back from two gigawatts of data centers specifically because of it moving away from providing compute for OpenAI. Admittedly, OpenAI has previously spent more on training models than inference (actually running them) and the company might be able to smooth downtime issues by shifting capacity. This would, of course, have a knock-on effect on its ability to continue developing new models, and the company is already losing ground, particularly when it comes to Chinese rivals like DeepSeek. As part of its deal with SoftBank, OpenAI must convert its bizarre non-profit structure into a for-profit entity by December 2025, or it’ll lose $10 billion from its promised funding. Furthermore, in the event that OpenAI fails to convert to a for-profit by October 2026, investors in its previous $6.6 billion round can claw back their investment, with it converting into a loan with an attached interest rate. Naturally, this represents a nightmare scenario for the company, as it’ll increase both its costs and its outgoings. This is a complex situation that almost warrants its own newsletter, but the long and short of it is that OpenAI would have to effectively dissolve itself, start the process of forming an entirely new entity, and distribute its assets to other nonprofits (or sell/license them to the for-profit company at fair market rates). It would require valuing OpenAI's assets, which in and of itself would be a difficult task, as well as getting past the necessary state regulators, the IRS, state revenue agencies, and the upcoming trial with Elon Musk only adds further problems. I’ve simplified things here, and that’s because (as I said) this stuff is complex. Suffice to say, this isn’t as simple as liquidating a company and starting afresh, or submitting a couple of legal filings. It’s a long, fraught process and one that will be — and has been — subject to legal challenges, both from OpenAI’s business rivals, as well as from civil society organizations in California. Based on discussions with experts in the field and my own research, I simply do not know how OpenAI pulls this off by October 2026, let alone by the end of the year. OpenAI has become a load-bearing company for the tech industry, both as a narrative — as previously discussed, ChatGPT is the only Large Language Model company with any meaningful userbase — and as a financial entity. Its ability to meet its obligations and its future expansion plans are critical to the future health — or, in some cases, survival — of multiple large companies, and that's before the after-effects that will affect its customers as a result of any financial collapse. The parallels to the 2007-2008 financial crisis are startling. Lehman Brothers wasn’t the largest investment bank in the world (although it was certainly big), just like OpenAI isn’t the largest tech company (though, again, it’s certainly large in terms of market cap and expenditure). Lehman Brothers’ collapse sparked a contagion that would later spread throughout the global financial services industry, and consequently, the global economy. I can see OpenAI’s failure having a similar systemic effect. While there is a vast difference between OpenAI’s involvement in people’s lives compared to the millions of subprime loans issued to real people, the stock market’s dependence on the value of the Magnificent 7 stocks (Apple, Microsoft, Amazon, Alphabet, NVIDIA and Tesla), and in turn the Magnificent 7’s reliance on the stability of the AI boom narrative still threatens material harm to millions of people, and that’s before the ensuing layoffs. And as I’ve said before, this entire narrative is based off of OpenAI’s success, because OpenAI is the generative AI industry. I want to lay out the direct result of any kind of financial crisis at OpenAI, because I don't think anybody is taking this seriously. Per The Information, Oracle, which has taken responsibility for organizing the construction of the Stargate data centers with unproven data center builder Crusoe, "...may need to raise more capital to fund its data center ambitions." Oracle has signed a 15-year lease with Crusoe, and, to quote The Information, "...is on the hook for $1 billion in payments to that firm." To further quote The Information: In simpler terms, Oracle is building a giant data center for one customer — OpenAI — and has taken on the financial burden associated with it. If OpenAI fails to expand, or lacks the capital to actually pay for its share of the Stargate project, Oracle is on the hook for at least a billion dollars, and, based on The Information's reporting, is also on the hook to buy the GPUs for the site. In reality, this development will likely cost tens of billions of dollars, $19 billion of which is due from OpenAI, which does not have the money until it receives its second tranche of funding in December 2025, which is contingent partially on its ability to convert into a for-profit entity, which, as mentioned, is a difficult and unlikely proposition. It's unclear how many of the Blackwell GPUs that Oracle has had to purchase in advance, but in the event of any kind of financial collapse at OpenAI, Oracle would likely take a loss of at least a billion dollars, if not several billion dollars. I have written a lot about publicly-traded AI compute firm CoreWeave, and it would be my greatest pleasure to never mention it again. Nevertheless, I have to. The Financial Times revealed a few weeks ago that CoreWeave's debt payments could balloon to over $2.4 billion a year by the end of 2025, far outstripping its cash reserves, and The Information reported that its cash burn would increase to $15 billion in 2025. As per its IPO filings, 62% of CoreWeave's 2024 revenue (a little under $2 billion, with losses of $863 million) was Microsoft compute, and based on conversations with sources, a good amount of this was Microsoft running compute for OpenAI. Starting October 2025, OpenAI will start paying Coreweave as part of its five-year-long $12 billion contract, picking up the option that Microsoft declined. This is also when CoreWeave will have to start making payments on its massive, multi-billion dollar DDTL 2.0 loan, which likely makes these payments critical to CoreWeave's future. This deal also suggests that OpenAI will become CoreWeave's largest customer. Microsoft had previously committed to spending $10 billion on CoreWeave's services "by the end of the decade," but CEO Satya Nadella added a few months later on a podcast that its relationship with CoreWeave was a "one-time thing." Assuming Microsoft keeps spending at its previous rate — something that isn't guaranteed — it would still be only half of OpenAI's potential revenue. CoreWeave's expansion, at this point, is entirely driven by OpenAI. 77% of its 2024 revenue came from two customers — Microsoft being the largest, and using CoreWeave as an auxiliary supplier of compute for OpenAI. As a result, the future expansion efforts — the theoretical 1.3 gigawatts of contracted (translation: does not exist yet) compute — are largely (if not entirely) for the benefit of OpenAI. In the event that OpenAI cannot fulfil its obligations, CoreWeave will collapse. It is that simple. I’m basing this on a comment I received from Gil Luria, Managing Director and Head of Technology Research at analyst D.A. Davidson & Co: CoreWeave receives preferential access to NVIDIA's GPUs, and makes up billions of dollars of its revenue. CoreWeave then takes those GPUs and raises debt using them as collateral, then proceeds to buy more of those GPUs from NVIDIA. NVIDIA was the anchor for CoreWeave's IPO, and CEO Michael Intrator said that the IPO "wouldn't have closed" without NVIDIA buying $250 million worth of shares. NVIDIA invested $100 million in the early days of CoreWeave, and, for reasons I cannot understand, also agreed to spend $1.3 billion over four years to, and I quote The Information, "rent its own chips from CoreWeave." Buried in CoreWeave's S-1 — the document every company publishes before going public — was a warning about counterparty credit risk, which is when one party provides services or goods to another with specific repayment terms, and the other party not meeting their side of the deal. While this was written as a theoretical (as it could, in theoretically, come from any company to which CoreWeave acts as a creditor) it only named one company: OpenAI. As discussed previously, CoreWeave is saying that, should a customer — any customer, but really, it means OpenAI — fail to pay its bills for infrastructure built on their behalf, or for services rendered, it could have a material risk to the business. CoreWeave's continued ability to do business hinges heavily on its ability to raise further debt (which I have previously called into question), and its ability to raise further debt is, to quote the Financial Times, "secured against its more than 250,000 Nvidia chips and its contracts with customers, such as Microsoft." Any future debt that CoreWeave raises would be based upon its contract with OpenAI (you know, the counterparty credit risk threat that represents a disproportionate share of its revenue) and whatever GPUs it still has to collateralize. As a result, a chunk of NVIDIA's future revenue is dependent on OpenAI's ability to fulfil its obligations to CoreWeave, both in its ability to pay them and their timeliness in doing so. If OpenAI fails, then CoreWeave fails, which then hurts NVIDIA. Contagion. With Microsoft's data center pullback and OpenAI's intent to become independent from Redmond, future data center expansion is based on two partners supporting CoreWeave and Oracle: Crusoe and Core Scientific, neither of which appear to have ever built an AI data center. I also must explain how difficult building a data center is, and how said difficulty increases when you're building an AI-focused data center. For example, NVIDIA had to delay the launch of its Blackwell GPUs because of how finicky the associated infrastructure (the accompanying servers and cooling them) is. For customers that already had experience handling GPUs, and therefore likely know how to manage the extreme temperatures created by them. As another reminder, OpenAI is on the hook for $19 billion of funding behind Stargate, money that neither it nor SoftBank has right now. Imagine if you didn't have any experience, and effectively had to learn from scratch? How do you think that would go? We're about to find out! Crusoe is a former cryptocurrency mining company that has now raised hundreds of millions of dollars to build data centers for AI companies, starting with a $3.4 billion data center financing deal with asset manager Blue Owl Capital. This (yet-to-be-completed) data center has now been leased by Oracle, which will, allegedly, fill it full of GPUs for OpenAI. Despite calling itself "the industry’s first vertically integrated AI infrastructure provider," with the company using flared gas (a waste byproduct of oil production) to power IT infrastructure, Crusoe does not appear to have built an AI data center, and is now being tasked with building a 1.2 Gigawatt data center campus for OpenAI. Crusoe is the sole developer and operator of the Abilene site, meaning, according to The Information, "...is in charge of contracting with construction contractors and data center customers, as well as running the data center after it is built." Oracle, it seems, will be responsible for filling said data center with GPUs and the associated hardware. Nevertheless, the project appears to be behind schedule. The Information reported in October 2024 that Abeline was meant to have "...50,000 of NVIDIA's [Blackwell] AI chips...in the first quarter of [2025]," and also suggested that the site was projected to have 100,000 Blackwell chips by the end of 2025. Here in reality, a report from Bloomberg in March 2025 (that I cited previously) said that OpenAI and Oracle were expected to have 16,000 GPUs available by the Summer of 2025, with "...OpenAI and oracle are expected to deploy 64,000 NVIDIA GB200s at the Stargate data center...by the end of 2026." As discussed above, OpenAI needs this capacity. According to The Information, OpenAI expects Stargate to handle three-quarters of its compute by 2030, and these delays call into question at the very least whether this schedule is reasonable, if not whether Stargate, as a project, is actually possible. I've written a great deal about CoreWeave in the past, and specifically about its buildout partner Core Scientific, a cryptocurrency mining company (yes, another one) that has exactly one customer for AI data centers — CoreWeave. A few notes: Core Scientific is also, it seems, taking on $1.14 billion of capital expenditures to build out these data centers, with CoreWeave promising to reimburse $899.3 million of these costs. It's also unclear how Core Scientific intends to do this. While it’s taken on a good amount of debt in the past — $550 million in a convertible note toward the end of 2024 — this would be more debt than it’s ever taken on. It also, as with Crusoe, does not appear to have any experience building AI data centers, except unlike Crusoe, Core Scientific is a barely-functioning recently-bankrupted bitcoin miner pretending to be a data center company. How important is CoreWeave to OpenAI exactly? From Semafor: But will it survive long term? Going back to the point of contagion: If OpenAI fails, and CoreWeave fails, so too does Core Scientific. And I don’t fancy Crusoe’s chances, either. At least Crusoe isn’t public. Up until fairly recently, Microsoft has been the entire infrastructural backbone of OpenAI, but recently (to free OpenAI up to work with Oracle) released it from its exclusive cloud compute deal. Nevertheless, per The Information, OpenAI still intends to spend $13 billion on compute on Microsoft Azure this year. What's confusing, however, is whether any of this is booked as revenue. Microsoft claimed earlier in this year that it surpassed $13 billion in annual recurring revenue — by which it means its last month multiplied by 12 — from artificial intelligence. OpenAI's compute costs in 2024 were $5 billion, at a discounted Azure rate, which, on an annualized basis, would be around $416 million in revenue a month for Microsoft. It isn't, however, clear whether Microsoft counts OpenAI's compute spend as revenue. Microsoft's earnings do not include an "artificial intelligence" section, but three separate segments: As a result, it's hard to say specifically where OpenAI's revenue sits, but based on an analysis of Microsoft's Intelligent Cloud segment from FY23 Q1 (note, financial years don’t always correspond with the calendar year, so we just finished FY25 Q2 in January) through to its most recent earnings, and found that there was a spike in revenue from FY23 Q1 to FY24 Q1. In FY23 Q1 (which ended on September 30, 2022, a month before ChatGPT's launch), the segment made $20.3 billion. The following year, in FY24 Q1, it made $24.3 billion — a 19.7% year-over-year (or roughly $4 billion) increase. This could represent the massive increase in training and inference costs associated with hosting ChatGPT, peaking at $28.5 billion in revenue in FY24 Q4 — before dropping dramatically to $24.1 billion in FY25 Q1 and raising a little to $25.5 billion in FY25 Q2. OpenAI spent 2023 training its GPT-4o model before transitioning to its massive, expensive "Orion" model which would eventually become GPT 4.5, as well as its video generation model "Sora." According to the Wall Street Journal, training GPT 4.5 involved at least one training run costing "around half a billion dollars in computing costs alone." These are huge sums, but it’s worth noting a couple of things. First, Microsoft licenses OpenAI’s models to third parties, so some of this revenue could be from other companies using GPT on Azure. And there’s also other companies running their own models on Azure. We’ve seen a lot of companies launch AI products, and not all of them are based on LLMs. Muddling things further, Microsoft provides OpenAI access to Azure cloud services at a discounted rate. And so, there’s a giant question mark over OpenAI’s contribution to the various spikes in revenue for Microsoft’s Intelligent Cloud segment, or whether other third-parties played a significant role. Furthermore, Microsoft’s investment in OpenAI isn’t entirely in cold, hard cash. Rather, it has provided the company with credits to be redeemed on Azure services. I’m not entirely sure how this would be represented on accounting terms, and if anyone can shed light on this, please get in touch. Would it be noted as revenue, or something else? OpenAI isn’t paying Microsoft, but rather doing the tech equivalent of redeeming some airmiles, or spending a gift card. Additionally, while equity is often treated as income for tax purposes — as is the case when an employee receives RSUs as part of their compensation package — under the existing OpenAI structure, Microsoft isn’t a shareholder but rather the owner of profit-sharing units. This is a distinction worth noting. These profit-sharing units are treated as analogous to equity, at least in terms of OpenAI’s ability to raise capital, but in practice they aren’t the same thing. They don’t represent ownership in the company as directly as, for example, a normal share unit would. They lack the liquidity of a share, and the upside they provide — namely, dividends — is purely theoretical. Another key difference: when a company goes bankrupt and enters liquidation, shareholders can potentially receive a share of the proceeds (after other creditors, employees, etc are paid). While that often doesn’t happen (as in, the liabilities far exceed the assets of the company), it’s at least theoretically possible. Given that profit-sharing units aren’t actually shares, where does that leave Microsoft? This stuff is confusing, and I’m not ashamed to say that complicated accounting questions like these are far beyond my understanding. If anyone can shed some light, drop me an email, or a message on Twitter or BlueSky, or post on the Better Offline subreddit. I have done my best to write this piece in as objective a tone as possible, regardless of my feelings about the generative AI bubble and its associated boosters. OpenAI, as I've written before, is effectively the entire generative AI industry, with its nearest competitor being less than five percent of its 500 million weekly active users. Its future is dependent — and this is not an opinion, but objective fact — on effectively infinite resources. If it required $40 billion to continue operations this year, it is reasonable to believe it will need at least another $40 billion next year, and based on its internal projections, will need at least that every single other year until 2030, when it claims, somehow, it will be profitable "with the completion of the Stargate data center." OpenAI requires more compute resources than anyone has ever needed, and will continue to do so in perpetuity. Building these resources is now dependent on two partners — Core Scientific and Crusoe — that have never built a data center, as Microsoft has materially pulled back on data center development, which have (as well as the aforementioned pullback on 2GW of data centers) "slowed or paused" some of its "early stage" data center projects. This shift is directly linked to Microsoft’s relationship with OpenAI, withTD Cowen's recent analyst report saying that data center pullbacks were, and I quote its March 26 2025 data center channel checks letter, "...driven by the decision to not support incremental OpenAI training workloads." In simpler terms, OpenAI needs more compute at a time when its lead backer, which has the most GPUs in the world, has specifically walked away from building it. Even in my most optimistic frame of mind, it isn't realistic to believe that Crusoe or Core Scientific can build the data centers necessary for OpenAI's expansion. Even if SoftBank and OpenAI had the money to invest in Stargate today, dollars do not change the fabric of reality. Data centers take time to build, requiring concrete, wood, steel and other materials to be manufactured and placed, and that's after the permitting required to get these deals done. Even if that succeeds, getting the power necessary is a challenge unto itself, to the point that even Oracle, an established and storied cloud compute company, to quote The Information, "...has less experience than its larger rivals in dealing with utilities to secure power and working with powerful and demanding cloud customers whose plans change frequently." A partner like Crusoe or Core Scientific simply doesn't have the muscle memory or domain expertise that Microsoft has when it comes to building and operating data centers. As a result, it's hard to imagine even in the best case scenario that they're able to match the hunger for compute that OpenAI has. Now, I want to be clear — I believe OpenAI will still continue to use Microsoft's compute, and even expand further into whatever remaining compute Microsoft may have. However, there is now a hard limit on how much of it there's going to be, both literally (in what's physically available) and in what Microsoft itself will actually OpenAI them to use, especially given how unprofitable GPU compute might be. Last week, a truly offensive piece of fan fiction — framed as a "report" — called AI 2027 went viral, garnering press coverage with the Dwarkesh Podcast and gormless, child-like wonder from the New York Times' Kevin Roose. Its predictions vaguely suggest a theoretical company called OpenBrain will invent a self-teaching agent of some sort. It's bullshit, but it captured the hearts and minds of AI boosters because it vaguely suggests that somehow Large Language Models and their associated technology will become something entirely different. I don't like making predictions like these because the future — especially in our current political climate — is so chaotic, but I will say that I do not see, and I say this with complete objectivity, how any of this continues. I want to be extremely blunt with the following points, as I feel like both members of the media and tech analysts have failed to express how ridiculous things have become. I will be repeating myself, but it's necessary, as I need you to understand how untenable things are. I see no way in which OpenAI can continue to raise money at this rate, even if OpenAI somehow actually receives the $40 billion, which will require it becoming a for-profit entity. While it could theoretically stretch that $40 billion to last multiple years, projections say it’ll burn $320 billion in the next five years. Or, more likely, I can’t see a realistic way in which OpenAI gets the resources it needs to survive. It’ll need a streak of unlikely good fortune, the kind of which you only ever hear about in Greek epic poems: If those things happen, I’ll obviously find myself eating crow. But I’m not worried. In the present conditions, OpenAI is on course to run out of money or compute capacity, and it's unclear which will happen first. Even in a hysterical bubble where everybody is agreeing that this is the future, OpenAI currently requires more money and more compute than is reasonable to acquire. Nobody has ever raised as much as OpenAI needs to, and based on the sheer amount of difficulty that SoftBank is having in raising the funds to meet the lower tranche ($10bn) of its commitment, it may simply not be possible for this company to continue. Even with extremely preferential payment terms — months-long deferred payments, for example — at some point somebody is going to need to get paid. I will give Sam Altman credit. He's found many partners to shoulder the burden of the rotten economics of OpenAI, with Microsoft, Oracle, Crusoe and CoreWeave handling the up-front costs of building the infrastructure, SoftBank finding the investors for its monstrous round, and the tech media mostly handling his marketing for him. He is, however, over-leveraged. OpenAI has never been forced to stand on its own two feet or focus on efficiency, and I believe the constant enabling of its ugly, nonsensical burnrate has doomed this company. OpenAI has acted like it’ll always have more money and compute, and that people will always believe its bullshit, mostly because up until recently everybody has. OpenAI cannot "make things cheaper" at this point, because the money has always been there to make things more expensive, as has the compute to make larger language models that burn billions of dollars a year. This company is not built to reduce its footprint in any way, nor is it built for a future in which it wouldn't have access to, as I've said before, infinite resources. Worse still, investors and the media have run cover for the fact that these models don't really do much more than they did a year ago and for the overall diminishing returns of Large Language Models. I have had many people attack my work about OpenAI, but none have provided any real counterpoint to the underlying economic argument I've made since July of last year that OpenAI is unsustainable. This is likely because there really isn't one, other than "OpenAI will continue to raise more money than anybody has ever raised in history, in perpetuity, and will somehow turn from the least-profitable company of all time to a profitable one." This isn’t a rational argument. It’s a religious one. It’s a call for faith. And I see no greater pale horse of the apocalypse than Microsoft's material pullback on data centers. While the argument might be that Microsoft wants OpenAI to have an independent future, that's laughable when you consider Microsoft's deeply monopolistic tendencies — and, for that matter, it owns a massive proportion of OpenAI’s pseudo-equity. At one point, Microsoft’s portion was valued at 49 percent. And while additional fundraising has likely diluted Microsoft’s stake, it still “owns” a massive proportion of what is (at least) the most valuable private startup of all time. And we’re supposed to believe that Microsoft’s pullback — which limits OpenAI’s access to the infrastructure it needs to train and run its models, and thus (as mentioned) represents an existential threat to the company — is because of some paternal desire to see OpenAI leave the childhood bedroom, spread its wings, and enter the real world? Behave. More likely, Microsoft got what it needed out of OpenAI, which has reached the limit of the models it can develop, and which Microsoft already retains the IP of. There’s probably no reason to make any further significant investments, though they allegedly may be part of the initial $10 billion tranche of OpenAI’s next round. It's also important to note that absolutely nobody other than NVIDIA is making any money from generative AI. CoreWeave loses billions of dollars, OpenAI loses billions of dollars, Anthropic loses billions of dollars, and I can't find a single company providing generative AI-powered software that's making a profit. The only companies even close to doing so are consultancies providing services to train and create data for models like Turing and Scale AI — and Scale isn't even profitable. The knock-on effects of OpenAI's collapse will be wide-ranging. Neither CoreWeave nor Crusoe will have tenants for their massive, unsustainable operations, and Oracle will have nobody to sell the compute it’s leased from Crusoe for the next 15 years. CoreWeave will likely collapse under the weight of its abominable debt, which will lead to a 7%+ revenue drop for NVIDIA at a time when revenue growth has already begun to slow. On a philosophical level, OpenAI's health is what keeps this industry alive. OpenAI has the only meaningful userbase in generative AI, and this entire hype-cycle has been driven by its success, meaning any deterioration (or collapse) of OpenAI will tell the market what I've been saying for over a year: that generative AI is not the next hyper-growth market, and its underlying economics do not make sense. I am not writing this to be "right" or "be a hater." If something changes, and I am wrong somehow, I will write exactly how, and why, and what mistakes I made to come to the conclusions I have in this piece. I do not believe that my peers in the media will do the same when this collapses, but I promise you that they will be held accountable, because all of this abominable waste could have been avoided. Large Language Models are not, on their own, the problem. They're tools, capable of some outcomes, doing some things, but the problem, ultimately, are the extrapolations made about their abilities, and the unnecessary drive to make them larger, even if said largeness never amounted to much. Everything that I'm describing is the result of a tech industry — including media and analysts — that refuses to do business with reality, trafficking in ideas and ideology, celebrating victories that have yet to take place, applauding those who have yet to create the things they're talking about, cheering on men lying about what's possible so that they can continue to burn billions of dollars and increase their wealth and influence. I understand why others might not have written this piece. What I am describing is a systemic failure, one at a scale hereto unseen, one that has involved so many rich and powerful and influential people agreeing to ignore reality, and that’ll have crushing impacts for the wider tech ecosystem when it happens. Don't say I didn't warn you. Subscribe today. It's free. Please. Great! You’ve successfully signed up. Welcome back! You've successfully signed in. You've successfully subscribed to Ed Zitron's Where's Your Ed At. Your link has expired. Success! Check your email for magic link to sign-in. Success! Your billing info has been updated. Your billing was not updated.
--------------------------------------------------

Title: Germany's best employers for professional development according to LinkedIn
URL: https://www.thelocal.de/20250414/germanys-best-employers-for-professional-development-according-to-linkedin
Time Published: 2025-04-14T14:52:10Z
Full Content:
The Local Europe ABVästmannagatan 43113 25 StockholmSweden Those looking to move to Germany for work this year, or to switch jobs in the country, might take a tip from LinkedIn's best employers ranking. LinkedIn, the online jobs board turned social media platform, published its "top companies" list for 2025 last week, including a ranking of the "25 best large employers for your professional development" in Germany. Germany's jobs market is marked by uncertainty at the moment as its major industries navigate economic stagnation on the domestic market as well as increasing turbulence on global markets. At the same time - and despite a slight uptick in unemployment - there are plenty of opportunities for jobseekers around, as Germany still lacks the skilled workers it needs to fill positions in key industries. 'The best employers for professional development' According to LinkedIn, more than half of professionals worldwide are currently looking to change change jobs or even industries, and many of them are interested in re-tooling their skills and qualifications to help secure their employment into the future. As well as benefits like a good salary and perks, jobseekers also increasingly expect their employer to provide training opportunities and promote their professional development. READ ALSO: The jobs and skills growing in demand across Germany To help candidates find the best opportunities, LinkedIn's ranking took special interest in employers that help employees develop their careers. Here are the top 25 companies in Germany: Notably, many of the top rated firms are manufacturers and software developers. Siemens, which took the number one spot, largely focuses on manufacturing machinery for automation. Its main locations in Germany are in Munich, Nuremberg and Berlin, and the most common job titles it hires for are project managers, software engineers and product managers. Stryker, which was rated second-highest, is a US-based medical equipment manufacturer with German locations in Freiburg and Kiel. It tends to hire sales representatives, manufacturing engineers, and construction administrators, and seeks employees with skills related to biomedical engineering, general surgery and human movement science. Third on the list is ServiceNow, a California-based software development company with locations in Munich, Frankfurt and Berlin. ServiceNow is focused largely on creating AI platforms for companies and tends to seek IT consultants and account managers. How was the ranking determined? The list of top employers in this category was limited to large companies (at 5,000 employees worldwide with at least 500 in Germany). According to LinkedIn, companies were evaluated on eight factors, which included development, skills growth, business stability, external job prospects, business affinity, gender diversity, educational level (of employees) and employer relevance. Companies with a turnover rate above ten percent were also excluded, as were those that had laid off ten percent or more of their workforce since the start of 2024. Interestingly, those constraints made LinkedIn's ranking look quite different from a a Statista survey of Germany's top employers released at the beginning of the year. That survey, commissioned by Stern magazine, saw the drugstore supermarket DM at the top of the list, followed by Adidas and Google Germany. Several automakers also made the list; BMW, Porsche and Audi were all in the top ten. REVEALED: The 'best' German companies to work for in 2025 Some of those companies were likely omitted from LinkedIn's ranking due to recently announced layoffs, such as those at the above mentioned car makers and Adidas. Join the conversation in our comments section below. Share your own views and experience and if you have a question or suggestion for our journalists then email us at news@thelocal.de. Please keep comments civil, constructive and on topic – and make sure to read our terms of use before getting involved. Please log in here to leave a comment. The Local Europe ABVästmannagatan 43113 25 StockholmSweden By signing up you agree to our Terms of Use and Privacy Policy. We will use your email address to send you newsletters as well as information and offers related to your account. 2025 The Local, All Rights Reserved.
--------------------------------------------------

Title: Microsoft Prepares for New Round of Layoffs in May 2025
URL: https://www.thebridgechronicle.com/tech/microsoft-layoffs-may-2025
Time Published: 2025-04-13T21:55:54Z
Full Content:
Microsoft is reportedly planning another round of layoffs, expected to begin in May 2025. This strategic move aims to streamline the company's organisational structure by reducing middle management positions and non-technical roles. The goal is to improve efficiency and increase the ratio of engineers to non-engineers within project teams, aligning with broader industry trends seen in tech giants like Google and Amazon. Join TBC's WhatsApp Channel to Stay Updated! Microsoft seeks to reduce bureaucratic layers and enhance the "span of control" for managers, allowing each to oversee more employees. This shift is designed to cut overhead costs and prioritize hands-on technical contributions. The company aims to adjust the "PM ratio" (Product Manager to Engineer ratio) to ensure more engineers are involved in product development compared to managers. This is inspired by Amazon's "Builder Ratio," which emphasizes a higher proportion of engineers to non-builders. Similar restructuring efforts have been undertaken by Google and Amazon, focusing on reducing managerial levels and prioritizing technical talent. Google recently reduced vice president and manager roles by 10% as part of an efficiency drive. Middle Management and Non-Technical Roles:These positions are expected to be most affected by the layoffs. The exact number of jobs at risk is not yet confirmed, but it could significantly impact certain teams. Performance-Based Considerations:Employees with consecutive low performance ratings may also face scrutiny, although the current layoffs are more focused on restructuring rather than performance-based cuts. Microsoft's planned layoffs reflect a strategic effort to optimize its workforce and enhance operational efficiency. Prioritising technical talent and streamlining management, the company aims to maintain competitiveness in a rapidly evolving tech landscape. Join TBC's WhatsApp Channel to Stay Updated! Help Us Create the Content You Love Take Survey Now! Enjoyed reading The Bridge Chronicle?Your support motivates us to do better. Follow us on Facebook, Instagram, Twitter and Whatsapp to stay updated with the latest stories.You can also read on the go with our Android and iOS mobile app. Follow Us Copyright © 2025 Sakal Media Group – All Rights Reserved Powered by Quintype
--------------------------------------------------

Title: Konstantinos Sinanas: The Greek engineer who brought Alexa’s voice to the Orion spacecraft
URL: https://en.protothema.gr/2025/04/13/konstantinos-sinanas-the-greek-engineer-who-brought-alexas-voice-to-the-orion-spacecraft/
Time Published: 2025-04-13T07:04:53Z
Full Content:
Konstantinos Sinanas, an acoustic and computer systems engineer who has worked for some of the largest tech companies in America—including Amazon, HP, Harman-Samsung, Synaptics, MeyerSound, and Crestron—is the Greek engineer who participated in the Artemis I – Callisto space program. The project was carried out in collaboration with NASA, Lockheed Martin, and Amazon, and he succeeded in realizing Jeff Bezos’s vision: enabling crews to give voice commands to Alexa and have them executed by the spacecraft‘s systems. “Many people tell me this project is an experience I’ll be able to share for the rest of my life. Science fiction became reality,” says the Greek Distinguished Technologist Konstantinos Sinanas in an interview with the Athens News Agency (APE), explaining that, “In the Artemis I – Callisto space program (a collaboration between NASA, Lockheed Martin, and Amazon), I was the Acoustic Design Lead for integrating Alexa into the Orion spacecraft. The project began during the pandemic, and there had been several failed attempts by other colleagues and teams before I took over. The pressure was immense—there was no room for failure, as it would affect not only me but also the future of Alexa, Amazon, Jeff Bezos personally, Lockheed, NASA, and the reputation of the United States in general.” There is no room for mistakes in space “In anything related to space, mistakes are not an option. Once the launch happens, you need to be 100% sure the systems will work. If there’s a problem, you can’t just ‘go and fix it.’ That’s why, beyond exhaustive system simulations, I insisted on on-site tests at the Orion mockup in Houston. Even though that caused a lot of friction and difficulties, I was certain it was the only way to succeed—and in the end, we did,” Mr. Sinanas emphasizes. Speaking about the field he has served for decades, he explained that he works on the research and development of microphones and micro-speakers—whether embedded in devices or as peripherals (wired/wireless headsets, speakers, microphones, etc.)—covering both consumer and professional audio products, including mobile phones, laptops, and smart devices. At the same time, he designs and equips audio labs and studios and conducts acoustic studies for spaces and installations. 15 Years in America’s Leading Tech Companies “In recent years, Konstantinos Sinanas worked at HP as a Distinguished Technologist at the R&D center, focusing on audio hardware and software, acoustics, innovation, and artificial intelligence. In addition to his main responsibilities, I also had the role of ambassador for international standards and specifications, mentor, and HP representative in global technology forums,” he notes. He explains that over the 15 years he worked in the U.S., he collaborated closely with companies such as “Microsoft, Intel, AMD, NVIDIA, Texas Instruments, Cirrus Logic, Qualcomm, Realtek, Dolby, DTS, Waves, and other HW/SW suppliers in the U.S., Europe, and Asia to create new HP technologies, applications, and products. This gave me the opportunity to work with the entire group of tech giants in Silicon Valley and to gain knowledge and connections I never imagined possible—even though I already had experience with major projects through Harman, with companies such as Google, Apple, JBL, AKG, Huawei, Lenovo, Dell, Asus, Oculus, Bloomberg, LG, and many others.” The Financial Crisis Pushed Him to America “Although I had a successful career in Greece as an educator and engineer, since 2007 I had started to see that the future of the country—especially for those who wanted to grow professionally and financially—was looking bleak. After much thought, sacrifices, and taking a big risk, I made the decision to move to the U.S. in 2010, along with my wife. We have lived in Astoria (New York), Edgewater with Crestron, Los Angeles with Harman-Samsung, Irvine, Orange County with Synaptics, Berkeley with MeyerSound, Santa Clara with Amazon, and in Houston, Texas, with HP,” he notes. When asked whether there’s a secret to success, Konstantinos Sinanas replies, “There are many—not ‘secrets,’ but talents, capabilities, and skills one must possess to build a successful career. It takes a combination of talent, specialized knowledge, flexibility, and continuous development. From crafting the right resume and handling interviews, to managing relationships with colleagues, partners, and the company. Consistency, productivity, integrity, and effectiveness are essential to surviving in the competitive tech space—especially in the U.S.” The Tech Sector Is Facing a Crisis in the U.S. Commenting on the current state of the tech industry in the U.S., he clarified, “Over the past two or three years, the tech sector has been facing a crisis due to poor policy and corporate strategic decisions. This has led to mass layoffs, downsizing, or closure of companies, with serious social consequences. Unfortunately, the reforms now being implemented should have happened a decade ago. Although they may seem strict or confusing to many, they are necessary to avoid worse outcomes for the future of the U.S.” What Comes Next? A Return to Greece As for his future plans? Konstantinos Sinanas answers spontaneously, without a second thought:“My goal is to return permanently to Greece and offer everything I gained abroad—knowledge, experience, innovation, and connections—into education, production, and research. Important efforts are being made, but I believe we still have a long way to go for our country to move forward. I hope that my wife and I will succeed in settling permanently in our homeland.” Explore related questions
--------------------------------------------------