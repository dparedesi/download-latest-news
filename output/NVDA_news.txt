List of news related to NVIDIA NVDA:

Title: 3 ASX ETFs that could quietly make you rich over 20 years
URL: https://www.fool.com.au/2025/12/02/3-asx-etfs-that-could-quietly-make-you-rich-over-20-years/
Time Published: 2025-12-02T06:51:50Z
Description: These funds have qualities that Warren Buffett would look for when making investments.
The post 3 ASX ETFs that could quietly make you rich over 20 years appeared first on The Motley Fool Australia.
--------------------------------------------------

Title: Accelerating Real-Time Financial Decisions with Quantitative Portfolio Optimization
URL: https://developer.nvidia.com/blog/accelerating-real-time-financial-decisions-with-quantitative-portfolio-optimization/
Time Published: 2025-12-01T23:44:52Z
Description: Financial portfolio optimization is a difficult yet essential task that has been consistently challenged by a trade-off between computational speed and model...
--------------------------------------------------

Title: The New Bubble: How AI and Passive Investing Have Turned the Market into a Powder Keg
URL: https://www.activistpost.com/the-new-bubble-how-ai-and-passive-investing-have-turned-the-market-into-a-powder-keg/
Time Published: 2025-12-01T23:00:00Z
Full Content:
The US equity market is a bubble. Here is why: In my mind, to be defined as a ‚Äúbubble‚Äù the potential for a sudden ‚Äúpop‚Äù needs to be there. No matter how you define it, the probability of an extremely large drawdown in the S&P 500 has exponentially increased in the past few years. This doesn‚Äôt mean it is a high probability ‚Äî it just means the tail has gotten much fatter. The main reason for this is index concentration is now being coupled with earnings concentration. Firstly, passive investing has clearly contributed to the top market caps consistently outperforming over the past decade. Passive is inherently pro-momentum. As these stocks were rewarded, it became easier for the companies to use their balance sheet for buying up competitors, seeking top talent, cheap access to debt so they could buy back more shares, etc. It has been a snowball of positive forces for the big tech space in the past 15 years and FLOWS have been a big part of it. However, what has notably changed in the past few years is that their actual earnings have become much more correlated. Yes, Google and Meta at the end of the day are ad companies. Those ads are seen on the screen of an iPhone. They feed Amazon orders. And all of that runs on the cloud behind the scenes. So in a way they have always had very correlated earnings growth, but now they are intertwining even more. Headlines from the past 12 months to give a taste: The Mag 7‚Äôs earnings as a percentage of the overall index has surged higher. That is because they are feeding each other‚Äôs growth now. Their balance sheets are becoming more and more intertwined while their market caps have become fueled by similar hopes. The point here is this: passive investing led to an increase in correlation of these stocks and contributed to their outperformance. But now, AI has led to a further increase in correlation at the fundamental level. To me, this is now what defines this market as a bubble. It is not about all-time high valuations. It is the fact that the stocks are all being pushed higher by similar forces (passive flows and buybacks) while at the fundamental level they are becoming more intertwined by the OBVIOUSLY permeable, flammable, and house-of-cards AI euphoria. Speaking of nuts‚Ä¶ We have just had 27 leveraged 3x and 5x single stock ETFs filed by Volatility Shares. 3x AMD ETF 3x AMZN ETF 3x COIN ETF 3x CRCL ETF 3x GOOGL ETF 3x MSTR ETF 3x NVDA ETF 3x PLTR ETF 3x TSLA ETF 3x Bitcoin ETF 3x Ether ETF 3x Solana ETF 3x XRP ETF 3x VIX ETF 5x AMD ETF 5x AMZN ETF 5x COIN ETF 5x CRCL ETF 5x GOOGL ETF 5x MSTR ETF 5x NVDA ETF 5x PLTR ETF 5x TSLA ETF 5x Bitcoin ETF 5x Ether ETF 5x Solana ETF 5x XRP ETF From a broader perspective‚Ä¶ These ‚Äú5x bullish‚Äù ETFs are scheduled to be listed towards the end of the year. We believe this may accurately coincide with a top in the market. Great caution is now warranted‚Ä¶ if you‚Äôve been with us for some time you will know that we shy away from bombastic sensationalist type of commentary and so we do not say this lightly. This is the most apprehensive we have been since the GFC for the Nasdaq and S&P 500 at least! Editor‚Äôs Note: As markets levitate on the same narrow set of names and the feedback loop tightens, investors would do well to step back and consider what happens when the momentum finally breaks. In our special report, Clash of the Systems: Thoughts on Investing at a Unique Point in Time, we take a hard look at the structural imbalances shaping this moment ‚Äî and how to navigate the risks and opportunities they create. Read the full report here for free.
--------------------------------------------------

Title: Apple shares hit new all-time intraday and closing highs
URL: https://macdailynews.com/2025/12/01/apple-shares-hit-new-all-time-intraday-and-closing-highs-90/
Time Published: 2025-12-01T21:11:29Z
Full Content:
Update font size. Reset In Nasdaq trading today, shares of Apple Inc. (AAPL) rose $4.25 to $283.10, a new all-time closing high. Apple‚Äôs all-time intraday high was also set today at $283.41. Apple‚Äôs 52-week low stands at $169.21 set on April 8, 2025, the very date on which we wrote, ‚ÄúSub-$170 AAPL seems like an absolute gift to us‚Ä¶‚Äù Today‚Äôs trading volume for AAPL shares was 40,170,975 versus Apple‚Äôs average trading volume of 51,432,647 shares. Apple‚Äôs PE Ratio currently stands at 37.90. Apple currently has a market value of $4.201 trillion, making it the world‚Äôs second-most valuable company. The top five U.S. publicly-traded companies, based on market value: Alphabet (GOOGL) ‚Äì $3.814T Microsoft (MSFT) ‚Äì $3.618T Amazon (AMZN) ‚Äì $2.500T Selected companies‚Äô current market values: ‚Ä¢ Meta Platforms (META) ‚Äì $1.615T ‚Ä¢ Taiwan Semi (TSM) ‚Äì $1.493T ‚Ä¢ Tesla (TSLA) ‚Äì $1.431T ‚Ä¢ Berkshire Hathaway (BRK-A) ‚Äì $1.098T ‚Ä¢ Walmart (WMT) ‚Äì $891.333B ‚Ä¢ Netflix (NFLX) ‚Äì $462.419B ‚Ä¢ Advanced Micro Devices (AMD) ‚Äì $357.778B ‚Ä¢ Cisco (CSCO) ‚Äì $300.441B ‚Ä¢ IBM (IBM) ‚Äì $285.853B ‚Ä¢ Disney (DIS) ‚Äì $191.965B ‚Ä¢ Intel (INTC) ‚Äì $190.848B ‚Ä¢ Sony (SONY) ‚Äì $171.638B ‚Ä¢ SoftBank (SFTBF) ‚Äì $147.189B ‚Ä¢ Adobe (ADBE) ‚Äì $136.949B ‚Ä¢ Spotify (SPOT) ‚Äì $119.176B ‚Ä¢ Dell (DELL) ‚Äì $88.814B ‚Ä¢ Nokia (NOK) ‚Äì $33.911B ‚Ä¢ Hewlett-Packard (HPQ) ‚Äì $22.928B ‚Ä¢ SiriusXM (SIRI) ‚Äì $7.008B ‚Ä¢ BlackBerry (BB) ‚Äì $2.373B ‚Ä¢ Sonos (SONO) ‚Äì $2.242B ‚Ä¢ RealNetworks (RNWK) was delisted from U.S. exchanges on December 21, 2022 and is no longer publicly traded.üç© Apple all-time high (AAPL) via NASDAQ here. MacDailyNews Take: To the moon, Alice! To the moon!!! Please help support MacDailyNews ‚Äî and enjoy subscriber-only articles, comments, chat, and more ‚Äî by subscribing to our Substack: macdailynews.substack.com. Thank you! Support MacDailyNews at no extra cost to you by using this link to shop at Amazon. Your email address will not be published. Required fields are marked * Comment * Name * Email * Website Notify me of follow-up comments by email. Notify me of new posts by email. Œî This site uses Akismet to reduce spam. Learn how your comment data is processed. Apple today released a new ad, ‚ÄúI‚Äôm Not Remarkable,‚Äù that puts the spotlight on the company‚Äôs accessibility features across iPhone, iPad, Mac‚Ä¶ Apple‚Äôs App Store faces the prospect of additional class-action-style damages claims in the European Union after the bloc‚Äôs highest court‚Ä¶ Apple has no intention of complying with the Indian government‚Äôs directive to pre-install a state-developed so-called ‚Äúcyber safety‚Äù app‚Ä¶ Apple today announced John Giannandrea, Apple‚Äôs senior vice president for Machine Learning and AI Strategy, is stepping down from his‚Ä¶ Warren Buffett‚Äôs Berkshire Hathaway reported 46 holdings, but its portfolio is quite top heavy with 238,212,764 shares of Apple accounting‚Ä¶ Enter your email address to follow MacDailyNews and receive notifications of new posts by email. Email Address Follow :-)
--------------------------------------------------

Title: NVIDIA (NVDA)‚Äôs Latest AI GPUs Sustain Analyst Optimism
URL: https://finance.yahoo.com/news/nvidia-nvda-latest-ai-gpus-174724209.html
Time Published: 2025-12-01T17:47:24Z
Description: We recently published 10 Best Strong Buy AI Stocks to Invest In. NVIDIA Corporation (NASDAQ:NVDA) is one of the best consumer cyclical stocks. NVIDIA...
--------------------------------------------------

Title: Top Stock Movers Now: Coinbase, Robinhood, Moderna, Synopsys, and More
URL: https://www.investopedia.com/top-stock-movers-now-coinbase-robinhood-moderna-synopsys-and-more-hood-coin-mrna-snps-11859381
Time Published: 2025-12-01T17:23:03Z
Full Content:
Major U.S. equities indexes lost ground Monday afternoon, as shares of tech and cryptocurrency-related companies pulled back. The S&P 500 and Nasdaq slid about 0.2%, while the Dow dropped 0.4%. Cryptocurrency exchange Coinbase Global (COIN) was one of the biggest decliners in the S&P 500, with shares down about 6% as the price of Bitcoin and other major cryptocurrencies fell. Shares of Robinhood Markets (HOOD) dropped close to 5%. Shares of vaccine maker Moderna (MRNA) slumped 6% following reports an official with the the Food and Drug Administration called for a stricter vaccine approval process. Sandisk (SNDK) shares plunged close to 7%, reversing last week's gains on enthusiasm for its addition to the S&P 500. Shares of Old Dominion Freight Line (ODFL) and J.B. Hunt Transport Services (JBHT) climbed about 6% and 4% respectively, following bullish comments from BMO Capital. The bank gave both stocks an ‚Äúoutperform‚Äù rating, pointing to Old Dominion benefiting from its less-than-truckload focus and J.B. Hunt‚Äôs cost savings and intermodal volumes, among other things. Wynn Resorts (WYNN) shares gained around 4% as Goldman Sachs put the casino operator on its conviction buy list. Goldman said Wynn has a best-in-class business in Las Vegas, and should benefit from improvements in Macao. Shares of Synopsys (SNPS) climbed 4% after chipmaker Nvidia (NVDA) said it's investing $2 billion in the maker of semiconductor and circuit design software as part of a partnership. Oil and gold futures rose. The yield on the 10-year Treasury note climbed to 4.09%. The U.S. dollar lost ground to the euro, pound, and yen.
--------------------------------------------------

Title: AMD Stock Drops 15% in a Month: Should You Buy, Sell, or Hold?
URL: https://www.barchart.com/story/news/36390125/amd-stock-drops-15-in-a-month-should-you-buy-sell-or-hold
Time Published: 2025-12-01T17:00:27Z
Description: The competitive landscape is changing for AI GPU suppliers like AMD as Google‚Äôs TPUs could gain momentum and hurt its growth prospects.
--------------------------------------------------

Title: Cathie Wood Is Buying GOOGL Stock as Alphabet Approaches $4 Trillion. Should You?
URL: https://www.barchart.com/story/news/36389673/cathie-wood-is-buying-googl-stock-as-alphabet-approaches-4-trillion-should-you
Time Published: 2025-12-01T16:28:43Z
Description: Influential investor Cathie Wood has loaded up on 174,293 Google shares after the Meta rumors. Here‚Äôs why GOOGL stock is worth owning heading into 2026.
--------------------------------------------------

Title: 5 Healthcare Names to Watch as Sector Rotation Is in Full Swing
URL: https://www.marketbeat.com/originals/5-healthcare-names-to-watch-as-sector-rotation-is-in-full-swing/?utm_source=yahoofinance&amp;utm_medium=yahoofinance
Time Published: 2025-12-01T15:51:00Z
Description: The healthcare sector is outperforming the broader market and tech sector in Q4, confirming a substantial capital shift into the defensive industry.
--------------------------------------------------

Title: The AI Race Is a Marathon, Not a Sprint. Here Is How AMD Stock Could Still Finish First.
URL: https://www.barchart.com/story/news/36389009/the-ai-race-is-a-marathon-not-a-sprint-here-is-how-amd-stock-could-still-finish-first
Time Published: 2025-12-01T15:49:40Z
Description: Despite short-term turbulence and fears over potential competitive setbacks, AMD remains well-positioned in the multi-phase AI race.
--------------------------------------------------

Title: Wall Street is Still Pounding the Table Over Nvidia, Alphabet and Wynn
URL: https://247wallst.com/investing/2025/12/01/wall-street-is-still-pounding-the-table-over-nvidia-alphabet-and-wynn/
Time Published: 2025-12-01T15:20:32Z
Full Content:
Investing Analysts at Guggenheim says Alphabet could run even higher. The firm raised its price target on GOOG to $375 from $330 with a buy rating. Analysts at Goldman Sachs just added Wynn to its conviction buy list. Sending You to Google News in 3 ¬© Thapana_Studio / Shutterstock.com December is historically strong for markets. In fact, ‚ÄúDecember could bring seasonal tailwinds back to the stock market and return it to all-time highs. Historically, since 1950, it‚Äôs the third-best month of the year for the Dow and S&P 500; it‚Äôs also the third-best month for the Nasdaq, since 1971, according to the Stock Trader‚Äôs Almanac,‚Äù as noted by CNBC. In addition, rate cuts are still on the table, especially after weaker-than-expected private sector jobs growth, retail sales, and consumer confidence. Plus, we strongly believe the worst of the volatility for 2025 is now behind us, as investors start to look ahead to 2026 and start to price in continued earnings growth and artificial intelligence excitement. Even better, analysts still like what they‚Äôre seeing in the markets, upgrading: Analysts at Morgan Stanley just reiterated an overweight rating on Nvidia (NASDAQ: NVDA), with a $250 price target. The firm says NVDA will maintain a dominant market share and that threats are becoming overstated. ‚ÄúWe continue to see NVIDIA maintaining dominant market share, as threats are becoming overstated, though we aren‚Äôt sure exactly what will turn sentiment around,‚Äù they said, as quoted by CNBC. ‚ÄúCustomers‚Äô biggest anxiety for the next 12 months is their ability to procure enough NVIDIA product generally, and Vera Rubin specifically.‚Äù Analysts at Guggenheim say Alphabet (NASDAQ: GOOG) could run even higher. The firm raised its price target on GOOG to $375 from $330 with a buy rating. The firm is confident in Alphabet because of strong cloud backlog growth, which is being supported by enterprise AI demand. It‚Äôs also confidence with Google Gemini‚Äôs rise as a leading AI platform with rapidly growing adoption metrics, as noted by CNBC. Analysts at Goldman Sachs just added Wynn to its conviction buy list. The firm is confident with Wynn‚Äôs (NASDAQ: WYNN) ‚ÄúWynn Al Marjan in the UAE in 1Q27, plus WYNN‚Äôs best-in-class Las Vegas assets, leverage to a higher-income consumers, a strong 2026 Las Vegas event calendar, and an improving backdrop in Macau should drive transformative upside at WYNN,‚Äù as quoted by CNBC. Latest Podcast Episode Amazon Strikes Back, And A Surprise $10,000 Portfolio Buy 38 min See us invest in our favorite AI stock ideas for free Live Dec 1, 2025 Nov 9, 2025 Analysts are doubling down on market leaders, with fresh upgrades for Nvidia, AMD, Walmart, Amazon, and Broadcom. Firms like Cantor‚Ä¶ UBS is bullish on Applied Materials (NASDAQ: AMAT). Just this morning, the firm upgraded AMAT to a buy rating with‚Ä¶ Analysts are pounding the table over Tesla (NASDAQ: TSLA). In fact, Wedbush just reiterated an outperform rating on the tech‚Ä¶ The broad markets are mixed to kick off trading today. S&P 500 down -0.10% Dow Jones Industrial Average up 0.13%‚Ä¶ The pullback is getting worse for markets. The S&P 500 is now below the 50-day moving average, which has been‚Ä¶ With AI bubble talk, markets are swimming in red. However, that‚Äôs not stopping analysts from pounding the table over stocks‚Ä¶ Even with the trade war and a high likelihood that the government won‚Äôt open until after Thanksgiving, markets are still‚Ä¶ Analysts are still upgrading Nvidia heading into earnings. Just today, analysts at William Blair reiterated an outperform rating on Nvidia‚Ä¶ Live Updates Get The Best NVIDIA Live Earnings Coverage Like This Every Quarter Get earnings reminders, our top analysis on‚Ä¶
--------------------------------------------------

Title: US stock market crashes today: Dow, S&P 500, Nasdaq all in red ‚Äî Is Wall Street‚Äôs December rally already breaking as crypto tumbles?
URL: https://economictimes.indiatimes.com/news/international/us/us-stock-market-crashes-today-dow-sp-500-nasdaq-all-in-red-is-wall-streets-december-rally-already-breaking-as-crypto-tumbles/articleshow/125697378.cms
Time Published: 2025-12-01T15:05:04Z
Full Content:
US stock market crashes today as the Dow drops 127 points, the S&P 500 slips 29 points, and the Nasdaq sinks 161 points. Tech and crypto stocks drag markets lower. Bitcoin‚Äôs fall hits Bitfarms and Cleanspark. Nvidia, Snap, and Intel also decline. Q32 Bio and AHMA surge on heavy volume. December starts with weak sentiment and rising volatility. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. Explore More Stories Amazon warns over 300 million users of major Black Friday impersonation scams targeting personal data What is Canada‚Äôs new colour-coded alert system and how it will ensure public safety during extreme weather Canada launches new alert system for extreme weather; Colour-coded system marks shift to impact-based forecasting Canadian Olympic swimming champion Penny Oleksiak suspended for two years over anti-doping whereabouts failures Who is Colleen Jones? Two-time World champion curler and veteran Canadian broadcaster dies at 65 What exactly is the Canada Pension Plan? New CPP payments rolling out nationwide on November 26; Check all the payment dates of 2025-26 - Why is Quebec not part of CPP? Madeleine Poulin, Radio-Canada‚Äôs first female correspondent in Ottawa and Paris, dies at 87 Yoplait recalls 'Yop yogurt' drinks in Canada over plastic contamination fears under Class 1 category - Check out which flavor and best-before dates beverage are subject to recall CMA Awards: Vince Gill honored with prestigious Willie Nelson Lifetime Achievement Award at 59th CMA Awards in Tennessee MGK rocks Canadian fans with explosive Grey Cup halftime show; Are Megan Fox, MGK really working on their relationship post daughter‚Äôs birth? Roughriders end 12-year drought, beat Alouettes for 5th Grey Cup title Who is Dr Sanjeev Sirpal? Trouble mounts for New Brunswick doctor accused of sexual assault in hospitals as he faces additional charges; what do we know so far Russian humanoid robot 'AIDOL' shockingly faceplants during much-hyped public debut - WATCH NHRC issues notice to Railways over Bhopal complaint on halal-only non-veg train meals EC extends voter roll revision; Oppn calls the exercise ‚Äòimpossible, irresponsible...‚Äô NC‚Äôs Md. Ramzan, part of INDIA bloc says J&K polls were 'most fair' Rajya Sabha clash: Kharge vs Rijiju over Dhankar's exit PM welcomes new Rajya Sabha Chairman CP Radhakrishnan MPs react to Modi‚Äôs ‚ÄòNo Drama‚Äô call; Congress pushes for SIR debate ‚ÄòNot drama, need delivery‚Äô: PM urges oppn to focus on strong issues Winter session: ‚ÄòSin Goods‚Äô tax among 13 bills; oppn ready for SIR fight Ramaphosa rejects Trump‚Äôs threat to bar S Africa from G20 'Should throw her hell out of...': Trump hits out at Ilhan Omar NHRC issues notice to Railways over Bhopal complaint on halal-only non-veg train meals EC extends voter roll revision; Oppn calls the exercise ‚Äòimpossible, irresponsible...‚Äô NC‚Äôs Md. Ramzan, part of INDIA bloc says J&K polls were 'most fair' Rajya Sabha clash: Kharge vs Rijiju over Dhankar's exit PM welcomes new Rajya Sabha Chairman CP Radhakrishnan MPs react to Modi‚Äôs ‚ÄòNo Drama‚Äô call; Congress pushes for SIR debate ‚ÄòNot drama, need delivery‚Äô: PM urges oppn to focus on strong issues Winter session: ‚ÄòSin Goods‚Äô tax among 13 bills; oppn ready for SIR fight Ramaphosa rejects Trump‚Äôs threat to bar S Africa from G20 'Should throw her hell out of...': Trump hits out at Ilhan Omar Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Slideshow Top Prime Articles Top Definitions Most Searched IFSC Codes Top Story Listing Private Companies Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Stories you might be interested in
--------------------------------------------------

Title: Michael Burry says Tesla is 'ridiculously overvalued,' slams Musk pay package
URL: https://finance.yahoo.com/news/michael-burry-says-tesla-is-ridiculously-overvalued-slams-musk-pay-package-150113993.html
Time Published: 2025-12-01T15:01:13Z
Description: Short seller Michael Burry just took a swipe at another richly valued stock: Tesla.
--------------------------------------------------

Title: AI Leader Nvidia Invests $2 Billion In Chip Design Firm Synopsys
URL: https://www.investors.com/news/technology/nvidia-stock-synopsys-stock-engineering-marketing-partnership/
Time Published: 2025-12-01T13:58:45Z
Description: Artificial intelligence chip maker Nvidia announced a $2 billion investment in electronic design automation firm Synopsys.
--------------------------------------------------

Title: Why Bitcoin price (BTC USD) crashed today: December crypto market sell-off reasons explained
URL: https://economictimes.indiatimes.com/news/international/us/bitcoin-price-crash-today-btc-usd-crash-why-crypto-market-falling-sell-off-reason-explained/articleshow/125695814.cms
Time Published: 2025-12-01T13:50:00Z
Full Content:
Bitcoin price crash today: Cryptocurrencies experienced significant declines on the first trading day of December, with Bitcoin dropping 5% and other major coins like Ethereum and Solana also falling. This downturn is attributed to Federal Reserve interest rate uncertainty and volatility in AI stocks, impacting investor sentiment and leading to broad selling pressure across the crypto market. Listen to this article in summarized format Unlock AI Briefing and Premium Content Bitcoin price USD crash 2025 (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. Chinese spy ships have entered Indian Ocean? Navy chief Tripathi clarifies ‚ÄòSea will drive India‚Äôs to $5 trillion economy‚Äô: Navy Chief 'Love lost over caste': Mah woman uses bf‚Äôs blood as vermilion, accuses cops of provocation Govt tables sin tax bill in Lok Sabha, tobacco products to be dearer now NHRC issues notice to Railways over Bhopal complaint on halal-only non-veg train meals EC extends voter roll revision; Oppn calls the exercise ‚Äòimpossible, irresponsible...‚Äô NC‚Äôs Md. Ramzan, part of INDIA bloc says J&K polls were 'most fair' Rajya Sabha clash: Kharge vs Rijiju over Dhankar's exit PM welcomes new Rajya Sabha Chairman CP Radhakrishnan MPs react to Modi‚Äôs ‚ÄòNo Drama‚Äô call; Congress pushes for SIR debate Chinese spy ships have entered Indian Ocean? Navy chief Tripathi clarifies ‚ÄòSea will drive India‚Äôs to $5 trillion economy‚Äô: Navy Chief 'Love lost over caste': Mah woman uses bf‚Äôs blood as vermilion, accuses cops of provocation Govt tables sin tax bill in Lok Sabha, tobacco products to be dearer now NHRC issues notice to Railways over Bhopal complaint on halal-only non-veg train meals EC extends voter roll revision; Oppn calls the exercise ‚Äòimpossible, irresponsible...‚Äô NC‚Äôs Md. Ramzan, part of INDIA bloc says J&K polls were 'most fair' Rajya Sabha clash: Kharge vs Rijiju over Dhankar's exit PM welcomes new Rajya Sabha Chairman CP Radhakrishnan MPs react to Modi‚Äôs ‚ÄòNo Drama‚Äô call; Congress pushes for SIR debate Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Prime Articles Top Slideshow Top Commodities Private Companies Top Story Listing Top Definitions Most Searched IFSC Codes Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Stories you might be interested in
--------------------------------------------------

Title: The Energy Breakthrough That Could Power the AI Era
URL: https://financialpost.com/globe-newswire/the-energy-breakthrough-that-could-power-the-ai-era-2
Time Published: 2025-12-01T13:31:08Z
Description: This article has been disseminated on behalf of MAX Power Mining Corp. and may include a paid advertisement. AUSTIN, Texas, Dec. 01, 2025 (GLOBE NEWSWIRE) ‚Äî MiningNewsWire Editorial Coverage: Global electricity demand is entering a historic inflection point. ‚Ä¶
--------------------------------------------------

Title: The Energy Breakthrough That Could Power the AI Era
URL: https://www.globenewswire.com/news-release/2025/12/01/3197002/0/en/The-Energy-Breakthrough-That-Could-Power-the-AI-Era.html
Time Published: 2025-12-01T13:30:00Z
Full Content:
December 01, 2025 08:30 ET | Source: MiningNewsWire MiningNewsWire This article has been disseminated on behalf of MAX Power Mining Corp. and may include a paid advertisement. AUSTIN, Texas, Dec. 01, 2025 (GLOBE NEWSWIRE) -- MiningNewsWire Editorial Coverage: Global electricity demand is entering a historic inflection point. The International Energy Agency (IEA) now forecasts that worldwide data center electricity consumption will nearly double by 2030, with AI-driven centers multiplying their energy use more than four-fold over the same period, a pace that strains already overloaded grids across the United States, China, Europe, Southeast Asia and elsewhere. The constraint is no longer bandwidth or chip capability ‚Äî it is electricity itself. Amid this tightening energy landscape, a compelling new frontier is emerging natural hydrogen, a geologic form of hydrogen being generated continuously within the Earth‚Äôs subsurface. Unlike manufactured hydrogen, geologic hydrogen can be produced without electrolysis and emits only water when used for energy production. It may represent the first scalable, low-carbon baseload power source for AI-era demand. That is why MAX Power Mining Corp. (OTC: MAXXF) (CSE: MAXX) (profile) has become the first publicly traded company in North America to advance a massive land package (1.3 million acres) permitted specifically for natural hydrogen exploration and development, including a commercial-scale natural hydrogen well, positioning itself at the forefront of a new energy class. MAX Power is working to establish itself as a leader among well-known companies that are innovating and leading in the AI space, including Microsoft Corporation (NASDAQ: MSFT), Apple Inc. (NASDAQ: AAPL), NVIDIA Corporation (NASDAQ: NVDA) and Alphabet Inc. (NASDAQ: GOOG).Disclosure: This does not represent material news, partnerships, or investment advice. Click here to view the custom infographic of the MAX Power Mining Corp. editorial. The Global Energy Crunch Meets a New ResourceArtificial intelligence is expanding at a pace that far exceeds the design capacity of existing electricity systems. In addition to IEA‚Äôs forecast, Bloomberg projections suggest that U.S. data centers alone could consume as much as 9% of all American electricity by 2035, a dramatic increase that underscores the shifting energy footprint of digital infrastructure. The IEA also reports that per-capita U.S. data-center usage could reach 1,200 kilowatt-hours per year, greatly surpassing consumption levels in most other countries and highlighting the intense energy requirements of emerging technologies. Hydrogen is often highlighted as a key decarbonization tool, yet nearly 99% of global hydrogen production comes from fossil fuels, resulting in significant emissions and high costs. Green hydrogen, while cleaner, requires large amounts of renewable electricity and is expensive to scale. This widening mismatch between electricity supply and clean-energy demand is prompting rapid scientific and commercial interest in geologic hydrogen. Unlike manufactured hydrogen, natural hydrogen arises from water‚Äìrock interactions, tectonic processes, and mineral reactions occurring deep underground. The U.S. Geological Survey and other research groups have noted that naturally occurring hydrogen may be far more abundant than previously understood, describing natural hydrogen as a possible near-limitless clean fuel generated by Earth itself. Investors are also taking notice. CNBC reports that Bill Gates and Jeff Bezos have backed Koloma, one of the leading natural hydrogen exploration companies, calling the emerging field a gold hydrogen rush. Natural hydrogen offers logistical advantages as well. If sourced near industrial corridors or AI compute clusters, it can serve as a continuous, on-site baseload power source. This would reduce the need for extensive transmission infrastructure and enable operators to place computing power directly above their energy source. For the first time, a clean and potentially low-cost resource may be emerging that aligns with the unprecedented demands of modern computing and electrification. MAX Power Delivers a Historic Milestone As scientific interest grows, MAX Power has made a landmark contribution by delivering the most extensive subsurface indications of natural hydrogen ever recorded in Canada, and potentially the first large-scale commercial discovery globally. This achievement marks a significant step forward for natural hydrogen development globally and positions North America as the breakout leader for hydrogen-focused geological study. MAX Power controls approximately 1.3 million acres of permitted land in Saskatchewan. The region has been studied for its subsurface gas potential, including helium and hydrogen precursors that form in geological systems known to generate natural hydrogen. Through these holdings, the company has successfully drilled North America‚Äôs first commercial-scale well dedicated to evaluating natural hydrogen at depth. Saskatchewan‚Äôs geological environment, with its mix of sedimentary basins, fault systems, and reactive rock formations, provides a strong basis for exploration. Government and academic institutions have noted that these subsurface conditions may be conducive to hydrogen generation. MAX Power‚Äôs approach focuses on testing these zones directly rather than relying solely on geological modeling. This form of empirical measurement represents an important advance, as it provides real data that can be used to validate long-standing scientific theories. The company‚Äôs early findings highlight why the region may have significant potential and why global attention is turning toward places with large-scale land packages capable of hosting hydrogen systems. The Lawson Well: From Theory to Measured Evidence MAX Power‚Äôs Lawson well provides the first technical data set confirming the presence of natural hydrogen in the Canadian subsurface. The company reported natural hydrogen across multiple horizons, supported by gas sampling, chemical analysis and downhole logging tools capable of identifying trace hydrogen concentrations. These indicators are significant because they move natural hydrogen from theoretical potential to measurable evidence within the region. Prior to this work, much of the scientific understanding relied on surface seeps and global analogs. The Lawson results demonstrate that hydrogen may be present in multiple geological layers, broadening the scope for future exploration. The data sets collected from Lawson will be among the most comprehensive ever assembled for natural hydrogen anywhere in the world. This includes gas-geochemical measurements, core and cuttings analysis, and structural data that may help map hydrogen migration pathways. These findings will influence the design of future wells, including decisions about target depth, casing, and resource evaluation strategies. Independent analysis is currently underway by third-party scientific institutions. These assessments will help determine whether the hydrogen observed corresponds to deeper, potentially productive reservoirs. Confirmation of such systems would strengthen the case for developing a broader natural hydrogen industry in Saskatchewan. If follow-up wells exhibit similar results, Canada could become the first region in North America to establish a commercial natural hydrogen basin. The Genesis Trend: A Potential Basin-Scale System MAX Power‚Äôs exploration footprint includes the Genesis Trend, a minimum 300-mile geological corridor that extends from Saskatchewan into Montana and the Dakotas. The Genesis Trend contains structural features and rock types associated with hydrogen generation in other parts of the world, including deep crustal faults, reactive ultramafic rocks and pathways for fluid movement. MAX Power‚Äôs permitted acreage across the province spans 1.3 million acres, with an additional 5.7 million acres under review, creating the opportunity to evaluate whether the region hosts a large-scale hydrogen system. A second fully funded well, located approximately 200 miles from the Lawson site, is expected to soon test a different structural region. If drilling in this area reveals similar hydrogen signatures, it would greatly strengthen the interpretation that Saskatchewan may contain a basin-wide hydrogen system rather than isolated pockets. This kind of large-scale potential aligns with global research published in ‚ÄúScience Advances,‚Äù which describes how tectonically active geological settings can generate sustained hydrogen through ongoing rock-water reactions. Continuous hydrogen generation is considered one of the most compelling features of natural hydrogen systems. Unlike fossil fuels, which take millions of years to accumulate and are finite, geologic hydrogen may be produced continuously by Earth‚Äôs internal processes. If commercial flow rates are established, this could create a renewable-like energy resource with implications for grid baseload supply and industrial energy use. Leading Global Scientists Join the Effort MAX Power has attracted collaboration from respected scientific institutions as interest in natural hydrogen grows. According to company reports, experts from the Petroleum Technology Research Centre, the University of Regina, the Saskatchewan Geological Survey, and the Colorado School of Mines recently visited the Lawson site and are participating in data analysis. The involvement of these organizations lends credibility to MAX Power‚Äôs findings and strengthens the scientific understanding of natural hydrogen systems in Canada. These groups bring expertise in subsurface analysis, basin modeling, mineralogy, and gas characterization, all disciplines essential to determining whether hydrogen accumulations could become commercially viable. The Petroleum Technology Research Centre is well known for its work in subsurface resource evaluation, including carbon capture and geological storage. The University of Regina and Saskatchewan Geological Survey contribute regional geological knowledge and scientific rigor into the study of hydrogen-bearing formations. Specialists from the Colorado School of Mines add further insight from global research programs examining natural hydrogen potential. This multi-institution approach ensures that the data collected is interpreted using internationally recognized scientific standards. It also helps support Canada‚Äôs emergence as a research hub for geologic hydrogen, especially as global interest expands in response to the world‚Äôs increasing energy challenges. Leadership Aligns with Pivotal Moment MAX Power recently appointed Ran Narayanasamy as chief executive officer, bringing nearly two decades of experience from SaskPower and leadership at the Petroleum Technology Research Centre. His background in energy systems, subsurface research, and transition planning provides the company with expertise aligned to the technical and regulatory demands of natural hydrogen development. Narayanasamy‚Äôs long-standing relationships across energy, academic and government sectors may help accelerate the company‚Äôs progress as it advances Canada‚Äôs first dedicated natural hydrogen well. His leadership arrives at a critical moment, as the company transitions from early scientific confirmation toward testing commercial viability. As the first-mover public company in this space, MAX Power holds approximately 1.3 million permitted acres in Saskatchewan and has identified multiple high-priority targets. The company has drilled Canada‚Äôs first deep well specifically designed to evaluate natural hydrogen as a commercial resource. If these efforts confirm consistent flow rates, natural hydrogen could become a significant new source of clean baseload power positioned directly near industrial centers and agricultural corridors. The implications of such a discovery would be substantial. Natural hydrogen could complement or even replace some manufactured hydrogen pathways, offering cleaner production and potentially lower costs. The combination of scientific progress, expanding technical datasets, and strengthened executive leadership positions MAX Power at the forefront of an evolving clean-energy sector. With growing interest from policymakers, researchers and global investors alike, the company‚Äôs development timeline coincides with what may be the early stage of the next major energy transition. AI Leaders Advance Next-Generation Intelligent Technologies Across the global technology landscape, leading innovators continue to push the boundaries of what artificial intelligence can deliver. New breakthroughs in enterprise automation, chip architecture, generative-AI development and multimodal reasoning are reshaping how organizations operate and how individuals interact with digital tools. Microsoft Corporation (NASDAQ: MSFT) was named a leader in the first AI-centric IDC MarketScape: Worldwide AI-Enabled Large Enterprise ERP Applications 2025 Vendor Assessment. Microsoft believes this recognition highlights the strength of Dynamics 365, particularly its Copilot and agent capabilities, redefining procure-to-pay and record-to-report processes with intelligent automation, predictive insights and streamlined integration. Apple Inc. (NASDAQ: AAPL) has launched M5, delivering the next big leap in AI performance and advances to nearly every aspect of the chip. Built using third-generation 3-nanometer technology, M5 introduces a next-generation 10-core GPU architecture with a Neural Accelerator in each core, enabling GPU-based AI workloads to run dramatically faster, with more than four times the peak GPU compute performance compared to M4.1. NVIDIA Corporation (NASDAQ: NVDA) has released NVIDIA Blueprints, which include everything an enterprise developer needs to build and deploy customized generative AI applications that make a transformative impact on business objectives. NVIDIA Blueprints are reference AI workflows tailored for specific use cases. They include sample applications built with NVIDIA NIM and partner microservices, reference code, customization documentation and a Helm chart for deployment. Alphabet Inc. (NASDAQ: GOOG) has announced Gemini 3, the best model in the world for multimodal understanding and the company‚Äôs most powerful agentic and vibe coding model. Gemini 3 delivers richer visualizations and deeper interactivity, all built on a foundation of state-of-the-art reasoning. The company is releasing Gemini 3 Pro in preview and making it available across a suite of Google products so users can use it in their daily lives to learn, build and plan anything. As these advancements move from research labs into everyday products and workflows, the possibilities for transformation expand dramatically. The latest wave of AI-driven systems promises faster insights, more intuitive user experiences, and powerful new foundations for innovation. Together, these developments signal a future in which intelligent technologies play an increasingly central role in how businesses grow, create, and solve complex challenges. For further information about MAX Power Mining Corp., visit the MAX Power Mining profile. About MiningNewsWire MiningNewsWire (‚ÄúMNW‚Äù) is a specialized communications platform with a focus on developments and opportunities in the Global Mining and Resources sectors. It is one of 70+ brands within the Dynamic Brand Portfolio @ IBN that delivers: (1) access to a vast network of wire solutions via InvestorWire to efficiently and effectively reach a myriad of target markets, demographics and diverse industries; (2) article and editorial syndication to 5,000+ outlets; (3) enhanced press release enhancement to ensure maximum impact; (4) social media distribution via IBN to millions of social media followers; and (5) a full array of tailored corporate communications solutions. With broad reach and a seasoned team of contributing journalists and writers, MNW is uniquely positioned to best serve private and public companies that want to reach a wide audience of investors, influencers, consumers, journalists and the general public. By cutting through the overload of information in today‚Äôs market, MNW brings its clients unparalleled recognition and brand awareness.MNW is where breaking news, insightful content and actionable information converge. To receive SMS alerts from MiningNewsWire, text ‚ÄúBigHole‚Äù to 888-902-4192 (U.S. Mobile Phones Only)For more information, please visit https://www.MiningNewsWire.com Please see full terms of use and disclaimers on the MiningNewsWire website applicable to all content provided by MNW, wherever published or republished: https://www.MiningNewsWire.com/Disclaimer MiningNewsWireLos Angeles, CAwww.MiningNewsWire.com310.299.1717 OfficeEditor@MiningNewsWire.com MiningNewsWire is powered by IBN
--------------------------------------------------

Title: NVIDIA and Synopsys Announce Strategic Partnership to Revolutionize Engineering and Design
URL: https://nvidianews.nvidia.com/news/nvidia-and-synopsys-announce-strategic-partnership-to-revolutionize-engineering-and-design
Time Published: 2025-12-01T13:00:00Z
Full Content:
Key Highlights NVIDIA and Synopsys, Inc. (NASDAQ: SNPS) today announced an expanded, strategic partnership to revolutionize design and engineering across industries. R&D teams, from the semiconductor industry to aerospace, automotive, industrial and beyond, face significant engineering challenges including increasing workflow complexity, escalating development costs and time-to-market pressure. This expanded partnership will integrate the strengths of NVIDIA‚Äôs AI and accelerated computing with Synopsys‚Äô market-leading engineering solutions to deliver capabilities enabling R&D teams to design, simulate and verify intelligent products with greater precision, speed and at lower cost. In addition, NVIDIA invested $2 billion in Synopsys common stock at a purchase price of $414.79 per share. ‚ÄúCUDA GPU-accelerated computing is revolutionizing design ‚Äî enabling simulation at unprecedented speed and scale, from atoms to transistors, from chips to complete systems, creating fully functional digital twins inside the computer,‚Äù said Jensen Huang, founder and CEO of NVIDIA. ‚ÄúOur partnership with Synopsys harnesses the power of NVIDIA accelerated computing and AI to reimagine engineering and design ‚Äî empowering engineers to invent the extraordinary products that will shape our future.‚Äù ‚ÄúThe complexity and cost of developing next-generation intelligent systems demands engineering solutions with a deeper integration of electronics and physics, accelerated by AI capabilities and compute. No two companies are better positioned to deliver AI-powered, holistic system design solutions than Synopsys and NVIDIA,‚Äù said Sassine Ghazi, president and CEO of Synopsys. ‚ÄúTogether we will re-engineer engineering and empower innovators everywhere to more efficiently realize their innovations.‚Äù Joint Development to Enable Future of Engineering on Accelerated Computing The multiyear partnership builds on strong, existing technology collaborations between the companies and includes the following initiatives: This partnership is not exclusive. NVIDIA and Synopsys continue to partner with the broader semiconductor and electronic design automation (EDA) ecosystem to create shared growth opportunities for the future of engineering and design. Press Conference: The CEOs of NVIDIA and Synopsys will conduct a webcast press conference today at 7 a.m. PST (10 a.m. EST) to discuss the announcement. The webcast will be available for the public to listen in here: https://events.q4inc.com/attendee/183492820 About NVIDIA NVIDIA (NASDAQ: NVDA) is the world leader in AI and accelerated computing. NVIDIA Forward-Looking Statements Certain statements in this press release including, but not limited to, statements as to: CUDA GPU-accelerated computing revolutionizing design ‚Äî enabling simulation at unprecedented scale, from atoms to transistors, from chips to complete systems, creating fully functional digital twins inside the computer; NVIDIA‚Äôs partnership with Synopsys harnessing the power of NVIDIA accelerated computing and AI to reimagine engineering and design ‚Äî empowering engineers to explore more ideas, simulate faster, and invent the extraordinary products that will shape the future; expectations with respect to growth, performance and benefits of NVIDIA‚Äôs products, services, and technologies, and related trends and drivers; expectations with respect to supply and demand for NVIDIA‚Äôs products, services, and technologies; expectations with respect to NVIDIA‚Äôs third party arrangements, including with its collaborators and partners; expectations with respect to technology developments and related trends and drivers; expectations with respect to market growth and trends; expectations with respect to AI and related industries; and other statements that are not historical facts are forward-looking statements within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended, which are subject to the ‚Äúsafe harbor‚Äù created by those sections based on management‚Äôs beliefs and assumptions and on information currently available to management and are subject to risks and uncertainties that could cause results to be materially different than expectations. Important factors that could cause actual results to differ materially include: global economic and political conditions; our reliance on third parties to manufacture, assemble, package and test our products; the impact of technological development and competition; development of new products and technologies or enhancements to our existing product and technologies; market acceptance of our products or our partners‚Äô products; design, manufacturing or software defects; changes in consumer preferences or demands; changes in industry standards and interfaces; unexpected loss of performance of our products or technologies when integrated into systems; and changes in applicable laws and regulations, as well as other factors detailed from time to time in the most recent reports NVIDIA files with the Securities and Exchange Commission, or SEC, including, but not limited to, its annual report on Form 10-K and quarterly reports on Form 10-Q. Copies of reports filed with the SEC are posted on the company‚Äôs website and are available from NVIDIA without charge. These forward-looking statements are not guarantees of future performance and speak only as of the date hereof, and, except as required by law, NVIDIA disclaims any obligation to update these forward-looking statements to reflect future events or circumstances. ¬© 2025 NVIDIA Corporation. All rights reserved. NVIDIA, the NVIDIA logo, CUDA-X, NVIDIA Cosmos, NVIDIA NeMo, Nemotron, NVIDIA NIM and NVIDIA Omniverse are trademarks and/or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated. Features, pricing, availability and specifications are subject to change without notice. About Synopsys Synopsys, Inc. (Nasdaq: SNPS) is the leader in engineering solutions from silicon to systems, enabling customers to rapidly innovate AI-powered products. We deliver industry-leading silicon design, IP, simulation and analysis solutions, and design services. We partner closely with our customers across a wide range of industries to maximize their R&D capability and productivity, powering innovation today that ignites the ingenuity of tomorrow. Learn more at www.synopsys.com. ¬© 2025 Synopsys, Inc. All rights reserved. Synopsys, Ansys, the Synopsys and Ansys logos, and other Synopsys trademarks are available at https://www.synopsys.com/company/legal/trademarks-brands.html. Other company or product names may be trademarks of their respective owners. Synopsys Forward-Looking Statements This press release includes certain forward-looking statements regarding the demand and market outlook, products, business, strategies and opportunities of Synopsys and NVIDIA, including the benefits, impact and performance of NVIDIA‚Äôs AI and accelerated computing platform and Synopsys‚Äô engineering solutions; Synopsys and NVIDIA‚Äôs collaboration efforts to redesign engineering and design across industries; expectations regarding the anticipated benefits of the multi-year partnership and specific initiatives, including for engineering teams and customers; expectations regarding the ability to harness AI efficiencies; and expectations with respect to technology developments and trends. These statements involve risks, uncertainties and other factors that could cause actual results, time frames or achievements to differ materially from those expressed or implied in such forward-looking statements. Such risks, uncertainties and factors include but are not limited to macroeconomic environment and global economic conditions; NVIDIA‚Äôs reliance on third parties to manufacture, assemble, package and test its products; the impact of technological development and competition; development of new products and technologies or enhancements to Synopsys‚Äô and NVIDIA‚Äôs existing product and technologies; market acceptance of Synopsys‚Äô, NVIDIA‚Äôs or their partners‚Äô products; changes in consumer preferences or demands; changes in industry standards and interfaces; and changes in applicable laws and regulations, including the impact of China export control restrictions; and the risks more fully described in filings Synopsys and NVIDIA make with the SEC from time to time, including in the ‚ÄúRisk Factors‚Äù section of their respective Annual Reports on Form 10-K, Quarterly Reports on Form 10-Q and other documents filed by either of them from time to time with the SEC. The information provided herein is as of the date hereof. Synopsys and NVIDIA assume no obligation and do not intend to update or revise any forward-looking statement, whether as a result of new information, future events or otherwise, unless required by law. Neither Synopsys nor NVIDIA gives any assurance that either Synopsys or NVIDIA will achieve its expectations. Many of the features and products described herein remain in various stages and will be offered on a when-and-if-available basis. The statements above are not intended to be, and should not be interpreted as a commitment, promise, or legal obligation, and the development, release, and timing of any features or functionalities described are subject to change and remains at the sole discretion of Synopsys. Synopsys will have no liability for failure to deliver or delay in the delivery of any of the products, features or functions set forth herein.
--------------------------------------------------

Title: US stock futures drift lower as Dow, S&P 500, Nasdaq slip today: Here are the top gainers and losers shaping Wall Street, with big earnings on deck
URL: https://economictimes.indiatimes.com/news/international/us/us-stock-futures-drift-lower-as-dow-sp-500-nasdaq-slip-today-here-are-the-top-gainers-and-losers-shaping-wall-street-with-big-earnings-on-deck/articleshow/125692196.cms
Time Published: 2025-12-01T10:49:30Z
Full Content:
US stock futures fell early Monday, with the Dow down 191 points, the S&P 500 off 37 points, and the Nasdaq lower by 171.50 points as yields hovered near 4.04%. NIO dropped 4%, Nvidia slipped 1.05%, and crypto miners tumbled. INVO Fertility jumped 16.7% and Twin Vee gained 7.34%. Markets await key tech earnings and the Fed‚Äôs rate decision. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. Explore More Stories Amazon warns over 300 million users of major Black Friday impersonation scams targeting personal data What is Canada‚Äôs new colour-coded alert system and how it will ensure public safety during extreme weather Canada launches new alert system for extreme weather; Colour-coded system marks shift to impact-based forecasting Canadian Olympic swimming champion Penny Oleksiak suspended for two years over anti-doping whereabouts failures Who is Colleen Jones? Two-time World champion curler and veteran Canadian broadcaster dies at 65 What exactly is the Canada Pension Plan? New CPP payments rolling out nationwide on November 26; Check all the payment dates of 2025-26 - Why is Quebec not part of CPP? Madeleine Poulin, Radio-Canada‚Äôs first female correspondent in Ottawa and Paris, dies at 87 Yoplait recalls 'Yop yogurt' drinks in Canada over plastic contamination fears under Class 1 category - Check out which flavor and best-before dates beverage are subject to recall CMA Awards: Vince Gill honored with prestigious Willie Nelson Lifetime Achievement Award at 59th CMA Awards in Tennessee MGK rocks Canadian fans with explosive Grey Cup halftime show; Are Megan Fox, MGK really working on their relationship post daughter‚Äôs birth? Roughriders end 12-year drought, beat Alouettes for 5th Grey Cup title Who is Dr Sanjeev Sirpal? Trouble mounts for New Brunswick doctor accused of sexual assault in hospitals as he faces additional charges; what do we know so far Russian humanoid robot 'AIDOL' shockingly faceplants during much-hyped public debut - WATCH NC‚Äôs Md. Ramzan, part of INDIA bloc says J&K polls were 'most fair' Rajya Sabha clash: Kharge vs Rijiju over Dhankar's exit PM welcomes new Rajya Sabha Chairman CP Radhakrishnan MPs react to Modi‚Äôs ‚ÄòNo Drama‚Äô call; Congress pushes for SIR debate ‚ÄòNot drama, need delivery‚Äô: PM urges oppn to focus on strong issues Winter session: ‚ÄòSin Goods‚Äô tax among 13 bills; oppn ready for SIR fight Ramaphosa rejects Trump‚Äôs threat to bar S Africa from G20 'Should throw her hell out of...': Trump hits out at Ilhan Omar Delhi Police bust Pakistan-backed module Parliament Winter Session | Kiren Rijiju says opposition wants SIR debate NC‚Äôs Md. Ramzan, part of INDIA bloc says J&K polls were 'most fair' Rajya Sabha clash: Kharge vs Rijiju over Dhankar's exit PM welcomes new Rajya Sabha Chairman CP Radhakrishnan MPs react to Modi‚Äôs ‚ÄòNo Drama‚Äô call; Congress pushes for SIR debate ‚ÄòNot drama, need delivery‚Äô: PM urges oppn to focus on strong issues Winter session: ‚ÄòSin Goods‚Äô tax among 13 bills; oppn ready for SIR fight Ramaphosa rejects Trump‚Äôs threat to bar S Africa from G20 'Should throw her hell out of...': Trump hits out at Ilhan Omar Delhi Police bust Pakistan-backed module Parliament Winter Session | Kiren Rijiju says opposition wants SIR debate Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Commodities Top Story Listing Top Prime Articles Top Definitions Top Slideshow Private Companies Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Stories you might be interested in
--------------------------------------------------

Title: Stock market today: Dow, S&P 500, Nasdaq futures retreat from rally in downbeat start to December
URL: https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-futures-retreat-from-rally-in-downbeat-start-to-december-011408498.html
Time Published: 2025-12-01T01:14:08Z
Description: Wall Street's strong late-November rebound looks set to hit a speed bump on the first trading day of December.
--------------------------------------------------

Title: Stock market today: Dow, S&P 500, Nasdaq futures sink, bitcoin plummets in downbeat start to December
URL: https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-futures-sink-bitcoin-plummets-in-downbeat-start-to-december-011408181.html
Time Published: 2025-12-01T01:14:08Z
Description: Wall Street's strong late-November rebound looks set to hit a speed bump on the first trading day of December.
--------------------------------------------------

Title: These 5 charts hint at where stocks might go next after a wild November for the market
URL: https://www.marketwatch.com/story/these-5-charts-hint-at-where-stocks-might-go-next-after-a-wild-november-for-the-market-47fd5583
Time Published: 2025-11-30T17:00:00Z
Description: November historically has been a strong month for the U.S. stock market. This year‚Äôs gains didn‚Äôt come easy.
--------------------------------------------------

Title: Experts Weigh In: Can Apple‚Äôs Stock Inch Past $300 per Share Before Year‚Äôs End?
URL: https://finance.yahoo.com/news/experts-weigh-apple-stock-inch-153905971.html
Time Published: 2025-11-30T15:39:05Z
Description: Apple shares have been surging lately. But can they reach $300 before 2025 ends? Analysts reveal some key factors that could drive Apple‚Äôs next big move.
--------------------------------------------------

Title: Stocks drift back toward record highs as the final month of 2025 gets underway: What to watch this week
URL: https://finance.yahoo.com/news/stocks-drift-back-toward-record-highs-as-the-final-month-of-2025-gets-underway-what-to-watch-this-week-122743521.html
Time Published: 2025-11-30T12:27:43Z
Description: As the market moves into December, investors will be watching for Fed updates and a steadier performance environment than they got in November.
--------------------------------------------------

Title: Google TPUv7: ‚Äúperf per TCO advantage of TPUs is so strong that you already get the gains from adopting TPUs even before turning one on‚Äù
URL: https://newsletter.semianalysis.com/p/tpuv7-google-takes-a-swing-at-the
Time Published: 2025-11-30T05:47:02Z
Full Content:
The two best models in the world, Anthropic‚Äôs Claude 4.5 Opus and Google‚Äôs Gemini 3 have the majority of their training and inference infrastructure on Google‚Äôs TPUs and Amazon‚Äôs Trainium. Now Google is selling TPUs physically to multiple firms. Is this the end of Nvidia‚Äôs dominance? The dawn of the AI era is here, and it is crucial to understand that the cost structure of AI-driven software deviates considerably from traditional software. Chip microarchitecture and system architecture play a vital role in the development and scalability of these innovative new forms of software. The hardware infrastructure on which AI software runs has a notably larger impact on Capex and Opex, and subsequently the gross margins, in contrast to earlier generations of software, where developer costs were relatively larger. Consequently, it is even more crucial to devote considerable attention to optimizing your AI infrastructure to be able to deploy AI software. Firms that have an advantage in infrastructure will also have an advantage in the ability to deploy and scale applications with AI. Google had peddled the idea of building AI-specific infrastructure as far back as 2006, but the problem came to a boiling point in 2013. They realized they needed to double the number of datacenters they had if they wanted to deploy AI at any scale. As such, they started laying the groundwork for their TPU chips which were put into production in 2016. It‚Äôs interesting to compare this to Amazon, who in the same year, realized they needed to build custom silicon too. In 2013, they started the Nitro Program, which was focused on developing silicon to optimize general-purpose CPU computing and storage. Two very different companies optimized their efforts for infrastructure for different eras of computing and software paradigms. We‚Äôve long believed that the TPU is among the world‚Äôs best systems for AI training and inference, neck and neck with king of the jungle Nvidia. 2.5 years ago we wrote about TPU supremacy, and this thesis has proven to be very correct. TPU‚Äôs results speak for themselves: Gemini 3 is one of the best models in the world and was trained entirely on TPUs. In this report, we will talk about the huge changes in Google‚Äôs strategy to properly commercialize the TPU for external customers, becoming the newest and most threatening merchant silicon challenger to Nvidia. We plan to: (Re-)Educate our clients and new readers about the rapidly growing commercial success of external TPU customers, starting with Anthropic and extending to Meta, SSI, xAI and even potentially OpenAI... Show that: The more (TPU) you buy, the more (NVIDIA GPU capex) you save! OpenAI hasn‚Äôt even deployed TPU yet and already increased perf per TCO by getting ~30% off their compute fleet due to competitive threats Explain the circular economy deals for AI Infrastructure. Revisit our original TPU deep dive with a refresher on the TPU hardware stack from silicon down to the software layer. Cover the positive developments on the open software ecosystem front as well as the critical missing ingredient for Google to make the TPU ecosystem a viable challenger to the CUDA moat: open source their XLA:TPU compiler, runtime, and multi-pod ‚ÄúMegaScaler‚Äù code. In the paywall, we will discuss the implications for Nvidia‚Äôs moat and compare Vera Rubin to the next gen TPUv8AX/8X (aka Sunfish/Zebrafish) Also cover the long term threat to Nvidia. First, let‚Äôs talk about the impact this news has had on the ecosystem. TPU performance has clearly caught the attention of its rivals. Sam Altman has acknowledged ‚Äúrough vibes‚Äù ahead for OpenAI as Gemini has stolen the thunder from OpenAI. Nvidia even put out a reassuring PR telling everyone to keep calm and carry on ‚Äî we are well ahead of the competition. We understand why. These past few months have been win after win for the Google Deepmind, GCP, and TPU complex. The huge upwards revisions to TPU production volumes, Anthropic‚Äôs >1GW TPU buildout, SOTA models Gemini 3 and Opus 4.5 trained on TPU, and now an expanding list of clients being targeted (Meta, SSI, xAI, OAI) lining up for TPUs. This has driven a huge re-rating of the Google and TPU supply chain at the expense of the Nvidia GPU-focused supply chain. While the ‚Äúsudden‚Äù emergence of Google and the TPU supply chain has caught many by surprise, SemiAnalysis institutional product subscribers have been anticipating this for the last year. Another reason Nvidia has been on the defensive is a growing chorus of skeptics who argue the company is propping up a ‚Äúcircular economy‚Äù by funding cash-burning AI startups, essentially moving money from one pocket to another with extra steps. We think this view is misplaced, but it has clearly struck a nerve inside Nvidia. The finance team issued a detailed response, reproduced below. We think a more realistic explanation is that Nvidia aims to protect its dominant position at the foundation labs by offering equity investment rather than cutting prices, which would lower Gross margins and cause widespread investor panic. Below, we outline the OpenAI and Anthropic arrangements to show how frontier labs can lower GPU TCO by buying, or threatening to buy TPUs. OpenAI hasn‚Äôt even deployed TPUs yet and they‚Äôve already saved ~30% on their entire lab wide NVIDIA fleet. This demonstrates how the perf per TCO advantage of TPUs is so strong that you already get the gains from adopting TPUs even before turning one on. Our Accelerator Industry Model, Datacenter Industry Model and Core Research subscribers saw the industry implications well before this was announced and became market consensus. In early August, we shared with our Accelerator Model clients that we saw massive upward revisions for Broadcom / Google TPU orders in the supply chain for 2026. We also revealed that the reason for these order increases was the fact that Google would begin selling systems externally to multiple customers. In early September, we revealed that one of the big external customers will be Anthropic, with demand of at least 1 million TPUs. This was officially confirmed by Anthropic and Google in October. We also called out Meta as a big TPU customer on the 7th of November, weeks before others. In addition we have discussed other customers as well. As a result, our institutional clients have had plenty of heads up on one of the largest performance dispersions in the AI Trade to date. SemiAnalysis was the first to break all these insights because no other research firm can connect the dots from the fabs to supply chain through the datacenters to the labs. To get access to these insights as and stay ahead of the curve: sales@semianalysis.com Onto the deal. The TPU stack has long rivaled Nvidia‚Äôs AI hardware, yet it has mostly supported Google‚Äôs internal workloads. In typical Google fashion, it never fully commercialized the TPU even after making it available to GCP customers in 2018. That is starting to change. Over the past few months, Google has mobilized efforts across the whole stack to bring TPUs to external customers through GCP or by selling complete TPU systems as a merchant vendor. The search giant is leveraging its strong in-house silicon design capabilities to become a truly differentiated cloud provider. Furthermore, it aligns with marquis customer Anthropic‚Äôs continued push to diversify away from its dependence on NVDA. The Anthropic deal marks a major milestone in this push. We understand that GCP CEO Thomas Kurian played a central role in the negotiations. Google committed early by investing aggressively in Anthropic‚Äôs funding rounds, even agreeing to no voting rights and a 15% cap on their ownership to expand the use of TPUs beyond internal Google. This strategy was eased by the presence of former DeepMind TPU talent within the foundation lab, resulting in Anthropic training Sonnet and Opus 4.5 on multiple types of hardware including TPUs. Google has already built a substantial facility for Anthropic, as shown below as part of our building-by-building tracker of AI labs. Beyond renting capacity in Google datacenters through GCP, Anthropic will deploy TPUs in its own facilities, positioning Google to compete directly with Nvidia as a true merchant hardware vendor. In terms of the split of the 1M TPUs: The first phase of the deal covers 400k TPUv7 Ironwoods, worth ~$10 billion in finished racks that Broadcom will sell directly to Anthropic. Anthropic is the fourth customer referenced in Broadcom‚Äôs most recent earnings call. Fluidstack, a gold-rated ClusterMax Neocloud provider, will handle on-site setup, cabling, burn-in, acceptance testing, and remote hands work as Anthropic offloads managing physical servers. DC infrastructure will be supplied by TeraWulf (WULF) and Cipher Mining (CIFR). The remaining 600k TPUv7 units will be rented through GCP in a deal we estimate at $42 billion of RPO, accounting for most of the $49 billion increase in GCP‚Äôs backlog reported in the third quarter. We believe additional deals with Meta, OAI, SSI, and xAI could provide additional RPO + direct hardware sales for GCP in coming quarters. Despite heavy internal and external demand, Google has not been able to deploy TPUs at the pace it wants. Even though it has more control over its hardware supply than other hyperscalers that still need curry favor with Jensen, Google‚Äôs main bottleneck is power. While other hyperscalers have expanded their own sites and secured significant colocation capacity, Google has moved more slowly. We believe the core issue is contractual and administrative. Each new datacenter vendor requires a Master Services Agreement, and these are multibillion-dollar, multiyear commitments that naturally involve some bureaucracy. Yet Google‚Äôs process is especially slow, often taking up to three years from initial discussions to a signed MSA. Google‚Äôs workaround carries major implications for Neocloud providers and cryptominers looking to pivot to AI DC infrastructure. Instead of leasing directly, Google offers a credit backstop, an off-balance-sheet ‚ÄúIOU‚Äù to step in if Fluidstack cannot pay its datacenter rent. Neoclouds like Fluidstack are nimble and flexible, making it easier for them to deal with new datacenter vendors like reformed cryptominers. This mechanic has been key to our bullish views on the cryptomining industry ‚Äì notably we were calling out numerous including IREN and Applied Digital at the beginning of the year when stock prices were materially lower. The opportunity for miners rests on a simple dynamic: the datacenter industry faces acute power constraints power, and cryptominers already control capacity through their PPAs and existing electrical infrastructure. We expect many more agreements to follow in the coming weeks and quarters. Prior to the Google/Fluidstack/TeraWulf deal, we had not seen any deal with a mere off-balance-sheet ‚ÄúIOU‚Äù in the Neocloud market. After the deal, we believe it has become the new de-facto standard financing template. This solves a key headache for Neoclouds looking to secure datacenter capacity and grow their business: A GPU cluster has a useful and economic life of 4-5years A large datacenter lease is typically 15+ years, with a typical payback period of ~8 years. This duration mismatch has made it very complicated for both Neoclouds and Datacenter vendors to secure financing for projects. But with the rise of the ‚Äúhyperscaler backstop‚Äù, we believe the financing issues are solved. We expect a new wave of growth for the NeoCloud industry. Check out our Accelerator and Datacenter models to understand the key beneficiaries. These are the how‚Äôs and why‚Äôs behind the Anthropic deal, now let‚Äôs get into the hardware. Furthermore, Neoclouds who count Jensen as an investor such as CoreWeave, Nebius, Crusoe, Together, Lambda, Firmus, and Nscale all have a notable incentive to not adopt any competing technology in their datacenter: TPUs, AMD GPUs, or even Arista switches are off limits! This leaves a gaping hole in the market for TPU hosting that is currently filled by a combination of crypto miners + Fluidstack. In the coming months, we expect to see more Neoclouds make the tough decision between pursuing a growing TPU hosting opportunity and securing allocations of the latest and greatest Nvidia Rubin systems. The answer is simple. It is a strong chip inside an excellent system, and that combination offers compelling performance and TCO for Anthropic. 2.5 years ago, we wrote about Google‚Äôs compute infrastructure advantage. Even with silicon that lagged Nvidia‚Äôs on paper, Google‚Äôs system-level engineering allowed the TPU stack to match Nvidia in both performance and cost efficiency. We argued then that ‚Äúsystems matter more than microarchitecture,‚Äù and the past two years have reinforced that view. Anthropic‚Äôs massive TPU orders are a direct validation of the platform‚Äôs technical strength. The GPU ecosystem has shifted forward as well. Nvidia‚Äôs GB200 represents a major leap forward, pushing Nvidia toward becoming a true systems company that designs full servers rather than only the chip package inside. While we are on the topic of the GB200‚Äôs huge innovation in rack-scale interconnect, one underappreciated point is that Google has been scaling up TPUs within and across racks since TPU v2 back in 2017! Further down in the report, we feature a deep dive on Google‚Äôs ICI scale-up networking, the only real rival to Nvidia‚Äôs NVLink. Google‚Äôs recent Gemini 3 model is now viewed as the state of the art frontier LLM. Like all earlier versions of Gemini, it was trained entirely on TPUs. That result offers concrete proof of both TPU capability and Google‚Äôs broader infrastructure advantage. Today‚Äôs attention often centers on hardware for inference and post-training, yet pre-training a frontier model remains the hardest and most resource-intensive challenge in AI hardware. The TPU platform has passed that test decisively. This stands in sharp contrast to rivals: OpenAI‚Äôs leading researchers have not completed a successful full-scale pre-training run that was broadly deployed for a new frontier model since GPT-4o in May 2024, highlighting the significant technical hurdle that Google‚Äôs TPU fleet has managed to overcome. One of the key highlights of the new model include noticeable gains in tool calling and agentic capability, especially on longer-horizon tasks for economically valuable tasks. Vending Bench is an evaluation that aims to measure how well models would run a business over a long period of time by placing them as the owner of a simulated vending machine business and Gemini 3 destroyed the competition. This launch brought not just improved capabilities but new products. Antigravity, a product born from the acqui-hire of former Windsurf CEO Varun Mohan and team, is Google‚Äôs answer to OpenAI‚Äôs Codex, officially entering Gemini into the vibe coding token guzzling wars. For Google to quietly muscle in and establish a performance lead in one of the most challenging hardware problems is a truly impressive feat for a company whose core business isn‚Äôt, or should we say, wasn‚Äôt in hardware business. The corollary to ‚ÄúSystems matter more than Microarchitecture‚Äù, is that while Google has been pushing the boundary on system and networking design, TPU silicon itself wasn‚Äôt too ground-breaking. Since then, TPU silicon has made massive strides with the latest generations. From the outset, Google‚Äôs design philosophy has been more conservative on silicon relative to Nvidia. Historically, TPUs have shipped with significantly fewer peak theoretical FLOPs, and lower memory specs than corresponding Nvidia GPUs. There are 3 reasons for this. First, Google places a high internal emphasis on ‚ÄòRAS‚Äô (Reliability, Availability, and Serviceability) for their infrastructure. Google prefers to sacrifice absolute performance in exchange for greater hardware uptime. Running things to the limit means higher instances of hardware mortality which has a real TCO impact in terms of system downtime and hot spares. After all, the hardware you cannot use has infinite TCO relative to performance. The second reason is that up until 2023, Google‚Äôs primary AI workload was recommendation system models to power their core Search and Ad properties. RecSys workloads carry much lower arithmetic intensity compared to LLM workloads which means fewer FLOPs are required relative to every bit of data that is transferred. The third comes down to the utility of ‚Äúpeak theoretical FLOPs‚Äù numbers that are marketed and how they can be manipulated. Merchant GPU providers like Nvidia and AMD want to market the best performance specifications possible for their chips. This incentivizes them to stretch marketed FLOPs to the highest number possible. In practice, these numbers are unable to be sustained. On the other hand, the TPU has primarily been internal facing, with much less pressure to inflate these specifications externally. This has important implications that we‚Äôll discuss further. The generous way to look at it would be Nvidia is better at DVFS therefore happy to report peak specs only. After we ushered in the LLM era, there has been a clear shift in Google‚Äôs TPU design philosophy. We can see that with the 2 most recent TPU generations that were designed-post LLM: TPUv6 Trillium (Ghostlite) and TPUv7 Ironwood (Ghostfish) reflect that change. We can see in the chart below that for TPUv4 and v5, compute throughput was much lower than the Nvidia flagship at the time. TPUv6 came very close to the H100/H200 on FLOPs, but it came 2 years later than the H100. With TPU v7, the gap narrows further with servers available only a few quarters later, while delivering almost the same level of peak theoretical FLOPs. What drove these performance gains? Partially it‚Äôs that Google started announcing TPUs as they ramp into production rather then after the next generation was being deployed. Furthermore, TPU v6 Trillium is manufactured on the same N5 node as TPU v5p with similar silicon area but was able to deliver a whopping 2x increase in peak theoretical FLOPs with significantly less power! For Trillium, Google quadrupled the size of each systolic array to 256 x 256 tiles from 128 x 128, and this increase in array size is what has delivered the increase in compute. Trillium was also the last of the ‚ÄúE‚Äù (lite) SKUs which meant it was equipped with only 2 sites of HBM3. While Trillium closed the gap to Hopper on compute, it fell far short of the H100/H200 on memory capacity and bandwidth, with only 2 stacks of HBM3 vs 5 and 6 stacks of HBM3 and HBM3E respectively. This made it painful to use for novices, but the performance TCO achieved for Trillium is unbeatable if you get shard your model properly and utilize all those cheap FLOPS. TPU v7 Ironwood is the next iteration where Google nearly completely closes the gap to the corresponding Nvidia flagship GPU on FLOPs, memory, and bandwidth albeit with general availability 1 year later than Blackwell. Compared to the GB200, FLOPs and memory bandwidth only have a slight shortfall, with capacity being the same with 8-Hi HBM3E, which is of course a significant shortfall to GB300 which has 288GB of 12-Hi HBM3E. Theoretical absolute performance is one thing but what matters is real world performance per Total Cost of Ownership (TCO). While Google procures TPUs through Broadcom and pays a hefty margin, it is significantly less than the margin Nvidia earns on not only the GPUs they sell but entire the whole system including CPUs, Switches, NICs, system memory, cabling and connectors. From Google‚Äôs perspective this results in the all-in TCO per Ironwood chip for the full 3D Torus configuration being ~44% lower than the TCO of a GB200 server. This more than makes up for the ~10% shortfall on peak FLOPs and peak memory bandwidth. This is from the perspective of Google and the price they procure TPU servers at. What about Google‚Äôs external customers when Google adds their margin on top? We assume that in the case where Google earns a margin on leasing TPU 7 to external customers that the TCO per hour can still be up to ~30% lower than the cost of the GB200 and ~41% lower than the cost of the GB300. This is what we believe is reflective of Anthropic‚Äôs pricing via GCP. Comparing theoretical FLOPs tells only part of the story. What matters is effective FLOPs, since peak numbers are almost never reached in real-world workloads. In practice, Nvidia GPUs typically achieve only about a small portion of their theoretical peak once communication overhead, memory stalls, power limits, and other system effects are factored in. A good rule of thumb for training is 30%, but utilization also varies heavily by workload. A large share of the gap comes down to software and compiler efficiency. Nvidia‚Äôs advantage here stems from the CUDA moat and the wide set of open source libraries that come out of the box, helping workloads run efficiently with high realized FLOPs and memory bandwidth. The TPU software stack is not as easy to use, though this is beginning to change. Inside Google, TPUs benefit from excellent internal tooling that is not exposed to external customers, which makes out of the box performance weaker. However, this only applies to small and/or lazy users, and Anthropic is neither of those. Anthropic has strong engineering resources and ex-Google compiler experts who know both the TPU stack and understand their own model architecture well. They can invest in custom kernels to drive high TPU efficiency. As a result, they can reach substantially higher MFU and much better $/PFLOP performance. We believe that despite lower marketed peak FLOPs, TPUs can reach higher realized Model FLOP Utilization (MFU) than Blackwell, which translates into higher effective FLOPs for Ironwood. A major reason is that marketed GPU FLOPs from Nvidia and AMD are significantly inflated. Even in tests designed to maximize throughput through GEMMs shaped far from real workloads, Hopper only reached about ~80% of peak, Blackwell landed in the 70s, and AMD‚Äôs MI300 series in the 50s-60s. The limiting factor is power delivery. These chips cannot sustain the clock speeds used in the peak math. Nvidia and AMD implement Dynamic Voltage and Frequency Scaling which means that the chip‚Äôs clock frequency is dynamically adjusted based on power consumption and thermals rather than a stable clock frequency that can actually be sustained. Nvidia and AMD then select the highest clock frequency that could possibly be delivered, even if very intermittently, to be used in the calculation of peak theoretical FLOPs (operations per cycle per ALU x number of ALUs x cycles per second i.e. clock frequency). There are other tricks that are employed, like running GEMMs on tensors filled with zeroes, as 0x0=0, the transistors don‚Äôt need to switch state from 0 to 1, therefore reducing the power draw of each operation. Of course, in the real world, zero-filled tensors are not multiplied together. When we put together much lower TCO and higher effective FLOPs utilization, from the perspective of Google the $ per effective FLOP becomes much cheaper, with ~15% MFU being the breakeven with GB300 at 30% MFU. This means if Google (or Anthropic) manages to hit half the FLOPs utilization of GB300, they still come out even. Of course, with Google‚Äôs elite compiler engineer team and deep understanding of their own models, the MFU they can realize on TPUs could be 40% potentially. That would be a whopping ~62% reduction in cost per effective training FLOP! However, when looking at the 600K rented TPUs, when we incorporate the higher TCO that Anthropic pays (ie inclusive of Google‚Äôs margin stacking) into this analysis, we estimate the cost to Anthropic to be $1.60 per TPU-hour from GCP, narrowing the TCO advantage. We believe that Anthropic can realize 40% MFU on TPUs due to both their focus on performance optimization as well as the TPU‚Äôs marketed FLOPs inherently being more realistic. This provides Anthropic with a staggering ~52% lower TCO per effective PFLOP compared to GB300 NVL72. The equilibrium where TCO per effective FLOP compared to the GB300 baseline is the same is at a much lower 19% extracted MFU for Anthropic. This means that Anthropic can suffer a sizeable performance shortfall relative to the baseline GB300 and the perf/TCO for training FLOPs still ends up being the same as the baseline Nvidia system. FLOPs are not the end all and be all for performance, memory bandwidth is super important for inference, especially on the bandwidth intensive decode step. It should be no surprise that $ per memory bandwidth for the TPU also ends up being much cheaper than GB300. There is significant evidence that at small message sizes such as 16MB to 64MB (loading an expert of a single layer), TPU‚Äôs even achieve higher memory bandwidth utilization then GPUs. All of this translates into more efficient compute to train and serve a model. Anthropic‚Äôs release of Opus 4.5 continued the usual focus on coding, setting a new SWE-Bench record. The main surprise was a ~67% price cut on the API. This price cut paired with the lower verbosity and higher token efficiency of the model compared to Sonnet (76% fewer tokens to match Sonnet‚Äôs best score, and 45% fewer to exceed it by 4 points) means Opus 4.5 is the best model for coding use cases and could effectively raise Anthropic‚Äôs realized token pricing as Sonnet is over 90% of token mix today. When it comes to pricing for external customers, Google needs to thread the needle to balance their own profitability whilst offering customers a competitive proposition. Our estimate for Anthropic pricing is on the lower end of ranges we‚Äôve heard for external pricing. For a flagship customer such as Anthropic, who will provide valuable input into both the software and hardware roadmap whilst ordering a huge amount of volumes, we‚Äôd expect sweetheart pricing. While Nvidia‚Äôs eye-watering 4x markup (~75% gross margin) offers a lot of room for pricing flexibility, a good amount of oxygen is sucked away by Broadcom. Broadcom, as the TPU‚Äôs co-designer, earns a high margin on the silicon which is the largest component of system BOM. Still, this leaves a lot of room for Google to earn very good acceptable margins. We can see this from comparing the GCP Anthropic deal to other large GPU-based cloud deals. Note that this is looking at the 600k TPUs that is being rented with the remaining 400k TPU v7 chips being bought upfront by Anthropic. Under these assumptions, the TPU v7 economics show superior EBIT margins than the other large GPU-based cloud deals we have observed, with only OCI-OpenAI coming close. Even with Broadcom‚Äôs margin stack on the chip-level BOM, Google can still eke out far superior margins and returns than much more commoditized GPU deals. This is where the TPU stack allows GCP to be a truly differentiated CSP. Meanwhile someone like Microsoft Azure, whose ASIC program is struggling, is confined to earning more mediocre returns in the mere business of leasing merchant hardware. We‚Äôve so far discussed how TPUs compare to Nvidia GPUs, focusing on per chip specs and the shortcomings. Now, let‚Äôs get back to the system discussion which is where TPU‚Äôs capabilities really start to diverge. One of the most distinctive features of the TPU is its extremely large scale up world size through the ICI protocol. The world size of a TPU pod reaches 9216 Ironwood TPUs, with large pod sizes being a feature of TPUs as early as TPUv2 back in 2017 scaling up to a full 256 1024-chip cluster size. Let‚Äôs start at the rack level, the basic building block of each TPU superpod. The TPU rack has a similar design over the last couple of generations. Each rack consists of 16 TPU Trays, 16 or 8 Host CPU Trays depending on the cooling configuration, a ToR Switch, power supply units, and BBUs. Each TPU tray consists of 1 TPU board with 4 TPU chip packages mounted. Each Ironwood TPU will have 4 OSFP cages for ICI connections and 1 CDFP PCIe cage for the connection to the Host CPU. Google has been implementing liquid cooled TPU racks since TPU v3 in 2018, but there are still some TPU generations in between that were designed to be air-cooled. The main difference between the liquid cooled and the air-cooled rack is that the air-cooled rack has 2 TPU trays to 1 host CPU tray ratio while the liquid cooled rack has a 1 to 1 ratio instead. An innovative design of TPU‚Äôs liquid cooling is that the flow rate of the coolant is actively controlled by the valves. This enables much more efficient cooling as the flow can be adjusted depending on the amount of workload that each chip has at any given time. Google‚Äôs TPU has also long adopted vertical power delivery, in which the VRM modules of the TPUs are on the other side of the PCB board. These VRM modules also require a cold plate for cooling. Overall, the TPU rack design is much simpler than that of the Nvidia Oberon NVL72 design, which has a much higher density and utilizes a backplane to connect GPUs to scale up switches. The scale up connections between the TPU trays are all over external copper cables or optics, which will be explained in the ICI section below. The connection between the TPU tray and the CPU tray is also over PCIe DAC cable. The building block of Google‚Äôs ICI scale-up network for TPUv7 is a 4x4x4 3D torus consisting of 64 TPUs. Each 4x4x4 cube of 64 TPUs maps to one physical rack of 64 TPUs. This is an ideal dimension as all 64 TPUs can be connected electrically to each other and still fit in a physical rack. The TPUs are connected to each other in a 3D torus configuration, with each TPU connecting to 6 neighbors total ‚Äì 2 logically adjacent neighboring TPUs for each of the X, Y and Z axes. Each TPU is always connected to 2 other TPUs via PCB traces within the compute tray but depending on where the TPU is located within the 4x4x4 cube, it will connect to 4 other neighbors either via Direct Attach Copper (DAC) cables or via an Optical Transceiver. Connections within the interior of the 4x4x4 cube happen over copper, while connections outside of the 4x4x4 cube (including wrap-around connections back to the other side of the cube as well as connections to neighboring 4x4x4 cubes) will use optical transceivers and OCSs. In the below diagram, we see that as this is a 3D Torus network: TPU 2,3,4 (on the Z+ face) has a wraparound connection back to the opposite Z-axis face to TPU 2,3,1 (on the Z- face) using an 800G optical transceiver and routing through an OCS. As mentioned above, in addition to the 2 neighboring TPUs that are always connected via PCB traces, TPUs will connect to 4 other neighbors using DACs, transceivers or a mix of both depending on where in the 4x4x4 cube they are. TPUs in the interior of the 4x4x4 cube will connect to the 4 other neighbors exclusively using DACs, TPUs on the face of the cube will connect via 3 DACs and 1 optical transceiver, TPUs on the edge of the cube will connect via 2 optical transceivers and 2 DACs, while TPUs on the corners will connect via 1 DAC and 3 optical transceivers. You can remember how many transceivers a given TPU will use by looking at how many of the TPU‚Äôs sides are facing the ‚Äúoutside‚Äù of the cube. The diagram above, as well as the table below, summarizes the number of respective location types for TPUs and can be used to derive the attach ratio of 1.5 Optical Transceivers per TPU v7. These transceivers connect to Optical Circuit Switches (OCSs) which enable connections between 4x4x4 cubes ‚Äì more on that in the next section. Google adopts a software-defined networking approach to manage network routes through Optical Circuit Switches (OCSs). An NxN OCS is basically a massive train station with N tracks in and N tracks out. Any train coming in can be transferred to any train coming out, but this has to be reconfigured at the station. Trains cannot be ‚Äúlooped back‚Äù or sent back on another N track in, they must be routed only to one of the N tracks out. The benefit of this approach is that the network can assemble smaller logical TPU slices ‚Äì for different workloads from the theoretical maximum of 9,216 chips in the ICI network layer. By rerouting ICI paths around faults in the network through slicing a larger cluster, cluster availability improves. Unlike Electronic Packet Switching (EPS) switches such as an Arista Tomahawk 5 where there is a fixed total bandwidth that is further split into several ports of smaller bandwidth sizes, OCSs allow any bandwidth of optical fiber to be connected to its ports. OCSs is also low latency compared to EPSs because optical signals entering an OCS simply bounce from the input port to the output port. For EPSs, optical signals must be converted to electrical signals when entering the switch ‚Äì one key reason why an OCS is typically more power efficient than an EPS. An EPS also allows routing of packets from any port to any port, while an OCS only allows you to route an ‚Äúin‚Äù port to any other ‚Äúout‚Äù port only. OCS ports only route individual fiber strands. This becomes a challenge for standard duplex transceivers because bandwidth is transmitted over multiple fiber strands, which reduces the effective radix and bandwidth of the OCS. To solve this problem, an FR optical transceiver is used to consolidate all wavelengths onto a single fiber strand to be connected to 1 OCS port. The Apollo Project innovatively achieved this in two steps. First, the 8 wavelengths ‚Äì 1 wavelength for each 100G lane ‚Äì are multiplexed through Coarse Wave Division Multiplexing (CWDM8) to transmit 800G over a single fiber pair, instead of 8 fiber pairs. Second, an optical circulator is integrated on the wave division multiplexing (WDM) transceiver to enable full duplex data flow, reducing requirements from 1 fiber pair to only 1 fiber strand. The circulator forms a bi-directional link by combining the Tx and Rx fiber strands at the transceiver onto a single fiber strand that is sent to the OCS switch. Google‚Äôs ICI scale-up network is unique in that it allows the connection of multiple 64 TPU 4x4x4 Cubes together in a 3D torus configuration to create massive world sizes. The TPUv7 has a stated maximum world size of 9,216 TPUs but today, Google supports the configuration of TPUs into multiple different slice sizes of between 4 TPUs all the way up to 2,048 TPUs. While Google can innovatively achieve an impressive scale-up cluster of 9,216 TPUs, the benefit of running training workloads on incrementally larger block sizes of up to approximately 8,000 TPUs at any point in time decreases. This is because larger block sizes are more prone to failures and disruption, therefore decreasing slice availability, which is defined by the fraction of time in which the ICI cluster is able to form a contiguous 3D torus slice. For slices that can fit entirely within a 4x4x4 Cube, we can simply carve these slices out of that cube using the copper interconnects within the rack as well as the optical transceivers on the face/edge/corner of the cube to wrap around and complete the 3D Torus if needed.To see how wraparound and inter-cube connections are made, let‚Äôs start by looking at how we would create a 64 TPU slice in a 4x4x4 topography. We can use the unit 4x4x4 cube of 64 TPUs corresponding to one physical 64 TPU rack to build up this topography. All 8 TPUs in the interior of the 4x4x4 cube can fully connect to all 6 neighbors using copper. If a TPU does not have an interior neighbor along a given axis, it will wrap around and connect to a TPU on the opposite side of the cube. For example, TPU 4,1,4 has no interior neighbor in the Z+ direction, so it will use one 800G optical transceiver to connect to an OCS assigned to the Z-axis, with the OCS configured to direct this connection to the Z- side of the cube, connecting to TPU 4,1,1. In the Y- direction, TPU 1,1,1 will use an optical transceiver to connect to a Y-axis OCS to link to the Y+ side of TPU 1,4,1 and so on. Each face of the 4x4x4 cube will connect via 16 different OCSs ‚Äì one OCS for each TPU on each face. For example, in the diagram below, on the X+ face, TPU 4,3,2 connects to the input side of OCS X,3,2. OCS X,3,2‚Äôs input side will also connect to the same TPU Index (4,3,2) on the X+ face of all 144 4x4x4 Cubes in the 9,216 TPU cluster. OCS X,3,2‚Äôs output side will then connect to the same TPU Index for every single cube in the cluster except this time on the X- face ‚Äì so it will connect to TPU 1,3,2 on all 144 cubes of the cluster. The diagram below illustrates how all 16 TPUs on the X+ face of Cube A connect via 16 OCSs to 16 TPUs on the X- of Cube B. These connections allow any ‚Äú+‚Äù face of any cube to connect to the ‚Äú-‚Äú face of any other cube, enabling complete fungibility of cubes when forming slices. There are two constraints to briefly point out. First, TPUs of one Index on a given face can never connect directly to a different index ‚Äì so TPU 4,3,2 could never be configured to connect to TPU 1,2,3. Second, as the OCS essentially acts as a patch panel ‚Äì TPUs connected on the input side cannot ‚Äúloop back‚Äù to connect to any other TPU that is also connected on the input side of the OCS - as an example, TPU 4,3,2 can never connect to TPU 4,3,3. So ‚Äì any TPU on the ‚Äú+‚Äù face can never connect to the ‚Äú+‚Äù face of any other cube, and any TPU on the ‚Äú-‚Äù face can never connect to the ‚Äú-‚Äù face of any other cube. Let‚Äôs go larger and see how a 4x4x8 Topography could be set up. In this configuration, we extend the slice by connecting two 64 TPU 4x4x4 cubes along the Z-axis. In this case, the OCS will reconfigure the optical port that TPU 4,1,4 is connected to so that it now connects to TPU 4,1,5 instead of wrapping around back to TPU 4,1,1 as was the case for a standalone 4x4x4 topography. Extending this, we will have 16 optical connections extending from the Z- and Z+ faces of each of the two 4x4x4 TPU cubes, for a total of 64 Fiber strands connected into 16 Z-Axis OCSs. It is important to remind readers that Cube A and Cube B depicted below are not necessarily physically located next to each other. Instead, they are connected via OCSs and they could each be in completely different locations in the datacenter. We will now move to a much larger topology ‚Äì the 16x16x16 topology, which brings us up to 4,096 TPUs. In this topology, we use a total of 48 OCSs to connect 64 Cubes of 64 TPUs each. In the diagram below, each multi-colored cube represents one 64 TPU 4x4x4 cube. Taking the bottom right 4x4x4 cube as an example ‚Äì this cube is connected to adjacent cubes along the Y-axis via OCSs. The maximum world size of 9,216 TPUs is built up using 144 4x4x4 cubes requiring 96 optical connections each amounting to a total requirement of 13,824 ports. Dividing this total port requirement by 288 (144 input and 144 output ports on each OCS) means we need 48 144x144 OCSs to support this maximum world size. But what is so great about Google‚Äôs unique ICI scale-up network ‚Äì other than all the fancy cube diagrams one can spend countless hours drawing? World Size: The most obvious benefit is the very large 9,216 TPU maximum world size that the TPUv7 Ironwood supports. Even though the maximum slice size of 9,216 may rarely be used due to the drawback of diminished goodput, slices of thousands of TPUs can and are commonly used. This is far larger than the 64 or 72 GPU world size that is common in the merchant accelerator market and for other custom silicon providers. Reconfigurable and Fungibility: The use of OCSs mean that the network topology inherently supports the reconfiguration of network connections to support a high number of different topologies ‚Äì in theory thousands of topologies. Google‚Äôs documentation site lists out 10 different combinations (image earlier in this section), but these are only the most common 3D slice shapes ‚Äì there are many more available. Even slices of the same size can be reconfigured differently. In the simple example of a Twisted 2D Torus diagrammed below, we see how looping across to an index of a different X coordinate instead of an index of the same X coordinate can reduce the worst-case number of hops and the worst-case bisection bandwidth. This can help improve all to all collective throughput. A TPUv7 cluster will twist at the 4x4x4 cube level. Reconfigurability also opens the door to a broad diversity of parallelisms. In a 64 or 72 GPU world size, different parallelism combinations are generally limited to the factors of 64. When it comes to the ICI scale-up network, the possibilities for implementing topologies to precisely match the combination of data parallelism, tensor parallelism and pipeline parallelism desired are plentiful. The fact that OCSs allow one to connect any ‚Äú+‚Äù face of any cube to the ‚Äú-‚Äú face of any other cube means that there is complete fungibility of cubes. Slices can be formed out of any set of cubes. So if there are any faults or change in user demands or usage, this will not obstruct the formation of new topology slices. Lower Cost: Google‚Äôs ICI network has a lower cost than most switched scale-up networks. Though the FR optics used can be slightly expensive due to the use of circulators, the mesh network reduces the overall number of switches and ports that are needed and eliminates cost arising from connections between switches. Low Latency and Better Locality: The use of direct links between TPUs means that it is possible to achieve much lower latency for TPUs that are physically located close to one another or are reconfigured to connect directly to each other. TPUs that are close to each other also have better data locality. The Datacenter Network (DCN) is a network separate to ICI that serves the role of both a typical backend and front-end network. It connects across an even larger domain ‚Äì 147k TPUs in the case of TPUv7 clusters. As discussed in our earlier post on Mission Apollo, where Google proposed replacing the Electronic Packet Switch (EPS)-containing spine layer of the traditional ‚ÄúClos‚Äù architecture with Paloma Optical Circuit Switches (OCS), Google‚Äôs DCN consists of an optically switched Datacenter Network Interconnect (DCNI) layer that combines several aggregation blocks, each of which connects several 9,216 TPU ICI clusters. In 2022, Google‚Äôs Apollo project proposed a DCN architecture that described using 136x136 OCS switches for TPUv4 pods with a pod size of 4,096 TPUs. OCS switches at the DCNI layer were organized into 4 Apollo zones, each containing a maximum of 8 racks of 8 OCS switches for a total of 256 OCS switches. When it comes to Ironwood, to support up to 147k TPUv7s on the same network, we hypothesize that the number of ports on the OCS will nearly double as opposed to increasing the maximum number of OCS switches.The diagram below illustrates what an Ironwood DCN network using 32 racks holding 256 300x300 OCS switches could look like. Assuming that there is no oversubscription between the spine layers of each aggregation block, a maximum of 16 ICI pods can be connected in the DCN with 4 aggregation blocks connecting 4 ICI pods each ‚Äì a total of 147,456 TPUs. The DCNI layer connects the 4 aggregation blocks ‚Äì depicted as the top layer in the diagram below. As with ICI, FR Optics are used to connect to the OCSs in order to maximize bandwidth per port on each OCS. While existing Ironwood clusters may only have 1 or 2 aggregation blocks, Google DCN‚Äôs unique architecture allows for new aggregation blocks of TPUs to be added to the network without significant rewiring. By using OCSs for the DCNI layer, the size of the DCN fabric can be incrementally expanded and the network can be re-striped to support new aggregation blocks. Furthermore, the bandwidth of aggregation blocks can be upgraded without having to change the make-up of the DCN layer. This allows the link speeds of existing aggregation blocks to be refreshed without changing the fundamental architecture of the network itself. The process of fabric expansion cannot go on indefinitely ‚Äì at significant scale, it becomes unmanageable to rewire the network. Traditionally, TPU software and hardware teams have been internal-facing. This comes with advantages such as the absence of pressure by marketing teams to inflate stated theoretical FLOPs. Another advantage of being only internal facing is that the TPU teams heavily prioritized internal feature requests & optimizing internal workloads. The disadvantage is that they did not care much about external customers or workloads. The number of external developers in the TPU ecosystem is way lower than in the CUDA ecosystem. This is one of the main weaknesses of the TPU as it is with all non-Nvidia accelerators. Google has since revised their software strategy for externally-facing customers and has already made major changes to their TPU team‚Äôs KPIs and how they approach contributing to the AI/ML ecosystem. There are 2 major changes that we will discuss: Massive engineering effort on PyTorch TPU ‚Äúnative‚Äù support Massive engineering effort on vLLM/SGLang TPU support The externalization strategy is clear to see by looking at the number of contributions from various TPU software repos by Google. We can see a noticeable increase in vLLM contributions starting from March. Then from May, the ‚Äútpu-inference‚Äù repo was created which is the official vLLM TPU unified back-end, and since then there has been a flurry of activity. Traditionally, Google only had first class support on the Jax/XLA:TPU stack (and TensorFlow/TF-Mesh RIP), but treated PyTorch on TPU as second class citizen. It relied on lazy tensor graph capture through PyTorch/XLA instead of having a first-class eager execution mode. Furthermore, it did not support PyTorch native distributed APIs (torch.distributed.*) or support PyTorch native parallelism APIs (DTensor, FSDP2, DDP, etc), but relied on weird out of tree XLA SPMD APIs (torch_xla.experimental.spmd_fsdp, torch_xla.distributed.spmd, etc.). This has led to a subpar non-native experience for external users that are used to the native PyTorch CUDA backend on GPUs and trying to switch to TPUs. In October, Google‚Äôs ‚ÄúCaptain Awesome‚Äù Robert Hundt quietly announced in the XLA repo that they will be moving away from a non-native lazy tensor backend towards a ‚Äúnative‚Äù TPU PyTorch backend that will support eager execution by default & integration with torch.compile & DTensor & torch.distributed APIs, etc. They will be doing this through the use of PrivateUse1 TorchDispatch key. This will mainly be done for Meta who has renewed interest in buying TPUs & does not want to move to JAX. It will also make it for people that enjoy PyTorch and do not like JAX to use TPUs too. Previously from 2020 to 2023, heavily used by a couple of teams at Meta FAIR used PyTorch XLA on TPUs but it was not widely adopted thus Meta leadership ended up cancelling the contracts in 2023. PyTorch XLA on TPUs is not a fun experience. The Meta FAIR GCP TPUs back then were even run using SLURM and not anything typical you would find on TPU stack like GKE/Xmanager/borg/etc. This new PyTorch <> TPU will create a smoother transition for ML scientists that are used to PyTorch on GPUs to switch to PyTorch on TPUs and take advantage of the higher performance per TCO on TPUs. Pallas is the kernel authoring language for writing custom kernels for TPU (similar to cuTile or Triton or CuTe-DSL). Meta & Google have also started work on supporting Pallas kernels as a codegen target for the Torch Dynamo/Inductor compile stack. This will allow for native TPU integration with PyTorch‚Äôs native torch.compile API & allow for end users to register custom pallas ops into PyTorch. In addition to the core in tree PyTorch native APIs, there is also work behind the scenes on integrating TPU pallas kernel language as a codegen target for Helion. You can think of Helion as a higher-level language for writing decently performing kernels in a high level language. Users can think about Helion as a low level Aten operators rather than as high level Triton/Pallas due to its similarity matching much closer to the Native PyTorch Aten ops. Another area where the CUDA ecosystem is supreme is for open ecosystem inference. Historically, vLLM & SGLang support CUDA as first class (as ROCm as 2nd class citizen). Now Google wants in to the vLLM & SGlang open inference ecosystem and have announced beta TPU v5p/v6e support for vLLM & SGLang through a very ‚Äúunique‚Äù integration. vLLM& SGLang currently does this by lowering the PyTorch modelling code into JAX and taking advantage of the existing mature JAX TPU compilation flow. In the future once PyTorch XLA RFC #9684 (aka native TPU PyTorch backend) gets implemented, vLLM & SGLang plan on evaluating whether to switch to using that instead of translating modelling from PyTorch to JAX through TorchAX. Google & vLLM claim that this lowering to jax path does not require any changes to the PyTorch modelling code but given how few models vLLM TPU supports so far, we doubt this is true. Furthermore, Google has open-sourced & integrated some of their TPU kernels into vLLM such as a TPU optimized paged attention kernels, compute-comms overlapped GEMM kernels & a couple other quantized matmul kernels. They do not yet have MLA-friendly TPU kernels. It would be interesting to see once Inductor Pallas TPU codegen integration is more mature, whether it is possible to integrate kernel fusion & pattern matching into the existing vLLM PassManager. SGLang is also looking into implementing an torch.compile PassManager to make managing kernel fusions for many models more maintainable. For Ragged Paged Attention v3, TPU handles it quite differently from vLLM GPU. vLLM manages KV cache with a technique similar to virtual memory and paging. However, this technique requires fetching dynamic addresses and performing scatter operations, something TPUs don‚Äôt support well. As a result, TPU kernels leverage fine-grained operation pipelining. Specifically, TPU‚Äôs page attention kernel prefetches query and KV blocks for the next sequence, so the memory loading is overlapped with computation. In the existing vLLM MoE kernel, we sort tokens by expert ID, dispatch tokens to the devices with the corresponding experts, perform group matrix multiplication, and combine tokens from experts back to original devices. However, the kernel performs poorly for two reasons: TPUs are slow at performing sorting operations, and the kernel is unable to overlap communication with computation. To work around this issue, Google developers designed all-fused MoE. All-fused MoE dispatches tokens for one expert per device at a time while overlapping MoE dispatch & MoE combine communications & avoiding sorting tokens by expert ID. With all-fused MoE, the Google engineer reported 3 - 4x speedup over existing kernels. Furthermore, another hardware unit in TPUs is the SparseCore (SC) used to accelerate embedding lookups and updates. SC comes with a scalar subcore SparseCore Sequencer (SCS) and multiple vector subcores SparseCore Tiles (SCT). SCT supports local and remote direct memory access at a more fine-grained 4-byte or 32-byte granularity, compared to TPU TensorCore‚Äôs 512-byte loads. This enables SC to perform gather/scatter operations and ICI communications while overlapping with TensorCore operations. At JAX DevLabs, we learned that programmability of SparseCore is a work in progress. We can expect Mosaic, the TPU custom kernel compiler, to compile in an MPMD fashion, where SCS and SCT executes different kernels, and different SparseCores can run different programs. We suspect once the programmability catches up, TPU MoE kernels would be able to perform dispatch and combine operations in a similar way as GPUs, instead of dispatching by expert IDs. In terms of disaggregated prefill decode, which we described in depth in our AMD 2.0 post, Google has experimental support on vLLM for single host disagg PD, not they do not support multi-host wideEP disagg prefill or MTP yet. These inference optimizations are critical to lower the TCO per million tokens and increase the perf per dollar and perf per watt. Furthermore, they have not yet integrated TPU vLLM inference support into popular RL frameworks like VERL, etc. Google is slowly moving in the correct direction in terms of how they approach the open AI/ML ecosystem especially for their ‚Äúnative‚Äù TPU backend. This week, there was an new inference benchmark on TPUv6e that dropped claiming that TPUv6e has 5x worst performance per dollar than NVIDIA GPUs. We disagree mainly due to 2 reasons. First of all, this is benchmark is on vLLM on TPUs which was only released an couple month ago thus does not yet have optimized performance. Google internal Gemini workloads & Anthropic workloads work on an internal custom inference stack that has better perf per TCO than NVIDIA GPUs. Secondly, Aritifical Analysis‚Äôs cost per million tokens is using the list price of $2.7/hr/chip for TPUv6e. No major customers of TPUs is paying anywhere close to that much for TPUv6e given the BOM is a tiny fraction of the H100. As everyone knows, most clouds have an high ball list price such that their account sales executives can do ‚Äúcar salesman‚Äù tactics and give massive discounts so that the customer thinks they are getting a good deal. The SemiAnalysis AI TCO Model tracks the acutal market rental price of TPUs across all the various contract lengths (1 month, 1 year, 3 years, etc). One part where Google is still approaching their software strategy incorrectly is with their XLA graph compiler & networking libraries & TPU runtime is still not open sourced nor well documented. This has led to frustrated users across the spectrum from advanced users to the average user of not being able to debug what is going wrong with their code. Furthermore their MegaScale codebase for multi-pod training is not open source either. We strongly believe that in order to accelerate the adoption, Google should open source it and the increased user adoption will outweigh all the software IP they will make public & free. Just like how PyTorch or Linux being open sourced rapidly increased adoption, open sourcing XLA:TPU & TPU runtime & networking libs will rapidly accelerated this too. Now that Google has gotten their act together on TPU and is selling them externally for people to put in their own datacenters, what are the implications on Nvidia‚Äôs business? Does Nvidia finally have a legitimate competitor that will put its market share and margins at threat? Behind the paywall, we will share our thoughts on what this means for Nvidia as well as reveal more about the TPU roadmap.
--------------------------------------------------

Title: Wildly Violent (and Profitable)
URL: https://dailyreckoning.com/wildly-violent-and-profitable/
Time Published: 2025-11-29T23:00:03Z
Full Content:
By Adam Sharp PostedNovember 29, 2025 The story of the world‚Äôs first IPO is a wild one. The Dutch East India Company (VOC) was founded in Amsterdam in 1602. Over the next hundred years, the VOC would dominate trade with Asia, wage multiple wars, commit genocide, and build monopolies. Along the way they sold gobs of spices, silks, and opium. But before all of that could happen, the VOC‚Äôs founders needed to raise money. So in 1602 the Dutch East India Company conducted the first initial public offering, giving all Dutchmen the chance to invest in this new venture. VOC Co-Founder Dirck Van Os | Source: Wikipedia The VOC IPO was unique because it was open to anyone, not just wealthy merchants and royalty. In total, 1,143 investors participated. Co-founder Dirck Van Os‚Äô maid, Neeltgen Cornelis, was the second-to-last investor on the registry, having subscribed 100 guilders, which was likely her life‚Äôs savings. If Mrs. Cornelis the maid held onto her shares for the long run, she did quite well. In some years, VOC investors received a dividend equivalent to 75% of the capital they initially committed. Now, that dividend occasionally came in the form of spices (cloves and mace in particular). But hey, profit is profit‚Ä¶ Dutch historian Lodewijk Petram has calculated the return of VOC shares (with dividends reinvested), and from its founding in 1602 through 1698, each 100 guilders invested turned into about 65,000. Source: The World‚Äôs First Stock Exchange VOC shares were groundbreaking because they were tradable on what would become the world‚Äôs first stock exchange. In addition, the Dutch East India Company introduced the concept of limited liability for shareholders. In other words, investors could only lose the amount they invested. They wouldn‚Äôt be responsible for the company‚Äôs debts or losses if the venture failed. The VOC set a new standard for how companies could raise capital and distribute profits. But the business model was downright diabolical‚Ä¶ The VOC quickly became a publicly-traded empire. By 1637 it was worth the equivalent of around $6.9 trillion in today‚Äôs money. That‚Äôs double the value of the largest modern companies such as Apple (AAPL), Microsoft (MSFT), and Nvidia (NVDA). The Dutch East India Company maintained its own navy with around 40 warships and 200 trading vessels at any given time. It fought wars against Spain, Portugal, Britain, and various Asian powers. These great powers clashed over lucrative trade routes and assets in Asia. They fought over territories such as the Spice Islands and the Philippines, and sold opium to China. In one notorious incident, the VOC invaded the Banda Islands, the world‚Äôs only source of nutmeg and mace at the time. Back then these spices were more valuable than gold. Using mercenaries which included Japanese samurai, VOC Governor-General Jan Pieterszoon Coen brutally massacred the Bandanese, publicly executing its leaders. Of around 15,000 natives, only a few hundred are believed to have survived. The VOC brought in slaves and other workers to take over Banda‚Äôs nutmeg and mace operations. These newly-acquired plantations were wildly profitable for shareholders. The company now had a total monopoly on two of the most valuable spices, which they sold into European markets at 1,000% markups. The Dutch East India Company was basically a publicly-traded evil empire. But for many years it did succeed in its mission of rewarding shareholders. Over time, however, the company lost its monopoly on spices and trade with Asia. Nutmeg and mace were smuggled out of Banda and cultivated elsewhere. Eventually the price of these once-rare goods collapsed. Artificial monopolies can only last so long. The VOC became increasingly corrupt and bureaucratic. It took on too much debt, and in time it essentially became a ponzi scheme. Ever-increasing debt loads were required to pay dividends. That‚Äôs a classic sign of the end approaching. The British East India Company eventually became a fierce competitor and seized many of the VOC‚Äôs prime territories. In 1799 the Dutch government dissolved the VOC and absorbed its assets and debts. The company had lasted almost 200 years. Despite the evil deeds committed by the Dutch East India Company, the firm played a critical role in the history of finance. It set a new standard for how companies could raise money and distribute profits to shareholders.
--------------------------------------------------

Title: Jim Cramer Explains Why He Says ‚ÄúOwn, Don‚Äôt Trade the Stock of NVIDIA‚Äù
URL: https://finance.yahoo.com/news/jim-cramer-explains-why-says-175304790.html
Time Published: 2025-11-29T17:53:04Z
Description: NVIDIA Corporation (NASDAQ:NVDA) is one of the stocks Jim Cramer recently talked about. Cramer explained why he ‚Äúwon‚Äôt give up‚Äù on the stock, as he commented...
--------------------------------------------------

Title: Dan Ives Says These Are the Top 3 Stocks to Buy Right Now
URL: https://www.barchart.com/story/news/36371180/dan-ives-says-these-are-the-top-3-stocks-to-buy-right-now
Time Published: 2025-11-29T17:00:02Z
Description: The Wedbush analyst reckons these stocks to be table pounders at the moment.
--------------------------------------------------

Title: Meta Platforms May Ditch NVIDIA Chips‚ÄîHere‚Äôs Why Investors Care
URL: https://www.marketbeat.com/originals/meta-to-buy-google-chips-why-it-could-shift-demand-from-nvidia/?utm_source=yahoofinance&amp;utm_medium=yahoofinance
Time Published: 2025-11-29T15:12:00Z
Description: Meta Platforms may be looking to alter where it spends its AI dollars. See what benefits the firm could reap from Google and Broadcom's chips.
--------------------------------------------------

Title: Nvidia (NVDA) Responds to Competition Fears as Meta Explores Google‚Äôs TPUs
URL: https://finance.yahoo.com/news/nvidia-nvda-responds-competition-fears-110654850.html
Time Published: 2025-11-29T11:06:54Z
Description: NVIDIA Corporation (NASDAQ:NVDA) is one of the AI Stocks Making Headlines on Wall Street. On November 25, Bank of America maintained a positive outlook on...
--------------------------------------------------

Title: ChatGPT was unveiled 3 years ago, kicking off the AI revolution. For investors, it did even more.
URL: https://finance.yahoo.com/news/chatgpt-was-unveiled-3-years-ago-kicking-off-the-ai-revolution-for-investors-it-did-even-more-110014912.html
Time Published: 2025-11-29T11:00:14Z
Description: OpenAI released ChatGPT on Nov. 30, 2022, not only kicking off the AI revolution but turning around one of the worst market environments of this century.
--------------------------------------------------

Title: Jim Cramer on NVIDIA: ‚ÄúAnything That Allows the Company to Sell in China Would Be Huge‚Äù
URL: https://finance.yahoo.com/news/jim-cramer-nvidia-anything-allows-064250979.html
Time Published: 2025-11-29T06:42:50Z
Description: NVIDIA Corporation (NASDAQ:NVDA) is one of the stocks that received Jim Cramer‚Äôs latest comments. Cramer noted the recent chatter around the President...
--------------------------------------------------

Title: Is NVIDIA (NVDA) One of the Best Semiconductor Stocks to Buy Heading into 2026?
URL: https://finance.yahoo.com/news/nvidia-nvda-one-best-semiconductor-061117049.html
Time Published: 2025-11-29T06:11:17Z
Description: NVIDIA Corporation (NASDAQ:NVDA) is one of the best Semiconductor Stocks to Buy Heading into 2026. On November 20, Raymond James analyst Simon Leopold...
--------------------------------------------------

Title: Alphabet: The AI Leader Best Positioned to Dominate 2026
URL: https://www.marketbeat.com/originals/alphabet-the-ai-leader-best-positioned-to-dominate-2026/?utm_source=yahoofinance&amp;utm_medium=yahoofinance
Time Published: 2025-11-28T20:07:00Z
Description: Alphabet has flipped its H1 sentiment to overwhelmingly bullish, boosted by accelerating growth, the release of Gemini 3, and Berkshire‚Äôs recent stake.
--------------------------------------------------

Title: Intel's Stock Pops as Rumors Swirl About a Big New Customer
URL: https://www.investopedia.com/intel-s-stock-pops-as-rumors-swirl-about-a-big-new-customer-apple-intc-11858735
Time Published: 2025-11-28T20:06:12Z
Full Content:
Could Intel be closer to scoring a deal with iPhone maker Apple? The chipmaker's shares surged Friday as an analyst added fuel to rumors that the iPhone maker could become a new customer for the chipmaker. Shares of Intel (INTC) popped over 10% during Friday's shortened trading session to lead gains on the S&P 500 and Nasdaq. (Read Investopedia's daily markets coverage here.) The likelihood of Apple (AAPL) becoming a new customer for Intel "has recently improved significantly," TF International Securities analyst Ming-Chi Kuo, citing industry surveys, posted on X Friday, suggesting that Intel could start shipping Apple processors as soon as 2027. A deal with Apple could boost confidence in a turnaround for Intel, which still faces persistent worries about its ability to secure long-term commitments to its manufacturing business. Apple and Intel did not respond to Investopedia's requests for comment in time for publication. Shares of Intel have roughly doubled in value this year after a flurry of recent deals, including a partnership with AI chip leader Nvidia (NVDA). Still, they remain well off their historical highs as the company is still working to convince investors regarding a sustainable turnaround in its business. One of those challenges continues to be securing new customers for its manufacturing operation. The deal with Nvidia did not include commitments to Intel's foundry, raising speculation about whether the relationship could expand later or if the lack of foundry commitments could point to troubles convincing customers. A deal with former Intel customer Apple could go a long way in helping assuage those concerns. Shares of Apple rose a bit less than 0.5% on Friday.
--------------------------------------------------

Title: Stock market today: S&P 500, Dow rise to end a rocky month, Nasdaq snaps 7-month win streak
URL: https://finance.yahoo.com/news/live/stock-market-today-sp-500-dow-rise-to-end-a-rocky-month-nasdaq-snaps-7-month-win-streak-180355656.html
Time Published: 2025-11-28T18:03:55Z
Description: US stocks rose for the fifth day in a row on Friday, but the Nasdaq snapped its monthly winning streak.
--------------------------------------------------

Title: Michael Burry just started a massive group chat on Substack, and it's as chaotic as you'd expect
URL: https://www.businessinsider.com/michael-burry-substack-group-chat-big-short-subscribers-ai-stocks-2025-11
Time Published: 2025-11-28T17:39:20Z
Full Content:
Every time Theron publishes a story, you‚Äôll get an alert straight to your inbox! Enter your email By clicking ‚ÄúSign up‚Äù, you agree to receive emails from Business Insider. In addition, you accept Insider‚Äôs Terms of Service and Privacy Policy. Michael Burry's group chat is going off. The investor of "The Big Short" fame invited all of his paid Substack subscribers to a group chat on Friday, and it quickly led to hundreds of replies ranging from memes to questions for Burry. This month, Burry pivoted from running a hedge fund to publishing a newsletter named "Cassandra Unchained." It has amassed more than 97,000 subscribers since it launched on Sunday. "This is a conversation space exclusively for paid subscribers‚Äîkind of like a group chat or live hangout," reads Burry's introductory post. "I plan to post updates that come my way, and you can jump into the discussion." The first reply on the chat reads: "I think Dr. Burry just broke Substack." Another early response jokes about Burry's disclosure this week that he owns bearish put options on Nvidia and Palantir stock: "I think Dr Burry is going to make more money from Substack than his NVDA and pltr puts ü§£" A third poked fun at a potential spike in traffic to Substack. "Someone pray for substacks backend engineers." "It's gonna be legendburry!!" one subscriber wrote, while another noted: "This chat is gonna be nuts." "Bro don't allow anyone to start threads. This a spam fest," one concerned poster added. Other subscribers rushed to post memes, videos, and even photos of Black Friday crowds. The questions to Burry ranged from who the next chair of the Federal Reserve might be, to how an 80-year-old should invest to prepare for a crash, to how the dollar stacks up against other currencies. Burry resurfaced on X in late October after more than two years of silence, and has wasted no time issuing numerous warnings of an AI bubble and taking aim at key players such as Nvidia and Palantir. The investor, who has 1.6 million X followers, is best known for predicting and profiting from the collapse of the US housing bubble that triggered a global financial crisis, and for issuing dire pronouncements of crashes and recessions. He became famous in financial circles after his bet against the subprime mortgage market was featured in author Michael Lewis' book "The Big Short," and actor Christian Bale played him in the movie adaptation. Jump to
--------------------------------------------------

Title: AI Stocks You Should Buy to Boost and Reenergize Your Portfolio
URL: https://finance.yahoo.com/news/ai-stocks-buy-boost-reenergize-163800128.html
Time Published: 2025-11-28T16:38:00Z
Description: Here, we have picked three AI stocks, NVDA, MU and ADI, which are well-poised to benefit from AI's growing use and ability to solve complex problems.
--------------------------------------------------

Title: Earnings live: S&P 500 on track for solid Q3 season, with reports from Macy's, C3.ai, Salesforce on deck
URL: https://finance.yahoo.com/news/live/earnings-live-sp-500-on-track-for-solid-q3-season-with-reports-from-macys-c3ai-salesforce-on-deck-151055563.html
Time Published: 2025-11-28T15:10:55Z
Description: The third quarter earnings season has been mostly positive, with most of the reports in the rearview mirror.
--------------------------------------------------

Title: Dow, S&P 500, Nasdaq futures muted as rocky month draws to an end, CME restores trading
URL: https://finance.yahoo.com/news/live/dow-sp-500-nasdaq-futures-muted-as-rocky-month-draws-to-an-end-cme-restores-trading-140109707.html
Time Published: 2025-11-28T14:01:09Z
Description: CME is gradually resuming operations after a futures outage that halted trading in US stock indexes.
--------------------------------------------------

Title: Dow, S&P 500, Nasdaq open muted as rocky month draws to an end, CME restores trading
URL: https://finance.yahoo.com/news/live/dow-sp-500-nasdaq-open-muted-as-rocky-month-draws-to-an-end-cme-restores-trading-140109595.html
Time Published: 2025-11-28T14:01:09Z
Description: CME is gradually resuming operations after a futures outage that halted trading in US stock indexes.
--------------------------------------------------

Title: Stock market today: Nasdaq, S&P 500, Dow rise toward a 5th straight day of gains to cap a rocky month
URL: https://finance.yahoo.com/news/live/stock-market-today-nasdaq-sp-500-dow-rise-toward-a-5th-straight-day-of-gains-to-cap-a-rocky-month-140109029.html
Time Published: 2025-11-28T14:01:09Z
Description: CME is gradually resuming operations after a futures outage that halted trading in US stock indexes.
--------------------------------------------------

Title: Wall Street Likes Server Stocks After Nvidia‚Äôs Q3. Is DELL or HPE Stock a Better Buy Here?
URL: https://www.barchart.com/story/news/36356183/wall-street-likes-server-stocks-after-nvidias-q3-is-dell-or-hpe-stock-a-better-buy-here
Time Published: 2025-11-28T12:30:02Z
Description: NVDA results and commentary from CEO Jensen Huang support a continued bull market for AI stocks. Dell and HPE are both expected to benefit.
--------------------------------------------------

Title: US stock futures rose today as Dow, S&P 500 and Nasdaq all in green ‚Äì here's top pre-market gainers
URL: https://economictimes.indiatimes.com/news/international/us/us-stock-futures-rose-today-as-dow-sp-500-and-nasdaq-all-in-green-heres-top-pre-market-gainers/articleshow/125635580.cms
Time Published: 2025-11-28T10:34:00Z
Full Content:
U.S. stock futures rose on Friday. Dow Futures hit 47,542, up 0.11%. S&P 500 Futures touched 6,835, up 0.10%. Nasdaq Futures moved to 25,347.75, up 0.18%. Pre-market gainers were strong. SMX jumped 78.16%. CDT rose 15.46%. Micron gained 3.24%. Crypto-linked stocks also advanced. The market showed steady buying ahead of new economic data. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. Explore More Stories What is Canada‚Äôs new colour-coded alert system and how it will ensure public safety during extreme weather Canada launches new alert system for extreme weather; Colour-coded system marks shift to impact-based forecasting Canadian Olympic swimming champion Penny Oleksiak suspended for two years over anti-doping whereabouts failures Who is Colleen Jones? Two-time World champion curler and veteran Canadian broadcaster dies at 65 What exactly is the Canada Pension Plan? New CPP payments rolling out nationwide on November 26; Check all the payment dates of 2025-26 - Why is Quebec not part of CPP? Madeleine Poulin, Radio-Canada‚Äôs first female correspondent in Ottawa and Paris, dies at 87 Yoplait recalls 'Yop yogurt' drinks in Canada over plastic contamination fears under Class 1 category - Check out which flavor and best-before dates beverage are subject to recall CMA Awards: Vince Gill honored with prestigious Willie Nelson Lifetime Achievement Award at 59th CMA Awards in Tennessee MGK rocks Canadian fans with explosive Grey Cup halftime show; Are Megan Fox, MGK really working on their relationship post daughter‚Äôs birth? Roughriders end 12-year drought, beat Alouettes for 5th Grey Cup title Who is Dr Sanjeev Sirpal? Trouble mounts for New Brunswick doctor accused of sexual assault in hospitals as he faces additional charges; what do we know so far Russian humanoid robot 'AIDOL' shockingly faceplants during much-hyped public debut - WATCH Who is Ben Watsa, the future chairman of Fairfax financial and heir to Prem Watsa‚Äôs $100-billion empire? 'Kumbh Shahi Snan in Haridwar on‚Ä¶': CM Dhami announces key dates Deaths, ICU cases and FIRs trigger outrage during voter-list revision drive Air Marshal Dixit explains Integrated Theatre Command Assam Polygamy Ban sparks controversy Imran Khan‚Äôs Sister speaks out - full interview PM Modi at Sri Krishna Matha, Udupi, Karnataka ‚ÄòSuspect worked with CIA in Afghanistan‚Äô: Kash Patel reveals... Sambit Patra Slams Rahul Gandhi over 'Toolkit' controversy Ex‚ÄëCJI Gavai comments on Justice Varma cash‚Äërecovery scandal ‚ÄòFaith, not merit?‚Äô: BJP's demand for Hindu quota at Vaishno Devi med college 'Kumbh Shahi Snan in Haridwar on‚Ä¶': CM Dhami announces key dates Deaths, ICU cases and FIRs trigger outrage during voter-list revision drive Air Marshal Dixit explains Integrated Theatre Command Assam Polygamy Ban sparks controversy Imran Khan‚Äôs Sister speaks out - full interview PM Modi at Sri Krishna Matha, Udupi, Karnataka ‚ÄòSuspect worked with CIA in Afghanistan‚Äô: Kash Patel reveals... Sambit Patra Slams Rahul Gandhi over 'Toolkit' controversy Ex‚ÄëCJI Gavai comments on Justice Varma cash‚Äërecovery scandal ‚ÄòFaith, not merit?‚Äô: BJP's demand for Hindu quota at Vaishno Devi med college Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Commodities Top Slideshow Top Prime Articles Private Companies Top Story Listing Top Definitions Top Market Pages Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Stories you might be interested in
--------------------------------------------------

Title: Nvidia (NVDA) Memo Calms Investors as Bernstein Reaffirms Outperform
URL: https://finance.yahoo.com/news/nvidia-nvda-memo-calms-investors-062120029.html
Time Published: 2025-11-28T06:21:20Z
Description: NVIDIA Corporation (NASDAQ:NVDA) is one of the AI stocks analysts are betting on. On November 26, Bernstein reaffirmed its Outperform rating on Nvidia and...
--------------------------------------------------

Title: This AI Dividend Stock Is a Buy Even as the S&P 500‚Äôs Yield Falls to Dot-Com Lows
URL: https://www.barchart.com/story/news/36349747/this-ai-dividend-stock-is-a-buy-even-as-the-s-p-500s-yield-falls-to-dot-com-lows
Time Published: 2025-11-28T00:30:02Z
Description: The S&P 500 Index‚Äôs dividend yield is now at levels last seen during the dot-com boom. For tech investors, though, Microsoft looks like a good buy given its ...
--------------------------------------------------

Title: Dow, S&P 500, Nasdaq futures muted as rocky month draws to an end, before CME glitch halts trading
URL: https://finance.yahoo.com/news/live/dow-sp-500-nasdaq-futures-muted-as-rocky-month-draws-to-an-end-before-cme-glitch-halts-trading-000737050.html
Time Published: 2025-11-28T00:07:37Z
Description: CME is gradually resuming operations after a futures outage that halted trading in US stock indexes.
--------------------------------------------------