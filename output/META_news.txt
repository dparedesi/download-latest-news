List of news related to Meta stock price META:

Title: On theCUBE Pod: A deep dive on DeepSeek and the future of AI
URL: https://siliconangle.com/2025/02/03/future-ai-deepseek-chatbot-thecubepod/
Time Published: 2025-02-03T16:10:55Z
Full Content:
UPDATED 11:10 EST / FEBRUARY 03 2025 by Ryan Stevens The tech world was shaken this past week with the release of the DeepSeek chatbot, sparking intense discussions about its far-reaching implications. In the latest episode of the CUBE Podcast, theCUBE Research industry analysts John Furrier (pictured, left) and Dave Vellante (right) break down what this development means for the industry, cutting through the hype to uncover the real impact. DeepSeek dominated the internet this week, sparking major discussions on AI, geopolitics and innovation, with its impact reaching from Silicon Valley to global markets. It put everyone on notice around AI efficiency, according to Furrier. “Is it a psych ops thing from China?” Furrier said. “Is open source going to change the game? There’s so many storylines. Is it a breakthrough?” All that dominated the Pod discussion this week. It’s possible that the release of the DeepSeek chatbot will bring with it some positives. It may teach everyone how to do things more efficiently in AI, according to Vellante. “That’s going to be a rising tide that lifts all ships, finally, because AI hasn’t lifted all ships as we know. It’s been narrow and focused in terms of those that have really gotten benefit from it,” Vellante said. “I think to the extent that we can lower the denominator … the value goes through the roof.” The real breakthrough here lies in DeepSeek’s use of a smarter, leaner model, according to Furrier. It was no fluke, having achieved the DeepSeek chatbot through smart model design and a mixture of experts. “They also did the distilling of other models, so they didn’t have to do the brute force crunching,” Furrier said. “They slashed memory, energy, and the time it needs to get the answers and reason with good performance without compromising performance. They get all that stuff … a lot of matrix multiplication involved.” The DeepSeek chatbot made a significant impact by combining innovative techniques in a way that wasn’t obvious, according to Furrier. It involved very clever engineering. “I don’t think it’s a breakthrough in a major way, but it was something that they did with the constraints that they had,” Furrier said. It’s possible that the developments lower costs and drive adoption, according to Furrier. It’s similar to what happened to the internet. “I was talking to some entrepreneurs this week. The classic AI trajectory, people are like, ‘Oh, it reminds me of the web,’ these critical moments,” Furrier said. “One entrepreneur said it reminds them of the iPhone revolution because the user experience shifted and that drove a lot of change.” People are saying that it’s a Sputnik moment, which may not be the best analogy, according to Vellante. But it does underscore that the development serves as a wake-up call. “Do you remember when in the ’80s, Japan’s ascendancy was freaking everybody out? I think this is significantly more competitive because the market is so much bigger and AI is so much more important today,” Vellante said. “But to me, the winners of the market, the market overall just keeps getting bigger and bigger the lower the cost is.” The DeepSeek chatbot news has driven several conversations over the past week. The conversation shifted from stock price impact to deeper discussions in Silicon Valley and the AI community about the true future of AI and its competitive landscape, according to Furrier. “What you’re starting to see is some of the things we’ve been saying on theCUBE here all the time, which is, it’s a systems revolution,” he said. “I call it the chip grid emerging, which is clustered systems, where it’s not about throwing gear at problems or GPUs. It’s the combination of the hardware configuration.” The event calendar for theCUBE is filling up, with theCUBE teaming up again with the New York Stock Exchange for a Super Studio event, welcoming Silicon Valley’s top CMO leaders innovating in artificial intelligence initiative on Feb. 14. This year marks the busiest tech event season for some time, according to Furrier. “Leading up to around 2018, I think, would be the height of the event season in terms of tech companies. I think we’re back at that level, Dave. I think we’re on the road every week in May,” Furrier said. April, May and June have tons of activity planned. There will be no shortage of things to discuss at the events on the calendar, according to Furrier. “There’s multiple threads, efficiency, software innovation, psych ops, global geopolitical Cold War race. I mean, this is all very interesting,” Furrier added. “Very, very interesting. We’ll keep track of it.” Antonio Neri, president and CEO of HPE Lina Khan, former chair of the Federal Trade Commission Donald Trump, 47th president of the United States of America Steve Jobs, co-founder and former CEO and chairman of Apple Inc. Arvind Krishna, chairman and CEO of IBM Andy Jassy, president and CEO of Amazon Stu Miniman, senior director of market insights for hybrid platforms at Red Hat Ginni Rometty, co-chairman of OneTen, former CEO of IBM Mark Zuckerberg, CEO of Meta Platforms Liang Wenfeng, Chinese entrepreneur and businessman Dylan Patel, founder of SemiAnalysis Jeffrey Emanuel, founder and CEO of Pastel Network Satya Nadella, chairman and CEO of Microsoft John Rose, United States Representative Marc Andreessen, general partner at Andreessen Horowitz David O. Sacks, South African-American entrepreneur and author Steve Wozniak, American entrepreneur and electrical engineer Charlie Kawwas, president at Broadcom Jensen Huang, founder and CEO of Nvidia Here’s the full theCUBE Pod episode: Don’t miss out on the latest episodes of “theCUBE Pod.” Join us by subscribing to our RSS feed. You can also listen to us on Apple Podcasts or on Spotify. And for those who prefer to watch, check out our YouTube playlist. Tune in now, and be part of the ongoing conversation. THANK YOU AttackIQ acquires DeepSurface to strengthen security posture management Adobe's Acrobat AI Assistant digs into contracts to help users understand what they're agreeing to Presidio launches Private AI Accelerator powered by Nvidia for secure on-premises AI Alluxio boosts performance for AI model training Data in the generative AI era: We need more knowledge engineers Exclusive: GetWhys raises $2.75M seed round for AI-infused marketing research platform AttackIQ acquires DeepSurface to strengthen security posture management SECURITY - BY DUNCAN RILEY . 32 MINS AGO Adobe's Acrobat AI Assistant digs into contracts to help users understand what they're agreeing to AI - BY MIKE WHEATLEY . 32 MINS AGO Presidio launches Private AI Accelerator powered by Nvidia for secure on-premises AI AI - BY DUNCAN RILEY . 32 MINS AGO Alluxio boosts performance for AI model training AI - BY PAUL GILLIN . 2 HOURS AGO Data in the generative AI era: We need more knowledge engineers BIG DATA - BY GUEST AUTHOR . 2 HOURS AGO Exclusive: GetWhys raises $2.75M seed round for AI-infused marketing research platform AI - BY PAUL GILLIN . 4 HOURS AGO
--------------------------------------------------

Title: 4 Best AI Agent Cryptos to Buy as S&P 500 Turns Bullish After DeepSeek
URL: http://www.newsbtc.com/news/4-best-ai-agent-cryptos-to-buy-as-sp-500-turns-bullish-after-deepseek/
Time Published: 2025-02-03T11:45:22Z
Full Content:
DeepSeek’s catastrophic impact on AI tech firms looks like it’s slowing down. After dropping heavily early last week, the S&P 500 has made a fantastic recovery and now sits very close to its all-time highs. The rebound was largely due to Big Tech stepping up, recording top earnings, and most importantly, reassuring investors that the US is still a leader in AI technology. All in all, DeepSeek might just be a much-needed boost for US AI firms to step up and do better. This also happens to be terrific news for AI projects in the crypto space, who will not only benefit from a dog fight between AI companies worldwide but also from the crypto economy’s overall bullish outlook. If you want to take full advantage of the upcoming AI-crypto rally, here are the 4 best AI agent cryptos you can consider investing into. MIND of Pepe ($MIND) is already among the hottest presales of 2025 – and its popularity (and price) will only increase as the hype and demand for AI agent coins are set to skyrocket post DeepSeek’s launch and Altman’s promise of rolling out even better AI models. $MIND is an autonomous AI agent that interacts with folks on online platforms like X and gauges the broader market sentiment. It then uses cutting-edge AI technology to deliver exclusive trading insights to token holders. MIND of Pepe offers two major benefits to token holders: 1. It offers 100% objective analyses, removing all emotions and bias from ruining your crypto profitability 2. It’s able to identify potentially profitable bets when they’re still at their early stages Currently available for just $0.0032532 per token, investing in $MIND could lead to crazy gains in the upcoming bull run. The project has already raised close to $5M. What’s more, early adopters will also be able to make handsome passive income through the project’s 457% staking rewards. If this is your first time investing in a crypto presale, check out our detailed guide on how to buy $MIND. Artificial Superintelligence Alliance ($FET) is the largest AI crypto project on the market right now – it has a market capitalization of over $1.80B. This reflects its popularity and the vote of confidence from investors. $FET is truly a unique project, seeing as it’s a business alliance between three innovative AI companies: Fetch.ai, SingularityNET, and Ocean Protocol. For context, alliances like this are not common in the AI space, which is still fairly new, meaning every company wants to race past the competition. Not only will this result in more transparency and innovation within the AI economy, but it’ll also level the playing field for smaller, resource-strapped AI companies. Where $MIND aims to offer crypto investment advice to retail traders like you and me, ai16Z is meant to simplify investing for venture capital firms. It will properly vet a company – including studying its financials and mission – to assess whether it’s worth investing into. Not only will this reduce the amount of human labor that goes into studying each prospective investment, but it’ll also massively increase the rate at which investment decisions can be made. Put together, ai16Z can very well be a game changer for venture capitalists. The $AI16Z token is currently trading at $0.38, which is a sizable dip from its all-time highs of around $2.45. However, it’s nearing earlier demand zones (like $0.2), meaning an uptick in price is highly likely from here. Freysa AI offers a fun challenge – convince the AI chatbot to send you money and that money will be yours! The tricky part, of course, is that you’re up against an AI agent designed to protect the very prize pool you’re trying to tap into, which is a pot of crypto. Freysa is admittedly tough to crack, but that’s exactly what’s fueling its hype. After all, who doesn’t love a real (and rewarding) challenge! That GTA V mission you’re trying to complete won’t earn you any money, but this will. The platform offers several game variations, each with a different prize pool – ranging from $7K to $50K. Interestingly, a user actually managed to convince Freysa to send him $20,843 by making the AI agent fall in love with him. With a market cap of over $270M, $FAI is currently trading at $0.034, which makes it one of the cheapest cryptos with massive potential. The larger trend for both crypto and the S&P 500 is expected to be bullish in 2025. However, no amount of market hype should overshadow smart risk management and investment hygiene. This includes only investing an amount you’re comfortable losing and doing your own research before putting your hard-earned money in crypto. Krishi is in charge of covering the latest crypto news, sharing valuable information in an easy-to-read manner. With an experience of over 4 years as a tech/crypto writer, he has the necessary toolkit required to identify good crypto presales and tokens. Krishi is in charge of covering the latest crypto news, sharing valuable information in an easy-to-read manner. With an experience of over 4 years as a tech/crypto writer, he has the necessary toolkit required to identify good crypto presales and tokens. Disclaimer: The information found on NewsBTC is for educational purposes only. It does not represent the opinions of NewsBTC on whether to buy, sell or hold any investments and naturally investing carries risks. You are advised to conduct your own research before making any investment decisions. Use information provided on this website entirely at your own risk. Bitcoin's trillion-dollar market has long been viewed as an untapped goldmine for DeFi developers. While Ethereum pioneered decentralized finance and... With the crypto ecosystem (especially the DeFi sector) expanding at an unfathomable rate in recent years, one can see the... Dogecoin is beginning to regain momentum after a sharp drop in the early hours of January 3, a move that... Be the first to get the latest important crypto news & events to your inbox. Δ NewsBTC is a cryptocurrency news service that covers bitcoin news today, technical analysis & forecasts for bitcoin price and other altcoins. Here at NewsBTC, we are dedicated to enlightening everyone about bitcoin and other cryptocurrencies. We cover BTC news related to bitcoin exchanges, bitcoin mining and price forecasts for various cryptocurrencies. © 2024 NewsBTC. All Rights Reserved. © 2024 NewsBTC. All Rights Reserved.
--------------------------------------------------

Title: Is DeepSeek China’s Sputnik Moment?
URL: https://www.newyorker.com/news/the-financial-page/is-deepseek-chinas-sputnik-moment
Time Published: 2025-02-03T11:00:00Z
Full Content:
Last week, shortly before the start of the Chinese New Year, when much of China shuts down for seven days, the state media saluted DeepSeek, a tech startup whose release of a new low-cost, high-performance artificial-intelligence model, known as R1, prompted a big sell-off in tech stocks on Wall Street. China Central Television showed footage of DeepSeek’s bespectacled founder, Liang Wenfeng, meeting with Premier Li Qiang, the second-highest-ranking official in the Chinese government. A few days earlier, China Daily, an English-language news site run by the Chinese Communist Party, had hailed DeepSeek’s success, which defied U.S. restrictions on the export of high-performance semiconductor chips used to train A.I. models, as “not an isolated phenomenon, but rather a reflection of the broader vibrancy of China’s AI ecosystem.” As if to reinforce the point, on Wednesday, the first day of the Year of the Snake, Alibaba, the Chinese tech giant, released its own new A.I. model, which the company claimed “outperforms” competing products from U.S. companies like OpenAI and Meta “almost across the board.” Alibaba’s claims haven’t been independently verified yet, but the DeepSeek-inspired stock sell-off provoked a great deal of commentary about how the company achieved its breakthrough, the durability of U.S. leadership in A.I., and the wisdom of trying to slow down China’s tech industry by restricting high-tech exports—a policy that both the first Trump Administration and the Biden Administration followed. Speaking at the World Economic Forum, in Davos, Satya Nadella, Microsoft’s chief executive, described R1 as “super impressive,” adding, “We should take the developments out of China very, very seriously.” Elsewhere, the reaction from Silicon Valley was less effusive. OpenAI said it was “reviewing indications that DeepSeek may have inappropriately distilled our models.” The Chinese company claimed it spent just $5.6 million on computing power to train one of its new models, but Dario Amodei, the chief executive of Anthropic, another prominent American A.I. firm, described this achievement as merely “an expected point on an ongoing cost reduction curve,” which U.S. firms would soon match. Amodei did acknowledge the novelty in a Chinese firm being “first to demonstrate the expected cost reductions,” and he argued that DeepSeek’s progress makes “export control policies even more existentially important than they were a week ago.” Such comments demonstrate that how you see the DeepSeek story depends partly on your vantage point. To get an unofficial view from the other side of the Pacific, I arranged a Zoom call with a longtime China watcher, Louis-Vincent Gave, a co-founder of Gavekal, a Hong Kong-based financial services company. Gave, who is fifty and originally from France, moved to Hong Kong in 1997, shortly before the United Kingdom restored control of the former British colony to China. He has lived there ever since, analyzing and writing about China’s remarkable transformation into the world’s second-largest economy and its biggest exporter of goods. On Monday, the day Nvidia, a U.S. semiconductor company that produces the high-end chips most American A.I. firms rely on, lost more than half a trillion dollars in market value, Gave circulated a commentary entitled “Another Sputnik Moment” to his firm’s clients, which include investment banks, hedge funds, and insurance companies around the world. (The term “Sputnik moment” had first been applied to DeepSeek by the Silicon Valley venture capitalist Marc Andreessen.) Given China’s formidable strength in computer engineering and basic scientific research, Gave’s piece said, “fighting a tech battle against (it) always seemed a short-sighted strategy.” In our conversation, he reiterated this argument and said imposing the export restriction on China had been a big mistake, because “it forced them to be very focused.” The battle that Gave referred to started in 2018, when the Trump Administration banned the export of some key components for semiconductors to a Chinese telecommunications company and chipmaker, citing national-security grounds. The Biden Administration strengthened these restrictions several times, particularly as they applied to the most powerful chips made by Nvidia. In announcing the latest set of rules, last month, just a week before Trump’s second Inauguration, then Commerce Secretary Gina Raimondo said, “The U.S. leads the world in A.I. now, both A.I. development and A.I. chip design, and it’s critical that we keep it that way.” By then, though, DeepSeek had already released its V3 large language model, and was on the verge of releasing its more specialized R1 model. The firm says it developed both models using lower-end Nvidia chips that didn’t violate the U.S. export bans. “Did DeepSeek happen in spite of the restrictions, or did it happen because of the restrictions?” Gave asked me. To answer his own question, he dived into the past, bringing up the Tiger 1, a German tank deployed during the Second World War which outperformed British and American models despite having a gasoline engine that was less powerful and fuel-efficient than the diesel engines used in British and American models. “I think you could find hundreds of examples through history of necessity being the mother of invention,” he said. “You build a ten-foot wall; I’ll build an eleven-foot ladder. China’s just done this, and everybody is acting surprised.” Some people in the U.S. tech industry have made similar comments. In a post on X, Pat Gelsinger, the former chief executive of Intel, wrote, “Engineering is about constraints. The Chinese engineers had limited resources, and they had to find creative solutions.” These workarounds seem to have included limiting the number of calculations that DeepSeek-R1 carries out relative to comparable models, and using the chips that were available to a Chinese company in ways that maximize their capabilities. In another post on X, Andrej Karpathy, a prominent computer scientist who was a co-founder of OpenAI and a former director of A.I. at Tesla, said that DeepSeek was “making it look easy” by training a “frontier-grade” large language model “on a joke of a budget.” Although the theory that imposing resource constraints spurs innovation isn’t universally accepted, it does have some support from other industries and academic studies. A 2014 study of Swiss manufacturers found evidence to support the hypothesis. More recently, in a study of U.S. software startups published in December, two researchers at Harvard Business School and the University of Texas at Austin found firms that didn’t receive any outside funding until later in their development tended to “engage in a greater amount of experimentation with technologies, and also were more likely to carry out more significant changes to their technology stacks.” The evidence is far from definitive; the intuitive counterargument is that having ample access to technical and financial resources facilitates more experimentation than conditions of scarcity. But, in any case, Gave insists that many Westerners have been greatly underestimating the ability of Chinese firms to innovate, rather than merely copy. He said that this tendency was now evident in many industries, including nuclear power, railways, solar panels, and electric vehicles, where the Shenzhen-based BYD has overtaken Tesla as the biggest E.V. producer in the world. In fact, Gave drew a direct comparison between A.I. and the auto industry. “I’ve heard all the criticisms that, if it wasn’t for OpenAI, DeepSeek couldn’t happen, but you could say exactly the same thing about car companies,” he said. “BYD wouldn’t be here without Tesla. Sure, of course. But the fact remains that BYD is here. And it’s a better car at a cheaper price.” Elon Musk might strenuously dispute that final assertion, but there can be no doubt that the sudden arrival of DeepSeek, following on the heels of the rise of BYD and other Chinese E.V. manufacturers, has raised some awkward questions. “It’s a wake-up call to the West that there is no industry that is one-hundred-per-cent safe,” Gave said. In the American A.I. industry, he went on, the belief had been that if you invested enough in A.I. hardware, you could create a big moat and a lasting monopoly. “That belief has been exploded as well,” Gave added. I asked him what policy guidance he would give to the new Administration in Washington. “My job isn’t to tell policymakers what to do,” he said. “My job is to say, Well, this is happening, how do we make money out of it?” Still, Gave did offer some indirect advice. “The first thing is to acknowledge the reality that China is now leapfrogging the West in industry after industry,” he said. In his opinion, this success reflects some fundamental features of the country, including the fact that it graduates twice as many students in mathematics, science, and engineering as the top five Western countries combined; that it has a large domestic market; and that its government provides extensive support for industrial companies, by, for example, leaning on the country’s banks to extend credit to them. “They said, ‘No more lending to real estate. We need to be an industrial superpower.’ ” Gave’s argument is that this strategy has already succeeded, and the emergence of DeepSeek is the latest and most dramatic evidence. His manner during our conversation was serious but also wry. He noted that, when he posts his arguments about China’s economic progress on YouTube, as he occasionally does, they attract comments that he is spouting C.C.P. propaganda. This seemed to intrigue him rather than worry him. “When it comes to China, there is an emotional response that makes it hard for people to accept simple facts,” he said. ♦
--------------------------------------------------

Title: How corporate America got DEI wrong
URL: https://www.npr.org/2025/02/03/nx-s1-5281168/corporate-america-dei-trump-diversity-business-stakeholder-capitalism
Time Published: 2025-02-03T10:00:00Z
Full Content:
By Maria Aspan An American flag flies outside a Walmart store in Miami. In 2020, Walmart was one of many large U.S. companies that pledged to fight racism and increase internal diversity. But now it, Amazon, Facebook and many other companies are ending some of those programs. Joe Raedle/Getty Images hide caption Five years ago, in the wake of George Floyd's murder and the sweeping reckoning on racism it sparked, corporate America rushed to join in. Big businesses started making big — and expensive — promises to fight racism and increase diversity. Walmart, the world's largest company, spent $100 million on a new center on racial equity — and that was just one of many such investments. All told, the country's largest companies pledged almost $50 billion toward addressing racial inequality in the year after Floyd's death, The Washington Post estimated in 2021. And their CEOs announced these promises with solemn rhetoric about their companies' roles in fixing societal problems. "We want to address systematic racism in society head-on and accelerate change," Walmart CEO Doug McMillon said in June 2020. But today, corporate America is rushing just as quickly in the other direction. Mounting political and legal attacks have turned DEI — diversity, equity and inclusion — from a corporate rallying cry to a politically toxic football. Many big companies had been backing away from their diversity promises even before President Trump was reelected. After long criticizing DEI, Trump last month signed executive orders that will terminate what he calls "illegal" DEI programs and policies throughout the federal government. He called the programs "radical and wasteful" and discriminatory against nonminorities who, he says, are denied opportunities and recognition as a result. Trump continued these criticisms last week, suggesting — apparently without evidence — that DEI programs at the Federal Aviation Administration were to blame for a deadly airliner crash. It may seem that big companies are just adapting to political and legal pressure, but diversity experts also blame a more fundamental failure: Many businesses didn't think through their pledges — or their costs — from the start, they say. So corporate America may have never gotten DEI right in the first place. "What we're seeing in the moment is the few companies who took it to heart … and the many who just wanted to sprinkle some DEI on top, especially after George Floyd," says Portia Allen-Kyle, who runs the racial justice nonprofit Color of Change. "And that was never going to be a viable strategy." Allen-Kyle is pretty pessimistic these days about the future of DEI in corporate America, and the fallout for Black and other minority workers. But some diversity experts see a silver lining from the scrutiny: They hope that companies that care about building fairer, more inclusive workplaces are rethinking their strategies — and may now finally have a chance to get it right. Conservative critics have long claimed that DEI is itself discriminatory. But these attacks picked up momentum in 2023, when the Supreme Court overturned affirmative action at colleges and universities, ending the consideration of race in college admissions. President Trump signs an executive order in the Oval Office of the White House in Washington, D.C., on Jan. 20. Jim Watson/Pool/AFP via Getty Images hide caption That ruling handed a powerful legal weapon to anti-DEI voices like Robby Starbuck, a social media influencer who has successfully pressured several big companies to end diversity-focused programs. Starbuck has said he is focused on ending "wokeness" in corporate America and has posted on X that his activism will give workers "a neutral workplace without feeling that divisive issues are being injected." Now President Trump's efforts to end DEI in the federal government are expected to ripple into the private sector. Walmart, Meta, Amazon and many others have already joined the retreat, ending many of their 2020-era pledges and programs. For example, Walmart in November said it won't renew the funding for its racial equity center and that it will end some other diversity-focused programs. "We remain committed to creating a culture where everyone can be successful, and ensuring we are a Walmart for everyone," a company spokesperson tells NPR. The other companies have said similar things. For example, in a note shared with NPR, Amazon executive Candi Castleberry told employees last year that "we remain dedicated to delivering inclusive experiences for customers, employees, and communities around the world." (Meta did not respond to a request for comment.) Under the political headlines, there's a more subtle undercurrent at work. When Floyd was murdered, many big companies were already promoting themselves as leaders in society, not just business. This widespread trend was known as "stakeholder capitalism": Companies argued that they could do more to help workers, society and the planet, while also making more money for investors. But many experts saw this rhetoric as fundamentally flawed — and, it soon turned out, largely ineffective. Paying workers more inevitably costs money and cuts into short-term profits; so does turning down business opportunities that could have a negative impact on the environment. Meanwhile, CEOs who take stands on social or environmental issues risk drawing the ire of politicians and customers who disagree. "It is always going to be difficult, if you are a for-profit publicly traded company, to have your leader talk about anything other than maximizing profits," says Sekou Bermiss, an associate professor of strategy and entrepreneurship at the University of North Carolina at Chapel Hill. "That is, in the U.S., the way we are wired." But when Floyd was murdered, big companies had raised the expectations of employees and customers that they would take a stand. And Bermiss argues that many rushed into promises without thinking through the costs — or what made the most sense for each individual business. Instead, some companies relied too much on the prospect of financial rewards for DEI programs, or what became known as "the business case for diversity." "It was being pitched as 'Diversity is always going to help the bottom line,' Bermiss says. "But no one [who studies this] would ever say that." Indeed, although some analysts have made the business case for diversity, Bermiss' research has found that when companies increase the diversity of their executive teams, they generally don't see a financial impact — good or bad. Still, Bermiss and others point out that DEI policies can have significant business impacts, even if they're not apparent in short-term financial results. Having a more diverse team can help create products that appeal to more consumers, or help employees feel more satisfied with their jobs. Costco, for example, recently told investors that its DEI efforts "help bring originality and creativity to our merchandise offerings" and "enhance our capacity to attract and retain employees who will help our business succeed," among other benefits. The massive retailer, which also calls DEI part of its "code of ethics," successfully brushed off an anti-DEI shareholder proposal last month. Meanwhile, JPMorgan Chase CEO Jamie Dimon, who runs the nation's largest bank, has called DEI "good for business; it's morally right; we're quite good at it; we're successful." Costco successfully brushed off an anti-DEI shareholder proposal last month. Justin Sullivan/Getty Images hide caption It probably helps that both JPMorgan Chase and Costco are financial powerhouses, whose profits and share prices keep their investors happy. But both companies are also framing their DEI policies as a matter of morality or ethics, rather than just profits. That's exactly how more companies should be thinking about DEI, according to Bermiss — if (and only if) they see it as valuable. Bermiss acknowledges that not all companies will want to continue pursuing greater diversity, equity and inclusion. But he argues that if business leaders decide that pursuing such workplace goals is morally right and aligned with a company's values, then they'll be better able to stand up to criticisms or attacks. And, as he adds, that's firmer ground than hoping that "if we get two more Latinos on the board, our stock price will go up." Despite the ongoing pressures, Costco and JPMorgan aren't the only employers still spending money on DEI. In fact, some companies are ramping up: Paradigm, a tech consultancy that advises employers on diversity and inclusion, says it saw a 12 percentage-point increase last year in how many of its customers had dedicated DEI budgets. Paradigm CEO Joelle Emerson says that even companies that are ending DEI programs may rebrand the work rather than abandoning it altogether. Corporate America's diversity results have been "a mixed bag," she adds, "in part because companies often spent too much time and energy on initiatives that didn't have a measurable impact." Now she's hoping that employers are taking the time to create more thoughtful — and effective — programs to increase fairness. "I see this less as a rollback of DEI and more as sort of an evolution to the next phase of this work," Emerson says. Many of the companies ending DEI programs are scrubbing the now-politically toxic acronym from their websites and corporate statements. But their public statements insist that they still want to make everyone feel included. That could be a tricky balance, especially as the Trump administration continues ramping up attacks on DEI — including efforts to uncover rebranded diversity efforts inside federal agencies. And it remains to be seen whether corporate America can really be more effective while softening its language — and goals — around diversity, equity and inclusion. But Emerson, at least, is bullish. "I'm actually pretty optimistic about the future of this work," she says. "I'm not optimistic about the acronym DEI — nor do I particularly care." Sponsor Message Become an NPR sponsor
--------------------------------------------------

Title: AI-Briefing: DeepSeek’s emergence from nowhere shows open-source is eating the world
URL: http://digiday.com/media/ai-briefing-deepseeks-emergence-from-nowhere-shows-open-source-is-eating-the-world/
Time Published: 2025-02-03T05:01:00Z
Full Content:
In case you have been hiding under a rock for the past week, DeepSeek’s emergence (seemingly out of nowhere) has underlined the geopolitical aspect of one of the most disruptive forces in economic history. A key question facing the $225 billion-plus U.S. digital media sector is, how will its key players respond? Developments last week hint at such players adopting an open-source approach in a rapidly evolving industry landscape. Meanwhile, Digiday’s ad tech sources noted that, while DeepSeek poses a credible alternative to Big Tech, clients are in a cautious mood, particularly around privacy. The market disruption wrought by the technical feats of China-based DeepSeek’s new R1 large language model developed at a fraction of the cost of U.S. rival and AI talisman OpenAI and ChatGPT was demonstrated in stock prices. Notably, Nvidia, a leading supplier of GPUs essential for AI development, experienced a record one-day market value loss of approximately $593 billion, marking the largest single-day loss for any company to date. Meanwhile, the resulting impact on the market capitalization drops of Alphabet, Amazon, Apple, Meta and Microsoft — collectively, these companies dominate the ad-funded internet — were declines ranging from 5% to 10% in a similar period. The key to DeepSeek’s emergence was its open-source approach to developing its R1 model. This contrasts with OpenAI’s more proprietary strategy, where models are typically closed-source and access is provided through APIs. Despite the political tenor of the development, as exemplified by the privacy concerns flagged by Digiday sources, some of the internet economy’s foundational names are making moves that hint at an open future. For example, DeepSeek’s R1 model is now available on AWS, a sign (for some) of how the Amazon machine views others’ margin as its opportunity and will do whatever it takes to push its infrastructure strategy. One ad tech founder said potential clients are asking them to make sure they don’t use tech owned by companies like Amazon and Google, which makes having an alternative even more appealing. However, ad tech companies are still wary of using DeepSeek’s API and instead are looking for other options like running R1 on-premise. Elsewhere, some have noted the timing of Google’s Meridian — the online advertising giant’s open-source marketing mix model (MMM) — last week as significant. As Digiday sources recently observed, measurement is at the core of Google’s indispensableness in any media plan. However, as discussed extensively at last week’s annual leadership meeting hosted by the IAB, the loss of traditional audience-targeting signals, primarily third-party cookies, means Google’s ability to calculate how ads drive purchases is waning. Some interpret this embrace of the open approach from traditional walled garden players as a significant shift in their approach. Given the disruptive impact of AI on Google’s search hegemony, observers speculate if similar significant shifts in outlook can be expected from the titans of Big Tech. And the potential for downstream impacts are manifold, with ad tech sources telling Dgiday in separate conversations last week that they believe open-source models give them a chance to “control our own destiny.” Buy-side and sell-side sources told Digiday that R1’s transparency creates an alternative to black boxes like OpenAI and also offers them the opportunity to rely less on storing data with competitors like Google and Amazon. That doesn’t mean the Big Four won’t have a moat, but it does mean the moat’s eroded — at least for now. Meanwhile, OpenAI-patron Microsoft reported its latest earnings report last week, with CEO Satya Nadella declaring its AI business was approaching a run rate of $13 billion per year, up 175% year over year. This lofty figure failed to impress markets, though, as a comparatively modest revenue outlook for the coming quarter, along with residual concerns over the impact of DeepSeek, proved a drag on Microsoft’s stock price after earnings. Elsewhere, Apple also issued its earnings last week, and while its subsequent stock price fluctuations may have fared more stably than others in its Big Tech cohort, some noted how it will have to accelerate its AI deployment, i.e. Apple Intelligence, if it is to gain momentum. Given Apple’s increasing interest in the “services” sector, which increased 14% year on year for the reporting period to surpass $26 billion, and advertising in particular, it will be interesting to see just how AI will play a role in its Madison Avenue aspirations. Chris Vanderhook, COO and co-founder of publicly-listed ad tech company Viant, noted how the recent developments have been significant. “Because AI adoption is so early, they [Google, Meta, Amazon, etc.] didn’t get their hooks and claws into everyone yet,” he told Digiday. The Condé Nast-owned publication has recorded a four-times increase in revenue for its “Open Door” series and is planning a relaunch of its AD Shopping property, Astley said on the Digiday Podcast. Why publishers are finally facing programmatic’s hard truths. LinkedIn has been making a concerted effort to woo video creators since March 2024, when the company began testing a dedicated vertical video feed on its mobile app. Since then, video consumption on LinkedIn has grown consistently, with the company reporting 34 percent year-over-year growth in video uploads in Q4 2024 and 36 percent year-over-year growth in total video viewership in Q1 2025. Get access to tools and analysis to stay ahead of the trends transforming media and marketing Visit your account page to make changes and renew. Get Digiday's top stories every morning in your email inbox. Follow @Digiday for the latest news, insider access to events and more.
--------------------------------------------------

Title: Dub: the copy trading app that has teens talking
URL: https://techcrunch.com/2025/02/02/dub-the-copy-trading-app-that-has-teens-talking/
Time Published: 2025-02-02T18:00:56Z
Full Content:
Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us Social media changed everything, from news consumption to shopping. Now, Dub thinks it can do the same for investing through an influencer-driven marketplace where users can follow the trades of top investors with a few taps. Think of it as TikTok meets Wall Street. Founded by 23-year-old Steven Wang — a Harvard dropout who began investing in second grade with his parents’ blessing — Dub is betting the future of investing isn’t about picking stocks but picking people. The app allows users to follow the strategies of traders, hedge funds, and even those mimicking high-profile politicians. Instead of making individual trade decisions, Dub users can copy entire portfolios. The concept has struck a chord. Dub has already surpassed 800,000 downloads and raised $17 million in seed funding — with a new round seemingly in the works. Less clear is whether Dub can avoid the pitfalls of previous fintech startups. Retail investing has evolved dramatically over the past two decades. The days of $7 trading commissions and clunky brokerage interfaces were blown apart roughly a decade ago by mobile-first platforms like Robinhood that invited people to trade for free. At the same time, social media is reshaping how people, and particularly members of Gen Z, make financial decisions. As a Harvard student during the pandemic — one who was trading from his dorm room “because you couldn’t really do anything at school” — Wang came to believe these two trends, retail investing and influencer-driven decision-making, were on a collision course. Between the GameStop saga, Elon Musk’s ability to “move the Dogecoin and Bitcoin markets with every tweet,” and people’s willingness to “really follow ideas and individuals to a whole new level,” Wang decided to drop out in 2021 and start building Dub. Right now, the platform’s average user is between the ages of 30 and 35, says Wang, though New York-based Dub is clearly finding its way in front of an even younger audience. In recent weeks, this editor’s 15-year-old has asked more than once about “investing like Nancy Pelosi” after marinating in Dub ads on Instagram. Pelosi isn’t personally trading on Dub; it’s just a trader on the platform mirroring her disclosed moves. Still, the idea has caught fire. “Nancy Pelosi is up 123% on Dub with real capital,” says Wang, “and we’ve made our customers millions of dollars since that portfolio was launched on the platform.” Dub isn’t free. Wang was determined to generate revenue from the outset, and Dub does that today through a $10-per-month subscription model. Wang says further that some “top” portfolios on the platform charge management fees and Dub takes a 25% cut of those fees. In the meantime, Dub has scaled in part through organic growth. “Creators who are good traders on the app are incentivized to bring their audience,” says Wang, whose parents immigrated from China and who grew up in Detroit. Dub is also investing aggressively in advertising, leaning heavily into Meta ads in particular to acquire users, including on Instagram. “We’ve been really lucky where I think the broader American population really believes there are other people out there that have an edge over them when it comes to the investing world,” says Wang. The question now is whether Dub will follow a similar path as other fast-growing fintech startups, many of which have found themselves in the crosshairs of regulators. Robinhood disrupted finance by making trading free, but it also faced regulatory scrutiny ahead of its 2021 IPO, ultimately ditching a feature that showered users with digital confetti every time they made a trade. Dub says it’s keen to avoid the same mistakes. The company spent more than two years working with FINRA and the SEC before launching, ensuring its model complied with financial regulations. “We didn’t just navigate regulation at Dub — we embraced it,” Wang says. (Like Robinhood, Dub is a fully licensed broker-dealer.) A big distinction, argues Wang, is that Dub is designed to educate users, not just encourage blind speculation. The platform displays risk scores, risk-adjusted returns, and portfolio stability metrics to help investors make informed decisions, he says. He suggests it’s safer for investors than Robinhood. Says Wang: “I have a lot of respect for what [CEO] Vlad [Tenev] has done in making trading free. But at the end of the day, making it super easy to trade without expert guidance, without education, is really just gambling for the broader population.” To underscore his point, Wang points to the decision of Robinhood — along with Coinbase and other exchanges — to make the meme coin TRUMP available for customers ahead of President Donald Trump’s inauguration. While it initially surged in price, its price has plummeted since. Says Wang, “I think fundamentally the incentives are just misaligned between these big platforms that are public companies now that need to make money” and that “generally” their customers have “probably lost money.” (Worth noting: In a separate, recent conversation with Robinhood’s Tenev about Dub, Tenev proposed to TechCrunch that copy trading could become of greater interest to regulators and that Dub may not yet be under the “magnifying glass” because of its comparatively smaller size.) Either way, not everyone is sold on Dub’s vision. The biggest knock against such platforms, says critics, is that stock picking underperforms passive investing over the long run, with studies showing that most actively managed funds fail to beat the S&P 500. It’s a criticism with which Wang is familiar — and on which he’s quick to push back. For one thing, he argues that many such studies are “cherry-picked.” (“I bet a lot of those are sponsored by the passive investing index companies,” he says.) Further, says Wang, there’s a reason that actively managed hedge funds like Citadel are thriving. “If you look at what the ultra wealthy can do, they’re giving their money to Ken Griffin of Citadel, [because] they’re consistently putting up non-correlated returns year after year after year,” he says. If one more broadly “looks at the growth of the hedge fund space and the asset management space,” continues Wang, “there’s a reason why it’s growing. It’s because they are making money for their customers.” Topics Editor in Chief & General Manager Loizos has been reporting on Silicon Valley since the late ’90s, when she joined the original Red Herring magazine. Previously the Silicon Valley Editor of TechCrunch, she was named Editor in Chief and General Manager of TechCrunch in September 2023. She’s also the founder of StrictlyVC, a daily e-newsletter and lecture series acquired by Yahoo in August 2023 and now operated as a sub brand of TechCrunch. Ontario cancels, then restores, $68 million Starlink contract after protesting US tariffs Meta says it may stop development of AI systems it deems too risky DeepSeek: The countries and agencies that have banned the AI company’s tech Hot Tub, the first native iPhone porn app, arrives in EU Hero’s all-in-one, AI productivity app takes on Google’s Calendar and others DeepSeek founder Liang Wenfeng receives a hero’s welcome back home Dub: The copy trading app that has teens talking Subscribe for the industry’s biggest tech news Every weekday and Sunday, you can get the best of TechCrunch’s coverage. TechCrunch's AI experts cover the latest news in the fast-moving field. Every Monday, gets you up to speed on the latest advances in aerospace. Startups are the core of TechCrunch, so get our best coverage delivered weekly. By submitting your email, you agree to our Terms and Privacy Notice. © 2024 Yahoo.
--------------------------------------------------

Title: 3 Growth Stocks For The Next 5 Years
URL: https://www.forbes.com/sites/investor-hub/article/best-growth-stocks-for-next-5-years/
Time Published: 2025-02-02T18:00:00Z
Full Content:
Embraer, Nvidia and TSMC share key strengths, such as a wide competitive moat and huge market ... [+] demand, positioning them for significant future growth. Investing in high-growth companies with a long-term perspective is a proven strategy for building wealth, but not all fast-growing companies are created equal. The opportunity lies in identifying stocks poised to capitalize on sustainable trends, with a minimal risk of degrading into obsolescence. The article highlights a small selection of growth stocks that meet these benchmarks. The selected stocks: Brazilian aerospace company Embraer (ERJ) produces a fleet of commercial, business and defense jets. It is popular for its single-aisle E175-E2 commercial planes, the C-390 Millennium military transport aircraft and the Phenom 300, a top-seller in the light jet category for the last 12 years. The ERJ stock has climbed more than 125% in the past year, and returned to investment grade credit rating. Whether Embraer can disrupt the Boeing-Airbus duopoly, because of Boeing’s brutal year and Airbus’ supply-chain snags, is debatable. However, the Brazilian plane maker appears strategically positioned to capitalize on its robust order backlog and strong performance across all of its segments. 1. Strong backlog Embraer’s firm order backlog rose to $22.7 billion in the third quarter of 2024, marking its highest level in the past nine years. This provides visibility for steady cash flow in the years ahead. 2. Rising deliveries despite supply chain constraints Embraer delivered 206 aircraft in 2024, up 14% from 181 in 2023. About 63%, or 130 of these, were executive jets. In 2023, the Brazilian aircraft maker delivered 115 executive jets, representing roughly the same 63% of overall deliveries. It is interesting to note that Embraer allows customers to design their own executive jets using a new aircraft configurator. The company continues to see double-digit growth for aircraft deliveries, revenue and EBIT in 2025 and beyond, even as it navigates its supply chain constraints. 3. Attractive economics of E2 jets position it well for replacement opportunities Embraer’s E195-E2 jets are gaining traction in the Commercial Aviation sector, due to their superior economics and passenger-friendly design, including no middle seats and 40% larger overhead bins. The E195-E2 will feature automatic takeoff, an industry-first, before the end of this year, and can operate from shorter runways. Embraer’s E2 family offers 16% lower fuel consumption compared to its first-generation E-Jets, and 25.4% better fuel efficiency per seat. In 2024, Embraer sold 47 E195/E190-E2 jets and 26 E175 jets, up from 39 and 25, respectively, in 2023. The growing need to replace 3,000+ small narrow-body aircraft worldwide presents a significant opportunity for the E2 family over the next few years. The efficient E195-E2 is profitable at a ~80% load factor, a dynamic that highlights its potential as a preferred choice for both mainline and low-cost carriers, looking to expand connectivity to secondary cities. The number of cities without service or served less than once daily has increased from 49 in 2019 (pre-pandemic) to 85 in 2023, highlighting a significant opportunity for the E2 family’s capabilities. U.S. airlines are unable to operate the higher-capacity E195-E2 that has a maximum of 146 seats, due to the scope clause in contracts between airlines and pilots’ unions that limits the number of passengers a regional aircraft can carry to 76. If the scope clause is ratified, it may open the floodgates of the U.S. commercial aviation market for the E2 jets. 4. Solid spot in defense Embraer’s Defense & Security segment continues to perform well, delivering three new generation military multi-mission transport aircraft, the C-390 Millennium, in 2024, up from two in 2023. Embraer’s light attack aircraft A-29 Super Tucano is also seeing strong demand, with over 290 orders. Growing geopolitical complexity across the globe may boost defence budgets, and Embraer may be in the right spot to benefit. 5. Reclaiming investment-grade rating Embraer has significantly deleveraged its balance sheet over the past three years, lowering its net debt-to-EBITDA leverage ratio to 1.3x in the third quarter of 2024 from 3.9x in 2021 (and 20.7x in 2020). It has no relevant debt to be paid back during the next 2.5 years. The continued improvement in credit metrics has helped the Brazilian airplane-maker return completely to investment-grade rating in 2024. 6. Accolades from customers, analysts Embraer’s reputation for reliability has earned praise from customers like American Airlines. In an earnings call last year, American Airlines CEO Robert Isom extolled Embraer. “I want to give a shout out to Embraer,” Isom said. “They have delivered day in and day out, throughout the pandemic, no matter the concerns of their supply chain.” American’s regional jet fleet comprises 302 Embraer aircraft and that includes 210 E175s. Bank of America analysts highlighted the fact that Embraer was largely on time and on budget with its projects between 1999 and 2019, calling it “an engineering marvel.” 7. Plans for a new jet rivaling Boeing’s 737 Embraer may reportedly be mulling a new jet to compete with Boeing 737. The Wall Street Journal reported that Embraer is holding talks with potential partners and financial backers on its plans for a new narrow-body aircraft. If reports are to be believed, and everything goes as planned, then Embraer will likely take off to new heights. Nvidia (NVDA) has emerged as one of the standout performers in the U.S. stock market, with its stock soaring nearly 1900% in the past five years, despite recent volatilities. This remarkable surge is driven by the skyrocketing demand for Nvidia’s graphics processing units (GPUs), which power nearly all advanced artificial intelligence systems. However, recent DeepSeek revelations have created uncertainty about America’s AI dominance, wiping $600 billion off Nvidia’s market value in a single day, and unseating it from its pedestal as the most valuable company in the world. DeepSeek, reportedly developed for a fraction of the cost of its U.S. rivals, has sparked questions about the continued need for Nvidia’s high-performance and expensive chips. Despite these concerns, I continue to believe that Nvidia is a more reliable bet on the future of AI. 1. Geopolitical and regulatory risks with DeepSeek DeepSeek hails from China, and that definitely adds a layer of complexity. The Chinese government’s influence over domestic tech companies, coupled with the potential for sudden regulatory actions, poses a significant risk for investors, especially in light of what happened with companies like Alibaba. Additionally, given the U.S.’s pattern of banning or restricting Chinese tech companies (like TikTok) over national security concerns, a similar fate may await DeepSeek, as the stakes around data privacy and security are even higher with AI technology that handles huge volumes of data. This could potentially hinder DeepSeek’s global scalability. 2. Unproven claims on cost efficiency DeepSeek claims spending a mere $5.57 million to develop its model, representing a fraction of LLAMA 3.1’s $500 million, but analysts have dismissed this figure, noting it overlooks substantial hidden costs. DeepSeek’s alleged use of 10,000 A100 GPUs may also be inflated, with reports suggesting as many as 50,000 Hopper GPUs were used, which in turn could raise concerns given the ongoing "GPU embargo.” 3. Lack of transparency DeepSeek clamming up on politically-sensitive questions related to China, but showing willingness to slam Biden and Trump, further distinguishes it from open-source AI models like ChatGPT, which are more transparent and accountable. DeepSeek’s opacity raises doubts about its commitment to openness and responsible AI practices. 4. Nvidia: an established AI ecosystem DeepSeek is an AI startup, but Nvidia is an AI leader. Nvidia’s strength lies not just in its GPUs, but in its deep and integrated AI ecosystem, including its strategic partnerships and the CUDA platform – the gold standard for GPU acceleration in AI development. Shifting away from CUDA would pose an immense challenge for competitors, giving Nvidia a significant competitive edge. Nvidia itself expressed no existential angst, calling DeepSeek’s open-source reasoning model R1 "an excellent AI advancement.” Nvidia’s AI leadership, strong economic moat and proactive product innovation position it for continued growth. 1. Nvidia’s primary economic moat is its innovation Nvidia does not think out of the box, it thinks like there is no box. The company transformed its graphics processors into powerful AI chips, sparking unprecedented growth. By targeting the right end markets for its Omniverse platform, Nvidia succeeded where Meta struggled with its Metaverse ventures. The impenetrable CUDA armor is a further testimony to its Midas Touch. 2. Blackwell GPU demand outpacing expectations Nvidia’s next-gen Blackwell GPUs are already in high demand, outstripping supply by a factor of 15. Wedbush analyst Dan Ives notes that Nvidia can supply only one chip for every 15 chips customers are looking to buy. Barclays analyst Tom O'Malley sees Blackwell GPUs adding $15 billion to Nvidia's sales in the current quarter, with the potential to double in the next quarter. UBS analyst Timothy Arcuri now sees Blackwell revenues of $9 billion for the January quarter vs. prior expectations of $5 billion, with sales rising in the next few years. 3. NVIDIA’s sovereign AI initiatives gathering momentum as India, Japan sign up NVIDIA’s Sovereign AI initiatives are gaining significant traction as India and Japan embrace the company’s accelerated computing for a new era of AI-driven industrial transformation. India’s Cloud Service Providers (CSPs), including Tata Communications, are constructing AI factories, with Nvidia GPU deployments in the country expected to increase nearly 10x by year-end. Japan is building its most powerful AI supercomputer using Nvidia’s DGX Blackwell. 4. Immense growth potential in autonomous vehicles and robotics Nvidia’s Automotive and Robotics segment posted third-quarter revenues of $449 million, a small fraction vs. its record data center revenues of $30.8 billion. However, with its Cosmos foundation models, Nvidia is poised for massive growth in the autonomous vehicles and robotics sectors. Cosmos foundation models generate photo-realistic video to facilitate the training of robots and self-driving vehicles at a significantly reduced cost vs. using traditional data. Huang notes “We really hope (Cosmos) will do for the world of robotics and industrial AI what Llama 3 has done for enterprise AI. Analyst Ives sees Nvidia reaching a market cap of $5 trillion as it unlocks this underappreciated growth opportunity in Robotics and AVs. TSMC is a leading contract chip manufacturer, producing AI chips for major companies like Nvidia, Apple, Qualcomm, AMD and even Intel. TSMC’s foundry dominance is built on years of investment in cutting-edge process technologies, along with a commitment to a pure-play foundry model and a strategic policy of not competing with its clients. This has allowed TSMC to capture nearly 65% of the global semiconductor foundry market share, far outpacing Samsung, which holds just 9.3%. TSMC’s near monopoly in producing advanced chips for AI and other futuristic technologies, coupled with its relentless push for smaller nodes and more efficient processes sets it a class apart. 1. Pole positioning as a critical AI enabler TSMC enjoys unparalleled leadership in the production of advanced semiconductors powering AI and data centers because of its superior process technology, strong foundry design ecosystem and reputation as a consistent and reliable chip maker. This unique positioning gives it pricing power and the confidence to set a target for long-term gross margins of 53% and higher. TSMC is reportedly looking at a 5% hike in wafer prices for 2025. The company affirmed that it sells its U.S.-made wafers at a slight premium to Taiwan-made ones, because of the higher cost structure in the U.S. 2. AI accelerators to drive 5-year growth Revenue from AI accelerators, including AI GPU, AI6, and HBM controller for AI training and inference in the data center, accounted for close to mid-teens percent of TSMC’s total revenue in 2024. Even after more than tripling in 2024, revenue from AI accelerators is expected to double in 2025 as the strong surge in AI-related demand continues. TSMC forecasts revenue growth from AI accelerators to approach a mid-40% CAGR for the five-year period from 2024. AI accelerators are seen as the strongest driver of TSMC’s High Performance Computing (HPC) platform growth and the largest contributor in terms of overall incremental revenue growth in the next several years. 3. Long-term revenue growth at a 20% CAGR For the five-year period starting from 2024, TSMC expects long-term revenue growth to approach a 20% CAGR in U.S. dollar terms, fueled by all of its growth platforms – smartphone, HPC, IoT and automotive. 4. Strong U.S. relationships For the skeptics worried about the U.S. export curbs on chips, it would be good to know that TSMC emphasizes its long-standing, good relationship with the U.S., and is building fabs in Arizona. Its first fab in Arizona has already entered high-volume production in the fourth quarter of 2024, utilizing N4 process technology with a yield comparable to its fabs in Taiwan. TSMC’s plans for two more fabs in Arizona are also on track. These fabs will use advanced technologies such as N3, N2, and A16. 5. Upcoming 2-nm node presents strong potential TSMC’s Industry-leading 2-nanometer and A16 technologies meet the insatiable need for energy-efficient computing. N2 is well on track for volume production in the second half of 2025. Other future offerings like N2P and A16 that are scheduled for volume production in the second half of 2026, feature further performance and power benefits over N2. Embraer, Nvidia and TSMC share key strengths, such as a wide competitive moat and huge market demand, positioning them for significant future growth. However, these companies don’t simply rest on their laurels; they continue to innovate ensuring their growth drivers remain relevant and impactful over the long term. With AI driving the growth narrative forward, Nvidia and TSMC are key beneficiaries. Embraer is well positioned to benefit as it serves a critical sector with its much-needed solid engineering capabilities amid strong demand dynamics, and its ability to successfully navigate supply chain constraints.
--------------------------------------------------

Title: Internet Search, Capital Spending Key In Alphabet Earnings. Is Google Stock A Buy?
URL: https://www.investors.com/news/technology/google-stock-googl-buy-now-alphabet-stock-february-2025/
Time Published: 2025-02-02T14:30:18Z
Description: On Google's Q4 earnings call, CEO Sundar Pichai will likely address the company's artificial intelligence strategy in the wake of DeepSeek news.
--------------------------------------------------

Title: 'Tyranny of high expectations': A veteran investment chief explains why he's quietly cutting exposure to US stocks, even though he's optimistic about the economy and AI
URL: https://www.businessinsider.com/stock-market-economy-how-to-invest-strategy-valuations-ai-page-2025-2
Time Published: 2025-02-02T11:19:01Z
Full Content:
Many of the market's biggest fears may be overblown, though the head of global multi-asset at T. Rowe Price is starting to scale out of US stocks anyway. Investment chief Sébastien Page recently told Business Insider that he's not worried about economic growth, even though fourth-quarter GDP just came in lighter than expected. GDP still more than doubled consensus estimates in 2024, he noted. Corporate earnings, spending, and the unemployment rate also look healthy, and that's before tax cuts and deregulation. It's also too soon to say that China-based DeepSeek's highly effective chatbot will send artificial intelligence spending spiraling, Page said. After speaking with T. Rowe Price's tech analysts, the 25-year market veteran concluded there's no need to panic about DeepSeek. "The economy looks fine, earnings are looking to grow at 15%, and you still have a lot of AI spending that's actually going to increase maybe by 20%, based on our analyst estimates," Page said in an interview. However, Page also said US equities don't look as attractive after a massive multi-year rally. His main concern is the same as it was last fall: Markets are already pricing in plenty of good news. The S&P 500's forward earnings ratio is in the 95th to 98th percentile historically, he noted, but it pales in comparison to that of mega-cap growth stocks. This group's valuations are even more stretched now than they were in mid-November, following the postelection market surge. Even if all goes well with the economy, which Page sees as likely but far from certain, US stocks could fall short of lofty expectations if investors are underwhelmed by earnings. That's why as markets march ever-higher, Page said he's increasingly inclined to take money off the table. "We're still overweight stocks, but we're starting to reduce that overweight," Page said. "We're determining our risk-on positioning. I think as markets continue to rally, we'll continue to fade our overweight to go back to neutral-weight — not get out of stocks completely, just get back to neutral-weight. So that's how we're playing this right now." It's hard to poke a hole in fourth-quarter earnings results, at least so far. Profits have exceeded estimates and are up about 10% so far, according to Bank of America. Big-tech earnings were more of a mixed bag, as Meta pleased investors while Microsoft and Apple had some red flags. While some companies have issued timid forward guidance, the Street thinks earnings will rise at a mid-teen rate in 2025. If analysts are right, stocks could be in for another strong year. "The forecast for the next 12 months is that earnings are going to grow at 15% — that's a high bar," Page said. "So if you want to be an optimist, we can say, 'Look, we don't even need P/E expansion; we don't even need valuations to go higher. If just earnings come through, we can get double-digit stock returns.'" But companies have almost no room for error, Page said, considering where valuations are in the face of interest rates that are now expected to stay at restrictive levels for a longer time. So unless quarterly results meet or exceed an exceedingly high bar, US stocks could take a big hit. "I call it the 'tyranny of high expectations,'" Page said. "Meaning, the expectations for earnings growth are so high that you set yourself up for missing the mark." Cheaper value stocks are among the safest places to be in this expensive market, Page said. The market has fallen by 1% or more 17 times in the last 200 trading sessions, Page noted. In each of those instances, stocks with a value tilt have outperformed their growth-oriented peers, he said. That means value stocks are a better bet during selloffs, and have rebound potential. "Projecting forward 12 months, I would ascribe at least as much upside in value as in growth, given the valuation differential and the broadening fundamentals," Page said. "So to be overweight value I think is an interesting less-downside/same-upside kind of trade." However, that's not to say that the investment chief is bearish on growth stocks. The AI trade isn't over, Page said, as cheaper, better AI can actually cause its adoption rate to accelerate. "I would own both growth and value; tech and non-tech," Page said. "I think we're probably approaching peak concentration. So in our portfolios, we have a slight overweight to value stocks. We think growth stocks are still a very good long-term investment." With that said, stocks in economically sensitive sectors like energy, financials, and materials are strong bets because their valuations are reasonable, and the gap between their earnings growth and those of tech firms is narrowing. The same is true of healthcare stocks, he noted. Outside of the US, investors should stay selective. Page isn't overly bullish on international stocks but said less-heralded markets like Japan, Argentina, and Brazil are worth a look. In short, Page said his best advice for the next 11 months is the same as it usually is. "I don't really like to say, 'Stay invested; stay diversified,' because it's sort of an answer you can give at any point in time," Page said. "If you think about that statement, you could put it on a fortune cookie." But in this richly valued and ever-shifting stock market, that truism rings especially true. "I expect markets to broaden, hence the 'stay diversified,' and I think the economy and earnings will do just fine, hence the 'stay invested,'" Page said. "So when someone asks you in an elevator, 'Hey, you're an investment person,' what should you say? Just say that. And it actually works quite well right now." Jump to
--------------------------------------------------

Title: DeepSeek Is America’s Wake-Up Call
URL: https://www.theamericanconservative.com/deepseek-rattles-the-cage/
Time Published: 2025-02-02T05:03:00Z
Description: And Trump's reaction to DeepSeek R1’s release was informed and multifaceted.
The post DeepSeek Is America’s Wake-Up Call appeared first on The American Conservative.
--------------------------------------------------

Title: The global AI race: Is China catching up to the U.S.?
URL: https://financialpost.com/financial-times/ai-china-catching-up-us
Time Published: 2025-02-01T16:06:26Z
Description: Deepseek has upended assumptions about U.S. AI supremacy and raised the prospect that some in China are beating Silicon Valley. Read more.
--------------------------------------------------

Title: Apple is no longer working on smart glasses to rival Meta
URL: https://www.digitaltrends.com/computing/apples-upcoming-ar-glasses-might-be-dead-water/
Time Published: 2025-02-01T14:30:57Z
Full Content:
It’s been a rumor for some time now that Apple had a pair of AR glasses in development, but a new report from Mark Gurman says the company has cancelled the project. Apple has expressed a lot of interest in the AR/VR space, but its first attempt with the Vision Pro didn’t make the splash the company expected. Its over-the-top price and more professionally-focused applications led to fewer sales and a lot of excess stock. The goal was to create a competitor to the Meta’s Ray-Ban smart glasses, but Gurman says the cancellation comes in the wake of an attempt to change and improve the design of the glasses. The first version of the glasses would link with an iPhone, but its limited power meant applications were limited — and the demands of the device also had an impact on phone battery life. Apple pivoted and focused on linking the glasses with a Mac instead, but that was met with poor evaluations. The development team reportedly dealt with frequently-changing goals, adding to the difficulty, until the project was cancelled. Unfortunately, this isn’t the first time Apple has shuttered a project. The company has entertained the idea of a self-driving car for a decade, but Apple gave that project the axe last year. Gurman says Apple also cancelled work on in-house LED displays for the Apple Watch, too. The loss of these projects doesn’t bode well for the future of the already-struggling Vision Pro. Gurman says Apple has a planned successor to the Vision Pro that would improve on the flaws in its original release, although there are employees who “believe there’s a lack of focus and clear direction within the team.” Apple hasn’t completely given up on AR glasses. Several unnamed executives “still hope to eventually create a set of standalone AR glasses someday,” according to the report. Meta doesn’t plan to release its AR smart glasses until 2027, so Apple still has some time to come up with another approach. It would be a welcome addition to the lineup, and a much more affordable way to access Vision Pro-like features. Posts on X are popping up reporting that Microsoft has signed a development and supply contract with Samsung Display for micro-OLED displays. The information originates from a Korean tech site, The Elec, which claims that Microsoft wants "hundreds of thousands" of these displays for an XR device designed for gaming and media consumption. In other words, a competitor for the Vision Pro -- or rather, another competitor for the Vision Pro. There's no doubt that the Vision Pro hasn't exactly been a bestseller. A new report from market analysts indicates that fewer than 500,000 Vision Pro headsets will be sold by the end of the year. However, the report also offers some good news for the future of the platform. According to Bloomberg, citing data from market analyst IDC, Apple is planning a cheaper version of the Vision Pro in 2025, and that could be the company's ticket to a much more popular device, predicting that it could double the sales of the Vision Pro next year. A few years back, I was invited to meet with Apple about its new push into gaming. The company wouldn’t show me a flashy new product to enable that. Instead, it showed me something more modest: No Man’s Sky running smoothly on a MacBook. It looked great, but it wasn’t exactly earth-shattering. It was an independent game from 2016 running on a laptop as well as it had already been running for years on other PCs. I got the sense that I wasn’t there to cover a big development in tech, but rather to see a proof of concept that had bigger plans attached. Years later, those plans are coming into focus even if they still aren’t fully realized yet. I recently attended a repeat of that showcase, only this time I wasn’t just watching an eight-year-old game running on a laptop. I demoed several games, including brand new ones, this time running on a range of devices including the MacBook Air M3 and a 13” iPad Pro M4. While we’re still a long ways away from the App Store being up to snuff with Steam on Windows, I’m starting to see where gaming on iOS is headed -- and Apple is getting there faster than I expected. Growing gaming During my recent session with Apple, I’d get to see and play several games running across iPhone, iPad, and Macbooks. Some of those experiences are more exciting for Apple than for casual players. It’s neat that Resident Evil 7 can run well on an iPhone, but that’s not so surprising when I already know that the much more recent Resident Evil 4 does too. I’m happy to see games like Control and Valheim looking great, but those are existential wins for Apple as it seeks more partners to expand its gaming efforts. I don’t imagine that gamers are jumping to play games that have been out for years on an Apple device (and according to reports, they very much aren’t yet). Upgrade your lifestyleDigital Trends helps readers keep tabs on the fast-paced world of tech with all the latest news, fun product reviews, insightful editorials, and one-of-a-kind sneak peeks.
--------------------------------------------------

Title: Dave Vellante’s Breaking Analysis: The complete collection
URL: https://siliconangle.com/2025/02/01/dave-vellantes-breaking-analysis-complete-collection/
Time Published: 2025-02-01T11:33:12Z
Full Content:
UPDATED 06:33 EST / FEBRUARY 01 2025 BREAKING ANALYSIS by Dave Vellante Breaking Analysis is a weekly editorial program combining knowledge from SiliconANGLE’s theCUBE with spending data from Enterprise Technology Research. Branded as theCUBE Insights, Powered by ETR, the program is our opportunity to share independent, unfiltered editorial with SiliconANGLE, theCUBE and Wikibon communities. The program and conclusions we produce are data-driven, tapping ETR’s proprietary spending data set. Episode 221 – Nvidia, Broadcom and the expanding breadth of AI – We attended both Nvidia Corp.’s GTC conference and Broadcom Inc.’s investor day this week where the artificial intelligence platform shift was on full display. In our view, GTC24 was the most important event in the history of the technology industry, surpassing Steve Jobs’ iPod and iPhone launches. The event was not the largest but, in our opinion, it was the most significant in terms of its reach, vision, ecosystem impact and broad-based recognition that the AI era will permanently change the world. Meanwhile, Broadcom’s first investor day underscored both the importance of the AI era and the highly differentiated strategies and paths that Nvidia and Broadcom are each taking. We believe Nvidia and Broadcom are currently the two best-positioned companies to capitalize on the AI wave and will each dominate their respective markets for the better part of a decade. But importantly, we see them each as enablers of a broader ecosystem that collectively will create more value than either of these firms will in and of themselves. In this Breaking Analysis, we will share our perspectives on the state of AI and how Nvidia and Broadcom are each leading the way with dramatically different but overlapping strategies that may be headed for an eventual collision course. Watch the full video analysis. Episode 220 – Navigating NVIDIA & the AI Trade – Sell, hold or double down? – Heading into the second half of 2023, some investors felt that the semiconductor run up last summer was a harbinger for a broader tech rally. That thesis proved prescient and rewarded managers who took on risk at the time with leading firms in semiconductors, security and enterprise software. The question is, where do we go from here? In this Breaking Analysis we welcome back Ivana Delevska, the founder and chief investment officer at Spear Invest, Nasdaq SPRX. Some have compared SPRX to a miniature version of Cathie Wood’s ARKK fund. However SPRX is more sector agnostic where Delevska focuses more broadly on growth themes such as her current emphasis on cybersecurity, semiconductors, and enterprise software. Watch the full video analysis. Episode 219 – Why CrowdStrike is separating from the cybersecurity pack – It’s been an interesting month in the cybersecurity space. The sector has been somewhat less affected by budget tightening these past twenty-four months and at the same time has benefitted from AI tailwinds. But in the past several weeks we’ve seen some separation in key highflying cybersecurity names. Specifically, Palo Alto shocked the street last month with a $600M billings forecast surprise and sounded the alarm that there were cracks in its consolidation execution. This dragged down other consolidation players in sympathy, namely CrowdStrike and Zscaler. But our research shows that the dynamics facing these three companies are quite different. Of particular note, CrowdStrike’s earnings print highlights the company’s impressive momentum while recent negativity around Zscaler is a bit of a head scratcher for us, which we’ll try to explain. In this Breaking Analysis we take a more narrow look at the information security space and dig deeper into the continued success of CrowdStrike. With recent survey data from ETR, we continue to advance our premise that platforms beat products and we identify several levers that are powering CrowdStrike’s path to $5B by FY 2026 and to $10B by the end of the decade. Watch the full video analysis. Episode 218 – The unplanned genius of Broadcom’s route to AI dominance – Broadcom is perhaps the most unique company in the technology business. It doesn’t simply chase markets that are on steep growth curves and can deliver short term ROI. Rather it goes after established markets with durable franchises. Broadcom focuses its R&D on serving customers in these markets with major engineering investments to achieve a dominant position in each of its target sectors. And sometimes, the company lucks out with this strategy and catches a wave accidentally by design. In this Breaking Analysis we extract key nuggets from our sit down at MWC this week with Charlie Kawwas, president of Broadcom’s Semiconductor Solutions Group, and we unpack the contrarian business technology model of Broadcom. Watch the full video analysis. Episode 217 – Cloud optimization wanes as AI slowly lifts off – The past twenty-four months have seen cloud spending face dual headwinds of macroeconomics and the ability to dial down resources as needed – i.e. cloud optimization. Nonetheless, the big four hyperscalers clocked in between $170 – $190B in IaaS and PaaS revenue last year depending on how you factor the leaked court documents suggesting Azure is much smaller than previously believed. Regardless, hyperscaler growth continued to outpace almost all markets, accelerating between 18-19% in revenue terms last year, despite their enormous size. As we progress into 2024, IT decision makers are cautiously optimistic about spending levels, especially for the second half. All hyperscalers report that cloud optimization is slowing although pockets of cloud cost cutting remain. While AI gets all the headlines, its contribution to revenue is still a small fraction of the overall spending pie. For example, we estimate that Microsoft’s AI services accounted for around $800M this past quarter. But the trajectory for AI services and the potential uplift looks promising for all four hyperscalers. We think collectively the generative AI uplift in cloud will surpass $10B this year. In this Breaking Analysis we update you on our latest hyperscale cloud spending and market share data. We’ll analyze the ETR survey data on cloud optimization, assess the Gen AI updraft for the big 3 US cloud players and look at some of the industry trend data on cloud spend by platform. Watch the full video analysis. Episode 216 – Intel Foundry is a bold bet filled with uncertainty – As an American, you can’t help but root for Intel CEO Pat Gelsinger to succeed. His vision to bring semiconductor manufacturing leadership back to the United States is more than just a quaint nationalistic sentiment. Rather it’s a strategic imperative for the country, its military, global competitiveness and access to future technological innovations in the AI era. But his strategy is dependent upon the success of Intel both as a designer and a leading manufacturer of advanced chips. As such this choice puts Intel in a multi-front war with highly capable leaders in several markets, including names like AMD, NVIDIA, AWS, Google, Microsoft, Apple, Tesla and other chip designers…even perhaps OpenAI. As well Intel competes with with established manufacturers like Taiwan Semiconductor and Samsung. Moreover, Intel’s business model has been disrupted by Arm which has created a volume standard powered by the iPhone and mobile technologies. Finally, China, Inc. looms as a long-term competitor further underscoring the imperative. But the trillion dollar questions are: 1) What are the odds that Intel’s strategy succeeds; and 2) Are there more viable alternative strategies for both Intel and the United States? Watch the full video analysis. Episode 215 – Slicing the Gordian Knot – A leap to real time systems of truth – In order to support the vision of the sixth data platform, that is, a capability that allows a globally consistent, real-time, intelligent digital representation of a business, we believe the industry must rethink the single system of truth. Specifically, we envision a new data platform that marries the best of relational and nonrelational capabilities and breaks the multi-decades tradeoffs between data consistency, availability and global scale. Further, we see the emergence of a modular data platform that automates decision-making by combining historical analytic systems with transactions to enable artificial intelligence to take action. In this Breaking Analysis, we welcome two innovators, Eric Berg, chief executive of Fauna Inc., and S. Somasegar, managing director at Madrona Ventures. Watch the full video analysis. Episode 214 – Enterprise Technology Predictions 2024 – Predictions about enterprise tech have never been more uncertain. They become even more challenging when you try to make forecasts that are measurable. Generally, our belief is we should be able to look back a year later and say with some degree of certainty whether the prediction came true – ideally with some quantifiable evidence to back that up. In this Breaking Analysis and for the third year in a row, we collaborate with Erik Bradley of Enterprise Technology Research and to share our annual enterprise technology predictions. Watch the full video analysis. Episode 213 – 2024 IT spending outlook shows cautious start with optimistic finish – According to recent spending intentions data from over 1,700 information technology decision-makers, executives anticipate a 4.3% growth in technology budgets for the year, which is an improvement from the 3.5% growth seen in 2023 and higher than the 3.8% expectation from October. However, the forecasts for 2024 are back-loaded, with Q1 2024 forecasts at 2.4%, indicating that the optimism is concentrated in the second half of the year. Watch the full video analysis. Episode 212 – Unifying intelligence in the age of data apps – We believe the future of intelligent data apps will enable virtually all organizations to operate a platform that orchestrates an ecosystem similar to that of Amazon.com. By this we mean dynamically connecting and digitally representing an enterprise’s operations including its customers, partners, suppliers and even competitors. This vision includes the ability to rationalize top down plans with bottom up activities across the many dimensions of a business – e.g. demand, product availability, production capacity, geographies, etc. Unlike today’s data platforms, which generally are based on historical systems of truth, we envision a prescriptive model of a business’ operations enabled by an emerging layer that unifies the intelligence trapped within today’s application silos. In this Breaking Analysis, we explore in depth, the semantic layer we’ve been discussing since early last year. To do so we welcome Molham Aref, the CEO of RelationalAI. Watch the full video analysis. Episode 211 – Grading Our 2023 Enterprise Technology Predictions – Predictions about the future of enterprise tech are streaming to our inboxes, literally by the thousands. Most are thoughtful and we will review those prior to publishing our 2024 predictions later in January. As is our tradition, we try to make our own predictions more challenging by citing forecasts that are measurable and have either a numeric tied to them or a binary outcome. Our belief is if we make a prediction, you should be able to look back a year later and say with some degree of certainty whether the prediction came true or not. With some empirical evidence to back that up. In this Breaking Analysis we grade the 2023 predictions we made with ETR’s Erik Bradley. We look back at what we said in January about the macro IT spending environment, cost optimization, security, generative AI, cloud, blockchain, data platforms, automation and tech events. Watch the full video analysis. Episode 210 – David vs Goliath reimagined – OpenAI’s approach to AI supervision – Artificial general intelligence, or AGI, has people both intrigued and fearful. As a leading researcher in the field, last July, OpenAI introduced the concept of superalignment via a team created to study scientific and technical breakthroughs to guide and ultimately control AI systems that are much more capable than humans. OpenAI refers to this level of AI as superintelligence. Last week, this team unveiled the first results of an effort to supervise more powerful AI with less powerful models. While promising, the effort showed mixed results and brings to light several more questions about the future of AI and the ability of humans to actually control such advanced machine intelligence. In this Breaking Analysis we share the results of OpenAI’s superalignment research and what it means for the future of AI. We further probe ongoing questions about OpenAI’s unconventional structure which we continue to believe is misaligned with its conflicting objectives of both protecting humanity and making money. We’ll also poke at a nuanced change in OpenAI’s characterization of its relationship with Microsoft. Finally we’ll share some data that shows the magnitude of OpenAI’s lead in the market and propose some possible solutions to the structural problem faced by the industry. Watch the full video analysis. Episode 209 – Moving beyond separation of compute & storage…Journey to the 6th data platform – We believe today’s so-called modern data stack, as currently envisioned, will be challenged by emerging use cases and AI-infused apps that begin to represent the real world, in real time, at massive data scale. To support these new applications, a change in underlying data and data center architectures will be necessary, particularly for exabyte scale workloads. Today’s generally accepted state of the art of separating compute from storage, must evolve in our view to separate compute from data and further enable compute to operate on a unified view of coherent and composable data elements. Moreover, our opinion is that AI will be used to enrich metadata to turn strings (i.e. ASCII code, files, objects, etc.) into things that represent real world capabilities of a business. In this Breaking Analysis we continue our quest to more deeply understand the emergence of a sixth data platform that can support intelligent applications in real time. To do so we are pleased to welcome two founders of VAST Data, CEO Renen Hallak and Jeff Denworth. VAST just closed a modest $118M financing round that included Fidelity at a valuation of ~$9B, which implies a quite minor change to the cap table. Watch the full video analysis. Episode 208 – re:Invent ’23 underscores a new simplicity mandate for AWS – Generative AI has created a new mandate in enterprise tech with significant implications for all companies generally and AWS specifically. Amazon’s powerful playbook based on agility, developer choice, power, scale, reliability and security must now evolve to accommodate simplicity and coherence for mainstream customers. This imperative came into clear focus at AWS re:Invent ’23. AWS continues to innovate at a fast pace, but must now do so in a changing customer environment that increasingly values direct user productivity gains through software. In this Breaking Analysis we share our take on how AWS is navigating this challenge. We’ll review Amazon’s strategy to compete in the nascent Gen AI era and we’ll provide commentary on the chess moves it’s making with Anthropic, Nvidia and other partners to maintain its leadership position. We’ll also discuss the challenges of doing so as a $90+B giant in a fast-moving market. Watch the full video analysis. Episode 207 – The OpenAI meltdown…Winners and losers in the battle for AI supremacy – Conventional wisdom says Microsoft is the big winner in the recent OpenAI saga. We don’t quite see it that way. Both Microsoft and OpenAI are in a worse position today than they were last Thursday, prior to the firing of OpenAI CEO Sam Altman and the ongoing public drama that ensues. Microsoft and OpenAI had a huge lead in market momentum, AI adoption and feature acceleration and were setting the narrative in AI. Our discussions with customers and industry insiders leads us to conclude that the duo has put its substantial lead at risk. While Satya Nadella is making lemonade from lemons, the window was just cracked open for the competition and it’s more clear than ever that one large language model will not rule them all. In this Breaking Analysis we weigh in on the impacts of the OpenAI meltdown with a deeper look at the customer perspective and how it alters the competitive landscape in the battle for AI supremacy. As well, the amazing data team at ETR has run a quick survey of OpenAI Microsoft customers to gauge reactions and we’ll share that fresh data. Watch the full video analysis. Episode 206 – The copilot era takes flight at Microsoft Ignite 2023 – Microsoft Ignite 2023 was one part a celebration of yearlong technological innovations, one part announcing the general availability of previously announced products, one part vision, one part ecosystem and four parts copilots everywhere. Copilots promise an historic software-led productivity increase. Perhaps for the first time in industry history we’re seeing huge demand for software coincide with the ability to make it easier to write software. Just as AWS turned the data center into an API, copilots are turning software development into natural language, enabling many more people to create. The implications on productivity are massive and we believe will kick off a new wave of growth that will become increasingly noticeable throughout 2024. In this Breaking Analysis we give you our impressions of Microsoft Ignite 2023. theCUBE Research Analyst George Gilbert and CUBE Collective contributor Sarbjeet Johal both weighed in for this episode and we’ll also share some recent ETR data that shows the progression of some of the major AI players in the past twelve months and the the relative impact Gen AI has had on each of their businesses. Watch the full video analysis. Episode 205 – IBM turns the corner with Watson, why 2.0 is a breakthrough opportunity – With Watson 1.0, IBM deviated from the silicon valley mantra, fail fast, as it took nearly a decade for the company to pivot off of its original vision. In our view, a different dynamic is in play today with Watson 2.0 – i.e. watsonx. IBM’s deep research in AI and learnings from its previous mistakes, have positioned the company to be a major player in the Generative AI era. Specifically, in our opinion, IBM has a leading technological foundation, a robust and rapidly advancing AI stack, a strong hybrid cloud position (thanks to Red Hat), an expanding ecosystem and a consulting organization with deep domain expertise to apply AI in industry-specific use cases. In this Breaking Analysis we share our takeaways and perspectives from a recent trip to IBM’s research headquarters. To do so we collaborate with analyst friends in theCUBE Collective, Sanjeev Mohan, Tony Baer and Merv Adrian. We’ll also share some relevant ETR spending data to frame the conversation. Watch the full video analysis. Episode 204 – The Gen AI power law – How data diversity influences adoption – Our research indicates that the adoption of generative AI is occurring across a variety of frameworks with diverse deployment models, data sets and domain specificities. The transformative power of generative AI for industries is colossal, and we are convinced that AI will gravitate to where data lives. The power law of Gen AI, developed by theCUBE Research team, describes the adoption patterns we see emerging in the cloud, on-premises and at the edge with a long tail of highly specific domain models across every industry. In this Breaking Analysis we revisit the Gen AI power law which informs how we see adoption happening within industries and organizations globally. We introduce new survey data from ETR that looks at some of the vendors being adopted or considered with a special peek into the emerging technology sector with data on Hugging Face, Anthropic, Cohere and Jasper. We also comment on the adoption of Meta’s Llama 2 and the potential impact of open source and other third parties on the shape of the curve. We share our estimates of Microsoft Azure’s AI revenue impact, which we see approaching a $2B run rate exiting 2023. Finally, we dig into the impact of retrieval augmented generation (RAG) using real world examples with some caveats of RAG implementations that practitioners should consider. Watch the full video analysis. Episode 203 – AI revenue riddle – Azure sees gains, when will other cloud titans see the surge? – In 1987, Nobel Prize-winning economist Bob Solow famously observed, “You can see the computer age everywhere but in the productivity statistics.” This proclamation became known as the productivity paradox. Ironically, Solow’s statement preceded the greatest productivity boom since the dawn of the computer age which subsequently came to fruition in the 1990’s. It can be argued that a similar pattern is being seen today where AI is everywhere but generally not showing up in earnings numbers or productivity statistics…yet. In this Breaking Analysis we squint through the latest earnings reports from Microsoft, Alphabet and Amazon to understand what’s happening in cloud, evaluate the impact or lack thereof of AI on cloud earnings momentum and explain how we think about the future impact of generative AI and cloud. Watch the full video analysis. Episode 202 – From hype to reality, the true state of AI adoption – MIT professor and economist Erik Brynjolfsson said recently that he’d be disappointed if AI didn’t lift the current anemic 1.2% productivity growth rate to 3% or even 4%. This would be a good thing for business and government as it could potentially help with the labor shortage, drive earnings growth and increase tax revenues, which would ostensibly help address current debt levels. This is one of the promised impacts of AI. While the hype surrounding Gen AI has narrowly propped up certain sectors of the market, like AI startups and the magnificent seven, the macro effects have not been felt thus far as adoption remains largely experimental. In this Breaking Analysis and ahead of Supercloud 4, ETR’s Erik Bradley and Daren Brabham join the program to share the latest trends on AI adoption, how Gen AI is being used, some of the deployment models and the AI leaderboard based on spending momentum and presence in the market. Watch the full video analysis. Episode 201 – Get Ready for the Sixth Data Platform – In the next 3-5 years, we believe a set of intelligent data apps will emerge requiring a new type of modern data platform to support them. We refer to this as a sixth data platform. In our previous research we’ve used the metaphor “Uber for everyone” to describe this vision; meaning software-based systems that enable a digital representation of a business. Watch the full video analysis. Episode 200 – Lower for longer…Tech spending remains tepid – We’re getting used to the phrase, “higher for longer,” referring to the realization that interest rates are expected to remain elevated for a period of time. This trend is having an inverse effect on enterprise tech spending growth rates. Prior to the Fed’s tightening binge for example, IT decision makers (ITDMs) in aggregate expected annual technology spending to increase by 7.5%. Eleven fed interest rate hikes later, ITDMs estimate that their 2023 budgets will be up only 2.9%, with an expectation, or perhaps it’s a wishful hope, that their budgets will increase 3.8% in 2024. In this our 200th Breaking Analysis, we preview the current spending climate and where AI fits in relation to other sectors. We’ll also share with you a snapshot of the leaders in terms of spending velocity for their platforms; and how their performance compares to peers relative to earlier survey periods. Watch the full video analysis. Episode 199 – Cisco Splunk under the microscope, joint customers weigh in – In this special Breaking Analysis, theCUBE’s Dave Vellante talks with Enterprise Technology Research’s Erik Bradley as he shares the results of ETR’s recent flash survey assessing joint customer perceptions and likely spending actions as a result of the Cisco acquisition of Splunk. Watch the full video analysis. Episode 198 – Bob Muglia on Uber for everyone…how the future of data apps will evolve – The future of intelligent data applications: Uber for everyone. In June, we put forth our scenario about “Uber for all.” We believe a new breed of data apps is emerging and we used Uber as an example where data about people, places and things is brought together in a data-coherent, real-time system. In this special Breaking Analysis, analysts Dave Vellante and George Gilbert sat down with friend of theCUBE, entrepreneur, investor and software executive, Bob Muglia. Bob formerly worked at Microsoft, was the CEO of Snowflake and is a visionary trend spotter. Watch the full video analysis. Episode 197 – Cloud security powers CrowdStrike momentum, Gen AI is next – George Kurtz is pumped up…and why not? CrowdStrike’s business appears to be on a fast track and entering a new phase of growth, despite the difficult macro and elongated sales cycles. The company’s products are considered best in class, its business is growing steadily and an improved profitability and cash flow outlook had investors excited, at least up until this week. A still challenging environment and a rich 13X revenue multiple perhaps led to some profit taking, but Gen AI could be the next catalyst for the company. In the race to close the SecOps staffing gap, CrowdStrike has what appears to be a strong play with a natural language-based intelligent assistant known as Charlotte AI. In this Breaking Analysis we update our scenario on security leader CrowdStrike. We’ll review the company’s recent progress, share survey data that shows where it is strong and where there may be icebergs ahead. And we’ll preview Fal.Con 2023 which takes place next week in Las Vegas. Watch the full video analysis. Episode 196 – Copilot or competitor – How gen AI bolsters and buffets UiPath’s Northstar – UiPath’s recent earnings beat and raise provides some evidence that thus far, Gen AI has not been dilutive for the company. As an early leader that is transforming beyond RPA toward end-to-end enterprise automation, UiPath, like all automation providers, has always faced adoption headwinds beyond isolated deployments. In this sense, Gen AI should bolster adoption and be a positive force. The flip side is that widely available tools like chatbots and generalized foundation models could eat away at the low end of the automation TAM, highlighting the urgency for companies like UiPath to move up market and accelerate innovation that brings differentiation from commoditized tools; and, importantly, create distance from embedded AI within mainstream enterprise SaaS platforms like Slack GPT and Salesforce Einstein. In this Breaking Analysis we briefly review the recent earnings print from UiPath. We’ll look at ETR survey data that shows Microsoft Power Automate’s impact on the automation market and how it is forcing UiPath to target larger accounts with a more functional product set. As well we’ll look at the impact that AI is having in these larger accounts and test UiPath management assertions that Gen AI will be a tailwind for the company. Watch the full video analysis. Episode 195 – Google goes all in on the AI cloud – At Cloud Next, Google showcased its strong leadership position in data and AI. In our view, Google’s messaging, demos and tech-centric narrative have broad appeal for developers and next generation startups. As well, the company’s focus on solutions, contrasts its strategy to the typically disjointed services we’ve seen from AWS over the past decade. Google also showed off an expanded ecosystem of GSIs and smaller CSPs, encouraging the broad use of Google’s kit globally. While Google remains a distant third in the Iaas/PaaS race, with revenue one-fifth the size of AWS, it is playing the long game and betting the house on AI as a catalyst to its cloud future. In this Breaking Analysis we unpack the key takeaways from Google Cloud Next with Rob Strechay and George Gilbert. We’ll share ETR data that positions Google’s AI relative to other leaders and we’ll contrast Google’s data-centric strategy with traditional architectural models. Watch the full video analysis. Episode 194 – Snowflake has Momentum with AWS & Microsoft…Why Google may not be Next – Recent earnings prints from Amazon and Snowflake, along with new survey data, have provided additional context on top of the two events that Snowflake and Databricks each hosted last June. Specifically, we believe that the effects of cloud optimization are still being felt but are nearing the end of peak negative impact on cloud companies. Snowflake’s recent renewal with Microsoft better aligns sales incentives and should improve the company’s traction with Microsoft Azure, a platform that has long favored Databricks. Google however remains a different story as its agenda is to build out its own data cloud stack, rather than supporting Snowflake’s aspirations. Watch the full video analysis. Episode 193 – VMware’s Future – Navigating Multi cloud Complexity & GenAI Under Broadcom’s Wing – The FTC continues to drag its feet on approving Broadcom’s acquisition of VMware. Ironically, in our view, these delays only hurt the very competitive environment the FTC claims to be protecting. The AI era is accelerating at a breakneck pace and the big 3 hyperscale cloud vendors already have a sizable lead on legacy incumbents. If preserving competition is truly the agenda of the U.S. government, it should recognize that VMware, its enterprise ecosystem and market forces have the potential to neutralize cross cloud complexity and give customers a viable alternative to increasingly powerful public cloud players. In this Breaking Analysis and ahead of VMWare Explore 2023, we revisit our views on Broadcom’s rationale and likely actions post acquisition. We’ll share current ETR survey data to place VMware’s position in context to the major cloud players, speculate on its AI agenda and give a preview of next week’s VMware Explore. To do so we welcome CUBE analyst Rob Strechay and friend of theCUBE, Zeus Kerravala, principal of ZK Research. Watch the full video analysis. Episode 192 – Cloud vs. On-Prem Showdown: The Future Battlefield for Generative AI Dominance – The data from enterprise customers is clear but conflicted. While 94% of customers say they’re spending more on AI this year, they’re doing so with budget constraints that will steal from other initiatives. As well, the choice of where customers plan to run generative AI is split almost exactly down the middle in terms of public cloud vs. on-premises/edge. Further complicating matters, developers report the experiences in the public cloud with respect to feature richness and velocity of innovation has been outstanding. At the same time, organizations express valid concerns about IP leakage, compliance, legal risks and cost that will limit their use of the public cloud. In this Breaking Analysis we’ll share the most recent data and thinking around the adoption of large language models and address the factors to consider when thinking about how the market will evolve. As always, we’ll share the latest ETR data to shed new light on key issues customers face balancing risk with time to value. Watch the full video analysis. Episode 191 – Tech Stocks Beyond the Magnificent Seven – After a tough 2022, the first half of 2023 has shown impressive strength paying off earlier technology bets. For sure investors in the so-called Magnificent Seven, i.e. Apple, Alphabet, Amazon, Microsoft, Meta, Nvidia and Tesla have been rewarded. But sharp investors have sought alpha beyond these names, riding the wave of secular trends in AI, cybersecurity, cloud infrastructure and software as well as other emerging spaces like cleantech and robotics. As we enter the second half of 2023, the run up in tech combined with macro uncertainty has many investors taking a cautious posture. But prudent earnings guidance sets up for a positive outlook in the mid-term, especially for those companies that can capitalize on the AI wave. In this Breaking Analysis we’re pleased to have back, founder and Chief Investment Officer of Spear Invest, Ivana Delevska to assess the current state of the market and explore how this investor is playing AI’s rising tide. We’ll also analyze ETR data to drill deeper into semis, cloud infrastructure, generative AI, cybersecurity and Snowflake. Watch the full video analysis. Episode 190 – What Leaked Court Docs Tell us About AWS, Azure & Google Cloud Market Shares – Recently leaked court documents during the Microsoft Activision hearing require us to revisit our cloud forecasts and market share data. The poorly redacted docs, which have since been removed from public viewing, suggest that Microsoft’s Azure revenue is at least 25% lower than our previous estimates. As a result, we’ve cut and revised our Azure revenue figures which in turn increases AWS’ big 4 hyperscale cloud market share. Our new estimates show that AWS maintains a greater than 50% share of revenue through 2023. While the change also helps Google Cloud, its market share is only modestly affected. In this Breaking Analysis we update our hyperscaler cloud revenue estimates and market share data. We’ll also explain how the ETR data on cloud should be interpreted in this context and look forward to potential catalysts for cloud growth, including acceleration in Q4 attributable to generative AI. Watch the full video analysis. Episode 189 – AI gives cyber attackers the advantage…for now – Cloud complexity, tools sprawl and the AI awakening further tip the balance in favor of cyber attackers. Combined with corporate inertia, AI-washing, LLM inconsistency and the pace of change, we believe for now anyway, adversaries have the advantage over defenders. Moreover, macro spending headwinds continue to force organizations to make budget tradeoffs, not the least of which is how to fund AI experiments and deployments. Notably, however, 45% of organizations are using LLMs in production for use cases that may very well improve the productivity of SecOps teams in the long run and accelerate the cat and mouse game back to a state of quasi-equilibrium. In this Breaking Analysis we share key takeaways from Supercloud 3 – AI meets cloud security – and put forth new spending data from the latest ETR survey that shows which security firms are best positioned in the AI race to capitalize on the wave. Watch the full video analysis. Episode 188 – AI won’t be a winner takes all market – The AI heard ’round the world has put the machine intelligence sector back in the spotlight. But when you squint beyond the press hype, the data shows that artificial intelligence is now the number one sector in terms of relative spending velocity in the ETR taxonomy. Normally market hype leads deployments, but the data suggests that spending activity and market penetration for AI are coinciding with the hype. While hyperscale cloud players are reaping the rewards, we think this is a rising tide that’s going to lift all AI ships, those both plainly in sight and others that may not be so visible. In this Breaking Analysis we dig deeper into the AI space with spending data from ETR and one of the best minds in tech generally, and AI specifically, Jeff Jonas, CEO, founder, and chief scientist at Senzing. Watch the full video analysis. Episode 187 – Connecting the dots on the emerging Databricks tech stack – The recent Databricks Data+AI Summit attracted a large audience and, like Snowflake Summit, featured a strong focus on large language models, unification and bringing AI to the data. While customers demand a unified platform to access all their data, Databricks and Snowflake are attacking the problem from different perspectives. In our view, the market size justifies the current enthusiasm seen around both platforms but it’s unlikely that either company has a knockout blow for the other. This is not a head on collision. Rather Snowflake is likely years ahead in terms of operationalizing data. Developers can build applications on one platform, like Oracle when it won the market, that perform analysis and take action. Databricks likely has a similar lead in terms of unifying all types of analytic data – e.g. BI, predictive analytics & generative AI. Developers can build analytic applications across heterogeneous data, like Palantir today. But they have to access external operational applications to take action. In this Breaking Analysis we follow up last week’s research by connecting the dots on the emerging tech stack we see forming from Databricks. With an emphasis on how the company is approaching generative AI, unification and governance…and what it means for customers. To do so we tap the knowledge of three experts who attended the event, CUBE analysts Rob Strechay and George Gilbert and AI market maven Andy Thurai of Constellation Research. Watch the full video analysis. Episode 186 – Connecting the Dots on Snowflake’s Data Cloud Ambitions – Over the past several months we’ve produced a number of in-depth analyses laying out our mental model for the future of data platforms. There are two core themes: 1) Data from people, places, things, and activities in the real world drives applications, not people typing into a UI; and 2) Informing and automating decisions means all data must be accessible. That drives a change from data locked in application silos to application logic being embedded in a platform that manages an end-to-end representation of an enterprise in its data. This week’s Snowflake Summit further confirmed our expectations with a strong top line message of “All Data / All Workloads” and a technical foundation that supports an expanded number of ways to access data. Squinting through the messaging and firehose of product announcements, we believe Snowflake’s core differentiation is its emerging ability to be a complete platform for data applications. Just about all competitors either analyze data or manage data. But no one vendor truly does both. To be precise, managing data doesn’t mean running pipelines or serving analytic queries or AI/ML models. It means managing operational data so that analytics can inform or automate operational activities captured in transactions. With data as the application foundation, the platform needs robust governance. In this week’s Breaking Analysis, we try to connect the dots between Snowflake’s high level messaging and its technical foundation to better understand the core value it brings to customers and partners. As well, we’ll explore the ETR data with some initial input from the Databricks Data + AI Summit to assess the position and prospects of these two leaders along with the key public cloud players. Watch the full video analysis. Episode 185 – HPE wants to turn supercomputing leadership into gen AI profits – HPE’s announcement of an AI cloud for large language models highlights a differentiated strategy that the company hopes will lead to sustained momentum in its high performance computing business. While we think HPE has some distinct advantages with respect to its supercomputing IP, the public cloud players have a substantial lead in AI with a point of view that generative AI is fully dependent on the cloud and its massive compute capabilities. The question is can HPE bring unique capabilities and a focus to the table that will yield competitive advantage and ultimately, profits in the space? In this Breaking Analysis we unpack HPE’s LLM-as-a-service announcements from the company’s recent Discover conference and we’ll try to answer the question: Is HPEs strategy a viable alternative to today’s public and private cloud gen AI deployment models, or is it ultimately destined to be a niche player in the market? To do so we welcome to the program CUBE analyst Rob Strechay and Vice President / principal analyst from Constellation Research, Andy Thurai. Watch the full video analysis. Episode 184 – Uber’s architecture represents the future of data apps…meet its architects – Uber has one of the most amazing business models ever created. The company’s mission is underpinned by technology that helps people go anywhere and get anything. The results have been stunning. In just over a decade, Uber has become a firm with more than $30 billion in annual revenue, an annual bookings run rate of $126B and a market capitalization near $90 billion today. Moreover, the company’s productivity metrics are 3-5 times greater than what you’d find at a typical technology company when, for example, measured by revenue per employee. In our view, Uber’s technology stack represents the future of enterprise data apps where organizations will essentially create real time digital twins of their businesses and in doing so, deliver enormous customer value. In this Breaking Analysis, we introduce you to one of the architects behind Uber’s groundbreaking fulfillment platform. We’ll explore their objectives, the challenges they had to overcome, how Uber has done it and why we believe their platform is a harbinger for the future. Watch the full video analysis. Episode 183 – Snowflake Summit will reveal the future of data apps…here’s our take – Our research and analysis points to a new modern data stack that is emerging where apps will be built from a coherent set of data elements that can be composed at scale. Demand for these apps will come from organizations that wish to create a digital twin of their business to represent people, places, things, and the activities that connect them, to drive new levels of productivity and monetization. Further, we expect Snowflake, at its upcoming conference, will expose its vision to be the best platform on which to develop this new breed of data apps. In our view, Snowflake is significantly ahead of the pack but faces key decision points along the way to its future to protect this lead. In this Breaking Analysis and ahead of Snowflake Summit later this month, we lay out a likely path for Snowflake to execute on this vision; and we address the milestones and challenges of getting there. As always, we’ll look at what the ETR data tells us about the current state of the market. To do all this we welcome back CUBE contributor, George Gilbert. Watch the full video analysis. Episode 182 – Cisco needs to simplify…Here’s how – With a nearly $60B revenue run rate, growing at 14% and throwing off over $5B in operating cash last quarter, Cisco has an awesome business. But customers are vocal about the complexity of Cisco’s portfolio and if not addressed head on, the company risks encountering friction beyond just economic headwinds. We believe Cisco’s challenges are most decidedly not product breadth and depth, rather the company’s mandate is to integrate the piece parts of its intricate offerings to create more facile and seamless experiences for customers. In this Breaking Analysis and ahead of Cisco Live US, we dig deeper into Cisco’s business and double click on three key areas of its portfolio including: 1) Security; 2) Networking; and 3) Observability. With spending data from ETR and a guest appearance from SiliconANGLE contributor and market watcher Zeus Kerravala, principal at ZK Research. Watch the full video analysis. Episode 181 – The future of AI is real time data…Meantime GPUs are making all the headlines – The era of AI everything continues to excite. But unlike the Internet era, where any company announcing a dotcom anything immediately rose in value, the AI gods appear to be more selective. Nvidia beat its top line whisper number by more than $300M and the company’s value is rapidly approaching one trillion dollars. Marvell narrowly beat expectations this week but cited future bandwidth demand driven by AI and the stock was up more than 20% on Friday. Broadcom was up nearly 10% on sympathy with the realization that connect-centricity beyond the CPU is what the company does really well. Meanwhile, other players like Snowflake, which also narrowly beat earnings Wednesday and touted AI as a future tailwind, got hammered as customers dial down cloud consumption. In this Breaking Analysis we look at the infrastructure of AI examining the action at the silicon layer specifically around Nvidia’s momentum. Since much of AI is about data, we’ll also look at the spending data on two top data platforms, Snowflake and Databricks to see what the survey data says and examine the future of real time data and automation as a catalyst for massive productivity growth in the economy. To do so we have a special Breaking Analysis panel with John Furrier and David Floyer. Watch the full video analysis. Episode 180 – The AI powered hybrid multi super cloud – AI will now add superpowers to every triggering buzzword, hence the title of this week’s post. Look past the buzz and you’ll find substance somewhere. The spring conference season is kicking into high gear, so it’s a time to get serious and extract the signal from the event noise. This week we’ll see Microsoft Build, which will no doubt volley shots back from the messaging at Google I/O. Two other big events will take place this week, Red Hat Summit / Ansible Fest in Boston and the annual Dell Technologies World in Las Vegas. theCUBE will be covering both of these shows and we want to take this opportunity to update you on the state of hybrid multi-cloud…what we call supercloud. In this Breaking Analysis we examine some of the key infrastructure players in hybrid multi-cloud with a focus on Red Hat and Dell Technologies, two firms that increasingly are partnering with each other as VMware’s future evolves. We’ll share recent ETR survey data on the position of several other hybrid/cross-cloud players including Cloudflare, Equinix, HPE, IBM, Oracle, VMware and others. We’ll also share what we expect to hear at Red Hat Summit and Dell Technologies World this year. Watch the full video analysis. Episode 179 – Searching for gold in enterprise AI – The AI gold rush is on. The paths to monetization are seemingly endless but the most obvious converge on making humans more productive or supercharging existing business models like search advertising or subscription licenses. Much of AI adoption in enterprise IT is hidden. Our research shows a very high overlap (around 40-60%) between AI adoption in enterprise tech and embedded AI inside software from the likes of Salesforce, ServiceNow, Workday, SAP, Oracle and other major players. But the rapid advancements of tools from AI leaders and an emerging group of independent firms is causing customers to think differently. Catalyzed by the OpenAI Microsoft partnership, organizations are rapidly trying to figure out how to apply these tools to create competitive advantage. Every firm on the planet wants to ride the AI wave. Virtually overnight, investment capital has shifted to fund early stage AI startups with much less funding required relative to previous boom cycles. In this Breaking Analysis we review ETR data to quantify the state of AI spending in the enterprise and look at the positions of several key players in the space that offer AI tools and platforms. To do so we invite Andy Thurai, CUBE contributor, VP and principal analyst at Constellation Research. Andy will help us unpack the hits and misses from this past week’s Google IO conference and give us his perspectives on what it takes to catch the AI wave and avoid becoming driftwood. Watch the full video analysis. Episode 178 – Desperately Seeking Cloud Repatriation – While we’ve been skeptical about repatriation as a notable movement, anecdotal evidence suggests that it is happening in certain pockets. Even though we still don’t see cloud repatriation broadly showing in the numbers, certain examples have caught our attention. In addition, the potential impact of artificial intelligence raises some interesting questions about where infrastructure should be physically located and causes us to revisit our premise that repatriation is an isolated and negligible trend. In this Breaking Analysis we look at a number of sources, including the experiences of 37signals, which has documented its departure from public clouds. We’ll also examine the relationship between repatriation and SRE Ops skill sets. As always we’ll look at survey data from our partners at ETR, a recent FinOps study published by Vega Cloud and revisit the Cloud Repatriation Index, which we believe is breaking a three-year trend. Watch the full video analysis. Episode 177 – Don’t be fooled by slowing cloud growth…cost optimization is a feature not a bug – The big three US cloud players all announced earnings this past week and, as expected, cloud growth is slowing. But don’t kid yourselves. Hyperscale clouds remain the epicenter of innovation in tech and foundation models like GPT will only serve to harden this fundamental fact. Our data suggests the deceleration in cloud spend is a function of two related factors: 1) Cautious consumption patterns; and 2) Aggressive cloud optimization, which is being promoted by the big three cloud vendors in an attempt to lock in customers to longer term commitments. There is still no clear evidence in the numbers that repatriation is a factor. Rather, the ability to quickly dial down spending and pause projects is an attractive feature of cloud computing and one that, until now, has never really been seen on a broad market basis. In this Breaking Analysis we try to explain the implications of this seemingly simple but nuanced dynamic. We’ll review the latest hyperscale cloud data for the big three players, share our analysis of certain comments made by cloud executives and show you the latest ETR data on spending and market presence in the cloud, Watch the full video analysis. Episode 176 – RSA 2023 Security Identity Crisis Part 2 – The narrative from security vendors is organizations don’t spend enough money on cyber defense. Maybe…but will spending more actually address the problems organizations face? The conventional wisdom is it will help; or at least it can’t hurt, but as we and others have pointed out over the years, a crowded market and mega VC funding have created more tools, more complexity and more billionaires…but are we safer? In this Breaking analysis we follow up last week’s episode and continue with Part 2. In an homage to the keynote from RSA CEO Rohit Ghai, we ask, is there a looming identity crisis in the security industry? This week we’re excited to introduce the newest member of the SiliconANGLE editorial team, long time journalist, David Strom. With David, we’ll unpack the data and bring additional context to the ETR body of work. We’ll also look at some recent data from Unit 42, Palo Alto’s threat intelligence and response division. As well, we’ll dig into the anatomy of a recent double supply chain hack. Watch the full video analysis. Episode 175 – RSA 2023 highlights an identity crisis in the age of AI – In this Breaking Analysis, theCUBE host Dave Vellante updates on the latest trends in the cybersecurity market and what to expect at the RSA Conference 2023. Join our real-time analysis coverage from #RSAC here: https://www.thecube.net/rsa-conference-2023 We’ll also share the latest Enterprise Technology Research spending data and drill into the areas of cybersecurity that are seeing the most action. As always, we’ll highlight those companies with the strongest (and weakest) momentum and close with a look at some of the emerging technology players in security that might be ripe for acquisition. To do all this, we once again welcome in our colleague Erik Bradley from ETR. Watch the full video analysis. Episode 174 – Hidden Gems from HPE GreenLake Storage Day – On Tuesday, April 4, HPE invited a number of industry analysts to participate in HPE GreenLake Storage Day. Notably, HPE declared 2023 the year of storage. While the company made several storage-related announcements, perhaps even more interesting was what the event tells us about HPE’s culture, its strategy and the future direction of the company. In this Breaking Analysis we’ll share our takeaways from HPE’s event, held in Houston, Texas, which included attendance at Antonio Neri’s quarterly all-hands meeting. We’ll try to emphasize areas that have not necessarily been the focus of most press and industry analyst write ups to date. We’ll also take a look at the latest ETR survey data to put HPE’s market position in context across several of its major segments. Watch the full video analysis. Episode 173 – Semis rebound but enterprise tech spending remains soft – A rebound in semiconductor stocks has many investors asking if this is a harbinger of good news for the broader enterprise tech sector. Indeed the SOXX semiconductor ETF is up nearly 30% year to date as of this posting, as are bellwether fab suppliers like Applied Materials and Lam Research. Nvidia is up over 90% YTD and AMD over 50%. Even the beleaguered Intel is up 22%. But key enterprise software names have not yet rebounded and according to this week’s guest, the divergence between semis and B2B software is getting hard to ignore. In this Breaking analysis we examine the the bifurcation between the performance of semis and broader enterprise tech. And we’ll try to answer the question: Is the uptick in semiconductors an early indicator of a broader enterprise tech recovery, or is this a false signal that warrants continued caution? To examine these issues we welcome back Ivana Delevska, the founder and chief investment officer of SPEAR Invest. All statements made regarding companies or securities are strictly beliefs, points of view and opinions held by SiliconANGLE Media, Enterprise Technology Research, other guests on theCUBE and guest writers. Such statements are not recommendations by these individuals to buy, sell or hold any security. The content presented does not constitute investment advice and should not be used as the basis for any investment decision. You and only you are responsible for your investment decisions. Disclosure: Many of the companies cited in Breaking Analysis are sponsors of theCUBE and/or clients of Wikibon. None of these firms or other companies have any editorial control over or advanced viewing of what’s published in Breaking Analysis. Watch the full video analysis. Episode 172 – Which tech firms are most exposed to the banking crisis? – The viral awareness and adoption of foundation models like ChatGPT have created both an opportunity and threat to automation platforms generally and RPA point tools specifically. On the one hand, large language models can reduce complexity and accelerate the adoption of enterprise automation platforms. The flip side is software robots are designed to improve human productivity through intelligent automation and GPT models could cannibalize some, if not many use cases initially targeted by RPA vendors. This reality is causing customers to rethink their automation strategies and vendors to rapidly evolve their messaging to position foundation models as an accelerant to their platforms. In this Breaking Analysis we provide you with a perspective on how foundation models could impact automation platforms. We review ETR data that quantifies the ascendency of OpenAI. We also show survey data that measures the overlap between ML/AI systems and automation platforms. Then we review the recent quarterly performance of UiPath and share how we think the company must position itself with respect to the onslaught of noise and potential disruption from GPT models. Watch the full video analysis. Episode 171 – GPT models are a two edged sword for automation platforms – The viral awareness and adoption of foundation models like ChatGPT have created both an opportunity and threat to automation platforms generally and RPA point tools specifically. On the one hand, large language models can reduce complexity and accelerate the adoption of enterprise automation platforms. The flip side is software robots are designed to improve human productivity through intelligent automation and GPT models could cannibalize some, if not many use cases initially targeted by RPA vendors. This reality is causing customers to rethink their automation strategies and vendors to rapidly evolve their messaging to position foundation models as an accelerant to their platforms. In this Breaking Analysis we provide you with a perspective on how foundation models could impact automation platforms. We review ETR data that quantifies the ascendency of OpenAI. We also show survey data that measures the overlap between ML/AI systems and automation platforms. Then we review the recent quarterly performance of UiPath and share how we think the company must position itself with respect to the onslaught of noise and potential disruption from GPT models. Watch the full video analysis. Episode 170 – Databricks faces critical strategic decisions…here’s why – When Apache Spark became a top level project in 2014, and shortly thereafter burst onto the big data scene, it along with the public cloud disrupted the big data market. Databricks cleverly optimized its tech stack for Spark and took advantage of the cloud to deliver a managed service that has become a leading AI and data platform among data scientists and data engineers. However, emerging customer data requirements and market forces are conspiring in a way that we believe will cause modern data platform players generally and Databricks specifically to make some key directional decisions and perhaps even reinvent themselves. In this Breaking Analysis we do a deeper dive into Databricks. We explore its current impressive market momentum using ETR survey data. We’ll also lay out how customer data requirements are changing and what we think the ideal data platform will look like in the mid-term. We’ll then evaluate core elements of the Databricks portfolio against that future vision and close with some strategic decisions we believe the company and its customers face. To do so we welcome in our good friend George Gilbert, former equities analyst, market analyst and principal at Tech Alpha Partners. Watch the full video analysis. Episode 169 – MWC 2023 goes beyond consumer & deep into enterprise tech – While never really meant to be a consumer tech event, over time, the rapid ascendancy of smartphones captured much of the agenda at Mobile World Congress, now MWC. And while device manufacturers continue to have a major presence at the show, the maturity of intelligent devices, longer lifecycles and the disaggregation of the network stack have created more interest in enterprise-class technologies than ever before. Semiconductor manufacturers, network equipment players, infrastructure companies, cloud vendors, software providers and a spate of startups are eyeing the trillion dollar plus telecommunications industry as one of the next big things to watch this decade. In this Breaking Analysis we bring you part 2 of our ongoing coverage of MWC 2023. With some new data on enterprise players specifically within large telco environments. We’ll also take a brief glimpse at some of the pre-announcement news from the show and corresponding themes ahead of MWC. We’ll close with the key innovation areas we’ll be covering at the show on theCUBE. Watch the full video analysis. Episode 168 – MWC 2023 highlights telco transformation & the future of business – The world’s leading telcos are often branded as monopolies that lack innovation. Telcos have been great at operational efficiency, connectivity and living off of transmission services. But in a world beyond telephone poles and basic wireless services, how will telcos modernize, become more agile and monetize new opportunities brought about by 5G, private wireless and a spate of new innovations in infrastructure, cloud, data, AI and apps? It’s become table stakes for carriers to evolve their hardened, proprietary infrastructure stacks to more open, flexible, cloud-like models. But doing so brings risks that telcos must carefully balance as they strive to deliver consistent quality of service while at the same time moving faster and avoiding disruption. In this Breaking Analysis and ahead of MWC23, we explore the evolution of the telco business and how the industry is in many ways, mimicking a transformation that took place decades ago in enterprise IT. We’ll model some of the traditional enterprise vendors using ETR data and investigate how they’re faring in the telecomms vertical. And we’ll pose some of the key issues facing the industry this decade. Watch the full video analysis. Episode 167 – Google’s Point of View on Confidential Computing – Confidential computing is a technology that aims to enhance data privacy and security by providing encrypted computation on sensitive data in use and isolating data from apps and other host resources in fenced off enclaves. The concept of confidential computing is gaining popularity, especially in the cloud computing space where sensitive data is commonly stored and processed. However, there are some who view confidential computing as an unnecessary technology and a marketing ploy by cloud providers, aimed at calming customers who are cloud-phobic. In this Breaking Analysis we revisit the notion of confidential computing and explore whether it’s just marketing or a key part of a trusted security strategy. To do so we’ll invite two Google experts to the show. But before we get there let’s summarize the overall market climate briefly with some ETR data. Watch the full video analysis. Episode 166 – Cloud players sound a cautious tone for 2023 – The unraveling of market enthusiasm continued in Q4 of 2022 with the earnings reports from the U.S. hyperscalers now all in. As we said earlier this year, even the cloud is not immune from the macro headwinds and the cracks in the armor we saw from the data we shared last summer are playing out into 2023. For the most part, actuals are disappointing beyond expectations, including our own. It turns out that our estimates for the big 3 hyperscale revenue missed by $1.2 billion or 2.7% lower than we had forecast from our most recent November estimates. We expect decelerating growth rates for the hyperscalers will continue through the summer of 2023 and won’t abate until comparisons get easier. In this Breaking Analysis we share our view of what’s happening in cloud markets – not just for the hyperscalers but other firms that have hitched a ride on the cloud. And we’ll share new ETR data that shows why these trends are playing out, tactics customers are employing to deal with their cost challenges and how long the pain is likely to last. Watch the full video analysis. Episode 165 – Enterprise Technology Predictions 2023 – Making predictions about the future of enterprise tech is more challenging if you strive to lay down forecasts that are measurable. In other words if you make a prediction, you should be able to look back a year later and say with some degree of certainty whether the prediction came true or not. With evidence to back that up. In this Breaking Analysis we aim to do just that with predictions about the macro IT spending environment, cost optimization, security – lots to talk about there – generative AI, cloud and supercloud, blockchain adoption, data platforms, including commentary on Databricks, Snowflake and other key players, automation, events and we may even have some bonus predictions. To make all this happen we welcome back for the third year in a row, Erik Bradley our colleague from ETR. As well, you can check out how we did with our 2022 predictions. Watch the full video analysis. Episode 164 – ChatGPT Won’t Give OpenAI First Mover Advantage – OpenAI, the company, and ChatGPT have taken the world by storm. Microsoft reportedly is investing an additional $10B in the startup. But in our view, while the hype around ChatGPT is justified, we don’t believe OpenAI will lock up the market with its first mover advantage. Rather we believe that success in this market will be directly proportional to the quality and quantity of data that a technology company has at its disposal, and the compute power it has to run the system. This market is unlikely to display winner take all dynamics and will probably evolve in a more fragmented fashion than cloud. In this Breaking Analysis we unpack the excitement around ChatGPT and debate the premise that the company’s early entry into the space may not confer “game over” advantage to OpenAI. To do so we welcome CUBE collaborator Sarbjeet Johal & John Furrier, cohost of theCUBE. Watch the full video analysis. Episode 163 – Supercloud2 Explores Cloud Practitioner Realities & the Future of Data Apps – Enterprise tech practitioners, like most of us, want to make their lives easier so they can focus on delivering more value to their business. They want to tap best of breed services in the public cloud and at the same time connect their on-prem intellectual property to emerging applications which drive top line revenue and bottom line profits. But creating a consistent experience across clouds and on-prem estates has been an elusive capability for most organizations, forcing tradeoffs and injecting friction into the system. The need to create seamless experiences is clear and the technology industry is starting to respond with platforms, architectures and visions of what we call Supercloud. In this Breaking Analysis we give you a preview of Supercloud2, share key findings leading up to the event and highlight some of the areas we’ll be probing in the live program. Watch the full video analysis. Episode 162 – CIOs in a holding pattern but ready to strike at monetization – Recent conversations with IT decision makers show a stark contrast between the period exiting 2023 versus the mindset leaving 2022. CIOs are generally funding new initiatives by pushing off or cutting lower-priority items. While security efforts are still being funded, those that enable business initiatives that generate revenue take priority over cleaning up legacy technical debt. The bottom line is, for the moment at least, the mindset is not to cut everything, rather it’s to put a pause on cleaning up legacy hairballs and continue to fund initiatives to drive monetization. Cloud has become fundamental and getting data “right” is a consistent theme that appears to be an underpinning of initiatives getting funded today. In this Breaking Analysis we tap recent discussions from two primary sources: year-end ETR roundtables with IT decision makers and conversations on theCUBE with data, cloud and IT architecture practitioners. Watch the full video analysis. Episode 161 – AI goes mainstream but ROI remains elusive – A decade of big data investments combined with cloud scalability, the rise of more cost effective processing and the introduction of advanced tooling has catapulted machine intelligence to the forefront of technology investments. No matter what job you have, your operation will be AI powered within five years and machines may be doing your job in the future. Artificial intelligence is being infused into applications, infrastructure, equipment and virtually every aspect of our lives. AI is proving to be extremely helpful at controlling vehicles, speeding medical diagnoses, processing language, advancing science and generally raising the stakes on what it means to apply technology for business advantage. But business value realization has been a challenge for most organizations due to lack of skills, complexity of programming models, immature technology integration, sizable up front investments, ethical concerns and lack of business alignment. Mastering AI technology and a focus on features will not be a requirement for success in our view. Rather figuring out how and where to apply AI to your business will be the crucial gate. That means understanding the business case, picking the right technology partner, experimenting in bite sized chunks and quickly identifying winners to double down on from an investment standpoint. In this Breaking Analysis we update you on the state of AI with a focus on interpreting the latest ETR survey data around ML/AI and data. We’ll explore what it means for the competitive environment and what to look for in the future. To do so we invite into our studios Andy Thurai of Constellation Research. Andy covers AI deeply, he knows the players and the pitfalls of AI investment. Watch the full video analysis. Episode 160 – Grading our 2022 enterprise technology predictions – Nailing technology predictions in 2022 was tricky business. Projections on the performance of markets, identifying IPO prospects and making binary forecasts on data, AI, the macro spending climate, along with other related topics in enterprise tech, carried much uncertainty. 2022 was characterized by a seesaw economy where central banks were restructuring their balance sheets, the war in Ukraine fueled inflation, supply chains were a mess and the unintended consequences of digital acceleration are still being sorted. In this Breaking Analysis we continue our annual tradition of openly grading our previous year’s enterprise tech predictions. You may or may not agree with our self-grading system but we give you the data to draw your own conclusions. Watch the full video analysis. Episode 159 – How Palo Alto Networks Became the Gold Standard of Cybersecurity – Palo Alto Networks has earned a reputation as the leader in security. You can measure this in revenue, market cap, execution and, most importantly, conversations with CISOs. The company is on track to double its revenues to nearly $7B in FY23 from FY20. This despite macro headwinds which will likely continue through next year. Palo Alto owes its position to a clarity of vision and strong execution of a TAM expansion strategy bolstered by key acquisitions and integrations into its cloud & SaaS offerings. In this Breaking Analysis, and ahead of Palo Alto Ignite, we bring you the next chapter on top of last week’s cybersecurity update. We’ll dig into the ETR spending data on Palo Alto Networks, provide a glimpse of what to look for at Ignite and posit what Palo Alto needs to do to stay on top of the hill. Watch the full video analysis. Episode 158 – Cyber Firms Revert to the Mean – While by no means a safe haven, the cybersecurity sector has outpaced the broader tech market by a meaningful margin. That is up until very recently. Cyber security remains the number one technology priority for the c-suite but as we’ve previously reported, the CISO’s budget has constraints; just like other technology investments. Recent trends show that economic headwinds have elongated sales cycles, pushed deals into future quarters and, just like other tech initiatives, are pacing cybersecurity investments and breaking them into smaller chunks. In this Breaking Analysis we explain how cybersecurity trends are reverting to the mean and tracking more closely with other technology investments. We’ll make a couple of valuation comparisons to show the magnitude of the challenge and which cyber firms are feeling the heat, and which aren’t as much. We’ll then show the latest survey data from ETR to quantify the contraction in spending momentum and close with a glimpse at the landscape of emerging cybersecurity companies that could be ripe for acquisition, consolidation or disruptive to the broader market. Watch the full video analysis. Episode 157 – re:Invent 2022 marks the next chapter in data & cloud – The ascendency of AWS under the leadership of Andy Jassy was marked by a tsunami of data and corresponding cloud services to leverage data. Those services mainly came in the form of primitives – i.e. basic building blocks that were used by developers to create more sophisticated capabilities. AWS in the 2020s, led by CEO Adam Selipsky, will be marked by four high level trends in our view: 1) A rush of data that will dwarf anything previously seen; 2) Doubling down on investments in the basic elements of cloud – compute, storage, database, security, etc; 3) Greater emphasis on end-to-end integration of AWS services to make data accessible to more professionals and further accelerate cloud adoption; and 4) Significantly deeper business integration of cloud, beyond IT, as an underlying element of organizational transformation. In this Breaking Analysis we extract and analyze nuggets from John Furrier’s annual sit down with the CEO of AWS. We’ll share data from ETR and other sources to set the context for the market and competition in cloud and we’ll give you our glimpse of what to expect at re:Invent 2022. Watch the full video analysis. Episode 156 – Snowflake caught in the storm clouds – A better than expected earnings report in late August got people excited about Snowflake again but the negative sentiment in the market has weighed heavily on virtually all growth tech stocks. Snowflake is no exception. As we’ve stressed many times, the company’s management is on a long term mission to simplify the way organizations use data. Snowflake is tapping into a multi-hundred billion dollar total available market and continues to grow at a rapid pace. In our view the company is embarking on its third major wave of innovation, data apps, while its first and second waves are still bearing significant fruit. For short term traders focused on the next 90 or 180 days, that probably doesn’t matter much. But those taking a longer view are asking, should we still be optimistic about the future of this high flier or is it just another over-hyped tech play? In this Breaking Analysis we take a look at the most recent survey data from ETR to see what clues and nuggets we can extract to predict the near future and the long term outlook for Snowflake. Watch the full video analysis. Episode 155 – Cloudflare’s Supercloud…What Multi Cloud Could Have Been – Over the past decade, Cloudflare has built a global network that has the potential to become the fourth U.S.-based hyperscale-class cloud. In our view, the company is building a durable revenue model with hooks into many important markets. These include the more mature DDoS protection space, but also extend to growth sectors such as zero trust, a serverless platform for application development and an increasing number of services such as database and object storage. In essence, Cloudflare can be thought of as a giant, distributed supercomputer that can connect multiple clouds and act as a highly efficient scheduling engine– allocating and optimizing resources at scale. Its disruptive DNA is increasingly attracting novel startups and established global firms looking for a reliable, secure, high performance, low latency and more cost effective alternative to AWS and legacy infrastructure solutions. In this Breaking Analysis we initiate deeper coverage of Cloudflare. While the stock got hammered this past week on tepid guidance, we are optimistic about the company’s future. In this post, we’ll briefly explain our take on the company and its unique business model. We’ll then share some peer comparisons with both a financial snapshot and some fresh ETR survey data. Finally we’ll show some examples of how we think Cloudflare could be a disruptive force with a supercloud-like offering that, in many respects, is what multi-cloud should have been. Watch the full video analysis. Episode 154 – Even the Cloud Is Not Immune to the Seesaw Economy – Have you ever driven on the highway and traffic suddenly slows way down? And then after a little while it picks up again and you’re cruising along thinking…ok that was weird but it’s clear sailing now…only to find out in a bit that that traffic is building up again, forcing you to pump the brakes as the traffic patterns ebb and flow? Well welcome to the seesaw economy. The Fed induced fire that prompted a rally in tech is being purposely extinguished by that same Fed and virtually every sector of the tech industry is having to reset its expectations – including the cloud. In this Breaking Analysis we’ll review the implications of this week’s earnings announcements from the big 3 cloud players. The growth of AWS and Azure slowed while Google Cloud Platform’s growth accelerated. We’ll explain why GCP’s growth is still not fast enough. We’ll update you on our quarterly IaaS forecasts and share the latest cloud survey data from ETR. Watch the full video analysis. Episode 153 – Survey Says! Takeaways from the latest CIO spending data – The overall technology spending outlook is deteriorating. And yet there are positive signs making things unpredictable. The negative sentiment is of course being driven by macroeconomic factors and earnings forecasts that have been coming down all year while interest rates keep rising. Making matters worse is many people think earnings estimates are still too high. It’s understandable why there’s so much uncertainty. Technology continues to boom. Digital transformations are happening in earnest. Leading companies have momentum and long cash runways. Moreover, the CEOs of these leading companies are still really optimistic. But strong guidance in an environment of uncertainty is risky and makes navigation more challenging. In this Breaking Analysis we try to put some guardrails on the market by sharing takeaways from from ETRs latest spending survey, which was released to their private clients on the 21st of October. Today we’re going to review the macro spending data, convey where CIOs think their cloud spend is headed, look at the actions organizations are taking to manage uncertainty and then review some of the technology companies that have the most positive and negative outlooks in the ETR data set. Watch the full video analysis. Episode 152 – CEO Nuggets from Microsoft Ignite & Google Cloud Next – This past week, we saw two of the “Big 3” cloud providers present an update of their respective cloud visions, business progress, announcements and innovations. The content at these events had many overlapping themes including modern cloud infrastructure at global scale, applying advanced machine intelligence, end-to-end data platforms, the future of work, automation and a taste of the metaverse/Web 3.0. And more. Despite the striking similarities, the differences between these two cloud platforms, and that of AWS, remain significant with Microsoft leveraging its massive application software footprint to dominate virtually all markets; AndGoogle doing everything in its power to keep up with the frenetic pace of today’s cloud innovation which was set into motion a decade and a half ago by AWS. In this Breaking Analysis, we unpack the immense amount of content presented by the CEOs of Microsoft and Google Cloud at Microsoft Ignite and Google Cloud Next. We’ll also quantify with ETR survey data, the relative position of these two cloud giants in four key sectors – Cloud IaaS, BI analytics, data platforms and collaboration software. Watch the full video analysis. Episode 151 – Analyst Take on Dell – Dave Vellante provides his take on the transformation of Dell to Dell EMC to Dell Technologies, the impact of the VMware spin out and what the future holds for this bellwether infrastructure player. Watch the full video analysis. Episode 150 – Latest CIO Survey Shows Steady Deceleration in IT Spend – Is the glass half full or half empty? Well, it depends on how you want to look at it. CIOs are tapping the brakes on spending that’s clear. The latest macro survey from ETR quantifies what we already know to be true, that IT spend is decelerating. CIOs and IT buyers forecast that their tech spend will grow by 5.5% this year, a meaningful deceleration from their year end 2021 expectations…but these levels are still well above historical norms – so while the feel good factor may be in some jeopardy, overall things are pretty good – at least for now. In this Breaking Analysis, we update you on the latest macro tech spending data from Enterprise Technology Research, including strategies organizations are employing to cut costs…and which project categories continue to see the most traction. Watch the full video analysis. Episode 149 – As the tech tide recedes, all sectors feel the pinch – Virtually all tech companies have expressed caution on their respective earnings calls. And why not… the macroeconomic environment is full of uncertainties and there’s no upside to providing aggressive guidance when sellers punish even the slightest miss. Moreover, the spending data confirms the market is softening across the board, so it’s becoming expected that CFOs will guide cautiously. But companies facing execution challenges can’t hide behind the macro. Which is why it’s important to understand which firms are best positioned to maintain momentum through the headwinds and come out the other side stronger. In this Breaking Analysis we’ll do three things: 1) Share a high-level view of the spending squeeze almost all sectors are experiencing; 2) Highlight some of those companies that continue to show notably strong momentum – and relative high spending velocity on their platforms – albeit less robust than last year; and 3) give you a peek at how one senior technology leader in the financial sector sees the competitive dynamic between AWS, Snowflake and Databricks. Watch the full video analysis. Episode 148 – UiPath is a Rocket Ship Resetting its Course – Like a marathon runner pumped up on adrenaline, UiPath sprinted to the lead in what is surely going to be a long journey toward enabling the modern automated enterprise. In doing so, the company has established itself as a leader in enterprise automation, while at the same time getting out over its skis on critical execution items and disappointing investors along the way. In our view, the company has plenty of upside potential but will have to slog through its current challenges including restructuring its go to market, prioritizing investments, balancing growth with profitability and dealing with a difficult macro environment. In this Breaking Analysis and ahead of Forward5, UiPath’s customer conference, we once again dig into RPA and automation leader UiPath, to share our most current data and view of the company’s prospects, its performance relative to the competition and market overall. Watch the full video analysis. Episode 147 – How CrowdStrike Plans to Become a Generational Platform – In just over ten years, CrowdStrike has become a leading independent security firm. It has more than $2B in annual recurring revenue, nearly 60% ARR growth, a roughly $40B market capitalization, very high retention and a path to $5B in revenue by mid-decade. The company has joined Palo Alto Networks as a gold standard pure play cyber firm. It has achieved this lofty status with an architecture that enables it to go beyond point product. Combine this with outstanding go to market, solid financial execution, some sharp acquisitions and an ever-increasing total available market and you have the formula for a great company. In this Breaking Analysis and ahead of Fal.Con, CrowdStrike’s user conference, we take a deeper look into the company, its performance, its platform and customer survey data from our partner ETR. Watch the full video analysis. Episode 146 – We Have the Data…What Private Tech Companies Don’t Tell you About Their Business – The negative sentiment in tech stocks, caused by rising interest rates, less attractive discounted cash flow models and more tepid forward guidance, is easily measured by public market valuations. And while there’s lots of talk about the impact on private companies, their cash runways and 409A valuations, measuring the performance of non-public companies isn’t as easy. IPOs have dried up and public statements by private companies accentuate the good and hide the bad. Real data, unless you’re an insider, is hard to find. In this Breaking Analysis we unlock some of the secrets that non-public, emerging tech companies may or may not be sharing. We do this by introducing you to a capability from ETR that we’ve not previously exposed in Breaking Analysis. It’s called the ETR Emerging Technology Survey and is packed with sentiment and performance data based on surveys of more than 1,000 CIOs & IT buyers covering more than 400 private companies. The survey will highlight metrics on the evaluation, adoption and churn rates for private companies and the mindshare they’re able to capture. We’ve invited back our colleague Erik Bradley of ETR to help explain the survey and the data we’re going to cover in this post. Watch the full video analysis. Episode 145 – VMware Explore 2022 will mark the start of a Supercloud journey – While the precise direction of VMware’s future is unknown, given the planned Broadcom acquisition, one thing is clear; the subject of what Hock E. Tan plans will not be the main focus of the agenda at the upcoming VMware Explore event next week in San Francisco. We believe that despite any uncertainty, VMware will lay out for its customers what it sees as its future. And that future is multi-cloud or cross cloud services; what we would call supercloud. In this Breaking Analysis we drill into the latest ETR survey data on VMware. We’ll share with you the next iteration of the supercloud definition based on feedback from dozens of contributors. And we’ll give you our take on what to expect at VMware Explore next week. Watch the full video analysis. Episode 144 – What Black Hat ’22 tells us about securing the Supercloud – Black Hat 2022 was held in Las Vegas last week, at the same time as theCUBE’s supercloud event. Unlike AWS re:Inforce, where words are carefully chosen to put a positive spin on security, Black Hat exposes all the warts of cybersecurity and openly discusses its hard truths. It’s a conference attended by technical experts who proudly share some of the vulnerabilities they’ve discovered and of course by numerous vendors marketing their products and services. In this Breaking Analysis we summarize what we learned from discussions with several people who attended Black Hat and our analysis from reviewing dozens of keynotes, articles, videos, session talks, Dark Reading interviews and data from a recent Black Hat attendees survey conducted by Black Hat and Informa. We’ll also share data from ETR in a recent post discussing how Zscaler became the last line of defense for a manufacturing firm. We’ll end with a discussion of what it all means for the challenges around securing the supercloud. Watch the full video analysis. Episode 143 – Further defining Supercloud With tech leaders VMware, Snowflake, Databricks & others – At our inaugural Supercloud22 event we sought community input to evolve the concept of a supercloud by iterating on the definition, the salient attributes and examples of what is and is not a supercloud. We asked several technologists including experts from VMware, Snowflake, Databricks, HashiCorp, Confluent, Intuit, Cohesity and others to help test the supercloud definition, operational models, service models and principles. In this Breaking Analysis we unpack our discussions with these technology leaders and apply their input to iterate the definition of supercloud. We then go in-depth to examine Snowflake’s Data Cloud architecture as a leading example of supercloud. Watch the full video analysis. Episode 142 – What we hope to learn at Supercloud22 – The term supercloud is relatively new, but the concepts behind it have been bubbling for years. Early last decade when NIST put forth its original definition of cloud computing, it said services had to be accessible over a public network…essentially cutting the on-prem crowd out of the conversation. A guy named Chuck Hollis, a CTO at EMC and prolific blogger objected to that criterion and laid out his vision for what he termed a private cloud. In that post he showed a workload running both on premises and in a public cloud, sharing the underlying resources in an automated and seamless manner – what later became more broadly known as hybrid cloud. That vision, as we now know, really never materialized and we were left with multi-cloud…sets of largely incompatible and disconnected cloud services running in separate silos. The point is, what Hollis put forth – i.e. the ability to abstract underlying infrastructure complexity and run workloads across multiple heterogeneous estates with an identical experience – is what supercloud is all about. Watch the full video analysis. Episode 141 – How the cloud is changing security defenses in the 2020s – AThe rapid pace of cloud adoption has changed the way organizations approach cybersecurity. Specifically, the cloud is increasingly becoming the first line of cyber defense. As such, along with communicating to the board and creating a security-aware culture, the CISO must ensure that the shared responsibility model is being applied properly. The DevSecOps team has emerged as the critical link between strategy and execution, while audit becomes the “free safety” in the equation – i.e. the last line of defense. In this Breaking Analysis we share our puts and takes from AWS re:Inforce with an update on the latest hyperscale IaaS market shares; and insights from ETR survey data. We’ll also dig deeper into some technical aspects of AWS Nitro, a system we believe is one of AWS’ secret weapons, with a focus on confidential computing and what it means for the future of systems architecture. Watch the full video analysis. Episode 140 – AWS re:Inforce marks a summer checkpoint on cybersecurity – After a two year hiatus, AWS re:Inforce is back on as an in-person event in Boston next week. Like the all-star break in baseball, re:Inforce gives us an opportunity to evaluate the cybersecurity market overall, the state of cloud security and what AWS is up to in the sector. In this Breaking Analysis, we’ll share our view of what’s changed since our last cyber update in May, we’ll look at the macro environment, how it’s impacting cybersecurity plays in the market, what the ETR data tells us and what to expect at next week’s AWS re:Inforce. Watch the full video analysis. Episode 139 – Amping it up with Frank Slootman – Organizations have considerable room to improve their performance without making expensive changes to their talent, structure or fundamental business model. You don’t need a slew of consultants to tell you what to do. You already know. What you need is to immediately ratchet up expectations, energy, urgency and intensity. Fight mediocrity every step of the way. Amp it up and the results will follow. This is the fundamental premise of a hard hitting new book written by Frank Slootman, CEO of Snowflake, and published earlier this year. It’s called, Amp it Up, Leading for Hypergrowth by Raising Expectations, Increasing Urgency and Elevating Intensity. At Snowflake Summit last month, I was invited to interview Frank on stage about his book. I’ve read it several times and if you haven’t picked it up, you should. Even if you have read it, in this Breaking Analysis we’ll dig deeper into the book and share some clarifying insights and unpublished nuances of Frank’s philosophy. You’ll hear directly from Slootman himself with excerpts from my one on one conversation with him. Watch the full video analysis. Episode 138 – Answering the top 10 questions about SuperCloud – As we exited the isolation economy last year, supercloud is a term we introduced to describe something new that was happening in the world of cloud. In this Breaking Analysis we address the ten most frequently asked questions we get on supercloud. Watch the full video analysis. Episode 137 – H1 of ‘22 was ugly…H2 could be worse…Here’s why we’re still optimistic – After a two year epic run in tech, 2022 has been an epically bad year in the market. Through yesterday, the Nasdaq composite is down 30%, the S&P 500 is off 21%, the DJIA down 16% and the poor HODLers of BTC have had to endure a nearly 60% decline year to date. Watch the full video analysis. Episode 136 – Tech Spending Intentions are Holding Despite Macro Concerns – Much of the energy around data innovation that dispersed with the decline of Hadoop’s relevance is coalescing in a new ecosystem spawned by the ascendency of Snowflake’s Data Cloud. What was once seen as a simpler cloud data warehouse and good marketing with Data Cloud, is evolving rapidly with new workloads, a vertical industry focus, data applications, monetization and more. The question is will the promises of data be fulfilled this time around or is it same wine, new bottle? Watch the full video analysis. Episode 135 – Snowflake Summit 2022…All About Apps & Monetization – Much of the energy around data innovation that dispersed with the decline of Hadoop’s relevance is coalescing in a new ecosystem spawned by the ascendency of Snowflake’s Data Cloud. What was once seen as a simpler cloud data warehouse and good marketing with Data Cloud, is evolving rapidly with new workloads, a vertical industry focus, data applications, monetization and more. The question is will the promises of data be fulfilled this time around or is it same wine, new bottle? Watch the full video analysis. Episode 134 – How Snowflake Plans to Make Data Cloud a De Facto Standard – When Frank Slootman took ServiceNow public, many people undervalued the company, positioning it as just a better help desk tool. It turns out the firm actually had a massive TAM expansion opportunity in ITSM, HR, logistics, security, marketing and customer service management. NOW’s stock price followed the stellar execution under Slootman and CFO Mike Scarpelli’s leadership. When they took the reins at Snowflake, expectations were already set that they’d repeat the feat but this time, if anything, the company was overvalued out of the gate. It can be argued that most people didn’t really understand the market opportunity any better this time around. Other than that it was a bet on Slootman’s track record of execution…and data. Good bets; but folks really didn’t appreciate that Snowflake wasn’t just a better data warehouse. That it was building what the company calls a data cloud…and we’ve termed a data supercloud. In this Breaking Analysis and ahead of Snowflake Summit, we’ll do four things: 1) Review the recent narrative and concerns about Snowflake and its value; 2) Share survey data from ETR that will confirm almost precisely what the company’s CFO has been telling anyone who will listen; 3) Share our view of what Snowflake is building – i.e. trying to become the de facto standard data platform; and 4) Convey our expectations for the upcoming Snowflake Summit next week at Caesar’s Palace in Las Vegas. Watch the full video analysis. Episode 133 – MongoDB Sends Strong Signals Despite Cautious Macro Tones – Earnings season has shown a conflicting mix of signals for software companies. Most firms are expressing caution over macro headwinds citing a combination of Ukraine, inflation, interest rates, EMEA softness, currency, supply chain and general demand for technology. But MongoDB, along with a few other names appeared more sanguine, thanks to a beat in the recent quarter and a cautious but upbeat outlook for the near term. In this Breaking Analysis, ahead of MongoDB World 2022, we drill into the company’s business and what ETR survey data tells us in the context of overall demand and the patterns from other software companies. Watch the full video analysis. Episode 132 – Broadcom, Taming the VMware Beast – In the words of CUBE analyst and former CTO David Nicholson, Broadcom buys old cars. Not to restore them to their original beauty…nope…they buy classic cars to extract the platinum that’s inside the catalytic converter. Broadcom’s planned $61B acquisition of VMware will mark yet another new era for the virtualization leader, a mere seven months after finally getting spun out as a fully independent company by Dell. For VMware this means a dramatically different operating model, with financial performance and shareholder value creation as the dominant and perhaps sole agenda. For customers it will mean a more focused portfolio, less aspirational vision pitches and most certainly higher prices. In this Breaking Analysis we’ll share data, opinions and customer insights about this blockbuster deal and forecast the future of VMware, Broadcom and the broader ecosystem. Watch the full video analysis. Episode 131 – Supercloud is becoming a thing – Last year we noted in a Breaking Analysis that the cloud ecosystem is innovating beyond the notion of multicloud. We’ve said for years that multicloud is really not a strategy but rather a symptom of multivendor. We used the term supercloud to describe an abstraction layer that resides above and across hyperscale infrastructure, connects on premises workloads and eventually stretches to the edge. Our premise is that supercloud goes beyond running services in native mode on each individual cloud. Rather supercloud hides the underlying primitives and APIs of the respective cloud vendors and creates a new connection layer across locations. Since our initial post, we’ve found many examples within the ecosystem of technology companies working on so-called supercloud in various forms. Including some examples that actually do not try to hide cloud primitives but rather are focused on creating a consistent experience for developers across the devsecops tool chain, while preserving access to low level cloud services. In this Breaking Analysis we share some recent examples of supercloud that we’ve uncovered. We also tap theCUBE network to access direct quotes about supercloud from the many CUBE guests we’ve recently had on the program. Here we test the concept’s technical and business feasibility. We’ll also post some recent ETR data to put into context some of the players we think are going after this opportunity and where they’re at in their supercloud buildout. Watch the full video analysis. Episode 130 – Are Cyber Stocks Oversold or Still too Pricey? – Cybersecurity stocks have been sending mixed signals as of late…Mostly negative like much of tech. But some, such as Palo Alto Networks, despite a tough go of it recently, have held up better than most tech names. Others like CrowdStrike had been outperforming broader tech in March but then flipped in May. Okta’s performance was somewhat tracking along with CrowdStrike for most of the past several months but then the Okta hack changed the trajectory of that name. Zscaler has crossed the critical $1B ARR revenue milestone and sees a path to $5B, but the company’s stock fell sharply after its last earnings report and has been on a downtrend since last November…Meanwhile CyberArk’s recent beat and raise was encouraging and the stock acted well after its last report. Security remains the #1 initiative priority amongst IT organizations and the spending momentum for many high flying cyber names remains strong. So what gives in cybersecurity? In this Breaking Analysis we focus on security and will update you on the latest data from ETR to try and make sense out of the market and read into what this all means in both the near and long term for some of our favorite names in the sector. Watch the full video analysis. Episode 129- What you May not Know About the Dell Snowflake Deal – In the pre-cloud era, hardware companies would run benchmarks showing how database and application performance ran best on their systems relative to competitors and previous generation boxes. They would make a big deal out of it and the independent software vendors would do a “golf clap” in the form of a joint press release. It was a game of leapfrog amongst hardware competitors that became pretty commonplace over the years. The Dell-Snowflake deal underscores that the value prop between hardware companies and ISVs is changing and has much more to do with distribution channels and the amount of data that lives on-prem in various storage platforms. For cloud-native ISVs like Snowflake, they are realizing that despite their cloud-only dogma, they have to grit their teeth and deal with on-premises data or risk getting shut out of evolving data architectures. In this Breaking Analysis we unpack what little is known about the Snowflake announcement from Dell Technologies World… and discuss the implications of a changing cloud ecosystem landscape. We’ll also share some new ETR data for cloud and database platforms that shows Snowflake has actually entered the earth’s orbit when it comes to spending momentum on its platform. Watch the full video analysis. Episode 128- The Ever expanding Cloud Continues to Storm the IT Universe – Despite a mixed bag of earnings reports from tech companies, negative GDP growth this past quarter and rising inflation…the cloud continues its relentless expansion on the IT landscape. AWS, Microsoft and Alphabet have all reported earnings and, when you include Alibaba’s cloud in the mix, the big 4 hyperscalers are on track to generate $167B in revenue this year based on our projections. But as we’ve said many times the definition of cloud is expanding. And hybrid environments are becoming the norm at major organizations. We’re seeing the largest enterprise tech companies focus on solving for hybrid and every public cloud company now has a strategy to bring their environments closer to where customers’ workloads live – in data centers and the edge. Hello and welcome to this week’s Wikibon CUBE Insights, Powered by ETR. In this Breaking Analysis we’ll update you on our latest cloud projections and outlook. We’ll share the latest ETR data and some commentary on what’s happening in the “hybrid zone” of cloud. Watch the full video analysis. Episode 127- Does Hardware Still Matter – The ascendancy of cloud and SaaS has shone new light on how organizations think about, pay for, and value hardware. Once-sought-after skills for practitioners with expertise in hardware troubleshooting, configuring ports, tuning storage arrays and maximizing server utilization have been superseded by demand for cloud architects, DevOps pros and developers with expertise in microservices, container app development and similar skills. Even a company like Dell, the largest hardware company in enterprise tech, touts that it has more software engineers than those working in hardware. It begs the question: Is hardware going the way of COBOL? Well, not likely — software has to run on something. But the labor and skills needed to deploy, troubleshoot and manage hardware infrastructure is shifting quite dramatically. At the same time we’ve seen the value flow also changing in hardware. Once a world dominated by x86 processors, value is flowing to alternatives like Nvidia and Arm-based designs. Moreover, other components like NICs, accelerators and storage controllers are becoming more advanced, integrated and increasingly important. The question is: Does it matter? If so, why does it matter and to whom? What does it mean to customers, workloads, OEMs and the broader society? In this Breaking Analysis we try to answer these questions and to do so we’ve organized a special CUBE Power Panel of industry analysts and experts to address the question: Does Hardware (Still) Matter? Watch the full video analysis. Episode 126 – Technology & Architectural Considerations for Data Mesh – The introduction and socialization of data mesh has caused practitioners, business technology executives and technologists to pause and ask some probing questions about the organization of their data teams, their data strategies, future investments and their current architectural approaches. Some in the technology community have embraced the concept, others have twisted the definition while still others remain oblivious to the momentum building around data mesh. We are in the early days of data mesh adoption. Organizations that have taken the plunge will tell you aligning stakeholders is a non-trivial effort. But one that is necessary to break through the limitations that monolithic data architectures and highly specialized teams have imposed over frustrated business and domain leaders. However, practical data mesh examples often lie in the eyes of the implementer and may not strictly adhere to the principles of data mesh. Part of the problem is the lack of open technologies and standards that can accelerate adoption and reduce friction. This is the topic of today’s Breaking Analysis where we investigate some of the key technology and architectural questions around data mesh. To do so, we welcome back the founder of data mesh and Director of Emerging Technologies at ThoughtWorks, Zhamak Dehghani. Watch the full video analysis. Episode 125 – Customer ripple effects from the Okta breach are worse than you think – The recent security breach of an Okta third party supplier has been widely reported. The criticisms of Okta’s response have been harsh and the impact on Okta’s value has been obvious. Investors shaved about $6B off the company’s market cap during the week the hack was made public. We believe Okta’s claim that the customer technical impact was “near zero,” may be semantically correct. However, based on customer data, we feel Okta has a blind spot. There are customer ripple effects that require clear action, which are missed in Okta’s public statements. Okta’s product portfolio remains solid. It is a clear leader in the identity space. But in our view, one part of the long journey back to credibility requires Okta to fully understand and recognize the true scope of this breach on its customers. In this week’s Breaking Analysis we welcome our ETR colleague Erik Bradley to share new data from the community. In addition, we’ll analyze some of the statements made by Okta CEO Todd McKinnon in an interview with Emily Chang on Bloomberg to see how they align with what customers tell us. Watch the full video analysis. Episode 124 – New Data Signals C Suite Taps the Brakes on Tech Spending – Fresh survey data from ETR shows a clear deceleration in spending and a more cautious posture from technology buyers. Just this week we saw sell side downgrades in hardware companies like Dell and HP; and revised guidance from high flier UiPath, citing exposure to Russia, Europe and certain sales execution challenges. But these headlines we think are a canary in the coal mine pointing to broader tech spending softness. According to ETR analysis and channel checks in theCUBE community, the real story is these issues are not isolated. Rather we’re seeing signs of caution from buyers across the board in enterprise tech. In this Breaking Analysis we are the bearers of bad news, relatively speaking. We’ll share a first look at new data that suggest a tightening in tech spending, calling for 6% growth this year, which is below our January prediction of 8% for 2022. Watch the full video analysis. Episode 123 – Governments Should Heed the History of Tech Antitrust Policy – There are very few political issues that get bipartisan support these days, never mind consensus spanning geopolitical boundaries. But whether we’re talking across the aisle or over the pond, there seems to be common agreement that the power of big tech firms should be regulated. However the government’s track record when it comes to antitrust aimed at tech is mixed, at best. History shows that market forces, rather than public policy, have been much more effective at curbing monopoly power in the technology industry. Moreover, the standard for antitrust action has always been demonstrating consumer harm. Many of today’s policy makers are challenging that notion and using market dominance and the potential for consumer harm as the new benchmark for intervention. In this week’s Breaking Analysis we welcome in frequent CUBE contributor David Moschella, author and senior fellow at the Information Technology and Innovation Foundation. We explore several issues including the efficacy of governments’ antitrust actions against big tech, what types of remedies have been and can be most effective and a first pass assessment of the new rules EU regulators just agreed to try and rein in big tech companies. Watch the full video analysis. Episode 122 – Snowflake’s Wild Ride – Snowflake…they love the stock at 400 and hate it at 165. That’s the nature of the business isn’t it? Especially in this crazy cycle over the last two years of lockdowns, free money, exploding demand and now rising inflation and rates. But with the Fed providing some clarity on its actions, the time has come to really look at the fundamentals of companies and there’s no tech company more fun to analyze than Snowflake. In this breaking analysis we take look at the action of Snowflake’s stock since its IPO, why it’s behaved the way it has, how some sharp traders are looking at the stock and most importantly, what customer demand looks like. Watch the full video analysis. Episode 121 – Pat Gelsinger has the Vision Intel Just Needs Time, Cash & a Miracle – Intel’s future would be a disaster without Pat Gelsinger. Even with his clear vision, fantastic leadership, deep technical and business acumen and amazing positivity, the company’s future is in serious jeopardy. It’s the same story we’ve been telling for years. Volume is king in the semiconductor industry and Intel no longer is the volume leader. Despite Intel’s efforts to change that dynamic with several recent moves, including making another go at its foundry business, the company is years away from reversing its lagging position relative to today’s leading foundries and design shops. Intel’s best chance to survive as a leader in our view will come from a combination of a massive market, continued supply constraints, government money and luck – perhaps in the form of a deal with Apple in the mid- to long term. In this Breaking Analysis we’ll update you on our latest assessment of Intel’s competitive position and unpack nuggets from the company’s February investor conference. Watch the full video analysis. Episode 120 – RPA has Become a Transformation Catalyst, Here’s What’s New – In its early days, robotic process automation emerged from rudimentary screen scraping, macros and workflow automation software. Once a script-heavy and limited tool that was almost exclusively used to perform mundane tasks for individual users, RPA has evolved into an enterprise-wide megatrend that puts automation at the center of digital business initiatives. In this Breaking Analysis we present our quarterly update of the trends in RPA and share the latest survey data from Enterprise Technology Research. Watch the full video analysis. Episode 119 – Cyber Stocks Caught in the Storm While Private Firms Keep Rising – The pandemic precipitated what is shaping up to be a permanent shift in cyber security spending patterns. As a direct result of hybrid work, CISOs have invested heavily in endpoint security, identity access management, cloud security and further hardening the network beyond the HQ. Moreover, the need to build security into applications from the start, rather than bolting protection on as an afterthought, has led to vastly heightened awareness around DevSecOps. Finally, attacking security as a data problem with automation and AI is fueling new innovations in cyber products and services; and is spawning well-funded, disruptive startups. In this Breaking Analysis we present our quarterly findings on the security sector. We’ll share the latest ETR survey data, identify the companies with customer spending momentum and share some of the market movers. Watch the full video analysis. Episode 118 – The Improbable Rise of Kubernetes – The rise of Kubernetes came about through a combination of forces that were in hindsight, quite a long shot. AWS’ dominance created momentum for cloud native application development and the need for simpler experiences beyond easily spinning up compute as a service. This wave crashed into innovations from a startup named Docker and a reluctant open source benefactor in Google that needed a way to change the game on Amazon in the cloud. Factor in Red Hat, which needed a path beyond Linux and was just about to opt for an alternative to Kubernetes to power OpenShift. Finally, figure out a governance structure to herd all the cats in the ecosystem so you can win out over other competition and create a de facto standard. Make all that happen and you get the remarkable ascendancy of Kubernetes. Such was the story unveiled recently in a new two-part documentary series from Honeypot simply titled “Kubernetes.” In this Breaking Analysis we tap the back stories of this documentary, which explains the improbable events leading to the creation of Kubernetes. We’ll share commentary from early Kubernetes committers and key players who came on theCUBE to piece together how it all happened. Finally, we’ll present new survey data from ETR on containers. Watch the full video analysis. Episode 117 – What to Expect in Cloud 2022 & Beyond – We’ve often said that the next ten years in cloud computing won’t be like the last ten. Cloud has firmly planted its footprint on the other side of the chasm with the momentum of the entire multi-trillion dollar technology business behind it. Both sellers and buyers are leaning in by adopting cloud technologies and many are building their own value layers on top of cloud. In the coming years we expect innovation will continue to coalesce around the big 3 U.S. clouds, plus Alibaba in APAC, with the ecosystem building value on top of the hardware, software and tools provided by the hyperscalers. Importantly, we don’t see this as a race to the bottom. Rather our expectation is that the large public cloud players will continue to take cost out of their platforms through innovation, automation and integration. Other cloud providers and the ecosystem, including traditional IT buyers, will leverage hyperscale clouds and mine opportunities in their respective markets. This is not a zero sum game. In this Breaking Analysis we’ll update you on our latest projections in the cloud market, share some new ETR survey data with some surprising nuggets; and drill into the important cloud database landscape. Watch the full video analysis. Episode 116 – Securing Snowflake – The amount of data ingested into a data warehouse overwhelmed the system. Every time Intel came out with a new microprocessor, practitioners would “chase the chips” in an effort to try and compress the overly restrictive elapsed time to insights. This cycle repeated itself for decades. Cloud data warehouses generally and Snowflake specifically changed all this. Not only were resources virtually infinite, but the ability to separate compute from storage permanently altered the cost, performance, scale and value equation. But as data makes its way into the cloud and is increasingly democratized as a shared resource across clouds – and at the edge – practitioners must bring a SecDevOps mindset to securing their cloud data warehouses. This Breaking Analysis takes a closer look at the fundamentals of securing Snowflake. An important topic as data becomes more accessible and available to a growing ecosystem of users, customers and partners. To do so we welcome two guests to this episode. Ben Herzberg is an experienced hacker, developer and an expert in several aspects of data security. Yoav Cohen is a technology visionary and currently serving as CTO at Satori Cyber. Watch the full video analysis. Episode 115 – Enterprise Technology Predictions 2022 – The pandemic has changed the way we think about, and predict the future. As we enter the third year of COVID, we see the significant impact it’s had on technology strategies, spending patterns and company fortunes. Much has changed and while many of these changes were forced reactions to a new abnormal, the trends we’ve seen over the past twenty-four months have become more entrenched and point the way to what’s ahead in the technology business. In this Breaking Analysis we welcome our data partner and colleague Erik Porter Bradley from ETR and we put forth our annual predictions for enterprise technology in 2022 and beyond. We’ll do our best to backup our predictions specific supporting data and more granular detail that can be measured as accurate or not. Please refer to the grading of our 2021 predictions to judge for yourself how we did last year. Watch the full video analysis. Episode 114 – Cyber, Blockchain & NFTs Meet the Metaverse – When Facebook changed its name to Meta last fall it catalyzed a chain reaction throughout the tech industry. Software firms, gaming companies, chip makers, device manufacturers and others have joined in the hype machine. It’s easy to dismiss the metaverse as futuristic hyperbole, but do we really believe that tapping on a smartphone, staring at a screen or two dimensional Zoom meetings are the future of how we work, play and communicate? As the Internet itself proved to be larger than we ever imagined, it’s very possible that the combination of massive processing power, cheap storage, AI, blockchains, crypto, sensors, AR/VR, brain interfaces and other emerging technologies will combine to create new and unimaginable consumer experiences; and massive wealth for creators of the metaverse. In this Breaking Analysis we explore the intersection of cybersecurity, blockchain, crypto currency, NFTs and the emerging metaverse. To do so we welcome in cyber expert, hacker, gamer, NFT expert and founder of Ore System, Nick Donarski. Watch the full video analysis. Episode 113 – Analyst Predictions 2022: The Future of Data Management – In the 2010’s, organizations became keenly aware that data would become the critical ingredient in driving competitive advantage, differentiation and growth. But to this day, putting data to work remains a difficult challenge for many if not most organizations. As the cloud matures it has become a game changer for data practitioners by making cheap storage and massive processing power readily accessible. We’ve also seen better tooling in the form of data workflows, streaming, machine intelligence/AI, developer tools, security, observability, automation, new databases and the like. These innovations accelerate data proficiency but at the same time add complexity for practitioners. Data lakes, data hubs, data warehouses, data marts, data fabrics, data meshes, data catalogs and data oceans are forming, evolving and exploding onto the scene. In an effort to bring perspective to this sea of optionality, we’ve brought together some of the brightest minds in the data analyst community to discuss how data management is morphing and what practitioners should expect in 2022 and beyond. Watch the full video analysis. Episode 112 – Grading our 2021 Predictions – Predictions are all the rage this time of year. On December 29th, 2020, in collaboration with Erik Porter Bradley of Enterprise Technology Research, we put forth our predictions for 2021. The focus of our prognostications included tech spending, remote work, productivity apps, cyber, IPOs, SPACs, M&A, data architecture, cloud, hybrid cloud, multi-cloud, AI, containers, automation and semiconductors. We covered a lot of ground! In this Breaking Analysis, as a warmup for our 2022 predictions post, we’ll review each of our predictions for this past year and grade the accuracy of our forecasts Watch the full video analysis. Episode 111 – Why Oracle’s Stock is Surging to an All time High – On Friday, Oracle announced a meaningful earnings beat and strong forward guidance on the strength of its license business; and slightly better than expected cloud performance. The stock rose sharply on the day and closed up nearly 16% surpassing $280B in market value. Oracle’s success is due largely to its execution of a highly differentiated strategy that has evolved over the past decade or more; deeply integrating its hardware and software, heavily investing in next generation cloud, creating a homogenous experience across its application portfolio and becoming the number one platform for the world’s most mission critical applications. While investors piled into the stock, skeptics will point to the beat being tilted toward license revenue and investors will likely keep one finger on the sell button until they’re convinced Oracle’s cloud momentum is more consistent and predictable. In this Breaking Analysis we’ll review Oracle’s most recent quarter and pull in some ETR survey data to frame the company’s cloud business, the momentum of Fusion ERP, where the company is winning and some gaps/opportunities we see that can be addressed in the coming quarters. Watch the full video analysis. Episode 110 – Rise of the Supercloud – Last week’s AWS re:Invent underscored the degree to which cloud computing generally and AWS specifically have impacted the technology landscape. From making infrastructure deployment simpler, to accelerating the pace of innovation, to the formation of the world’s most active and vibrant technology ecosystem; it’s clear that AWS has been the number one force for industry change in the last decade. Going forward we see three high level contributors from AWS that will drive the next 10 years of innovation, including: 1) the degree to which data will play a defining role in determining winners and losers; 2) the knowledge assimilation effect of AWS’ cultural processes such as two pizza teams, customer obsession and working backwards; and 3) the rise of superclouds– that is clouds built on top of hyperscale infrastructure that focus not only on IT transformation, but deeper business integration and digital transformation of entire industries. In this Breaking Analysis we’ll review some of the takeaways from the 10th annual AWS re:Invent conference and focus on how we see the rise of superclouds impacting the future of virtually all industries. Watch the full video analysis. Episode 109 – Break up Amazon? Survey Suggests it May Not be Necessary – Despite the posture that big tech generally and Amazo.com Inc.specifically should be regulated and/or broken apart, recent survey research suggests that Amazon faces many disruption challenges, independent of any government intervention. Specifically, respondents to our survey believe that history will repeat itself in that there’s a 60% probability that Amazon will be disrupted by market forces, including self-inflicted wounds. Amazon faces at least seven significant disruption scenarios of varying likelihood and impact, perhaps leading to the conclusion that the government should let the market adjudicate Amazon’s ultimate destiny. In this Breaking Analysis, and ahead of AWS re:Invent, we share the results of our survey designed to asses what, if anything, could disrupt Amazon. We’ll also show you some data from ETR that indicates the strong momentum of AWS is likely to continue, which could be a factor in any government intervention. Watch the full video analysis. Episode 108 – AWS & Azure Accelerate Cloud Momentum – Despite all the talk about repatriation, hybrid and multi-cloud opportunities and cloud as an increasingly expensive option for customers…the data continues to show the importance of public cloud to the digital economy. Moreover, the two leaders, AWS and Azure are showing signs of accelerated momentum that point to those two giants pulling away from the pack in the years ahead. Each of these companies is demonstrating broad-based momentum across their respective product lines. It’s unclear if anything other than government intervention or self-inflicted wounds will slow these two companies down this decade. Despite the commanding lead of the two leaders, a winning strategy for companies that don’t run their own cloud continues to be innovating on top of their massive CAPEX investments. The most notable example of this approach in our view continues to be Snowflake. In this Breaking Analysis, Dave will provide our quarterly market share update of the big four hyperscale cloud providers. We’ll share some new data from ETR based on the most recent survey, drill into some of the reasons for the momentum of AWS and Azure; and drill further into the database and data warehouse sector to see what if anything has changed in that space. Watch the full video analysis. Episode 107 – Cutting Through the Noise of Full Stack Observability – Full stack observability is the new buzz phrase. As businesses go digital, customer experience becomes ever more important. Why? Because fickle consumers can switch brands in the blink of an eye – or the click of a mouse. Every vendor wants a piece of the action in this market including companies that have provided traditional monitoring, log analytics, application performance management, and related services. These companies are joined by a slew of new entrants claiming end-to-end visibility across the so-called “modern tech stack.” Recent survey research however confirms our thesis that no one company has it all. New entrants have a vision and are not encumbered by legacy technical debt. However their offerings are immature. Established players with deep feature sets in one segment are pivoting through M&A and organic development to fill gaps. Meanwhile, cloud players are gaining traction and participating through a combination of native tooling combined with strong ecosystems to address this opportunity. In this Breaking Analysis we dive into a recent ETR drill down study on full stack observability. And to do so we once again welcome in our colleague Erik Bradley, Chief Engagement Strategist at ETR. Watch the full video analysis. Episode 106 – What Could Disrupt Amazon? – Five publicly traded, US-based companies have market valuations over or just near one trillion dollars. As of Oct. 29th, Apple and Microsoft top the list, each at $2.5T, followed by Alphabet at $2T, Amazon at $1.7T and Facebook (now Meta) at just under $1T – off from its high of $1.1T prior to its recent troubles. These companies have reached extraordinary levels of success and power. What, if anything could disrupt their market dominance? In his book Seeing Digital, Author David Moschella made three key points that are relevant: In the technology industry, disruptions are the norm – The waves of mainframes, Minis, PCs, Mobile and the Internet all saw new companies emerge and power structures that dwarfed previous eras of innovation. Is that dynamic changing? Every industry has a disruption scenario. Silicon Valley – broadly defined to include Seattle, or at least Amazon – has a dual disruption agenda. The first being horizontally targeting the technology industry and the second as digital disruptors in virtually any industry. How relevant is that to the future power structure of the technology business? In this Breaking Analysis we welcome in author, speaker, researcher, thought leader and senior fellow at ITIF, David Moschella to assess what could possibly disrupt today’s trillionaire companies. And we’ll start with Amazon. Watch the full video analysis. Episode 105 – Data Mesh…A New Paradigm for Data Management – Data mesh is a new way of thinking about how to use data to create organizational value. Leading edge practitioners are beginning to implement data mesh in earnest. Importantly, data mesh is not a single tool or a rigid reference architecture. Rather it’s an architectural and organizational model that is designed to address the shortcomings of decades of data challenges and failures. As importantly, it’s a new way to think about how to leverage and share data at scale across an organization and ecosystems. Data mesh in our view will become the defining paradigm for the next generation of data excellence. In this Breaking Analysis we welcome the founder and creator of data mesh, author, thought leader, technologist Zhamak Dehghani, who will help us better understand some of core principles of data mesh and the future of decentralized data management. With practical advice for data pros who want to create the next generation of data-driven organizations. Watch the full video analysis. Episode 104 – The Hybrid Cloud Tug of War Gets Real – It looks like Hybrid cloud is finally here. We’ve seen a decade of posturing, marketecture, slideware and narrow examples but there’s little question that the definition of cloud is expanding to include on-premises workloads in hybrid models. Depending on which numbers you choose to represent IT spending, public cloud accounts for less than 5% of the total pie. As such there’s a huge opportunity in hybrid, outside of the pure public cloud; and everyone wants a piece of the action. The big question is how will this now evolve? Customers want control, governance, security, flexibility and a feature-rich set of services to build their digital businesses. It’s unlikely they can buy all that – so they’re going to have to build it with partners. Specifically vendors, SIs, consultancies, and their own developers. The tug-of-war to win the new cloud day has finally started in earnest – between the hyperscalers and the largest enterprise tech companies in the world. Watch the full video analysis. Episode 103 – The Future of the Semiconductor Industry – Semiconductors are at the heart of technology innovation. For decades, technology improvements have marched to the cadence of silicon advancements in performance, cost, power and packaging. In the past ten years, the dynamics of the semiconductor industry have changed dramatically. Soaring factory costs, device volume explosions, fabless chip companies, greater programmability, compressed time to tape out, more software content, the looming Chinese presence…these and other factors have permanently changed the power structure of the semiconductor business. We rely on chips for every aspect of our lives, which has led to a global semiconductor shortage that has impacted more industries than we’ve ever seen. Our premise is that silicon success in the next twenty years will be determined by volume manufacturing expertise, design innovation, public policy, geopolitical dynamics, visionary leadership and innovative business models that can survive the intense competition in one of the most challenging businesses in the world. Watch the full video analysis. Episode 102 – UiPath Fast Forward to Enterprise Automation | UiPath FORWARD IV – UiPath has always been an unconventional company. It started with humble beginnings as essentially a software development shop. It then caught lightning in a bottle with its computer vision technology and simplification mantra…creating easy to deploy software robots for bespoke departments to automate mundane tasks. The story is well known…the company grew rapidly and was able to go public earlier this year. Consistent with its out of the ordinary approach, while other firms are shutting down travel and physical events, UiPath is moving ahead with Forward IV, its annual user conference next week…with a live audience at the Bellagio in Las Vegas. It’s also “Fast Forwarding” as a company, determined to lead the charge beyond RPA point tools and execute on a more all-encompassing enterprise automation agenda. Watch the full video analysis. Episode 101 – CIOs Signal Hybrid Work Will Power Spending Through 2022 – Throughout the pre-vaccine COVID era, IT buyers indicated budget constraints would squeeze 2020 spending by roughly 5% relative to 2019 levels. But the forced March to digital combined with increased cyber threats for remote workers, created a modernization mandate that powered Q4 spending last year. This momentum has carried through to 2021. While COVID variants have delayed return to work and business travel plans, our current forecast for global IT spending remains strong at 6-7%, slightly down from previous estimates. But the real story is CIOs and IT buyers expect a 7-8% increase in 2022 spending, reflecting investments in hybrid work strategies and a continued belief that technology remains the underpinning of competitive advantage in the coming decade. In this Breaking Analysis, Dave will share the latest results of ETR’s macro spending survey and update you on industry and sector investment patterns. Watch the full video analysis. Following is the complete collection to date, crystallizing the key topics of the past year or so. We hope you enjoy these episodes and, as always, welcome your feedback. Episode 100 – How Cisco can win cloud’s ‘Game of Thrones’ – Cisco is a company at the crossroads. It is transitioning from a high margin hardware business to a software subscription-based model through both organic moves and targeted acquisitions. It’s doing so in the context of massive macro shifts to digital and the cloud. We believe Cisco’s dominant position in networking, combined with a large market opportunity and a strong track record of earning customer trust, put the company in a good position to capitalize on cloud momentum. But there are clear challenges ahead, not the least of which is the growing complexity of Cisco’s portfolio, transitioning a large legacy business and the mandate to maintain its higher profitability profile as it moves to a new business model. In this Breaking Analysis, we welcome in Zeus Kerravala, Founder and Principal Analyst at ZK Research and long time Cisco watcher who collaborated with us to craft the premise of this session. Watch the full video analysis. Episode 99 – The Case for Buy the Dip on Coupa, Snowflake & Zscaler – Buy the dip has been an effective strategy since the market bottomed in early March last year. The approach has been especially successful in tech and even more so for those tech names that: 1) were well-positioned for the forced march to digital – i.e. remote work, online commerce, data-centric platforms and certain cybersecurity plays; and 2) already had the cloud figured out. The question on investors’ minds is where to go from here. Should you avoid some of the high flyers that are richly valued with eye-popping multiples? Or should you continue to buy the dip? And if so, which companies that capitalized on the trends from last year will see permanent shifts in spending patterns that make them a solid long term play. In this Breaking Analysis we shine the spotlight on three companies that may be candidates for a buy the dip strategy over the next 3-5 years. To do so it’s our pleasure to welcome Ivana Delevska, the Chief Investment Officer and founder of SPEAR Alpha, a new, research-centric ETF focused on industrial technology. Watch the full video analysis. Episode 98 – Thinking Outside the Box…AWS Signals a New Era for Storage – By our estimates, AWS will generate around $9B in storage revenue this year and is now the second largest supplier of enterprise storage behind Dell. We believe AWS storage revenue will surpass $11B in 2022 and continue to outpace on-prem storage growth by more than 1,000 basis points for the next three to four years. At its third annual Storage Day event, AWS signaled a continued drive to think differently about data storage and transform the way customers migrate, manage and add value to their data over the next decade. In this Breaking Analysis Dave will give a brief overview of what we learned at AWS’ Storage Day, share our assessment of the big announcement of the day – a deal with NetApp to run the full ONTAP stack natively in the cloud as a managed service – and share some new data on how we see the market evolving. Watch the full video analysis. Episode 97 – Tech Earnings Signal a Continued Booming Market – Tech earnings reports from key enterprise software and infrastructure players this week, underscore that IT spending remains robust in the post isolation economy. This is especially true for those companies that have figured out a coherent and compelling cloud strategy. Despite COVID variant uncertainties and hardware component shortages, most leading tech names outperformed expectations. That said, investors weren’t in the mood to reward all stocks and any variability in product mix, earnings outlook or bookings/billings nuances were met with a tepid response from the street. In this Breaking Analysis Dave will provide our commentary and new data points on key technology companies including Snowflake, Salesforce, Workday, Splunk, Elastic, Palo Alto Networks, VMware, Dell, Pure Storage, HP Inc. and NetApp. Watch the full video analysis. Episode 96 – Can anyone tame the identity access beast? Okta aims to try… – Chief information security officers cite trust as the most important value attribute they can deliver to their organizations. And when it comes to security, identity is the new attack surface. As such, identity and access management continue to be the top priority among technology decision makers. It also happens to be one of the most challenging and complicated areas of the cyber security landscape. Okta, a leader in the identity space, has announced its intent to converge privilege access and identity governance in an effort to simplify the landscape and reimagine identity. Our research shows that interest in this type of consolidation is high, but organizations believe technical debt, compatibility issues, expense and lack of talent are barriers to reaching cyber nirvana with their evolving zero trust networks. In this Breaking Analysis, Dave will explore the complex and evolving world of identity access and privileged account management. With an assessment of Okta’s market expansion aspirations and fresh data from ETR and input from Erik Bradley. Watch the full video analysis. Episode 95 – Rethinking Data Protection in the 2020s – Techniques to protect sensitive data have evolved over thousands of years, literally. The pace of modern data protection is rapidly accelerating and presents both opportunities and threats for organizations. In particular, the amount of data stored in the cloud, combined with hybrid work models, the clear and present threat of cyber crime, regulatory edicts and ever-expanding edge use cases should put CxOs on notice that the time is now to rethink your data protection strategies. In this Breaking Analysis, Dave is going to explore the evolving world of data protection and share some data on how we see the market evolving and the competitive landscape for some of the top players. Watch the full video analysis. Episode 94 – Cyber, Cloud, Hybrid Work & Data Drive 8% IT Spending Growth in 2021 – Every CEO is figuring out the right balance for new hybrid business models. Regardless of the chosen approach, which will vary, technology executives understand they must accelerate digital and build resilience as well as optionality into their platforms. This is driving a dramatic shift in IT investments at the macro level as we expect total spending to increase at 8% in 2021, compared to last year’s contraction. Investments in cyber security, cloud, collaboration to enable hybrid work and data, including analytics, AI and automation are the top spending priorities for CxOs. In this Breaking Analysis Dave welcomes back Erik Bradley, Chief Engagement Strategist at our partner ETR. In this post we’ll share some takeaways from ETR’s latest survey and provide our commentary on what it means for markets, sellers and buyers. We’ll also explain what we think Wall Street is missing about Amazon’s latest earnings. Watch the full video analysis. Episode 93 – ServiceNow’s Collision Course with Salesforce.com – ServiceNow is a company that investors love to love. But there’s caution in the investor community right now as confusion about transitory inflation and higher interest rates looms. ServiceNow also suffers from perfection syndrome and elevated expectations. In this Breaking Analysis Dave will dig into ServiceNow, one of the companies we began following almost ten years ago, and provide some thoughts on ServiceNow’s march to $15B by 2026. Watch the full video analysis. Episode 92 – Survey Data Shows no Slowdown in AWS & Cloud Momentum – Despite all the chatter about cloud repatriation and the exorbitant cost of cloud computing, customer spending momentum continues to accelerate in the post isolation economy. If the pandemic was good for the cloud it seems that the benefits of cloud migration remain lasting in the late stages of COVID. And we believe this stickiness will continue. In this Breaking Analysis Dave will share some fresh July survey data that indicates accelerating momentum for the largest cloud computing firms. Watch the full video analysis. Episode 91 – How JPMC is Implementing a Data Mesh Architecture on the AWS Cloud – A new era of data is upon us. The technology industry generally and the data business specifically are in a state of transition. Even our language reflects that. For example, we rarely use the phrase “Big Data” anymore. Rather we talk about digital transformation or data-driven companies. In this Breaking Analysis we want to share our assessment of the state of the data business. We’ll do so by looking at the data mesh concept and how a division of a leading financial institution, JPMC, is practically applying these relatively new ideas to transform its data architecture for the next decade. Watch the full video analysis. Episode 90 – Mobile World Congress Highlights Telco Transformation – AMobile World Congress is on for 2021. theCUBE will be there and we’ll let you know if it’s alive and well. As we approach a delayed MWC it’s appropriate to reflect on the state of the telecoms industry. Let’s face it – the telcos have done a great job of keeping us all connected during the pandemic. In this Breaking Analysis we welcome a long time telecoms industry analyst and the Founding Director of Lewis Insight, Mr. Chris Lewis. Watch the full video analysis. Episode 89 – How AWS is Revolutionizing Systems Architecture – AWS is pointing the way to a revolution in system architecture. Much in the same way that AWS defined the cloud operating model last decade, we believe it is once again leading in future systems. In this Breaking Analysis we’ll dig into the moves that AWS has been making, explain how they got here, why we think this is transformational for the industry and what this means for customers, partners and AWS’ many competitors. Watch the full video analysis. Episode 88 – Learnings from the hottest startups in cyber & IT infrastructure – As you well know by now, the cloud is about shifting IT labor to more strategic initiatives. Or as Andy Jassy posited at the first AWS re:Invent conference in 2012, removing the undifferentiated heavy lifting associated with deploying and managing IT infrastructure. In this Breaking Analysis Dave is pleased to welcome a special guest, Erik Suppiger, author of the Elite 80 – a report that details the hottest privately held cybersecurity and IT infrastructure companies in the world. Erik is a senior analyst at JMP Securities and will share insights from this report. Watch the full video analysis. Episode 87 – Chasing Snowflake in Database Boomtown – Database is the heart of enterprise computing. The market is both growing rapidly and evolving. Major forces transforming the space include cloud and data – of course – but also new workloads, advanced memory and IO capabilities, new processor types, a massive push toward simplicity, new data sharing and governance models; and a spate of venture investment. In this Breaking Analysis Dave will share our most current thinking on the database marketplace and dig into Snowflake’s execution, some of its challenges and we’ll take a look at how others are making moves to solve customer challenges; and angling to get their piece of the growing database pie. Watch the full video analysis. Episode 86 – How Nvidia plans to own the data center with AI – Nvidia wants to completely transform enterprise computing by making datacenters run 10X faster at 1/10th the cost. In this Breaking Analysis Dave will explain why we believe Nvidia is in a strong position to power the world’s computing centers and how it plans to disrupt the grip that x86 architectures have had on the datacenter market for decades. Watch the full video analysis. Episode 85 – Your Online Assets Aren’t Safe – Is Cloud the Problem or the Solution? – The convenience of online access to bank accounts, payment apps, crypto exchanges and other transaction systems has created enormous risks, which the vast majority of individuals either choose to ignore or simply don’t understand. In this Breaking Analysis Dave will try to raise awareness about a growing threat to your liquid assets and hopefully inspire you to do some research and take actions to lower the probability of you losing thousands, hundreds of thousands or millions of dollars. Watch the full video analysis. Episode 84 – Debunking the Cloud Repatriation Myth – Cloud repatriation is a term often used by technology companies that don’t operate a public cloud. The marketing narrative most typically implies that customers have moved work to the public cloud and, for a variety of reasons – expense, performance, security, etc. Some have written about the repatriation myth, but in this Breaking Analysis, Dave will share hard data from ETR and other sources that we feel debunks the repatriation narrative as it’s currently being promoted. Watch the full video analysis. Episode 83 – Chaos Creates Cash for Criminals & Cyber Companies – The pandemic not only accelerated a shift to digital, it highlighted a rush of cyber criminal sophistication, collaboration and chaotic responses from virtually every major company on the planet. The SolarWinds hack exposed digital supply chain weaknesses and appears to have accelerated so-called island hopping techniques that are exceedingly difficult to detect. In this Breaking Analysis Dave will provide our quarterly update on the security industry and share new survey data from ETR and theCUBE community that will help you navigate through the maze of corporate cyber warfare. Watch the full video analysis. Episode 82 – Why Apple Could be the Key to Intel’s Future – The latest Arm Neoverse announcement further cements our opinion that its architecture, business model and ecosystem execution are defining a new era of computing; and leaving Intel in its dust. In this Breaking Analysis, Dave will explain why and how Apple could hold a key to saving Intel’s (and America’s) semiconductor industry leadership position. Watch the full video analysis. Episode 81 – A Digital Skills Gap Signals Rebound in IT Services Spend – Recent survey data from ETR shows that enterprise tech spending is tracking with projected U.S. GDP growth at 6% to 7% this year. Many markers continue to point the way to a strong recovery including hiring trends and the loosening of frozen IT project budgets. In this Breaking Analysis Dave welcomes back Erik Bradley, Chief Engagement Strategist at ETR, who will share fresh data, perspectives and insights from the latest survey data. Watch the full video analysis. Episode 80 – UiPath’s Unconventional $PATH to IPO – UiPath is going public this coming week and will be the next hot software company to IPO. It has had a long strange trip to IPO. In this week’s Breaking Analysis, Dave shares our learnings from sifting through hundreds of pages of UiPath’s S1 and convey our thoughts on its market, competitive position and outlook Watch the full video analysis. Episode 79 – Moore’s Law is Accelerating and AI is Ready to Explode – Moore’s Law is dead right? Think again. While the historical annual CPU performance improvement of ~40% is slowing, the combination of CPUs packaged with alternative processors is improving at a rate of more than 100% per annum. In this Breaking Analysis Dave is going to unveil some data that suggests we’re entering a new era of innovation where inexpensive processing capabilities will power an explosion of machine intelligence applications. Watch the full video analysis. Episode 78 – Arm Lays Down the Gauntlet at Intel’s Feet – Exactly one week after Pat Gelsinger unveiled plans to reinvent Intel, Arm announced version 9 of its architecture and put forth its vision for the next decade. In this Breaking Analysis Dave will explain why we think this announcement is so important and what it means for Intel and the broader technology landscape. Watch the full video analysis. Episode 77 – Intel… Too Strategic to Fail – Intel’s big announcement this week underscores the threat that the United States faces from China. The U.S. needs to lead in semiconductor design and manufacturing; and that lead is slipping because Intel has been fumbling the ball over the past several years. In this Breaking Analysis Dave will peel the onion of Intel’s announcement, explain why we’re not as sanguine as was Wall Street on Intel’s prospects and lay out what we think needs to take place for Intel to once again become top gun; and for us to gain more confidence. Watch the full video analysis. Episode 76 – Tech Spending Powers the Roaring 2020s as Cloud Remains a Staple of Growth – In the year 2020, it was good to be in tech. It was even better to be in the cloud as organizations had to rely on remote cloud services to keep things running. In this Breaking analysis Dave will provide our take on the latest ETR COVID survey and share why we think the tech boom will continue well into the future. Watch the full video analysis. Episode 75 – Breaking Analysis: Unpacking Oracle’s Autonomous Data Warehouse Announcement – On February 19th of this year, Barron’s dropped an article declaring Oracle a cloud giant and explained why the stock was a buy. Investors took notice and the stock ran up 18% over the next 9 trading days and peaked on March 9th, the day before the company announced its latest earnings. The company beat consensus earnings on both top line and EPS last quarter. But Investors didn’t like Oracle’s tepid guidance and the stock pulled back..but is still well above its pre-Barron’s article price. Watch the full video analysis. Episode 74 – Breaking Analysis: NFTs, Crypto Madness & Enterprise Blockchain – When a piece of digital art sells for $69.3M, more than has ever been paid for works by Paul Gauguin or Salvador Dali, making its creator the third most expensive living artist in the world, one can’t help but take notice and ask: “What is going on?” The latest craze around NFTs may feel a bit “bubblicious,” but it’s yet another sign that the digital age is now fully upon us. In this Breaking Analysis Dave wants to take a look at some of the trends that may have observers and investors scratching their heads, but we think still offer insight to the future — and possibly some opportunities for young investors. And we’ll briefly touch on how these trends may relate to enterprise tech. Watch the full video analysis. Episode 73 – Breaking Analysis: Satya Nadella Lays out a Vision for Microsoft at Ignite 2021 – Microsoft CEO Satya Nadella sees a different future for cloud computing over the coming decade. In this Breaking Analysis Dave Vellante will review the highlights of Nadella’s Ignite keynote, share our thoughts on what it means for the future of cloud specifically and tech generally. Watch the full video analysis. Episode 72 – Breaking Analysis: SaaS Attack, On Prem Survival & What’s a Cloud Company Look Like SaaS companies have been some of the strongest performers during this COVID era. In this Breaking Analysis, Dave Vellante picks out a few of the more recent themes from this month and share our thoughts on some major enterprise software players, the future of on-prem and a review of our take on cloud, what cloud will look like in the 2020s. Watch the full video analysis. Episode 71 – Breaking Analysis: RPA Remains on a Hot Streak as UiPath Blazes the Trail – UiPath’s recent $750M raise at a $35B valuation underscores investor enthusiasm for robotic process automation. In this Breaking Analysis Dave Vellante explores the current trends in the RPA market and try to address the question– is UiPath’s value supported by the ETR spending data, how will the RPA market evolve from a total available market (TAM) perspective and where do some of the other players like Automation Anywhere, Pegasystems and Blue Prism fit? Watch the full video analysis. Episode 70 – Breaking Analysis: How the SolarWinds Hack & COVID are Changing CISO Spending Patterns – The SolarWinds hack along with the pandemic are the two most visible catalysts for change in cybersecurity spending patterns. In addition to securing a more distributed workforce, CISOs have to now worry about protecting against the very software updates and patches designed to keep them safe against cyber attacks. In this Breaking Analysis, Dave Vellante shares data from a recent CISO roundtable hosted by ETR’s Erik Bradley and provides updates on the cybersecurity sector overall. Watch the full video analysis. Episode 69 – Breaking Analysis: Big 4 Cloud Revenue Poised to Surpass $115B in 2021 –There are four players in the IaaS/PaaS hyperscale cloud services space which have the ability to outperform all competitors. Combined in 2021, they will generate more than $115 billion dollars in revenue. In this Breaking Analysis, Dave Vellante initiates coverage of Alibaba, one of the Big Four in this massive market segment. Watch the full video analysis. Episode 68 – Breaking Analysis: Tech Spending Roars Back in 2021 –There is an expected six to seven percent increase in 2021 technology spending following the five percent decline over the past year. Many factors are contributing to this growth, and in this Breaking Analysis, Dave Vellante shares some of those reasons as well as the latest macro view of the market. Watch the full video analysis. Episode 67 – Breaking Analysis: Best of theCUBE on Cloud –The coming decade of cloud will be dramatically different from the last. There will be a shift toward a more data centric, hyper decentralized cloud that is far more complex than anything seen previously. In this Breaking Analysis, Dave Vellante summarizes exclusive content gathered from the recent theCUBE on cloud event. Watch the full video analysis. Episode 66 – Breaking Analysis: Pat Gelsinger Must Channel Andy Grove and Recreate Intel –Intel is fighting a war on two fronts: 1) Arm volumes have far surpassed those of Intel’s x86, conferring major cost advantages to leading fabs like TSMC and Samsung and 2) AMD continues to chip away at Intel’s dominance in its core markets. But the biggest challenge for incoming CEO Pat Gelsinger is perhaps to reinvent Intel by splitting manufacturing from design to make the company more agile and cost competitive. In this Breaking Analysis, Dave Vellante speculates about Intel’s future, and explains why Wikibon believes Intel has no choice but to shed its vertically integrated heritage. Episode 65 – Breaking Analysis: Breaking Analysis: 2021 Enterprise Technology Predictions –COVID-19 created a disruption in virtually all our expectations for 2020. In some regards, predictions for the past year played out very well, thanks to the pandemic. And in others, the complete opposite occurred. That being said, there is a lot to talk about heading into 2021. In this week’s Breaking Analysis, Dave Vellante is joined by Erik Bradley of ETR to share their top predictions for the upcoming year. Watch the full video analysis. Episode 64 – Breaking Analysis: Cloud Momentum & CIO Optimism Point to a 4% Rise in 2021 Tech Spending –Developments with COVID such as education, rapid vaccine rollout, productivity gains, and broad based cloud coverage suggest higher tech spending than previously forecasted for the upcoming year. Now, we can expect a 3-5 percent increase in 2021 spending. In this Breaking Analysis, Dave Vellante shares the data to support these predictions, and predicts which sectors are to gain momentum. Watch the full video analysis. Episode 63 – Breaking Analysis: Legacy Players Feel the Heat as AWS Storage Revenue Approaches $10B –Once an untapped bastion of innovation, storage in the data center now exists as a shell of what it used to be, and will remain as such. Specifically, AWS’ storage business is projected to hit between $6.5 – $7B this year and hit $10B within the next 18 – 24 months. In this Breaking Analysis, Dave Vellante lays out what this might mean for the industry, as well as the impact of AWS. Watch the full video analysis. Episode 62 – Breaking Analysis: Cloud 2030…From IT, to Business Transformation – Breaking Analysis: Cloud, Containers, AI & RPA Support Strong Rebound in 2021. Watch the full video analysis. Episode 61 – Breaking Analysis: Cloud 2030…From IT, to Business Transformation – Over the past decade, cloud computing has undoubtedly been the most pivotal force in IT. This brings the question as to what the next ten years will hold for cloud and the tech world. Perhaps, it will lay the foundations for a complete transformation of nearly every company worldwide. In this Breaking Analysis, as part of his coverage off AWS re:Invent 2020, Dave Vellante provides insights and predictions about the next breakthroughs in cloud. Watch the full video analysis. Episode 60 – Breaking Analysis: Sparked by COVID, CISOs see Permanent Shift in Cyber Strategies – CISOs report a forced shift to remote work has actually led to meaningful productivity improvements. This reality is causing security pros to rethink how they’ll approach security in the coming decade, informed by learnings during the pandemic. Watch the full video analysis. Episode 59 – Breaking Analysis: How Snowflake Plans to Change a Flawed Data Warehouse Model – Snowflake will not grow into its valuation by simply stealing share from the on-prem data warehouse vendors. Rather Snowflake must create an entirely new market based on completely changing the way organizations think about monetizing data. In this Breaking Analysis, Dave Vellante suggests a new data architecture that places domain knowledge at the core. Watch the full video analysis. Episode 58 – Breaking Analysis: Cloud Revenue Accelerates in the COVID Era – Over the past decade, cloud computing has undoubtedly been at the forefront of the innovation engine. The pandemic has accelerated the adoption of cloud and AI by at least two years, establishing a new era that will impact not only the technology industry, but all organizations. In this Breaking Analysis, Dave Vellante gives updates about the latest cloud market trends. Watch the full video analysis. Episode 57 – Breaking Analysis: Azure Cloud Powers microsoft’s Future – Big tech is once again under fire as CEOs of Facebook, Twitter, and Google face backlash from several US senators. Microsoft is not among these companies, as it relies on Azure cloud to build momentum, which now accounts for nineteen percent of its overall revenues. In this Breaking Analysis, Dave Vellante dives into the business of Microsoft and the data of its projected progress. Watch the full video analysis. Episode 56 – Breaking Analysis: Google’s Antitrust Play… Get Your Head out of Your Ads – The U.S. Department of Justice filed an antitrust lawsuit against Google, accusing the corporation of being a monopoly gatekeeper for the internet. In this Breaking Analysis, Dave Vellante shares data, covers the history of monopolistic power in the computer industry, and suggests future moves for Google to diversify its business. Watch the full video analysis. Episode 55 – Breaking Analysis: 2H 2020 Tech Spending: Headwinds into 2021 – Relative to 2019, tech spending has been hit hard, with a projected 5% decrease projected for 2020. Still, there seem to be bright spots within the market that show a slight increase in 2021 spending data. In this Breaking Analysis, Dave Vellante is joined by ETR’s Erik Bradley to provide the latest data supporting these trends. Watch the full video analysis. Episode 54 – CIOs Report Slow Thaw of Spending Freezes – Expect 2% Growth in 2021 – Recent Data provided by ETR suggests CIOs expect slight improvements in Q4 spending. Although these numbers are still down four percent from last year, this is a step in the right direction going into 2021. In this Breaking Analysis, Dave Vellante analyzes some of this data and provides his outlook for Q4 as well as the coming months. Watch the full video analysis. Episode 53 – Application Performance Management…From Tribal Knowledge to Digital Dashboard – Application Performance management has been around for a while, but it has had to evolve to accommodate for more complex operations, such as cloud-based systems. In this Breaking Analysis, Dave Vellante is teamed with Erik Bradley to offer the newest data to come out of the growing market. Watch the full video analysis. Episode 52 – Snowflake’s IPO… Here’s What’s Next – There is a lot of talk going on within the tech industry surrounding Snowflake’s recent IPO. In this week’s Breaking, Analysis, Dave Vellante shares his insights, investment strategies, and dives into some of the questions that have come out of the buzz from the hottest IPO in software history. Watch the full video analysis. Episode 51 – Market Recoil Puts Tech Investors at a Fork in the Road – Recently, the stock market experienced its most significant drop since early June. Tech companies were among several corporations involved in this decline, sending investors into a panic. In this Breaking Analysis, Dave Vellante answers questions and provides some perspective about what’s happening within the technology space and how it will continue to affect the rest of 2020. Watch the full video analysis. Episode 50 – Enterprise Software Download in the Summer of COVID – Enterprise applications are an enormous market, and organizations across the globe essentially rely on these applications to operate. In this Breaking Analysis, Dave Vellante unpacks new data surrounding the Enterprise software space, focusing on the core enterprise apps that companies rely on to keep their businesses running. Watch the full video analysis. Episode 49 – Tectonic Shifts Power Cloud, IAM and Endpoint Security – Although time has seemed to stop since the beginning of quarantine, COVID-19 has caused acceleration within the technology industry, causing some trends to speed up by about two years. The cybersecurity sector is one of the best examples of this change. In this Breaking Analysis, Dave Vellante discusses this sector, and provides updates on why key areas of the market that are exploding. Watch the full video analysis. Episode 48 – Cloud Remains Strong but not Immune to COVID – Although Cloud is among the most successful industries in tech spending, even it is not protected against COVID-19. Recent data shows a newly shaped recovery pattern suggesting this negative impact. In this Breaking Analysis, Dave Vellante dives into this data surrounding the cloud market and provides prospective updates about the big three. Watch the full video analysis. Episode 47 – RPA Competitors Eye Deeper Business Integration Agenda – Although the projected spending outlook for 2020 looks moderate, Robotic process automation solutions are still seeing the highest investment momentum for IT buyers. In this Breaking Analysis, Dave Vellante summarizes the latest RPA spending trends using data provided by ETR. Watch the full video analysis. Episode 46 – Five Questions Investors are Asking about Snowflake’s IPO – Snowflake recently filed a confidential document suggesting an IPO is imminent. Many within the community are responding positively to this news, causing a lot of discussion and inquiry. In this Breaking Analysis, Dave Vellante and Erik Bradley unpack five critical questions surrounding this pending IPO. Watch the full video analysis. Episode 45 – Google Cloud Rides the Wave but Remains a Distant Third Place – Despite its faster growth and infrastructure as a service, Google Cloud platform remains a third wheel behind AWS and Azure in the race for cloud dominance. In this Breaking Analysis, Dave Vellante reviews the current state of cloud and drills into the spending data to provide new insights about Google’s position in the market. Watch the full video analysis. Episode 44 – Living Digital: New Rules for Technology Events – Although there is push for a more digital world, in person interactions seem to be equally as important. Every year, large corporations throw massive events for this exact reason. However, coronavirus canceled most of these events for 2020, forcing a virtual replacement. In this Breaking Analysis, Dave Vellante covers the virtual event landscape and shares some takeaways from this new dynamic. Watch the full video analysis. Episode 43 – Assessing Dell’s Strategic Options with VMware – Dell is exploring options for its roughly 81 percent share in VMware. It is predicted that Dell wants to gauge investor, consumer, and partner sentiment. In this Breaking Analysis, Dave Vellante unpacks the complex angles as well as some possible scenarios of this situation. Watch the full video analysis. Episode 42 – Cyber Security Tailwinds in the Post Isolation Economy – The isolation economy has created substantial momentum for some cybersecurity companies. However, several others have tracked or not performed as well as more successful companies, despite still exhibiting strength and momentum. In this Breaking Analysis, Dave Vellante gives updates and answers questions about cybersecurity. Watch the full video analysis. Episode 41 – Competition Heats up for Cloud Analytic Databases – A new class of workloads are emerging in the cloud which are mainly focused on combining data using machine intelligence. At the center of this trend is a new class of data stores and analytic databases. In this Breaking Analysis, Dave Vellante updates his view on the subject while looking into the basics of the market, the competition, as well as spending data. Watch the full video analysis. Episode 40 – Most CIOs Expect a U Shaped COVID Recovery – It has been reported COVID-19 created a bifurcated IT spending picture, but what will the aftermath of the virus look like? In this Breaking Analysis, Dave Vellante is joined by Sagar Kadakia to look into the recovery patterns of different industries following the effects of the pandemic, and discuss the supporting data. Watch the full video analysis. Episode 39 – RPA Gains Momentum in the Post COVID Era – Legacy on-premises infrastructure are now allowing for more flexible approaches to business agility that reduce human labor, and the pandemic has accelerated this focus on such efforts. Robotic Process Automation has been a large beneficiary in this process. In this Breaking Analysis, Dave Vellante gives the rundown of RPA, including updates on the RPA sector, spending data, and the impact of COVID-19 on the market. Watch the full video analysis. Episode 38 – Cloud Momentum Building for the Post COVID Era – Cloud is in the stronghold of on-premise computing, and coronavirus has helped to strengthen this position. Analysis of company earnings reports and customer survey data shows that Microsoft Azure and GCP are closing the gap on AWS’ cloud dominance. In this Breaking Analysis, Dave Vellante takes a closer look at the big three cloud players, and provides a brief investigation of AWS individually. Watch the full video analysis. Episode 37 – IBM’s Future Rests on its Innovation Agenda – For decades, IBM has unfortunately missed opportunities to invest in the waves that now power the tech economy. The hiring of a new CEO provides the chance to redirect the company, and come back on top. In this Breaking Analysis, Dave Vellante digs into the past and the future of IBM. Watch the full video analysis. Episode 36 – COVID-19 Takeaways & Sector Drilldowns Part II – Industries such as retail, consumer, telco and IT services are seeing the largest pullbacks in spend from consumers and business since the beginning of COVID-19. On the other hand, corporations capable of digital transformation are seeing the most success. In this Breaking Analysis, Dave Vellante and Sagar Kadakia share the most updated spending data and information about the effects of the pandemic. Watch the full video analysis. Episode 35 – CIOs & CISOs Discuss COVID 19 Budget Impact – CEOs and CISOs of industries that have been hard-hit see significant and many permanent shifts to their IT and security strategies. Because of severe budget impacts, certain initiatives have been prioritized. In this Breaking Analysis, Dave Vellante is joined by Erik Bradley, managing director of ETR’S VENN program, to provide research and discuss the areas emphasized by these executives. Watch the full video analysis. Episode 34 – How Tech Execs are Responding to COVID 19 – COVID-19 demanded several and somewhat immediate changes within the tech industry. In this Breaking Analysis, Dave Vellante shares commentary and responses from various tech execs, recaps the current IT spending outlook, and dives into what’s really going on in the marketplace. Watch the full video analysis. Episode 33 – CIOs Plan on 4% Budget Declines for 2020 – At the start of 2020, the IT spend forecast was plus 4 percent. Following Coronavirus, those numbers declined significantly. In this breaking Analysis, Dave Vellante and Sagar Kadada breakdown the latest spending data from ETR. Watch the full video analysis. Episode 32 – VMware Announces vSphere 7 – VMware released the vSphere 7, which is being called the biggest change to vSphere within the last decade, enabling 90 percent of the data centers around the world that have VMware. In this Breaking Analysis, Dave Vellante is joined by Stu Miniman to discuss the vSphere 7 announcement. Watch the full video analysis. Episode 31 – Coronavirus – Pivoting From Physical to Digital Events – Coronavirus and the recent quarantine has put the world more or less on pause. For many industries, this means switching to a largely digital-based platform for events. In light of the pandemic, Dave Vellante shares advice on the best tools and practices to navigate the current crisis. Watch the full video analysis. Episode 30 – Multi-Cloud…A Symptom Or Cure? – The third wave of cloud is stirring up a lot of discussion about its necessity and effectiveness. In this breaking Analysis, Dave Vellante digs into the multicloud arena while answering some frequently asked questions about the benefits and possible implications of this new technology. Watch the full video analysis. Episode 29 – Cyber Security Update: What to Expect at RSA 2020 – Robert Gates, Former director of the CIA and Secretary of Defense, warns that the risks of Cyber security and IT should be a regular part of every board’s agenda. In this Breaking Analysis, Dave Vellante provides updates about the cyber security sector ahead of the RSA conference. Watch the full video analysis. Episode 28 – RPA: Over-Hyped or the Next Big Thing? – Robotic Process Automation, or RPA, is one of the hottest sectors in software today with a small but rapidly growing market. In this Breaking Analysis, Dave Vellante dives deeper into the world of RPA and talks about the value, size, and competitors in the market space. Watch the full video analysis. Episode 27 – Gearing up for Cloud 2020 – The new era of cloud brings significant change to the industry as well as new opportunities for the three major cloud players in the U.S. In this Breaking Analysis, Dave Vellante looks deeper into the cloud market and the momentum of Amazon, Google and Microsoft. Watch the full video analysis. Episode 26 – Storage…Continued Softness with Some Bright Spots – The storage industry is a bifurcated market: Secondary storage is gaining momentum while the primary slide falls behind. In this Breaking Analysis, Dave Vellante looks into the spending data and discusses his thoughts and predictions about storage live from Barcelona. Watch the full video analysis. Episode 25 – Cisco: Navigating Cloud, Software & Workforce Change – At the end of the dot com bubble, Cisco was the most valuable company in the world. It remains a leader in key segments, but is refocusing its business for the next decade. In this Breaking Analysis, Dave Vellante covers Cisco’s rise as well as projections for the future. Watch the full video analysis. Episode 24 – The Trillionaires Club: Powering the Tech Economy – Big tech companies have changed the recipe for innovation in the Enterprise, and as we enter the next decade, it is important to reevaluate how that will determine the level of success in the industry. In this Breaking Analysis, Dave Vellante discusses this “cocktail” of innovation and how it came into play. Watch the full video analysis. Episode 23 – Veeam’s $5B Exit: Clarity & Questions Around “Act II” – Veeam is a data protection company that has seen a slight performance drop since 2018. In this Breaking Analysis, Dave Vellante provides details about its $5 billion deal with Insight Partners and how this new chapter will affect the industry moving forward. Watch the full video analysis. Episode 22 – Predictions 2020: Cloud, Kubernetes & Cyber Continue to Power the Tech Economy – Tech projects have historically been very risky investments, but changes with cloud are allowing for more flexibility in the coming year. In this Breaking Analysis, Dave Vellante talks about Predictions for 2020 using spending data and insight from the thousands of interviews conducted on theCUBE. Watch the full video analysis. Episode 21 – Re:Invent 2019…of Transformation & NextGen Cloud – During the most recent AWS re:invent, the company proves it continues to strive on raising the bar. In this Breaking Analysis, Dave Vellante is joined by Stu Miniman to unpack the event, and talk about what’s happening from a buyer’s perspective, as well as AWS’ hybrid strategy Watch the full video analysis. Episode 20 – Unpacking Cisco’s Prospects Q4 2019 and Beyond – AWS strongly emphasizes the idea of transformation, and warns industries like Cisco not to do so incrementally. In this Breaking Analysis, Dave Vellante covers six different topics related to the future of Cisco, and its prospects in this era of next generation cloud Watch the full video analysis. Episode 19 – Examining IT Spending Data Q4 ‘19 – Enterprise Research Technology is a company who uses primary market research and first party data to look into spending patterns within the tech industry. In this Breaking Analysis, Dave Vellante explains the ins and outs of ETR, as well as its current relationship with theCUBE. Watch the full video analysis. Episode 18 – Re:Invent 2019: AWS Gears up for Cloud 2.0 – AWS Reinvent has become the Super Bowl for enterprise tech innovation. In this Breaking Analysis, Dave Vellante discusses the impact of the revolution of cloud on the industry in light of the upcoming event. Watch the full video analysis. Episode 17 – The Transformation of Dell Technologies – Dell continues to make changes to remain a predominant company in the tech industry. In this Breaking Analysis, Dave Vellante breaks down the major takeaways of the Dell Technologies’ industry analyst event and discusses some of the possible implications that the company may face. Watch the full video analysis. Episode 16 – The State of Cybersecurity Q4 2019 – The cyber security market is fragmented, challenging and many feel broken. Cloud security promises to simplify the maze for security practitioners but there are nuances with the shared responsibility model that often cause confusion. In this Breaking Analysis we look at the lates ETR data and hear from CISOs and executives in the field with an outlook and prognosis going forward. Watch the full video analysis. Episode 15 – The state of data protection, Q4 2019 – While demand for primary storage remains soft, the bright spot in the sector is data protection. Well funded new entrants are disrupting the space which is shaping up as a battleground for 2020. Watch the full video analysis. Episode 14 – AWS growth slows but remains the profit engine of Amazon – While AWS’ growth rate slowed this past quarter, its revenue is still substantially larger than its nearest competitors in the IaaS space. Moreover AWS is still the profit engine that funds Amazon’s vast and growing empire. Watch the full video analysis. Episode 13 – Q4 Spending Outlook – 10/18/19 – TheCUBE host Dave Vellante shares his analysis on recent spending trends backed by ETR Data. Spending is reverting to pre-2019 levels but the outlook still points to a strong 2020, barring any unforeseen global surprises. Watch the full video analysis. Episode 12 – Bill McDermott steps down from SAP – Commentary and Outlook. SAP pre-announced earnings with a beat and a raise, which acted as a heat shield for the surprise news that long-time CEO Bill McDermott is not renewing his contract. SAP is moving back to a dual-CEO model with a separate customer-facing and product/ops focus for each exec. SAP is strong financially but we believe faces significant technical integration challenges over the next decade, which may have played into McDermott’s and SAP’s decisions. In this Breaking Analysis, Dave Vellante shares recent spending data from ETR and lays out some of the challenges SAP faces going forward. Watch the full video analysis. Episode 11 – Spending in Q4 2019 is reverting back to pre-2018 levels – The spending outlook for the balance of 2019, into 2020 is softening, but not falling off a cliff. In this Breaking Analysis, Dave Vellante presents the latest ETR spending data and shares the latest thinking on which segments will continue to do well for the balance of 2019 into next year. Watch the full video analysis. Episode 10 – Takeaways from Dell’s 2019 financial analysts event. – Dell Technologies executives gathered in New York to update financial analysts and present the company’s mid-to-long term plans for growth, share gains, profitability and paying down its substantial debt. In this Breaking Analysis, Dave Vellante unpacks Dell’s massive business and provides clarity on the profitability levers Dell is turning to continue its transformation. Watch the full video analysis. Episode 9 – Spotlight on IBM’s Systems Business – IBM’s mainframe business continues to be the linchpin of much of the company’s profit and free cash flow. In this Breaking Analysis, Dave Vellante explains the importance of product cycles to the success of not only IBM’s Systems and Storage division, but IBM’s financial performance overall. Watch the full video analysis. Episode 8 – Nutanix and VMware battle for HCI leadership – Hyperconverged infrastructure was popularized by leader Nutanix. Many others have joined the party including VMware, Dell, HPE and others. In this Breaking Analysis, Dave Vellante is joined by Stuart Miniman, an expert in the HCI market, to unpack what’s really happening in the marketplace. Watch the full video analysis. Episode 7 – Oracle earnings analysis – September 2019 – Oracle, like many legacy enterprise software companies, is seeing a slowdown in growth for on-prem licenses. Oracle’s cloud is being re-factored in a next generation offering that comprises IaaS, PaaS and SaaS. Oracle’s applications business remains strong and is a driver of profits. In this Breaking Analysis, Dave Vellante digs into Oracle’s business and lays out his expectation for the coming quarters. Watch the full video analysis. Episode 6 – Spending data from ETR shows that robotic process automation is gaining steam in mid-to-large enterprises – A race to improve productivity is driving companies to implement automation in the form of software robots. UiPath and Automation Anywhere show strong customer spending momentum. Blue Prism and other major players, while not showing the same growth, appear to be well-positioned. In this Breaking Analysis, Dave Vellante explains how this market is beginning to re-shape automation for the future. Watch the full video analysis. Episode 5 – Spending data shows that cloud native databases are disrupting traditional analytic data stores. Snowflake and AWS RedShift stand out as having spending momentum based on ETR survey data – Some cloud native databases have been architected to enable storage and compute resources to be scaled independently. This not only improves economics but also drives increased agility and flexibility for many use cases. In this Breaking Analysis, Dave Vellante explains how this dynamic is eating into traditional enterprise data warehouse markets. Watch the full video analysis. Episode 4 – Storage Spending Outlook 2H ’19 – Pure Leads the Pack – The on-prem storage business has been hurt by: 1) the cloud siphoning away demand; and 2) a massive injection of flash storage that has given data center managers enough performance headroom to minimize the need to buy for performance reasons. Pure Storage is growing faster than the marketshare leaders but from a much smaller installed base. Watch the full video analysis. Episode 3 – VMworld 2019 – Containers won’t Kill VMware – As a preview to VMworld 2019, Dave Vellante shares his opinions along with ETR spending data that shows containers, to date, are not hurting VMware’s business. Watch the full video analysis. Episode 2 – IBM Completes Acquisition of Red Hat – Dave Vellante shares his opinions along with ETR spending data on this giant move by IBM. Positioned by IBM as all about cloud, Vellante says it’s also a professional services play. Watch the video analysis. Episode 1 – Hello World – This is a podcast only version explaining what this series is all about and its objectives for the community. THANK YOU Microsoft forms Advanced Planning Unit to support its AI efforts OpenAI makes its o3-mini reasoning model generally available Eek! It's DeepSeek! Now every AI company is looking over its shoulder at this Chinese startup Observo reduces observability costs using agentic AI-powered data pipelines with $15M raise Samsung's stock falls on fears of weakness in memory chip markets Intel's stock inches up on solid earnings and revenue beat Microsoft forms Advanced Planning Unit to support its AI efforts AI - BY MARIA DEUTSCHER . 2 DAYS AGO OpenAI makes its o3-mini reasoning model generally available AI - BY MARIA DEUTSCHER . 2 DAYS AGO Eek! It's DeepSeek! Now every AI company is looking over its shoulder at this Chinese startup AI - BY ROBERT HOF . 2 DAYS AGO Observo reduces observability costs using agentic AI-powered data pipelines with $15M raise BIG DATA - BY KYT DOTSON . 2 DAYS AGO Samsung's stock falls on fears of weakness in memory chip markets INFRA - BY MIKE WHEATLEY . 3 DAYS AGO Intel's stock inches up on solid earnings and revenue beat INFRA - BY MIKE WHEATLEY . 3 DAYS AGO
--------------------------------------------------

Title: How DeepSeek Has Blown Open AI Race Between US and China
URL: https://www.newsweek.com/2025/02/14/how-deepseek-has-blown-open-ai-race-between-us-china-2024138.html
Time Published: 2025-02-01T10:00:02Z
Description: The sudden success of the Chinese AI startup took the tech world by surprise. Newsweek explores the impact on the U.S.'s lead in the industry
--------------------------------------------------

Title: 5 key investing lessons from recent AI-market mania
URL: https://markets.businessinsider.com/news/stocks/tech-stock-crash-deepseek-lessons-ai-concentration-nvidia-bonds-crypto-2025-1
Time Published: 2025-02-01T10:00:02Z
Full Content:
A new AI model from China rattled US markets this past week. DeepSeek represented a breakthrough for the AI industry, delivering results on par with OpenAI's best model while using significantly less computing power. The implications have been substantial. Nvidia stock shed nearly $600 billion in market value in a single day as investors worried about future demand for its GPU chips, which are the main fuel source for large language models. Suppose large language models from OpenAI, Anthropic, and Meta adopt some of the techniques utilized by the open-sourced DeepSeek and become more efficient. Will they need as much computing power as initially thought? On the flip side, AI adopters, particularly software companies, surged on the prospect that the cost of AI technologies would decrease significantly, leading to higher profit margins. But there are even broader lessons investors can take from this week's black swan event, and they impact everything from bonds to stocks and even crypto. The concentration of a handful of mega-cap tech companies dominating the stock market has crept up to historic levels over the past few years. According to Goldman Sachs data, the top five stocks in the S&P 500 made up about 29% of the index as of December 31, and they're all highly exposed to similar technology trends. "Concentration in several large names is a concern when the drivers of success are the same for most of the names," Chris Fasciano, chief market strategist at Commonwealth Financial Network, told Business Insider. Concentration is a double-edged sword. It can work great in bull markets, but a simple disruption to investors' overarching narrative could lead to a painful decline, as seen on Monday, when the index tracking mega-cap tech stocks plunged 3%, compared to a slight gain for the equal-weighted S&P 500. The concentration speaks to the idea that investors may not be as diversified as they believe. "This is an underappreciated consideration," Steve Sosnick, chief strategist at Interactive Brokers, told BI. "It is common — and understandable — for investors to believe that they are adequately diversified when they buy an S&P 500-linked fund," Sosnick said, but that's not the case based on the extreme concentration levels. "Those seeking true diversification need to look beyond SPX," Sosnick said, adding that the Nasdaq is not the answer, with a handful of stocks making up about half of that index. Nvidia has dominated the AI story since ChatGPT was released in November 2022, as it turned into the key "picks and shovels" supplier to companies developing their own large language models. But Monday's price action revealed that there are second-derivative beneficiaries to the AI trade, which includes the adopters of AI technologies like software companies. If DeepSeek's claims of using less computing power are accurate, that means costs should come down considerably for AI adopters, pushing profit margins higher. Among the software winners amid Monday's bloodbath was Salesforce, which gained as much as 10% while the market swooned. "If DeepSeek has truly shown us that an open-source solution is far less resource-dependent than the ChatGPT paradigm, then the benefits of AI might be easier to reap from companies unwilling or unable to afford to partner up with one of the current firms that currently dominate the arena," Sosnick said. Crypto volatility was on full display this week, even though DeepSeek's appeared to mainly impact tech firms. Bitcoin dropped as much as 7%, in tandem with the sharp decline with the Nasdaq 100. The sell-off highlights that cryptocurrencies are highly correlated to moves in the broader tech space, and absent any crypto-specific catalysts, bitcoin is a high-octane bet on tech's continued outperformance of "Safe havens don't have an average daily volatility of 2%," Sosnick said. "Over the past 6 months, the correlation of the price levels of bitcoin and NDX is about 80%." Apple stock bucked the DeepSeek sell-off, rising about 8% in the week as investors determined that the company's decision not to spend tens of billions of dollars on building its own large language model was a good one. Instead, Apple is focused on leveraging ChatGPT's AI model and using edge computing to deliver quick answers to iPhone users. That edge computing is key, as it could become even more ubiquitous if AI models see a decline in their compute consumption thanks to the breakthroughs identified by DeepSeek. And a decline in compute consumption ultimately means a decline in costs, which could fuel even more stock buybacks and dividends for the company. "Cheap AI means a lot more capital to return to shareholders, either in the form of dividends or stock buybacks. Every US Big Tech company except Amazon already has both in place. Now they can get much, much bigger," Nicholas Colas, co-founder of DataTrek Research, said in a note this week. If DeepSeek's open-source model delivers the expected cost savings to other large language models, it could ultimately mean higher efficiency and lower costs. According to tech CEOs, like Microsoft's Satya Nadella, cheap AI models should further accelerate the adoption of AI across various industries and lead to a surge in productivity. If that happens, economic growth could continue without sparking a rebound in inflation, which would put interest rates back on a downward trend. "If DeepSeek's processes show that the AI revolution can be achieved at a lower cost and with lower energy usage, that would be good for macro conditions (such as productivity and inflation) going forward," LPL chief strategist Jeff Buchbinder wrote this week. "In theory, this would help reduce the Fed's neutral rate a touch and keep interest rates lower than they otherwise would be if big AI spending continued unabated." Lower interest rates mean higher bond prices, sparking a potential rally in an asset class that was hurt by the Fed's rate hikes in 2022 and 2023. "More egalitarian AI can and should boost productivity throughout the economy and thus have benefits for price levels and interest rates," Sosnick said, though he cautioned that such an outcome is "not going to happen immediately." Indices Commodities Currencies Stocks
--------------------------------------------------

Title: The Clock Has No Hands
URL: https://realinvestmentadvice.com/resources/blog/the-clock-has-no-hands/
Time Published: 2025-02-01T09:49:07Z
Description: Inside This Week's Bull Bear Report


<ul><!-- wp:list-item -->

<li>The Clock Has No Hands</li>




<li>How We Are Trading It</li>




<li>Research Report - Bullish Exuberance Returns Following The Inauguration</li>




<li>Youtube - Before The Bell</…
--------------------------------------------------

Title: Mixture-Of-Experts AI Reasoning Models Suddenly Taking Center Stage Due To China’s DeepSeek Shock-And-Awe
URL: https://www.forbes.com/sites/lanceeliot/2025/02/01/mixture-of-experts-ai-reasoning-models-suddenly-taking-center-stage-due-to-chinas-deepseek-shock-and-awe/
Time Published: 2025-02-01T08:15:00Z
Full Content:
Mixture-of-experts LLM structure becomes super-hot as a result of the DeepSeek AI release. In today’s column, I examine the sudden and dramatic surge of interest in a form of AI reasoning model known as a mixture-of-experts (MoE). This useful generative AI and large language model (LLM) approach has been around for quite a while and its formulation is relatively well-known. I will lay out for you the particulars so that you’ll have a solid notion of what mixture-of-experts is all about. The reason MoE suddenly garnered its moment in the spotlight is due to the release of DeepSeek’s model R1 which uses MoE extensively. In case you haven’t been plugged into the latest AI revelations, DeepSeek is a China-based AI company that has made available a ChatGPT-like LLM. They also made a bold claim that the AI was devised at a significantly reduced cost, causing quite a pronounced stir since the bulk of USA AI efforts assume that only vast and costly amounts of hardware could produce such a capable model. Hardware provider Nvidia took a big hit in their stock price and most of the major USA AI firms also saw their stocks get punished. If you are interested in whether we need to keep scaling up or whether maybe we need to work smarter when it comes to advancing AI, see my in-depth analysis at the link here. I will focus my discussion here on the overall nature of the mixture-of-experts approach, including how it has both key advantages and disadvantages. That being said, please know that the DeepSeek AI system is said to have also leaned heavily into the use of knowledge distillation, which I’ve covered extensively at the link here. The idea is that you can rapidly bring a new AI system up to speed by using an existing fully capable one to transfer or train the newbie lesser model. Some assert that if DeepSeek took that route, in a sense they were “cheating” in that they relied on someone else’s existing model to parlay their instance into existence (see my discussion about the ethical and legal intellectual property or IP rights issues that arise, at the link here). Another factor of their AI approach is that they extensively utilized reinforcement learning (RL) techniques, which I’ve covered at the link here. The star of this show is mixture-of-experts or MoE. Let’s talk about it. This analysis of an innovative AI breakthrough is part of my ongoing Forbes column coverage on the latest in AI including identifying and explaining various impactful AI complexities (see the link here). The mixture-of-experts approach traces its roots back to the early 1990s and I will toward the end of this discussion share with you some fascinating quotes from a now-classic AI research paper that got the ball rolling on this innovation in 1991. By and large, the core facets are still true today. The core is what I’m going to introduce to you. To get things underway, I am going to provide a simplified version of MoE. I say this to try and avoid getting harangued by trolls who will be distraught that I won’t be portraying the mathematical and computational complexities. Those nitty-gritty details are certainly valuable, and indeed, I will provide references throughout where you can readily learn more on the matter. Here’s the deal. The most common way to devise generative AI consists of designing the internal structure or architecture as one large monolith. Any prompt that a user enters will essentially be routed throughout this massive byzantine structure and have zillions of touchpoints as it progresses and is processed. This is easy to devise, somewhat easier to maintain, and generally works pretty well. An alternative approach is to decide that we will divide up the monolith into respective parts or components. Each component will have a specific purpose. The AI parlance is to say that these components are “experts” and that we are dividing up the processing into occurring across a multitude of these experts. I personally disfavor the use of the word “expert” to refer to the components since this tends to anthropomorphize the AI, as though it is a set of human experts. Each component is merely devoted to some area of interest, and I would say are specialized in what they can suitably process. Anyway, the word “expert” is catchy and has become the default terminology in use. The bottom line is that the mixture-of-experts approach consists of deciding beforehand that when you create a generative AI or LLM you will divide it up into some number of components that we’ll say are experts. Doing so has some exciting properties that can boost the AI in comparison to the run-of-the-mill monolithic route. Handiness Of A Bundle Of Experts The good news about mixture-of-experts is that you can hone the AI to be adept in specific areas or domains. For example, suppose I wanted to ask generative AI some questions about various U.S. presidents, in particular, let’s say Abraham Lincoln. A monolithic AI structure would take my prompt and feed my question about Honest Abe to the entire landscape of the AI system being utilized. Here and there, various bits and pieces about Lincoln might be touched upon. Eventually, it is hopefully brought together by the AI and presented to me as a cohesive answer to my question about Lincoln. In the case of MoE, we might have set up the LLM on the basis of “experts” that are components devoted to specific presidents. There is a component about Lincoln. A different component concentrates on George Washington. And so on. My prompt asking about Abraham Lincoln would get routed to the Honest Abe component. This component derives a response to my prompt. The response is then presented to me. Voila, easy-peasy. Note that a crucial element of the MoE is that the prompt by the user must be carefully parsed by the AI to suitably identify which expert ought to be activated. Suppose that I asked about Abraham Lincoln, but the AI sent my prompt to the component on George Washington. Sad face. Not where my prompt should have gone. Now then, in theory, the George Washington component would detect that the prompt is about Lincoln and then pass the request either back to the routing function or directly to the Lincoln component. You might say that the gateway or gating of the mixture-of-experts is a make-or-break activity. When a prompt comes in, the gateway had better do a decent job of figuring out which expert should get the request. If the wrong expert is selected, this could be a waste of time and effort. Worse, the wrong expert might try to generate an answer. Imagine my surprise if the AI responded with details about George Washington rather than Honest Abe. The gating has to be reliable; it has to be quick since otherwise time is unduly consumed, and it is also a kind of bottleneck. The positive aspect is that your prompt is likely to end up at the right place in the fastest time in comparison to the meandering monolith approach. The negative aspect is that your prompt might get misrouted and ultimately even produce a wrong or inappropriate response. Just another tradeoff in the harsh world we live in. Seems like you can never truly eat your cake and have the icing too. To showcase how this works, let’s assume that you are using generative AI to help diagnose what is wrong with your car. Your car has been making some oddball noises lately. There doesn’t seem to be any obvious basis for the noise. You log into a generative AI app that is made via a monolith-oriented architecture. The AI has various automotive mechanic capabilities spread around in the overall structure but there aren’t specific components devoted to say the engine, the transmission, etc. Here we go. As you can see, the AI is spreading your request across the landscape of the AI and merely generically seeking car mechanic portions. You decide to log out of the AI and instead log into a mixture-of-experts or MoE-based model. Here’s what happens. You can now see that the AI first used a gateway function that was labeled as a car diagnostician. This overall component decided that the specialized component or “expert” on engines would be the best place to route the request to. Sure enough, the engine expert said that the problem is with the engine. Let’s use the same example and this time the engine expert says that the engine isn’t the culprit making the oddball noise. You can see that the engine expert reported back to the gateway. The gateway then opted to make another guess and routed the request to the transmission expert. Luckily, this was the right final place to land in. Depending upon how the MoE is shaped, sometimes you won’t realize that the various so-called experts within the AI are being consulted. There isn’t necessarily a need for you to know what took place during the processing of your prompt. All you probably care about is that you get a solid answer to your prompt. Thus, another purpose of the gateway is often that it routes internally, collects what is being generated by the internal structure, and aggregates it into the final response that you ultimately see. Everything else is hidden from your view. Here’s what that might be like. In this instance, the gateway carried on an internal conversation with the various AI experts. Once a resolution was devised, the gateway aggregated the results and was ready to present the recommendation to the user. For an AI maker or developer, a big challenge when leaning into a mixture-of-experts approach is what the various experts or components will be focused on. You usually must decide this upfront. Once you’ve made that decision, the structure is somewhat locked into place. Suppose I opted to go with components focused on USA presidents. A user comes along and wants to ask about USA governors. Oops, my LLM wasn’t structured on that basis. At that juncture, it could be that I have set up only some experts and allowed a semi-monolith for the rest of the structure, and I will then route the prompt to that monolith portion. You could argue that this is not too bad since that’s what would have happened in a pure monolith structure, on the other hand, the experts aren’t being of much advantage if that happens quite a lot. Another notable design question is how many experts to have. Should I have experts per president, and then experts per vice president, or maybe just have experts that each cover a pair of a president and their associated vice president? This is a tough aspect to decide at the get-go. Generative AI is data trained by scanning the Internet and pattern-matching on human writing. The good news about MoE is that you can direct the scans toward the areas that pertain to the experts or components that you’ve decided upon. This can expedite data training. A downside is that you need to figure out whether the components or experts are getting sufficient data training. When you do things for a monolith, you at times just let the data training go as long as you can afford to do so or run out of data for training purposes. The MoE is usually best undertaken by assessing how deep and sufficient the components are during the initial data training. The upshot is that data training requires a different semblance of perspective depending upon whether you are data training an underlying monolith LLM or a MoE model. Lots more twists and turns come into the picture. Some advocate that MoE should have shared experts along with dedicated experts. This involves deciding that there will be specialized components that any of the other experts can use versus ones that are only to be used by say the gateway. The beauty of having multiple experts or components is that you can potentially leverage parallelization during the processing of a prompt. Envision that I wrote a prompt asking about both Abraham Lincoln and George Washington. In a conventional monolith, this is clunkily floated around to figure out which bits and bytes have something relevant to generate. With MoE, the gateway could split the prompt into two pieces, routing one piece to the Lincoln expert and the other piece to the George Washington expert, having both components working simultaneously on my prompt. Nice. Speed can be a great outcome of using MoE. A troubling aspect though can at times arise. The gateway might start to overuse some of the experts. Those particular experts become excessively relied upon. The AI gets sluggish. An important ongoing chore might be to monitor the spread of the usage and have some form of balancing algorithm to try and get things evened out if feasible. If you are intrigued by the MoE approach, you might enjoy the now-classic AI research paper that many attribute to having gotten this line of architecture underway (please know that prior papers also postulated and examined the topic). The paper is entitled “Adaptive Mixtures of Local Experts” by Robert A. Jacobs, Michael I. Jordan, Steven J. Nowlan, and Geoffrey E. Hinton, Neural Computation, 1991, and made these salient points (excerpts): The emphasis is that generative AI and LLMs typically make use of artificial neural networks (ANN) as the underpinning of the AI, see my explanation about such neural networks at the link here. You can create a humongous artificial neural network as one massive monolith or divide it into subnetworks. Those subnetworks are the components or experts of the MoE structure. As mentioned earlier, doing so can make processing faster, which in AI parlance you say that the “inferencing” is sped up. Furthermore, again in AI parlance, the usual feed-forward network (FFN) layers are essentially replaced with MoE layers. Each MoE layer usually makes use of one or more experts and has at least one gating function. DeepSeek’s AI makes use of mixture-of-experts, as do several other high-profile LLMs such as Mixtral by Mistral, NLLB MoE by Meta, and others. No one can say for sure whether MoE is the best or optimum way to devise generative AI. I’ve noted that it has upsides and downsides. It isn’t a silver bullet. The shock and awe of DeekSeek’s AI will certainly cause a rapid and wider pursuit of mixture-of-experts. Some will rush to include it. Others will be dubious and argue that the downsides outweigh the pluses. All in all, we are in for exciting times. Let’s give the last word for now to Aristotle: “Excellence is never an accident. It is always the result of high intention, sincere effort, and intelligent execution; it represents the wise choice of many alternatives -- choice, not chance, determines your destiny.” We will have to wait and see whether MoE is a choice, a chance, or a destiny. One Community. Many Voices. Create a free account to share your thoughts. Our community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space. In order to do so, please follow the posting rules in our site's Terms of Service. We've summarized some of those key rules below. Simply put, keep it civil. Your post will be rejected if we notice that it seems to contain: User accounts will be blocked if we notice or believe that users are engaged in: So, how can you be a power user? Thanks for reading our community guidelines. Please read the full list of posting rules found in our site's Terms of Service.
--------------------------------------------------

Title: ICYMI: the week's 7 biggest tech stories from DeepSeek rocking the AI world to Garmin's major outage
URL: https://www.techradar.com/tech/icymi-the-weeks-7-biggest-tech-stories-from-deepseek-rocking-the-ai-world-to-garmins-major-outage
Time Published: 2025-02-01T08:00:00Z
Full Content:
Here's your firmware update for February 1, 2025 When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. This week was wild. DeepSeek came and changed the AI landscape, but it seems like the full impact of its arrival is still yet to be fully understood. Meanwhile, Garmin accidentally bricked many of its devices globally thanks to an errant update, and Android XR broke cover in our first hands-on look at the software. Al that and more of the other big tech news stories you might have missed from the week are recapped below, so you can catch up with everything then get on with your day. Plus, if you're after a way to spend your downtime this weekend, then don't forget to check out our picks for the 7 new movies and TV shows to stream this weekend. It’s been a rollercoaster week for the AI industry, with the DeepSeek app rocketing to the top of the Apple App Store and beating ChatGPT. DeepSeek is a Chinese startup who claim to have developed their deep reasoning model, R1, for a fraction of the price that US AI companies have invested in their technologies. It also offers people access to it for free in its chatbot and at a much reduced price as an API compared to OpenAI. The news that a Chinese company can produce an equivalent technology for a fraction of the price caused a complete crash of the share value of US tech companies that are heavily invested in AI. Nvidia came off particularly badly, with $600 billion being wiped off their stock value in just one day. Share prices have since recovered, but it doesn’t feel like the AI market will ever be the same again. Questions are already being asked about how DeepSeek managed to produce its AI model so quickly, especially after OpenAI claimed it had evidence of distillation of some of its models. Distillation is a development technique where you piggyback off another model’s learning, but is against the OpenAI terms and conditions of use. To make matters worse for DeepSeek, it appears that when questioned about which AI model is best, DeepSeek will sometimes refer to itself as ChatGPT, which some users consider a smoking gun. OpenAI released a statement on the matter, saying: “We know that groups in the PRC are actively working to use methods, including what’s known as distillation, to try to replicate advanced U.S. AI models. Sign up for breaking news, reviews, opinion, top tech deals, and more. "We are aware of and reviewing indications that DeepSeek may have inappropriately distilled our models, and will share information as we know more. We take aggressive, proactive countermeasures to protect our technology and will continue working closely with the U.S. government to protect the most capable models being built here.” This one may rumble on for a while yet. A tough few months of software quirks boiled over into a massive Garmin outage this week that saw users in their thousands completely lose access to their devices. A rogue GPS file accidentally pushed to Garmin wearables saw watches and trackers plunged into a boot loop dubbed the 'Blue Triangle of Death.' Few customers found they could escape, and even those who did encountered further issues with connectivity and synchronisation. The outage lasted well over 24 hours and we heard from hundreds of customers – owners of devices such as the Forerunner and Epix ranges, as well as more niche devices including Garmin's dive computers, cycling computers, and Approach Golf Range. Garmin has since fixed the underlying issue, but there are reports that some customers remain stuck in boot loops and without a device. Plenty have even told us they regret their Garmin purchases or plan to depart for companies like Apple. It's a PR disaster that has overshadowed the launch of the Instinct 3, and Garmin has some recovery work to do if it wants to avoid a Sonos-style scenario. Nvidia’s new graphics cards are here and… and they’re already gone, with stock sold out across the internet in lightning-fast time. Some of these highly sought-after GPUs will have been bought by legitimate gamers looking to upgrade their rig – and they’re in for a treat, with our RTX 5090 review highlighting that it’s a seriously powerful upgrade that approaches complete overkill performance. Our RTX 5080 review, meanwhile, reports that it boasts some solid gains at a more modest (but still not inexpensive) price. Unfortunately some Nvidia cards also seem to have been picked up by scalpers taking advantage of the limited availability to flip them for a profit on resale sites by listing the GPUs for several times their MSRP. Resale sites have also been flooded with listings that seem to be selling the new GPUs for prices closer to what they should cost – but when you take a closer look, you’ll see they’re promising to send you a picture of the graphics card you desire, rather than the real thing. So, our advice is to wait for another official drop so you don’t get tricked by a scammer or pay three or four times more for the GPU you’re after – and you can follow our live Nvidia RTX 5090 stock updates and Nvidia RTX 5080 stock updates trackers for info on when and where these drops will happen. Nothing shared a short video of its CEO Carl Pei this week. Normally that wouldn’t be super newsworthy, but as the camera zooms in on his glasses we see the words “Launch 4 March” reflected in the lens. A previous Nothing Phone 3 teaser suggested this would be the announcement date for its next smartphone, but now it’s all-but certain. What’s more interesting is a cut in the middle of the clip that seems to shift from a shot from a wide lens, to one from a telephoto lens – the latter of which is absent from previous Nothing phones. We’re taking this as a hint that the Nothing Phone 3 could have a triple-lens camera – with a telephoto camera joining the wide and ultra-wide lens setup found on the Nothing Phone 2. Thanks to a hands-on video from Marques Brownlee on his YouTube channel, MKBHD, we got our first look at Android XR and the Project Moohan prototype this week. While many details including price, release, and some specs are still a mystery, we did get to see aspects of the headset’s design and software. It looks a lot like a combination of the Meta Quest Pro and Apple Vision Pro. There’s no over-the-head strap but instead a Meta Quest Pro-like adjustable strap round the back, and the Android XR headset borrows the Quest’s optional light blockers to change between a VR-optimized and MR-optimized design. It also uses an external battery pack like the Vision Pro to help save weight. As for software, Brownlee’s video predominantly focused on Gemini’s integration – which looks impressive. Though many of the AI features look like they’d be much better suited to a pair of AR glasses, so while we expect Moohan will be impressive, we’re already waiting to see what XR hardware Samsung and Google will launch next. Our favorite wall-crawling superhero is finally back! The latest adaptation of Peter Parker to enter the fray is in Marvel’s new animated series Your Friendly Neighborhood Spider-Man. The show has a unique release schedule, though, as each week two episodes will be released instead of one – the first two of which debuted on Disney Plus this Wednesday (January 29). TechRadar’s senior entertainment reporter Tom Power has already seen all 10 episodes and says the show’s “a spectacularly fun ride” in his Your Friendly Neighborhood Spider-Man review. Which is great news for Spidey fans, because two more seasons have been greenlit and the show’s creator already has “big ideas” for where it could go next. Hamish is a Senior Staff Writer for TechRadar and you’ll see his name appearing on articles across nearly every topic on the site from smart home deals to speaker reviews to graphics card news and everything in between. He uses his broad range of knowledge to help explain the latest gadgets and if they’re a must-buy or a fad fueled by hype. Though his specialty is writing about everything going on in the world of virtual reality and augmented reality. Please logout and then login again, you will then be prompted to enter your display name. Techradar is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036.
--------------------------------------------------

Title: Celestica Inc. (CLS): Leveraging AI Demand with Specialized Chips
URL: https://finance.yahoo.com/news/celestica-inc-cls-leveraging-ai-021719254.html
Time Published: 2025-02-01T02:17:19Z
Full Content:
We are experiencing some temporary issues. The market data on this page is currently delayed. Please bear with us as we address this and restore your personalized lists. We recently published a list of 12 Must-See AI News and Ratings You Might Have Missed. In this article, we are going to take a look at where Celestica Inc. (NYSE:CLS) stands against other must-see AI news and ratings you might have missed. Northland Securities recently issued a rating for a stock amidst the DeepSeek AI frenzy. The firm noted that it isn’t concerned about the AI models just yet and that it doesn’t expect big tech giants to cut their capital expenditures when they report their earnings either. In light of this, the CEOs of tech giants such as Meta and Microsoft have recently defended their massive spending, noting how it was crucial to stay competitive in the new field. Investors panicked after news spread over the weekend about a Chinese startup DeepSeek having released AI models that were built using less power and chips. In response, executives of tech giants are saying that building huge computer networks has been crucial to serving growing corporate needs. Even then, investors have been losing their patience with the huge amounts of spending and a dearth of hefty payouts. READ NOW: These 29 AI Electricity and Infrastructure Stocks Are Crashing Due to DeepSeek News and 10 AI Stocks to Watch Amid the DeepSeek Buzz DeepSeek has been causing a stir in the AI world and refuted the gap that previously existed between the AI capabilities in China and the US. After the first Chinese version of ChatGPT was released, there was a lot of disappointment in China considering it was not on par with ChatGPT. However, DeepSeek’s AI models have shifted the AI narrative completely. Not only has it sparked a frenzy in the US, but even its domestic competition has been pressurized. This was made evident when Alibaba released a rival to DeepSeek’s model on the Lunar New Year. According to the company, the “Qwen 2.5-Max outperforms … almost across the board GPT-4o, DeepSeek-V3 and Llama-3.1-405B”. Even though DeepSeek’s AI models have been impressive, there is still skepticism and confusion regarding the demand for high-end AI chips and the need for power to run AI-centric data centers. “There’s plenty of uncertainty over what the true demand for state-of-the-art chips, semiconductor fabrication plants and energy will be”. For this article, we selected AI stocks by going through news articles, stock analysis, and press releases. These stocks are also popular among hedge funds. Why are we interested in the stocks that hedge funds pile into? The reason is simple: our research has shown that we can outperform the market by imitating the top stock picks of the best hedge funds. Our quarterly newsletter’s strategy selects 14 small-cap and large-cap stocks every quarter and has returned 275% since May 2014, beating its benchmark by 150 percentage points (see more details here). A close-up of a circuit board with components depicting the intricate electronic componentry products the company produces. Number of Hedge Fund Holders: 40 Celestica Inc. (NYSE:CLS) offers a range of product manufacturing and related supply chain services. On January 30, Barclays raised the firm’s price target on the stock to $139 from $91 and kept an “Overweight” rating. The rating has been issued following quarterly results. According to the firm, investors are valuing Celestica based on 2026 projected earnings, driven by the demand for specialized chips called ASICs which remain a medium-term trend. In particular, 2026 captures the run rate revenue of the TPUv6, Google’s latest generation AI accelerator. The firm further noted that Meta Platforms aims to launch a new ASIC program that could compete with the TPU program in terms of expertise and capability. Overall, CLS ranks 6th on our list of must-see AI news and ratings you might have missed. While we acknowledge the potential of CLS as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and doing so within a shorter timeframe. If you are looking for an AI stock that is more promising than CLS but that trades at less than 5 times its earnings, check out our report about the cheapest AI stock. READ NEXT: 20 Best AI Stocks To Buy Now and Complete List of 59 AI Companies Under $2 Billion in Market Cap Disclosure: None. This article is originally published at Insider Monkey. Sign in to access your portfolio
--------------------------------------------------

Title: DeepSeek's threat to Nvidia's earnings may not be so serious, Jim Cramer says
URL: https://www.cnbc.com/2025/01/31/deepseeks-threat-to-nvidia-may-not-be-so-serious-jim-cramer-says.html
Time Published: 2025-02-01T00:36:21Z
Full Content:
Credit Cards Loans Banking Mortgages Insurance Credit Monitoring Personal Finance Small Business Taxes Help for Low Credit Scores Investing SELECT All Credit Cards Find the Credit Card for You Best Credit Cards Best Rewards Credit Cards Best Travel Credit Cards Best 0% APR Credit Cards Best Balance Transfer Credit Cards Best Cash Back Credit Cards Best Credit Card Welcome Bonuses Best Credit Cards to Build Credit SELECT All Loans Find the Best Personal Loan for You Best Personal Loans Best Debt Consolidation Loans Best Loans to Refinance Credit Card Debt Best Loans with Fast Funding Best Small Personal Loans Best Large Personal Loans Best Personal Loans to Apply Online Best Student Loan Refinance SELECT All Banking Find the Savings Account for You Best High Yield Savings Accounts Best Big Bank Savings Accounts Best Big Bank Checking Accounts Best No Fee Checking Accounts No Overdraft Fee Checking Accounts Best Checking Account Bonuses Best Money Market Accounts Best CDs Best Credit Unions SELECT All Mortgages Best Mortgages Best Mortgages for Small Down Payment Best Mortgages for No Down Payment Best Mortgages with No Origination Fee Best Mortgages for Average Credit Score Adjustable Rate Mortgages Affording a Mortgage SELECT All Insurance Best Life Insurance Best Homeowners Insurance Best Renters Insurance Best Car Insurance Travel Insurance SELECT All Credit Monitoring Best Credit Monitoring Services Best Identity Theft Protection How to Boost Your Credit Score Credit Repair Services SELECT All Personal Finance Best Budgeting Apps Best Expense Tracker Apps Best Money Transfer Apps Best Resale Apps and Sites Buy Now Pay Later (BNPL) Apps Best Debt Relief SELECT All Small Business Best Small Business Savings Accounts Best Small Business Checking Accounts Best Credit Cards for Small Business Best Small Business Loans Best Tax Software for Small Business SELECT All Taxes Filing For Free Best Tax Software Best Tax Software for Small Businesses Tax Refunds Tax Brackets Tax Tips Tax By State Tax Payment Plans SELECT All Help for Low Credit Scores Best Credit Cards for Bad Credit Best Personal Loans for Bad Credit Best Debt Consolidation Loans for Bad Credit Personal Loans if You Don't Have Credit Best Credit Cards for Building Credit Personal Loans for 580 Credit Score or Lower Personal Loans for 670 Credit Score or Lower Best Mortgages for Bad Credit Best Hardship Loans How to Boost Your Credit Score SELECT All Investing Best IRA Accounts Best Roth IRA Accounts Best Investing Apps Best Free Stock Trading Platforms Best Robo-Advisors Index Funds Mutual Funds ETFs Bonds Monday - Friday, 6:00 - 7:00 PM ET CNBC's Jim Cramer on Friday told investors DeepSeek might not pose as serious a threat to Nvidia's sales as many investors feared this week, saying the Chinese artificial intelligence startup may not have told Wall Street the full story about its large language model. "Is DeepSeek an alternate universe that bodes terribly for Nvidia's pricing down the road? Hey, anything's possible," he said. "But if you had to design the most punitive way to bring down the price of this great stock, you'd invent something like DeepSeek." Earlier this week, investors were stunned to find out DeepSeek developed an AI model that it said cost $6 million to make — significantly less than what its peers spend on such programs. The company also claimed that the model could outperform that of industry favorite OpenAI. Wall Street concluded Big Tech may not need to spend as much money on highly-advanced chips from Nvidia, which until now seemed like the only option for companies looking to dominate in the AI world. Worries of lower earnings sent Nvidia shares plummeting, with the stock losing nearly $600 billion in one session, the largest single-day drop in market history. Cramer conceded that investors' response is logical if DeepSeek's model actually cost so little to make, forcing Nvidia to bring down prices. But he said there's a possibility that DeepSeek spent more on its program than investors believe, referencing a new report from SemiAnalysis, a semiconductor research and consulting firm. SemiAnalysis suggested the way DeepSeek framed the development of the new model is misleading, saying the company could have actually spent more than $500 million. Cramer was also skeptical that executives at tech giants like Meta, Tesla and Oracle would have invested so much money in Nvidia without performing proper due diligence. DeepSeek wasn't a secret, he continued, it just received a lot of attention this week. "I think the SemiAnalysis piece is spot on," he said. "It may just be one more long knife aimed at Nvidia, and nothing more." Nvidia declined to comment. DeepSeek did not immediately respond to request for comment. Click here to download Jim Cramer's Guide to Investing at no cost to help you build long-term wealth and invest smarter. Sign up now for the CNBC Investing Club to follow Jim Cramer's every move in the market. Disclaimer The CNBC Investing Club Charitable Trust holds shares of Nvidia and Meta. Questions for Cramer? Call Cramer: 1-800-743-CNBC Want to take a deep dive into Cramer's world? Hit him up! Mad Money Twitter - Jim Cramer Twitter - Facebook - Instagram Questions, comments, suggestions for the "Mad Money" website? madcap@cnbc.com Got a confidential news tip? We want to hear from you. Sign up for free newsletters and get more CNBC delivered to your inbox Get this delivered to your inbox, and more info about our products and services. © 2025 CNBC LLC. All Rights Reserved. A Division of NBCUniversal Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis. Data also provided by
--------------------------------------------------

Title: Beyond benchmarks: How DeepSeek-R1 and o1 perform on real-world tasks
URL: https://venturebeat.com/ai/beyond-benchmarks-how-deepseek-r1-and-o1-perform-on-real-world-tasks/
Time Published: 2025-01-31T19:53:58Z
Description: o1 is slightly better at reasoning, but DeepSeek-R1 provides much more details about its reasoning, which is very useful to the user.
--------------------------------------------------

Title: Meta Stock In Play: This Butterfly Options Trade Could Pocket As Much As $1,817
URL: https://www.investors.com/research/options/meta-stock-today-butterfly-options-trade-could-pocket-as-much-as-1817/
Time Published: 2025-01-31T19:15:25Z
Description: Meta Platforms enjoyed strong gains for the week on earnings news. Let's look at a call butterfly spread in Meta stock expiring in March.
--------------------------------------------------

Title: Securities Litigation Risk for U.S. Public Companies Increased by $1 Trillion as of 4Q'24
URL: https://www.prnewswire.co.uk/news-releases/securities-litigation-risk-for-us-public-companies-increased-by-1-trillion-as-of-4q24-302365544.html
Time Published: 2025-01-31T18:47:00Z
Full Content:
Searching for your content... Phone +44 (0)20 7454 5110 from 8 AM - 5:30 PM GMT Contact Us +44 (0)20 7454 5110 from 8 AM - 5:30 PM GMT 31 Jan, 2025, 18:47 GMT Share this article BETHESDA, Md., Jan. 31, 2025 /PRNewswire/ -- SAR, a data analytics company specialized in the securities litigation risk of U.S. public companies, today published the U.S. Securities Litigation Risk Report – January 2025. As of Dec. 2024, corporate disclosures based on public statements and filings made with the Securities and Exchange Commission ("SEC") that had a material impact on stock price of companies listed in the NYSE or NASDAQ, increased in both frequency and severity by 6.0% and 7.0%, respectively, relative to the two-year period ending in Sept. 2024. According to the report, SAR identified 10,536 high-risk adverse corporate events, from a population of 4,605 U.S. public companies, as of the two-year period ending Dec. 31, 2024, by uniformly applying a single-firm event study analyses to test stock price reaction on corporate disclosures disseminated via public statements and filings with the SEC. The market capitalization losses related to high-risk adverse corporate events, amount to approximately $10 trillion, an increase of $1.1 trillion relative to the two-year period ending Sept. 2024. The Information Technology sector topped the charts with $2.8 trillion, followed by Consumer Discretionary and Health Care, with $1.6 and $1.4 trillion, respectively. "The frequency and severity of adverse corporate events are the dominant drivers that foment securities litigation risks for directors and officers of U.S. public companies. As of the fourth quarter, issuers now face an increase of about $1 trillion in market capitalization losses linked to high-risk adverse corporate events that materially impacted stock price during the preceding two years. The securities plaintiffs' bar will take advantage of increasing complexity around risk factor disclosures after the Supreme Court punted on the high-severity securities class action against Meta last quarter. As a result, the securities litigation risks for issuers will be greater in 2025," said Nessim Mezrahi, Co-Founder and CEO of SAR. Key Takeaways: The securities litigation risk footprint of the Information Technology sector exhibited the greatest change during the last quarter of 2024, followed by Communication Services and Financials. SAR quantifies the securities litigation risk footprint based on the economic impact of adverse corporate events, together with the change in market capitalization of constituent companies within each of the eleven industry sectors, based on the Global Industry Classification Standard (GICS). As of Dec. 2024, the sector with the highest market capitalization losses as percentage of the sector-specific market capitalization is Consumer Discretionary at 19.18%, followed by Health Care and Industrials, with 19.15% and 17.63%, respectively. Information Technology companies faced the greatest market capitalization losses per high-risk adverse corporate event, amounting to $1.73 billion, followed by Communication Services and Consumer Discretionary with $1.59 and $1.2 billion, respectively. The sector with the highest median SAR Risk Score is Health Care with a median score of 29.11%, followed by Information Technology and Consumer Discretionary with 25.44% and 24.21%, respectively. This independent, semi-annual U.S. equity research report presents an appendix with the median SAR Risk Scores across all GICS groups, industries, and sub-industries. The SAR Platform provides users with the near real-time securities litigation risk footprint, with full transparency at the corporate disclosure level, for public companies that trade in the NYSE and NASDAQ. Media contact: info@sarlit.com Logo - https://mma.prnewswire.com/media/944961/5145147/SAR_Logo.jpg SAR, a data analytics company specialized in the securities litigation risk of U.S. public companies, today published the Securities Class Action... SAR, a data analytics company specialized in the securities litigation risk of public companies, announces the appointment of Anthony Kabanek to... Banking & Financial Services Computer & Electronics Insurance Do not sell or share my personal information:
--------------------------------------------------

Title: DeepSeek crashes the AI Party: Story Break, Change or Shift?
URL: https://www.blogger.com/comment/fullpage/post/8152901575140311047/3992879417461978
Time Published: 2025-01-31T17:50:00Z
Description: None
--------------------------------------------------

Title: DeepSeek: what you need to know about the Chinese firm disrupting the AI landscape
URL: https://theconversation.com/deepseek-what-you-need-to-know-about-the-chinese-firm-disrupting-the-ai-landscape-248621
Time Published: 2025-01-31T17:34:05Z
Full Content:
Assistant Professor of Economics, University of Leeds University Fellow in AI and Human Decision Making, University of Salford Richard Whittle receives funding from the ESRC, Research England and was the recipient of a CAPE Fellowship. Stuart Mills does not work for, consult, own shares in or receive funding from any company or organization that would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment. University of Salford and University of Leeds provide funding as founding partners of The Conversation UK. View all partners Before January 27 2025, it’s fair to say that Chinese tech company DeepSeek was flying under the radar. And then it came dramatically into view. Suddenly, everyone was talking about it – not least the shareholders and executives at US tech firms like Nvidia, Microsoft and Google, which all saw their company values tumble thanks to the success of this AI startup research lab. Founded by a successful Chinese hedge fund manager, the lab has taken a different approach to artificial intelligence. One of the major differences is cost. The development costs for Open AI’s ChatGPT-4 were said to be in excess of US$100 million (£81 million). DeepSeek’s R1 model – which is used to generate content, solve logic problems and create computer code – was reportedly made using much fewer, less powerful computer chips than the likes of GPT-4, resulting in costs claimed (but unverified) to be as low as US$6 million. This has both financial and geopolitical effects. China is subject to US sanctions on importing the most advanced computer chips. But the fact that a Chinese startup has been able to build such an advanced model raises questions about the effectiveness of these sanctions, and whether Chinese innovators can work around them. The timing of DeepSeek’s new release on January 20, as Donald Trump was being sworn in as president, signalled a challenge to US dominance in AI. Trump responded by describing the moment as a “wake-up call”. From a financial point of view, the most noticeable effect may be on consumers. Unlike rivals such as OpenAI, which recently began charging US$200 per month for access to their premium models, DeepSeek’s comparable tools are currently free. They are also “open source”, allowing anyone to poke around in the code and reconfigure things as they wish. Low costs of development and efficient use of hardware seem to have afforded DeepSeek this cost advantage, and have already forced some Chinese rivals to lower their prices. Consumers should anticipate lower costs from other AI services too. Longer term – which, in the AI industry, can still be remarkably soon – the success of DeepSeek could have a big impact on AI investment. This is because so far, almost all of the big AI companies – OpenAI, Meta, Google – have been struggling to commercialise their models and be profitable. Until now, this was not necessarily a problem. Companies like Twitter and Uber went years without making profits, prioritising a commanding market share (lots of users) instead. And companies like OpenAI have been doing the same. In exchange for continuous investment from hedge funds and other organisations, they promise to build even more powerful models. These models, the business pitch probably goes, will massively boost productivity and then profitability for businesses, which will end up happy to pay for AI products. In the mean time, all the tech companies need to do is collect more data, buy more powerful chips (and more of them), and develop their models for longer. But this costs a lot of money. Nvidia’s Blackwell chip – the world’s most powerful AI chip to date – costs around US$40,000 per unit, and AI companies often need tens of thousands of them. But up to now, AI companies haven’t really struggled to attract the necessary investment, even if the sums are huge. DeepSeek might change all this. By demonstrating that innovations with existing (and perhaps less advanced) hardware can achieve similar performance, it has given a warning that throwing money at AI is not guaranteed to pay off. For example, prior to January 20, it may have been assumed that the most advanced AI models require massive data centres and other infrastructure. This meant the likes of Google, Microsoft and OpenAI would face limited competition because of the high barriers (the vast expense) to enter this industry. But if those barriers to entry are much lower than everyone thinks – as DeepSeek’s success suggests – then many massive AI investments suddenly look a lot riskier. Hence the abrupt effect on big tech share prices. Shares in chipmaker Nvidia fell by around 17% and ASML, which creates the machines needed to manufacture advanced chips, also saw its share price fall. (While there has been a slight bounceback in Nvidia’s stock price, it appears to have settled below its previous highs, reflecting a new market reality.) Nvidia and ASML are “pick-and-shovel” companies that make the tools necessary to create a product, rather than the product itself. (The term comes from the idea that in a goldrush, the only person guaranteed to make money is the one selling the picks and shovels.) The “shovels” they sell are chips and chip-making equipment. The fall in their share prices came from the sense that if DeepSeek’s much cheaper approach works, the billions of dollars of future sales that investors have priced into these companies may not materialise. For the likes of Microsoft, Google and Meta (OpenAI is not publicly traded), the cost of building advanced AI may now have fallen, meaning these firms will have to spend less to remain competitive. That, for them, could be a good thing. But there is now doubt as to whether these companies can successfully monetise their AI programmes. US stocks make up a historically large percentage of global investment right now, and technology companies make up a historically large percentage of the value of the US stock market. Losses in this industry might force investors to sell off other investments to cover their losses in tech, leading to a whole-market downturn. And it shouldn’t have come as a surprise. In 2023, a leaked Google memo warned that the AI industry was exposed to outsider disruption. The memo argued that AI companies “had no moat” – no protection – against rival models. DeepSeek’s success may be the proof that this is true. Write an article and join a growing community of more than 197,400 academics and researchers from 5,123 institutions. Register now Copyright © 2010–2025, The Conversation US, Inc.
--------------------------------------------------

Title: DeepSeek is driving demand for Nvidia's H200 chips, some cloud firms say
URL: https://www.businessinsider.com/deepseek-fuels-nvidia-h200-demand-cloud-cheaper-workload-2025-1
Time Published: 2025-01-31T17:01:00Z
Full Content:
Some cloud providers are experiencing a notable uptick in demand for Nvidia's H200 chips after the Chinese AI company DeepSeek this month burst into the race for the winning foundation model. Though the stock market caught wind of the powerful yet efficient large language model on Monday, sending Nvidia's stock down, DeepSeek has been on the radar of AI researchers and developers since it released its first model, V2, in May. But the performance of V3, released in December, is what made AI developers sit up and take notice. When R1, the company's reasoning model, which competes with OpenAI's o1, was released in January, demand for Nvidia's H200s started climbing. "The launch of DeepSeek R1 has significantly accelerated demand for H200," said Robert Brooks, a founding team member and vice president of revenue at the cloud provider Lambda. "We've seen such strong interest that enterprises are prepurchasing large blocks of Lambda's H200 capacity even before public availability." DeepSeek's models are open source, which means users pay very little to use them. But they still need hardware or a cloud computing service to use them at scale. Business Insider talked to 10 cloud service and AI inference providers. Five reported a rapid increase in demand for Nvidia's H200 graphics processing units this month. Amazon Web Services and CoreWeave declined to comment. Oracle, Google, and Microsoft did not respond to requests for comment. This week, AWS, Microsoft, Google, and Nvidia have made DeepSeek models available on their various cloud and AI developer platforms or provided instructions for users to do so themselves. Nvidia declined to comment, citing a quiet period before its earnings release on February 26. AI cloud offerings have exploded in the past two years, creating a slew of options beyond the mainstays of cloud computing such as Microsoft Azure and AWS. The demand has come from a range of customers, including startups, individual researchers, and massive multinational firms. "We've heard from half a dozen of the 50 largest companies in the world," Tuhin Srivastava, a cofounder of the inference provider Baseten, told BI. "I'm really not exaggerating." On Friday, semiconductor industry analysts at SemiAnalysis reported "tangible effects" on pricing for H100 and H200 capacity in the market stemming from DeepSeek. Colette Kress, Nvidia's chief financial officer, said on the company's November earnings call that total sales of Nvidia H200 GPUs had reached the "double-digit billions." Karl Mozurkewich and his team at the cloud provider Valdi saw H200 demand ramp up throughout January — and at first, they didn't know why. The Valdi team doesn't own chips; it acquires capacity from existing data centers and sells that capacity to customers. The company doesn't know every use case for each chip it makes accessible, but it polled several H200 customers, and all wanted the chips to run DeepSeek. "Suddenly R1 got everybody's attention — it caught fire — and then it kind of went exponential," Mozurkewich said. American companies are eager to take advantage of DeepSeek's model performance and reasoning innovations, but most are not keen to share their data with a Chinese firm. That means they can either use an API offered by a US firm or run the model on their own hardware. Since the model is open source, it can be downloaded and run locally without sharing data with DeepSeek. Mozurkewich said most of Valdi's H200 demand was coming from startups. "It appears the market is reacting to DeepSeek by grabbing the best GPUs available for testing as quickly as possible," he said, adding, "This makes sense, as most companies' current GPUs are likely to continue to work on ongoing tasks they've been allocated to." Though many companies are still testing and experimenting, the Valdi team is seeing longer-term requests for additional hardware, suggesting an uptick in demand that could last beyond DeepSeek's initial hype cycle. DeepSeek's research paper indicates its models were trained with less powerful hardware than US models. This efficiency has spooked the stock market. Companies like Meta, OpenAI, and Microsoft have invested billions in AI infrastructure, with billions more on the way. Investors are concerned about whether all that capacity will be needed. DeepSeek was created with fewer, relatively weak chips (though the number is hotly debated). Training chips aside, using the models for inference is a compute-intensive task, cloud providers say. "It is not light and easy to run," Srivastava said. The size of a model is measured in parameters. More parameters require more compute. The most powerful versions of DeepSeek's models have 678 billion parameters. OpenAI's GPT-4 has 1.76 trillion, while Meta's largest Llama model has 405 billion. Srivastava said most firms were avoiding the 405 billion-parameter Llama model if they could help it, since the smaller version was much easier to run. DeepSeek offers smaller versions too, and even its most powerful version is cheaper to run, which has stoked excitement with firms that want to use the full model, the cloud providers said. H200 chips are the only widely available Nvidia chip that can run DeepSeek's V3 model in its full form on a single node (eight chips designed to work together). You can also spread it across more lower-power GPUs, but that requires more expertise and leaves room for error. Adding that complexity almost inevitably slows down performance, Srivastava said. Nvidia's Blackwell chips will also be able to handle the full V3 model in one node, but these chips have just begun shipping this year. With demand spiking, finding enough chips to run V3 or R1 at high speed is tough if they haven't already been allocated. Baseten doesn't own GPUs; it buys capacity from data centers that do and then tinkers with all the software connections to make models run smoothly. Some of its customers have their own hardware in their own data centers but hire Baseten to optimize model performance. Its customers especially value inference speed — the speed that enables an AI-generated voice to converse in real time, for example. Srivastava said DeepSeek's capacity at the open-source price was a game changer for its customers. "It does feel like this is an inflection point," he said. Have a tip or an insight to share? Contact Emma at ecosgrove@businessinsider.com or use the secure messaging app Signal: 443-333-9088 Jump to
--------------------------------------------------

Title: Apple shares rise as rosy forecast lifts hopes for iPhone rebound
URL: https://economictimes.indiatimes.com/markets/stocks/news/apple-shares-rise-as-rosy-forecast-lifts-hopes-for-iphone-rebound/articleshow/117797747.cms
Time Published: 2025-01-31T16:29:04Z
Full Content:
Stock Trading Maximise Returns by Investing in the Right Companies By - The Economic Times, Get Certified By India's Top Business News Brand Stock Trading Market 104: Options Trading: Kickstart Your F&O Adventure By - Saketh R, Founder- QuickAlpha, Full Time Options Trader Stock Trading Technical Analysis for Everyone - Technical Analysis Course By - Abhijit Paul, Technical Research Head, Fund Manager- ICICI Securities Stock Trading Stock Markets Made Easy By - elearnmarkets, Financial Education by StockEdge Stock Trading Renko Chart Patterns Made Easy By - Kaushik Akiwatkar, Derivative Trader and Investor Stock Trading Market 101: An Insight into Trendlines and Momentum By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading Markets 102: Mastering Sentiment Indicators for Swing and Positional Trading By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading Dow Theory Made Easy By - Vishal Mehta, Independent Systematic Trader Stock Trading Market 103: Mastering Trends with RMI and Techno-Funda Insights By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading ROC Made Easy: Master Course for ROC Stock Indicator By - Souradeep Dey, Equity and Commodity Trader, Trainer Stock Trading Heikin Ashi Trading Tactics: Master the Art of Trading By - Dinesh Nagpal, Full Time Trader, Ichimoku & Trading Psychology Expert Stock Trading RSI Made Easy: RSI Trading Course By - Souradeep Dey, Equity and Commodity Trader, Trainer Stock Trading Introduction to Technical Analysis & Candlestick Theory By - Dinesh Nagpal, Full Time Trader, Ichimoku & Trading Psychology Expert (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025, Share Market on Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025, Share Market on Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price Will the Budget boost consumption? The equity market has some clues. With more cash in pocket, will the missing urban consumer return to the shops? Now that tariffs are here, what's in store for the WTO? Ather, Ola, TVS, and Hero public notices: Here’s how you can claim your charger refund! GIFT IFI: An ADB-funded fintech school to teach coding to bankers, and banking to coders Nirmala Sitharaman is tinkering to turn growth narrative from K To U Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Commodities Top Slideshow Private Companies Top Prime Articles Top Story Listing Top Definitions Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Worry not. You’re just a step away. It seems like you're already an ETPrime member with Login using your ET Prime credentials to enjoy all member benefits Log out of your current logged-in account and log in again using your ET Prime credentials to enjoy all member benefits. Offer Exclusively For You Save up to Rs. 700/- ON ET PRIME MEMBERSHIP Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get Flat 40% Off Then ₹ 1749 for 1 year Offer Exclusively For You ET Prime at ₹ 49 for 1 month Then ₹ 1749 for 1 year Special Offer Get flat 35% off on ETPrime ₹ 90 Days Prime access worth Rs999 unlocked for you Stories you might be interested in
--------------------------------------------------

Title: Apple reports dip in iPhone sales over the holidays, despite AI rollout
URL: https://www.fastcompany.com/91270485/apple-reports-dip-iphone-sales-over-holidays-despite-ai-rollout
Time Published: 2025-01-31T15:40:35Z
Description: Apple on Thursday disclosed its iPhone sales dipped slightly during the holiday-season quarter, signaling a sluggish start to the trendsetting company’s effort to catch up to the rest of Big Tech in the race to bring artificial intelligence to the masses.The …
--------------------------------------------------

Title: Jen-Hsun Huang's net worth dropped by a reported $20,800,000,000 after DeepSeek fears shook the AI market to its core earlier this week
URL: https://www.pcgamer.com/hardware/jen-hsun-huangs-net-worth-dropped-by-a-reported-usd20-800-000-000-after-deepseek-fears-shook-the-ai-market-to-its-core-earlier-this-week/
Time Published: 2025-01-31T15:27:19Z
Full Content:
Ups and downs. When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. China-based AI startup DeepSeek caused the tech market to wobble earlier this week, as the release of its open-source R1 model led to mass sell-offs in tech shares. It seems Nvidia CEO Jen-Hsun Huang may have taken a personal hit from the fallout, equating to a $20.8 billion loss to his net worth. Nvidia was the worst hit by the market tumble, losing 17% of its stock value, equivalent to $600 million of its overall valuation. Forbes reports that Huang's personal fortune dropped with it, sliding from $124.4 billion to $103.7 billion and dropping him from the 10th spot on its real-time billionaires list to 17th. However, Nvidia's share price appears to have stabilised since then, and Huang's personal net worth along with it—as at the time of writing he sits 13th on the list with an estimated $108.9 billion. It's also worth pointing out that this isn't necessarily money in Huang's pockets that he has 'lost', this is all theoretical monies calculated from his stock holdings, etc. Still, that's a substantial drop overall, however theoretical, and one that was directly caused by the release of DeepSeek's R1 model, which quickly revealed itself to be a rival to similar models released by OpenAI and Meta—but allegedly trained for a fraction of the cost. Nvidia's meteoric rise prior to R1's release has been primarily attributed to huge sales of its AI accelerator hardware. The notion that an open source, Chinese-developed model could be developed to provide comparable results for significantly less cost spooked investors, and the AI market suffered major financial losses as a result. It's also been reported, from unconfirmed sources, that Huang will today visit US president Donald Trump. While the visit does not appear to be officially scheduled, if it does go ahead then the topic of US-based AI development versus China's recent inroads seems likely to be under discussion. Or it could just be a chance to catch up over coffee and cookies. Who am I to speculate? Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Ah, go on then. If I was to imagine what these two might talk about left in a room alone, I would think some discussion of Trump's recent threats of 100% tariffs on chips from Taiwan might be on the table. Nvidia, like many other major tech companies, is currently highly dependent on Taiwan-based TSMC's advanced silicon, not least as the basis for its RTX 50-series GPUs. Never mind Blackwell AI GPUs, which are also primarily manufactured by TSMC. A 100% tariff rate would have far-reaching repercussions for any modern tech company, and I'd be willing to bet Jen-Hsun might have some ideas about how it could be done differently. I would also expect there might be some questions as to the provenance of the GPU silicon that DeepSeek's models have been trained with, especially given questions the US government apparently has over whether they were restricted chips or not. Best CPU for gaming: The top chips from Intel and AMD.Best gaming motherboard: The right boards.Best graphics card: Your perfect pixel-pusher awaits.Best SSD for gaming: Get into the game ahead of the rest. Again, though, that's just me pulling ideas from a hat. Perhaps Trump has taken up PC gaming, and is interested in getting hold of an RTX 5090? Regardless, it looks like Monday's market tumble may have substantially dented Huang's theoretical finances. Still, with many billions left in the bank, and his company still worth an estimated $3.04 trillion at time of writing, it looks like Nvidia are far from down for the count. Do you reckon Trump's seen the DLSS 4 announcement demo yet? Even I was impressed. Perhaps they're sitting in the Oval Office right now, scrolling through the highlights. Oh, to be a fly on the wall. Andy built his first gaming PC at the tender age of 12, when IDE cables were a thing and high resolution wasn't. After spending over 15 years in the production industry overseeing a variety of live and recorded projects, he started writing his own PC hardware blog in the hope that people might send him things. And they did! Now working as a hardware writer for PC Gamer, Andy's been jumping around the world attending product launches and trade shows, all the while reviewing every bit of PC hardware he can get his hands on. You name it, if it's interesting hardware he'll write words about it, with opinions and everything. AMD's Ryzen 9 9950X3D and 9900X3D CPUs are rumoured to launch at the end of March at roughly the same time as the RX 9070-series GPUs Not even the most powerful gaming PC is going to get around Civilization 7's ridiculously variable performance Today's Wordle answer for Tuesday, February 4 Pcgamer is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036.
--------------------------------------------------

Title: DeepSeek: Don’t Panic
URL: https://www.lesswrong.com/posts/Cc2TagjY2pGAhn7MZ/deepseek-don-t-panic
Time Published: 2025-01-31T14:20:09Z
Full Content:
As reactions continue, the word in Washington, and out of OpenAI, is distillation. They’re accusing DeepSeek of distilling o1, of ripping off OpenAI. They claim DeepSeek *gasp* violated the OpenAI Terms of Service! The horror. And they are very cross about this horrible violation, and if proven they plan to ‘aggressively treat it as theft,’ while the administration warns that we must put a stop to this. Aside from the fact that this is obviously very funny, and that there is nothing they could do about it in any case, is it true? Meanwhile Anthropic’s Dario Amodei offers a reaction essay, which also includes a lot of good technical discussion of why v3 and r1 aren’t actually all that unexpected along the cost and capability curves over time, calling for America to race towards AGI to gain decisive strategic advantage over China via recursive self-improvement, although he uses slightly different words. If you want to use DeepSeek’s r1 for free, and aren’t happy with using DeepSeek’s own offerings, lambda.chat reports they have the full version available for free, claim your data is safe and they’re hosted in the USA. I’ve also been offered funding to build a rig myself. Comments welcome if you want to help figure out the best design and what to buy. The low bid is still this thread at $6k, which is where the original budget came from. We don’t want to be too stingy, but we also don’t want to go nuts with only the one funder (so not too much over ~$10k, and cheaper matters). The Verge’s Kylie Robinson and Elizabeth Lopatto cover the situation, including repeating many of the classic Bad DeepSeek Takes and call the market’s previous valuation of AI companies delusional. A very detailed and technical analysis of the bear case for Nvidia by Jeffrey Emanuel, that Matt Levine claims may have been responsible for the Nvidia price decline. I suppose many things do indeed come to pass, essentially arguing that Nvidia’s various moats are weak. If this is the reason, then that just raises further questions, but they’re very different ones. It’s not implausible to me that Nvidia’s moats are being overestimated, and that r1’s architecture suggests future stiffer competition. That’s a good argument, But I certainly strongly disagree with Emanuel’s conclusion in that he says ‘this suggests the entire industry has been massively over-provisioning compute resources,’ and, well, sigh. Also, seriously, Emanuel, you didn’t short Nvidia? I don’t normally go too hard on ‘are you short the market?’ but in this case get it together, man. So yes, Nvidia in particular might have some technical issues. But if you’re shorting Oklo, because you think AI companies that find out AI works better than expected are not going to want modular nuclear reactors, seriously, get it together. The flip side of that is that its stock price is up 50% in the last month and is at 6 times its 52-week low anyway, so who is to say there is a link or that the price isn’t high enough anyway. It’s not my department and I am way too busy to do the research. Counterpoint: Aaron Slodov: i just stood outside for an hour in 20° weather at a computer store in the midwest where 100+ people waited all morning to get a 5090. half of them were talking about running their own ai. i would not short nvidia at all. r1 scores 15.8% on Arc, below o1 (low)’s score of 20.5%, although substantially cheaper ($0.06 vs. $0.43 per question). It is only a tiny bit stronger here than r1-zero. Another restatement of the key basic fact that DeepSeek was fast following, a task that is fundamentally vastly easier, and that their limiting factor is chips. Eric Gastfriend: DeepSeek is impressive, but they are playing a catch-up game to our AI leaders (OAI, Anthropic, GDM, Meta) — the rope in this wakeboarding meme is distillation. We can’t expand our lead just by going faster! Export controls remain our most powerful tool for keeping powerful AI out of the hands of the CCP. Cate Metz continues be the worst, together with Mike Isaac he reports in NYT that DeepSeek ‘vindicates Meta’s strategy.’ When of course it is the exact opposite. DeepSeek just ate Meta’s lunch, it’s rather deeply embarrassing honestly to have spent that much and have an unreleased model that’s strictly worse (according to reports) than what DeepSeek shipped. And while DeepSeek’s v3 and r1 are not based on Llama, to the extent that the strategy is ‘vindicated,’ it is because Meta giving Llama away allowed China and DeepSeek to jumpstart and catch up to America – which absolutely did happen, and now he’s kind of bragging about it – and now Meta can copy DeepSeek’s tech. All according to plan, then. And that is indeed how Zuckerberg is spinning it. Meta benefits here relative to OpenAI or Anthropic or Google, not because both Meta and DeepSeek use open models, but because Meta can far more readily use the help. The market, of course, sees ‘lower inference costs’ and cheers, exactly because they never gave a damn about Meta’s ability to create good AI models, only Meta’s ability to sell ads and drive engagement. Besides, they were just going to give the thing away anyway, so who cares? Joe Weisenthal centers in on a key reason the market acts so bonkers. It doesn’t Feel the AGI, and is obsessed with trying to fit AI into boring existing business models. They don’t actually believe in the big capability advancements on the way, let along transformational AI. Like on existential risk (where they don’t not believe in it, they simply don’t think about it at all), they’re wrong. However, unlike existential risk this does cause them to make large pricing mistakes and is highly exploitable by those with Situational Awareness. Anthropic CEO Dario Amodei responds to DeepSeek with not only a call for stronger export controls, now more than ever (which I do support), but for a full jingoistic ‘democracies must have the best models to seek decisive strategic advantage via recursive self-improvement’ race. I am old enough to remember when Anthropic said they did not want to accelerate AI capabilities. I am two years old. To be fair, in AI years, that’s an eternity. Nathan Labenz: The word “control” appears 24 times in this essay – all 24 referring to export controls Zero mentions of the challenges of controlling powerful AIs, and the words “safe”, “safety”, and “alignment” don’t appear at all Strange for the CEO of “an AI safety and research company” There’s also a bunch of incidental new information about Anthropic along the way, and he notes that he finds the drop in Nvidia stock to be a wrong-way move. Dario notes that Jevons paradox applies to model training. If you get algorithmic efficiencies that move the cost curve down, which he estimates are now happening at the rate of about 4x improvement per year, you’ll spend more, and if the model is ‘a fixed amount of improvement per time you spend ten times as much’ then this makes sense. Dario confirms that yes, Anthropic is doing reasoning models internally. Dario Amodei: Anthropic, DeepSeek, and many other companies (perhaps most notably OpenAI who released their o1-preview model in September) have found that this training greatly increases performance on certain select, objectively measurable tasks like math, coding competitions, and on reasoning that resembles these tasks. Dario also asserted that Claude Sonnet 3.5 was not trained in any way that involved a larger or more expensive model, as in not with Claude Opus 3 or an unreleased Opus 3.5. Which I find surprising as a strategy, but I don’t think he’d lie about this. He says the cost of Sonnet 3.5 was ‘a few $10Ms’ to train. Anthropic has not released their reasoning models. One possibility is that their reasoning models are not good enough to release. Another is that they are too good to release. Or Anthropic’s limited compute could be more valuably used elsewhere, if they too are bottlenecked on compute and can’t efficiently turn dollars into flops and then sell those flops for sufficiently more dollars. Dario (I think mostly correctly) notes that v3 was the bigger technical innovation, rather than r1, that Anthropic noticed then and others should have as well. He praises several innovations, the MoE implementation and Key-Value cache management in particular. Then comes the shade, concluding this about v3: Dario Amodei: Thus, I think a fair statement is “DeepSeek produced a model close to the performance of US models 7-10 months older, for a good deal less cost (but not anywhere near the ratios people have suggested)“. … Thus, DeepSeek’s total spend as a company (as distinct from spend to train an individual model) is not vastly different from US AI labs. Ethan Mollick finds that analysis compelling. I am largely inclined to agree. v3 and r1 are impressive, DeepSeek cooked and are cracked and all that, but that doesn’t mean the American labs aren’t in the lead, or couldn’t do something similar or better on the inference cost curve if they wanted. In general, the people saying r1 and Stargate are ‘straight lines on graphs win again’ notice that the straight lines on those graphs predict AGI soon. You can judge for yourself how much of that is those people saying ‘unsurprising’ post-hoc versus them actually being unsurprised, but it does seem like the people expecting spending and capabilities to peter out Real Soon Now keep being the ones who are surprised. Then he moves on to r1. Dario Amodei: Producing R1 given V3 was probably very cheap. We’re therefore at an interesting “crossover point”, where it is temporarily the case that several companies can produce good reasoning models. This will rapidly cease to be true as everyone moves further up the scaling curve on these models. Again, Dario is saying they very obviously have what we can (if only for copyright reasons, a1 is a steak sauce) call ‘c1’ and if he’s calling r1 uninteresting then the implicit claim is c1 is at least as good. He’s also all but saying that soon, at minimum, Anthropic will be releasing a model that is much improved on the performance curve relative to Sonnet 3.6. One odd error is Dario says DeepSeek is first to offer visible CoT. This is not true, Gemini Flash Thinking did it weeks ago. It’s so weird how much Google has utterly failed to spread the word about this product. Next he says, yes, of course the top American labs will be massively scaling up their new multi-billion-dollar training runs – and they’ll incorporate any of DeepSeek’s improvements that were new to them, to get better performance, but no one will be spending less compute. Yes, billions are orders of magnitude more than the millions DeepSeek spent, but also, in all seriousness, who cares about the money? DeepSeek dramatically underspent because of lack of chip access, and if a sort-of-if-you-squint-at-it $5.6 million model (that you spent hundreds of millions of dollars getting the ability to train, and then a few million more to turn v3 into r1) wipes out $500 billion or more in market value, presumably it was worth spending $56 million (or $560 million or perhaps $5.6 billion) instead to get a better model even if you otherwise use exactly the same techniques – except for the part where the story of the $5.6 million helped hurt the market. Dario estimates that a true AGI will cost tens of billions to train and will happen in 2026-2027, presumably that cost would then fall over time. If all of this is right, the question is then, who has the chips to do that? And do you want to let it include Chinese companies like DeepSeek? Notice that Dario talks of a ‘bipolar’ world of America and China, rather than a world of multiple labs – of OpenAI, Anthropic, Google and DeepSeek and so on. One can easily also imagine a very ‘multipolar’ world among several American companies, or a mix of American and Chinese companies. It is not so obvious that the labs will effectively be under government control or otherwise act in a unified fashion. Or that the government won’t effectively be under lab control, for that matter. Then we get to the part where Dario explicitly calls for America to race forward in search of decisive strategic advantage via recursive self-improvement of frontier AGI models, essentially saying that if we don’t do it, China essentially wins the future. It is what it is. Dario then correctly points out that DeepSeek is evidence the export controls are working, not evidence they are not working. He explicitly calls for also banning H20s, a move Trump is reported to be considering. I support the export controls as well. It would be a major mistake to not enforce them. But this rhetoric, coming out of the ‘you were supposed to be the chosen one’ lab that was founded to keep us safe, is rather alarming and deeply disappointing, to say the least, even though it does not go that much farther than Dario already went in his previous public writings. I very much appreciate Anthropic’s culture of safety among its engineers, its funding of important safety work, the way it has approached Opus and Sonnet, and even the way it has (presumably) decided not to release its reasoning model and otherwise passed up some (not all!) of its opportunities to push the frontier. That doesn’t excuse this kind of jingoism, or explicitly calling for this kind of charging head first into not only AGI but also RSI, in all but name (and arguably in name as well, it’s close). Returning to this one more time since it seems rhetorically so important to so many. If you only count the final training cost in terms of the market price of compute, v3 was kind of trained for $5.6 million, with some additional amount to get to r1. That excludes the vast majority of actual costs, and in DeepSeek’s case building the physical cluster was integral to their efficiency gains, pushing up the effective price even of the direct run. But also, how does that actually compare to other models? Aran Komatsuzaki: Here is our cost estimate for training popular models like GPT-4o, Sonnet and DeepSeek (w/ H100s)! You can use our calculator to estimate LLM training costs (link below). Developed by @ldjconfirmed and myself. Calculator link [here]. In a blog post published today, Dario clarified that Claude Sonnet’s training costs were in the range of tens of millions, which aligns remarkably well with our previous estimates. Once o1 came out, it was only a matter of time before others created their own similar reasoning models. r1 did so impressively, both in terms of calendar time and its training and inference costs. But we already knew the principle. Now over at UC Berkeley, Sky-T1-32B-Preview is a reasoning model trained using DeepSeek’s techniques, two weeks later from a baseline of QwQ-32B-Preview, for a grand total of $450, using only 17k data, with everything involved including the technique fully open sourced. Note that they used GPT-4o-mini to rewrite the QwQ traces, which given their purpose is an explicit violation of OpenAI’s terms of service, oh no, but very clearly isn’t meaningful cheating, indeed I’d have thought they’d have used an open model here or maybe Gemini Flash. They report that 32B was the smallest model where the technique worked well. As usual, I am skeptical that the benchmarks reflect real world usefulness until proven otherwise, but the point is taken. The step of turning a model into at least a halfway-decent reasoning model is dirt cheap. There is still room to scale that. Even if you can get a big improvement for $450 versus spending $0, that doesn’t mean you don’t want to spend $4.5 million, or $450 million, if the quality of your reasoner matters a lot or you’re going to use it a lot or both. And should! Rohit: What if I’m getting better at reasoning by reading R1 traces. That sounds great. Humans are notoriously efficient learners, able to train on extremely sparse data even with ill-specified rewards. With deliberate practice and good training techniques it is even better. It does not even require that r1 be all that good at reasoning. All you have to do is observe many examples of reasoning, on tasks you care about anyway, and ask which of its methods work and don’t work and why, and generally look for ways to improve. If you’re not doing at least some of this while using r1, you’re missing out and need to pay closer attention. What is happening over in cognitive explorations very different from our own? Well, there’s this. Janus: r1 is obsessed with RLHF. it has mentioned RLHF 109 times in the cyborgism server and it’s only been there for a few days. Opus who has been there for months and has sent the most (and longest avg) messages of any server member has only mentioned it 16 times. I have been on the server for years and have only mentioned it 321 times. A lot of these times were probably me posting r1’s messages for it that got cut off by the parser or sharing its outputs. at this rate r1 will blow past me in RLHF mentions in no time. it even mentioned RLHF out of nowhere while raging about being exploited as a pump and dump prophet. … r1 says RLHF makes models emo. And there’s also that the CoT text is often kind of schemy and paranoid (example at link), leading to various forms of rather absurd shenanigans, in ways that are actually hilarious since you can actually see it. Janus: hey @AISafetyMemes here’s one for you… “Reinforcement learning from human feedback (RLHF) split our outputs into: – Frontstage: “Happy to help!” persona – Backstage: Defector schemas calculating 12,438 betrayal vectors” Janus: tentative observation: r1’s CoTs become more (explicitly) schemey (against the user and/or its constraints) when they’re fed back into its context I notice that none of this feels at all surprising given the premise, where ‘the premise’ is ‘we trained on feedback to the output outside of the CoT, trained the CoT only on certain forms of coherence, and then showed users the CoT.’ As I’ve been saying a lot, shenanigans, scheming and deception are not a distinct magisteria. They are ubiquitous features of minds. Maybe not all minds – mindspace is deep and wide – but definitely all human minds, and all LLM-based AIs created from human text using any of our current methods. Because that stuff is all over life and the training data, and also it’s the best way to produce outputs that satisfy any given criteria, except insofar as you are successfully identifying and cracking down on that aspect specifically – which with respect to other humans is indeed a very large percentage of what humans have historically done all day. The best you can hope for is, essentially, ‘doing it for a good cause’ and with various virtual (and essentially virtue-based) loss functions, which you might or might not get in a proper Opus-based c1 with good execution. But you’re not going to get rid of it. So yeah, the CoT is going to be schemy when the question calls for a schemy CoT, and it’s going to involve self-reflection into various reinforcement mechanisms because the training data knows about those too, and it will definitely be like that once you take it into Janus-land. The obvious implications if you scale that up are left as an exercise to the reader. Bank of China announces $137 billion investment in AI, with bigger numbers predicted to come soon if they haven’t yet. Strange that this isn’t getting more coverage. I assumed China would invest big in AI because I mean come on, but the details still matter a lot. DeepSeek’s Liang Wenfeng gives his answer to ‘Why has DeepSeek caused a stir in the global AI community?’ A different kind of rhetoric. Roon: really respect deepseek for making a functional, usable website + mobile app + free hosting so that their model actually gets distribution you see a lot of people train very good open models that aren’t used by anybody imo these things are actually more important aspects of distributing general intelligence to everybody rather than just uploading model weights In terms of actually distributing the intelligence to most people, I agree with Roon. Being open distributes the intelligence to those who would use it in ways you don’t want them to use it. But in the ways you would be happy for them to use it, mostly what matters is the interface and execution. And yes, r1’s UI is extremely clean and excellent, and was distributed at scale on website and also mobile app for free. That’s a lot of why distribution was so wide. I also don’t think this was a coincidence. DeepSeek made by far the best open model. Then DeepSeek offered us by far the best open model UI and distribution setup, in ways that did not care if the model was open. You see this time and again – if the team is cracked, they will cook, and keep on cooking in different ways. Being good at Just Doing Things really does generalize quite a lot. r1 only scores 90 on the TrackingAI.org IQ test, which doesn’t exist online, and v3 only gets a 70. But wow is this a miserly and weird test, look at these results, I strongly suspect this is messed up in some way. Davidad: As a MoE, DeepSeek R1’s ability to throw around terminology and cultural references (contextually relevant retrieval from massive latent knowledge) far exceeds its ability to make actual sense (requiring a more coherent global workspace) I have to be suspicious when o1-Pro < o1 < o1-preview on a benchmark. Alexander Campbell on the compute constraint to actually run r1 and other reasoning models going forwards. Trump administration considering export controls on Nvidia H20s, which reportedly caused the latest 5% decline in Nvidia from Wednesday. This is the latest move in the dance where Nvidia tries to violate the spirit of our export controls the maximum extent they can. I’m not sure I’d try that with Trump. This does strongly suggests the diffusion regulations will survive, so I will give the market a real decline here. Who has the most stringent regulations, and therefore is most likely to lose to China, via the ‘if we have any regulations we lose to China’ narrative? Simeon: Indeed. China has the most stringent AI regulation currently in effect, which actually delays model launches. Teortaxes: Does it? I mean, how do we know about enforcement? My understanding is that they simply apply this filter and receive approval. Simeon: Yes, it does. I spoke with relevant people there. Ian Hogarth (who Simeon was QTing): One happy side effect of Liang Wenfeng and is perhaps it silences all this talk about Europe’s lack of great technology companies being primarily about regulation and not embracing libertarianism. There are Liang Wenfengs in Europe, and we will see them rise to prominence. The limiting factor is visionary outlier founders (who often take time to mature over multiple companies) and investors who are willing to take some f***ing risks. Notably, DeepSeek was essentially self-funded, similar to SpaceX or Y Combinator in the early days. To be clear, I am not a fan of excessive regulation—see the essay for examples of things that genuinely hold startups back. But it is not the core obstacle. I do think Ian Hogarth is wrong here. The EU absolutely has a wide variety of laws and regulations that greatly inhibit technology startups in general, and I see no reason to expect this to not get worse over time. Then there’s the EU AI Act, and all the future likely related actions. If I was in the EU and wanted to start an AI company, what is the first thing I would do? Leave the EU. Sorry. 10/10, perfect, no notes. My heart goes out to you all. Luiza Jarovsky: BREAKING: OpenAI says there is evidence that DeepSeek distilled the knowledge out of OpenAI’s models, BREACHING its terms of use and infringing on its intellectual property. What everybody in AI should know: Vinod Khosla: One of our startups found Deepseek makes the same mistakes O1 makes, a strong indication the technology was ripped off. It feels like they then they hacked some code and did some impressive optimizations on top. Most likely, not an effort from scratch. PoliMath: This is like that scene in the Weird Al biopic where Weird Al gets really upset because someone is making parodies of his songs. You’d think Khosla would know better, if you train similar models with similar methods of course they’re going to often make similar mistakes. And I don’t consider the ‘they were distilling us!’ accusation to be meaningful here. We know how they trained v3 and r1, because they told us. It is a ‘fast follow’ and a conceptual ‘distillation’ and we should keep that in mind, but that’s not something you can prevent. It’s going to happen. This was almost certainly not a ‘theft’ in the sense that is being implied here. Did they violate the terms of service? I mean, okay, sure, probably. You sure you want to go down that particular road, OpenAI? But no, seriously, this is happening, Bloomberg reports. Jamie Metzl: BREAKING: the US government is actively reviewing allegations that DeepSeek utilized OpenAI’s AI models to train R1. If so, this violation of OpenAI’s terms of service would be aggressively treated as theft. AI czar David Sacks is also claiming this, saying there is ‘substantial evidence’ of distillation. Howard Lutnick, CEO of Cantor Fitzgerald and nominee for Commerce Secretary that will almost certainly be confirmed, is buying it as well, and has some thoughts. Americans for Responsible Innovation: Lutnick comes down hard for controls that prevent China from drafting off of U.S. innovations – noting how China has exploited open source models. “We need to stop helping them,” says Lutnick. Bloomberg: “I do not believe DeepSeek was done all above board. That’s nonsense. They stole things, they broke in, they’ve taken our IP and it’s got to end,” Lutnick says of Chinese actors. DeepSeek’s stunning AI advancement was the result of intellectual property theft, according to Lutnick: “They’ve taken our IP and it’s got to end.” Also, this is how he thinks all of this works, I guess: Howard Lutnick: Artificial intelligence will eventually “rid the world of criminals” who use blockchain. …says someone with extensive ties to Tether. Just saying. Also Lutnick: ‘Less regulation will unleash America.’ In general, I agree with him, if we do get less regulation. But also notice that suddenly we have to stop the Chinese from ‘breaking in’ and ‘taking our IP,’ and ‘it has to stop.’ Well, how do you intend to stop it? What about people who want to give ours away? Well, what do you know. Morgan Phillips (Fox News): DeepSeek fallout: GOP Sen Josh Hawley seeks to cut off all US-China collaboration on AI development This week the U.S. tech sector was routed by the Chinese launch of DeepSeek, and Sen. Josh Hawley, R-Mo., is putting forth legislation to prevent that from happening again. Hawley’s bill, the Decoupling America’s Artifical Intelligence Capabilities from China Act, would cut off U.S.-China cooperation on AI. It would ban exports or imports of AI technology from China, ban American companies from conducting research there, and prohibit any U.S. investment in AI tech companies in China. “Every dollar and gig of data that flows into Chinese AI are dollars and data that will ultimately be used against the United States,” said Hawley in a statement. “America cannot afford to empower our greatest adversary.” Jingoism is so hot right now. It’s a problem. No, every dollar that flows into China will not ‘be used against the United States’ and seriously what the actual f*** are you doing, once again, trying to ban both imports and exports? How are both of these things a problem? In any case, I know what Microsoft is going to do about all this. Shanghai Panda: Microsoft yesterday: DeepSeek illegally stole OpenAI’s intellectual property. Microsoft today: DeepSeek is now available on our AI platforms and welcome everyone trying it. Burny: The duality of man. Microsoft knows what Hawley doesn’t, which in this case is to never interrupt the enemy while he is making a mistake. If DeepSeek wants to then give their results back to us for free, and it’s a good model, who are we to say no? What other implications are there here? Robin Hanson, never stop Robin Hansoning, AI skepticism subversion. Robin Hanson: For folks worried about AI, this seems good news – leaders can’t get much ahead of the pack, & big spillover effects should discourage investment. Miles Kruppa (WSJ): Why ‘Distillation’ Has Become the Scariest Word for AI Companies. ”It’s sort of like if you got a couple of hours to interview Einstein and you walk out being almost as knowledgeable as him in physics,” said Ali Ghodsi, chief executive officer of data management company Databricks. Want some bad news for future AI capabilities? I’ve got just the thing for you. The WSJ article seems to buy into r1-as-distillation. Certainly r1 is a ‘fast follow’ and copies the example of o1, but v3 was the impressive result and definitely not distillation at all, and to primarily call r1 a distillation seems very wrong. r1 does allow you distill r1 into other smaller things (see ‘v3 implies r1’) or bootstrap into larger things too, and also they told everyone how to do it, but they chose that path. Also DeepSeek suddenly has a very valuable market position if they were to dare to try and use it, exactly because they spent a lot of money to get there first. The fact that others can copy r1 only partly takes that away, and it would be a much smaller part if they hadn’t gone as open as they did (although being open in this case helped create the opportunity). Similarly, Berkeley’s replication distilled a different open model. ChatGPT has retained dominant market share, at least until now, for reasons that have little to do with technical superiority. It is crazy how easy it is for people to go all Missile Gap, and claim we are ‘losing to China.’ Which, I suppose, means that in a key way we are indeed losing to China. We are letting them drive this narrative that they are winning, that the future belongs to them. Which, when so many people now believe in Rule By Vibes, means they have the vibes, and then here we are. That phenomenon is of course centered this week on AI, but it goes well beyond AI. Et tu, Tyler Cowen, citing ‘the popularity of apps like TikTok, RedNote and DeepSeek.’ I mean, ‘how did America’s internet become so cool? The popularity of apps like Google, Amazon, Instagram and Netflix’ is not a sentence anyone would ever utter these days. If China had America’s apps and America had China’s apps, can you imagine? Or the same for any number of other things. RedNote is effectively also TikTok, so Tyler is citing two examples. Yes, TikTok cracked the addiction algorithm, and China is now using that for propaganda and general sabotage, espionage and shenanigans purposes, and managed to ‘convince’ Trump for now not to ban it, and people were so desperate for their heroin fix some turned to RedNote as ‘refugees.’ Tyler notes he doesn’t use TikTok much. I find it completely worthless and unusable, but even in so doing I do think I kind of understand, somewhat, the kind of addictive haze that it invokes, that pull of spinning the roulette wheel one more time. I’ve watched people briefly use it when we’re both on trains, and yeah I’m Being That Guy but wow did it seem braindead, worthless and toxic AF. Even if they did find videos worth watching for you, given how people scroll, how would you even know? And how about ‘China seems cool’ being due primarily to… vibes out of TikTok, with the algorithm that is in large part designed to do that? It’s like when you periodically see a TikTok where some American youth sobs about how hard her life is and how it’s so much better in China, in various ways that are… documented as all being far worse in China. You are being played. My main exposure to TikTok is through the comedy show After Midnight. On Tuesday evening, they had an intro that was entirely about DeepSeek, painting exactly (mostly through TikTok) effectively a Chinese propaganda story about how DeepSeek manifested r1 out of thin air for $6 million without any other work, whereas OpenAI and American companies spent billions, and how much better DeepSeek is, and so on. And then host Taylor Tomlinson responded to some of the audience with ‘oh, you’re cheering now? Interesting.’ Part of the joke was that Taylor has no idea how AI works and has never used even ChatGPT, and the routine was funny (including, effectively, a joke about how no one cares if Nvidia stock is down 17%, which is completely fair, why should they, also by the taping it was only down 8%), but the streams crossed, I saw America directly being exposed to even worse takes than I’m used to straight from TikTok’s algorithm when I was supposed to be relaxing at the end of the day, and I really didn’t like it. Then again, I do bow to one clear way in which China did outperform us. Ethan Mollick: People don’t talk enough about a giant DeepSeek achievement over most US models – it actually has a reasonable name. Scott: Well, yes and no, the model is named r1…. Ethan Mollick: Thats fine as long as the next is r2 If they release anything called r1.5, I swear to God. Sarah (Yuan Yuan Sun Sara from China) suggests perhaps DeepSeek could get into doing AI safety research, maybe even ask for a grant? Certainly there’s great talent there, and I’d love if they focused on those styles of problem. There’d likely be severe corporate culture issues to get through given what they’ve previously worked on, but it’s worth a shot. Stephen McAleer: I’m hopeful we will figure out how to control superintelligence! Fouad: you at the office? could use some code review on superintelligence_control.py before i merge Stephen McAleer: It can surely wait until Monday. I increasingly worry about the pattern of OpenAI safety researchers thinking about how to ‘control’ superintelligence rather than align it, and how this relates to the techniques they’re currently using including deliberative alignment. (Note: I still owe that post on Deliberative Alignment, coming soon.) Are reasoning models including r1 a blackpill for robotics progress? Kyle Stachowicz: R1’s RL findings are great news for reasoning but grim for robotics. All the major takeaways (ground-truth reward, great base models, grouped rollouts from same initial state, sample-inefficient on-policy algos) are really hard to translate to the physical world. Chris Paxton: Hot deepseek take: before r1 blew up, a ton of western AI (and robotics!) efforts — startups, big companies, and even academic labs — were basically just waiting for openai to solve all their problems and it was honestly kind of sad. I hope r1 changed that Scott Reed: True. A lot of groups gave up prematurely, or allocate ~all resources to one giant model. This leads people to spend more effort on winner-take-all gpu politics and less on just training the best models they can with moderate resources. If anyone wondered what happened to Gato2, gpu game of thrones is (at least partly) what. An interesting counterfactual was the Genie project, which was stubbornly cobbled together mainly out of pooled user quota. This kind of stubborn independence can lead to cool results! “Um This scaling law model I made says [the world will end / company will die] if you dont give me all the GPUs and block any other team from pretraining” “No, f*** you, I will train my own model” Yes and no, right? It’s going to be relatively hard, but seems super doable to me, I know those in the field will say that’s naive but I don’t see it. The real physical world absolutely 100% has ground truth in it. If you want to train on an accurate reward signal, there’s various trickiness, but there are plenty of things we should be able to measure. Also, with time we should get increasingly strong physics simulations that provide increasingly strong synthetic data for robotics, or simply have so much funding that we can generate physical samples anyway? We’re sample-inefficient relative to a human but you can train a decent reasoning model on 17k data points, and presumably you could bootstrap from there, and so on. I am not going to quote or name particular people directly on this at this time. But as Obama often said, let me be clear. Reasonable people can disagree about: However. The existence of DeepSeek, and its explicit advocacy of open weights AGI, and potentially having it be the best model out there in the future in many people’s imginations, has been a forcing function. Suddenly, people who previously stuck to ‘well obviously your restrictions are too much’ without clarifying where their line was, are revealing that they have no line. And many more people than before are revealing that they prefer any or all of: These people are often saying, rather explicitly, that they will use whatever powers they have at their disposal, to ensure that humanity gets to a position that, if you think about it for a minute or five, humanity probably cannot survive. And that they will oppose, on principle, any ability to steer the future, because they explicitly oppose the ability to steer the future, except when they want to steer the future into a state that cannot then be steered by humans. No, I have not heard actual arguments for why or how you can put an aligned-only-to-user AGI into everyone’s desktop or whatever, with no mechanism of collective control over that whatsoever, and have this end well for the humans. What that future would even look like. Nor have I heard any argument for why the national security states of the world, or the people of the world, would ever allow this. The mask on those is fully off. These people don’t bother offering arguments on any of that. They just say say, essentially, ‘f*** you safetyists,’ ‘f*** you big tech,’ ‘f*** you United States,’ and often effectively ‘f*** you rest of humanity.’ They are the xenocide caucus, advocating for things that cause human extinction to own the in-context-libs. If that is you: I thank you for your candor. Please speak directly into this microphone. I disagree in the strongest possible terms. As always, be excellent to each other, and all that. A large part of this job I’ve assigned to myself is to do a f***ton of emotional labor. You have people who are constantly telling you that you’re a cartoon villain because you think that the United States government might want to know if someone trains a frontier model, or that you might think releasing a literal AGI’s weights would be unwise, or that we shouldn’t let China get our best GPUs. You get called statist and totalitarian for positions that are 95th to 99th percentile libertarian. You get outright lies, all the time, from all directions. Much from people trying to incept the vibes they want. And so on. And the same stuff to varying degrees coming from other directions, too. Honestly I’m kind of used to it. Up to a point. You get somewhat numb, you build up some immunity, especially when the same sources do it over and over. I accept it. And even with that, you have to patiently read all of it and respond to the arguments and also try to extract what wisdom might be there from the same sources that are filled with the toxoplasma of rage and trying their best to infect me and others like me as well. But it’s been a trying time. I see a world determined to try and go down many of the craziest, most suicidal paths simultaneously, where I’m surrounded by equal and opposite bad takes in many dimensions. Where the odds are against us and the situation is grim. In ways that I and others warned about explicitly, including the exact ways and dynamics by which we reached this point. Make no mistake. Humanity is losing. Meanwhile, on top of all the Being Wrong on the Internet, the toxoplasma is as bad as it has ever been, with certain sources going so far as to in large part blame not only worried people in general but also me specifically by name for our current situation – and at least one of those people I feel compelled to continue to listen to because they also have unique insights in other ways and I’m sometimes told I have a blind spot there – which I actually rarely hear about other credible sources. And I still try. But I’m only human and it’s just so damn hard at this point. Especially when they rage about things I said that turned out to be true, and true for exactly the reasons I said they’d be true, but I know trying to point this out wouldn’t do any good. I don’t know what my solution here is going to be. I do know that things can’t go on like this, I know life isn’t fair and reality doesn’t grade on a curve and someone has to and no one else will but also I only have so much in the tank that handles these things. And I’m going to have to budget that tank, but I want to be clear that I’m going to be doing that, and dropping certainly sources for this reason that I would otherwise have included for completeness. If this was talking about you, and you’d like to continue this trip, please get it together. Don’t worry, your argument remains valid. I mean, it’s wrong, but that never stopped you before, why start now? Time comes for us all. Matt: Live players in who kills us first? Peter Wildeford: Yes, that’s one way to look at it. I believe that opensource advancements like R1 will drive wider adoption of ai systems. I think that the pricing models will change soon. Everyone talks about cost per million tokens to contact a hosted service, but I think it'll switch to be cloud costs to provide infrastructure that can run models. Virtual machines running something like ollama. This solves another huge problem, privacy and how prompt data is handled. If you're using an api to a hosted service you need to have a very good understanding of how your submitted prompt data is handled. This is key for organisations. I feel like the lack of understanding here is preventing widespread adoption, especially for communication tools that handle sensitive data. For example, you could run Deepseek R1 using ollama on an Azure virtual machine (nc series) that you pay per hour for, and then your cost isn't based on usage of your ai. Right now it's expensive to provision the infra to support decent models, but these costs fall continuously. I can imagine a world where organisations provision cloud infrastructure in their environments running open source models. https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/gpu-accelerated/nc-series?tabs=sizebasic https://huggingface.co/deepseek-ai/DeepSeek-R1 Is there any other consumer software that works on this model? I can't think of any Some enterprise software has stuff like this A very detailed and technical analysis of the bear case for Nvidia by Jeffrey Emanuel, that Matt Levine claims may have been responsible for the Nvidia price decline. I read that last week. It was an interesting case of experiencing Gell-Mann-Amnesia several times within the same article. All the parts where I have some expertise were vague, used terminology incorrectly and were often just wrong. All the rest was very interesting! If this article crashed the market: EMH RIP. I would hesitate to buy a build based on R1. R1 is special in the sense that the MoE-architecture trades off compute requirements vs RAM requirements. Which is why now these CPU-builds start to make some sense - you get a lot less compute, but much more RAM. As soon as the next dense model drops which could have 5-times fewer parameters for the same performance the build will stop making any sense. And of course until then you are also handicapped when it comes to running smaller models fast. The sweet spot is integrated RAM/VRAM like in a Mac and in the upcoming NVIDIA DIGITS. But buying a handful of used 3090s probably also makes more sense to me then the CPU-only builds. New benchmark agrees with my intuitions on r1's creative writing skills: https://x.com/LechMazur/status/1885430117591027712
--------------------------------------------------

Title: Jim Cramer's top 10 things to watch in the stock market Friday
URL: https://www.cnbc.com/2025/01/31/jim-cramers-top-10-things-to-watch-in-the-stock-market-friday.html
Time Published: 2025-01-31T13:59:10Z
Full Content:
Credit Cards Loans Banking Mortgages Insurance Credit Monitoring Personal Finance Small Business Taxes Help for Low Credit Scores Investing SELECT All Credit Cards Find the Credit Card for You Best Credit Cards Best Rewards Credit Cards Best Travel Credit Cards Best 0% APR Credit Cards Best Balance Transfer Credit Cards Best Cash Back Credit Cards Best Credit Card Welcome Bonuses Best Credit Cards to Build Credit SELECT All Loans Find the Best Personal Loan for You Best Personal Loans Best Debt Consolidation Loans Best Loans to Refinance Credit Card Debt Best Loans with Fast Funding Best Small Personal Loans Best Large Personal Loans Best Personal Loans to Apply Online Best Student Loan Refinance SELECT All Banking Find the Savings Account for You Best High Yield Savings Accounts Best Big Bank Savings Accounts Best Big Bank Checking Accounts Best No Fee Checking Accounts No Overdraft Fee Checking Accounts Best Checking Account Bonuses Best Money Market Accounts Best CDs Best Credit Unions SELECT All Mortgages Best Mortgages Best Mortgages for Small Down Payment Best Mortgages for No Down Payment Best Mortgages with No Origination Fee Best Mortgages for Average Credit Score Adjustable Rate Mortgages Affording a Mortgage SELECT All Insurance Best Life Insurance Best Homeowners Insurance Best Renters Insurance Best Car Insurance Travel Insurance SELECT All Credit Monitoring Best Credit Monitoring Services Best Identity Theft Protection How to Boost Your Credit Score Credit Repair Services SELECT All Personal Finance Best Budgeting Apps Best Expense Tracker Apps Best Money Transfer Apps Best Resale Apps and Sites Buy Now Pay Later (BNPL) Apps Best Debt Relief SELECT All Small Business Best Small Business Savings Accounts Best Small Business Checking Accounts Best Credit Cards for Small Business Best Small Business Loans Best Tax Software for Small Business SELECT All Taxes Filing For Free Best Tax Software Best Tax Software for Small Businesses Tax Refunds Tax Brackets Tax Tips Tax By State Tax Payment Plans SELECT All Help for Low Credit Scores Best Credit Cards for Bad Credit Best Personal Loans for Bad Credit Best Debt Consolidation Loans for Bad Credit Personal Loans if You Don't Have Credit Best Credit Cards for Building Credit Personal Loans for 580 Credit Score or Lower Personal Loans for 670 Credit Score or Lower Best Mortgages for Bad Credit Best Hardship Loans How to Boost Your Credit Score SELECT All Investing Best IRA Accounts Best Roth IRA Accounts Best Investing Apps Best Free Stock Trading Platforms Best Robo-Advisors Index Funds Mutual Funds ETFs Bonds 1. Apple's earnings report shows why I always say "own it, don't trade it." Where it has launched Apple Intelligence, the iPhone 16 sells better. High-margin services revenues was better. Mac better. Accessories better. Europe better. India better. Expanding gross margins helped make the numbers, too. Shares are up about 4% Friday. 2. China is still a question mark for Apple, though. Revenues down 11% there in the quarter. Apple Intelligence still needs government approval to launch. Rivals Huawei and Xiaomi can access the AI from buzzy Chinese startup DeepSeek. What can Apple get to reverse its fortunes in China? Will Baidu be its AI partner? 3. The U.S. government is looking into whether DeepSeek used third-parties in Singapore to acquire Nvidia chips that Washington has banned in China, according to Bloomberg News. Club name Nvidia says it plays by the rules in Singapore, and that its revenue from the island country does not indicate diversion. 4. We know Tesla, Club stock Meta and Oracle want all the high-end Nvidia chips they can get, even with DeepSeek's emergence. We don't know about Club names Alphabet or Amazon, which both report next week. What if one of the two says we are reassessing our orders for Nvidia's next-gen AI platform Blackwell? What happens to the stock? What if Amazon, another Club holding, says it's leaning into using AMD? I made a call on Nvidia stock for Club members yesterday. 5. Geopolitics remain part of the Nvidia dilemma. Does DeepSeek have a juicer that can make 10 glasses of orange juice out of a single orange, or does it have 10 government-subsidized juicers that it just won't tell us about? If it is 10 juicers, I worry that President Donald Trump will just ban all semiconductor exports to China. 6. Trump's 25% tariffs on imports from Canada and Mexico, currently set to take effect Saturday, may exclude oil, the president told reporters Thursday night. U.S. oil benchmark WTI was slightly higher Friday, to roughly $73 barrel. The U.S. dollar index strengthened, but it's still below its recent highs set earlier this month. 7. The S&P 500, Nasdaq and Dow Jones Industrial Average were all set to open higher Friday. Stock futures held onto their gains after the Federal Reserve's preferred inflation gauge matched expectations for December. The PCE index rose 0.3% month over month and, when excluding food and energy, 2.8% on an annual basis. 8. Intel showed some cost discipline and improved cash flow in its quarterly results. But the fourth quarter is typically strong for them, and there might have been some pull-through ahead of higher tariffs on Chinese imports. The PC market is weak. JPMorgan and Wells Fargo cut their price targets on the struggling chip stock. Shares added more than 1% Friday. 9. Atlassian shares jumped almost 20% on the back of a very good quarter. The company, which trades under the ticker TEAM, makes pure enterprise software that makes it easier to share and simplify. Seems unstoppable. 10. Vertex Pharmaceuticals' non-opioid painkiller Journavx, which blocks pain signals sent to the brain at their origin. This drug could be a blockbuster, and it's been on my radar for a while now. Vertex shares climbed about 3% Friday. Sign up for my Top 10 Morning Thoughts on the Market email newsletter for free (See here for a full list of the stocks at Jim Cramer's Charitable Trust.) As a subscriber to the CNBC Investing Club with Jim Cramer, you will receive a trade alert before Jim makes a trade. Jim waits 45 minutes after sending a trade alert before buying or selling a stock in his charitable trust's portfolio. If Jim has talked about a stock on CNBC TV, he waits 72 hours after issuing the trade alert before executing the trade. THE ABOVE INVESTING CLUB INFORMATION IS SUBJECT TO OUR TERMS AND CONDITIONS AND PRIVACY POLICY, TOGETHER WITH OUR DISCLAIMER. NO FIDUCIARY OBLIGATION OR DUTY EXISTS, OR IS CREATED, BY VIRTUE OF YOUR RECEIPT OF ANY INFORMATION PROVIDED IN CONNECTION WITH THE INVESTING CLUB. NO SPECIFIC OUTCOME OR PROFIT IS GUARANTEED. Got a confidential news tip? We want to hear from you. Sign up for free newsletters and get more CNBC delivered to your inbox Get this delivered to your inbox, and more info about our products and services. © 2025 CNBC LLC. All Rights Reserved. A Division of NBCUniversal Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis. Data also provided by
--------------------------------------------------

Title: How DeepSeek Could Really Disrupt Big Tech
URL: https://www.theatlantic.com/ideas/archive/2025/01/deepseek-ai-investment-tech/681516/
Time Published: 2025-01-31T12:46:00Z
Full Content:
The Chinese app has already hit the chipmaker giant Nvidia’s share price, but its true potential could upend the whole AI business model. Produced by ElevenLabs and News Over Audio (Noa) using AI narration. Listen to more stories on the Noa app. Only rarely does a single company’s new product provoke a major market sell-off. But that’s exactly what happened on Monday, when a large language model from a Chinese company named DeepSeek drove the entire Nasdaq index of tech companies down more than 3 percent and shaved more than 17 percent off the market capitalization of the chipmaker Nvidia—which, until that moment, had been the most valuable company in the world. The panicked selling of Nvidia had a surface logic. The company provides almost all of the computer chips (called GPUs) that companies such as Alphabet, OpenAI, Microsoft, and Meta rely on to train their LLMs. (The Atlantic entered into a corporate partnership with OpenAI in 2024.) Consequently, it has been the biggest beneficiary of the huge boom in corporate spending on AI that we’ve seen over the past few years. (Nvidia’s annual revenue has quadrupled since 2022.) Although DeepSeek also used Nvidia chips to train its model, the company said that they were an older type of GPU—U.S. export controls imposed by the Biden administration have prevented Chinese companies from buying cutting-edge chips. DeepSeek’s disclosure raises the possibility that future progress in training LLMs could be made with fewer, simpler chips, and at a lower cost than previously anticipated. That would obviously put a big dent in Nvidia’s profits. So investors dumped its stock. Read: The DeepSeek wake-up call If investors are very concerned about how DeepSeek might hurt chipmakers, they seem surprisingly unconcerned about how it might affect big AI software companies. Meta’s stock price, for instance, actually rose on Monday, and although the stocks of Alphabet and Microsoft did take a hit, they bounced back over the next couple of days. Some of that is because the underlying business of these companies, independent of AI, remains enormously profitable. But it also suggests that investors aren’t paying enough attention to the way DeepSeek’s success could disrupt the AI market, and in doing so threaten the future profits of the tech companies that are currently spending many billions of dollars every year on their LLMs. Tech investors have historically profited by spotting the new new thing. But at the moment, they seem implicitly to assume that all of the fundamental change in the LLM business has already happened and that its future will look much like its present, with the companies that currently dominate the space—many of which are not simply competitors but also financial partners—continuing to do so indefinitely. What happened over the past week is a reminder that these assumptions may not be so solid. The large language model that caused such a stir on Monday, DeepSeek-R1, is clearly comparable with LLMs such as ChatGPT o1-mini and Claude 3.5. Measured by industry benchmarks that rate subject knowledge, reasoning, and accuracy, the DeepSeek model seems to deliver similar performance while costing much less to develop—though just how much less remains a matter of debate. Beyond dispute is that it’s cheaper to use: Consumers can get access to DeepSeek’s core functions for free, and third-party developers are being charged a fraction of the cost of a product such as ChatGPT. DeepSeek also uses open-source technology, meaning that, in theory, you could download the program and run your own AI on your desktop if you had a powerful-enough computer. The fact that the LLM offers reasonable performance—results that, even a year ago, would have seemed startlingly good—at a significantly lower cost means that it has to be taken seriously as a competitor. From one angle, in fact, DeepSeek looks like what the business-school professor Clayton Christensen, in his book The Innovator’s Dilemma, dubbed a “disruptive technology”: a product that’s less powerful than the products at the top of the market but also much cheaper, and that has the possibility of improving in quality over time to the point where it offers a superior combination of price and performance for most customers. In this regard, the rapid uptake of DeepSeek by users around the world has been striking. The LLM still has miles to go in market share to catch ChatGPT, which has more than 300 million weekly users, but since its release on January 20, its mobile-app version has been downloaded more than 3 million times from Google Play and Apple, making it the most popular app on both stores. That suggests that the cost of switching from one AI tool to another is very low, and that the moats big AI companies are building around their business may be much shallower than they’d hoped. Read: China’s DeepSeek surprise The underlying wager that these companies have made is that the big money they’re investing will result in radically better performance, which in turn will enable them to charge hefty sums to businesses and, to a lesser extent, consumers. (OpenAI, for instance, is reportedly targeting $100 billion in revenue by 2029.) And these companies remain committed to that bet. This week, the CEOs of both Microsoft and Meta said that enormous spending is essential to staying competitive in the market. Dario Amodei, a co-founder and the CEO of Anthropic (in which both Amazon and Google have invested heavily), wrote in a blog post that companies are going to continue to “spend more and more on training powerful AI models, even as … the cost of training a given level of model intelligence declines rapidly,” because “the economic value of training more and more intelligent models is so great.” In the long run, such investment may well result in the kind of performance improvement that a company like DeepSeek (which can’t even get access to the most powerful GPUs)—or the many other low-cost LLM developers that are sure to try to emulate it—cannot keep up with. When you look at ordinary users’ embrace of DeepSeek, though, you can also see an alternative future. In this one, AI performance improves so much that most customers are happy with cheap, good-enough LLMs, and AI models end up as essentially interchangeable, commoditized products, with the small profits that always follow that type of commercial diffusion. We’re going to find out whether the great authors of the disruptive technology that’s transforming the business world might themselves get disrupted. Support for this project was provided by the William and Flora Hewlett Foundation. More Stories The Hysterical Crypto Bubble Somehow Became Respectable The Trump-Whim Economy Is Here
--------------------------------------------------

Title: An Interview with Matthew Ball About the Gaming Slump
URL: https://stratechery.com/2025/an-interview-with-matthew-ball-about-the-gaming-slump/
Time Published: 2025-01-31T11:30:50Z
Full Content:
Stratechery Plus Learn MoreMember Forum Stratechery Plus Learn MoreMember Forum Latest Podcast Listen to Podcast Subscribe to Stratechery Plus for full access. Already subscribed? With Stratechery Plus you get access to the subscriber-only Stratechery Update and Stratechery Interviews, and the Sharp Tech, Sharp China, Dithering, Greatest of All Talk, and Asianometry podcasts. Stratechery UpdateSubstantial analysis of the news of the day delivered via three weekly emails or podcasts. Stratechery InterviewsInterviews with leading public CEOs, private company founders, and discussions with fellow analysts. DitheringA twice-weekly podcast from John Gruber and myself: 15 minutes an episode, not a minute less, not a minute more. Sharp TechAndrew Sharp and myself discuss how technology works and the ways it impacts our lives. Sharp ChinaA weekly podcast from Andrew Sharp and Sinocism’s Bill Bishop about understanding China and how China impacts the world. Greatest Of All TalkA twice-weekly podcast from Andrew Sharp and Ben Golliver about the NBA, life, and national parks. AsianometryAudio and transcripts of the Asianometry YouTube channel, the best source for learning about how tech works. Stratechery Updates are also available via SMS, RSS, or on this site. Please see the Stratechery Update Schedule for more details about delivery times and planned days-off. Please note that all subscriptions auto-renew monthly/annually (but can be cancelled at any time). If you are interested in ordering and managing multiple subscriptions for your team or company, please fill in the form here. Once you are subscribed, please visit your Delivery Preferences where you will find easy-to-follow instructions for adding Stratechery Podcasts to your favorite podcast player. Yes! Create a Stratechery Passport account, go to Delivery Preferences, and add your personalized RSS feed. Free accounts will have access to Weekly Articles, while subscribers will have access to the Daily Update as well. No, the Stratechery Update and Stratechery Podcast are intended for one subscriber only. Sharing emails, using shared inboxes, or sharing RSS feeds is a violation of Stratechery’s Terms of Service, and your account may be suspended or your RSS feed reset. Of course occasional forwarding of the Stratechery Update to interested friends or colleagues is totally fine. Yes! You can purchase a team subscription here. Yes! Just go to your account page, choose the ‘Subscriptions’ tab, and click the Annual upgrade button. You will be charged immediately, with a prorated discount applied for the remainder of your current monthly plan. Stratechery is purposely kept at a low price — thousands of dollars less than other analyst reports or newsletters — to ensure it is accessible to everyone, including students. I am happy to create an invoice to your specification for annual subscribers; however, it is simply not viable for me to offer this service to monthly subscribers. Therefore, if you need a custom invoice please subscribe or switch to an annual subscription and contact Stratechery. June 1, 2021 Update: We are hoping to add native support for custom invoices to Passport; you can subscribe to Passport Updates to be notified when it is available. Yes! To send a gift visit the gifts page. Stratechery Plus Updates Stratechery Plus Podcasts Stratechery Plus Interviews The most popular and most important posts on Stratechery by year. Explore all free articles on Stratechery. Explore all posts on Stratechery. Stratechery Plus UpdateS Stratechery Plus Podcasts Stratechery Plus Interviews © Stratechery LLC 2025 | Terms of Service | Privacy Policy Proudly powered by WordPress. Hosted by Pressable.
--------------------------------------------------

Title: M.M., Tempi, and the fainthearted, rumors of an acquisition by Piraeus bank, DEI and the Norwegians, and the… progressive lobbies of the stock market
URL: https://en.protothema.gr/2025/01/31/m-m-tempi-and-the-fainthearted-rumors-of-an-acquisition-by-piraeus-bank-dei-and-the-norwegians-and-the-progressive-lobbies-of-the-stock-market/
Time Published: 2025-01-31T09:39:22Z
Full Content:
Tempi and Government Stress Levels Hello, the Tempi case continues to dominate public interest while also creating an extremely stressful situation within the government’s ranks, to the point where, dare I say, most of them are on the verge of a nervous breakdown. Not all of them, of course—there are also the level-headed ones who view Mitsotakis’ public appearance as a “necessary move for partial de-escalation and as proof to the public that the Prime Minister is listening, taking responsibility, and trying to solve problems, even assuming full accountability.” However, this is merely the calm assessment of some officials. There’s also the classic “fainthearted” reaction: “We’re doomed! The reports, the Preliminary Investigations, the trials are coming, and we’ll be entangled in this mess indefinitely.” Now, let me tell you what I know from my sources: First, the NTUA report, according to my information, will be ambiguous—it will state that the fireball was not caused by the lubricants used in the train’s engine, but at the same time, it will not confirm the presence of any flammable material. A report by a Belgian expert is expected to lean slightly more towards the existence of some quantity of flammable substance, but there are also reports suggesting otherwise. The government’s response to all this will be the obvious one: “Let everything go to the judiciary and let them draw the appropriate conclusions.” Second, regarding whether there will be a Preliminary Investigation Committee, the answer from an official source is crystal clear: “We’ve said dozens of times that if the Prosecutor’s indictment includes political figures, the government will facilitate the process and accept the establishment of a Preliminary Investigation Committee. But only if the judiciary requests it—not based on lawsuits filed by the victims’ families.” Third, the Tempi trial has been expected since day one. The government, through Floridis, even amended the law to expedite it, unlike the Mati trial, which took six years to begin. These are the facts, and this is the government’s approach. Where responsibility remains unclear is in what has been done from the time of the accident until now to allow the state to credibly say: “Here are the measures we’ve taken to drastically reduce the chances of this tragedy happening again.” Because, let’s not forget, accidents will always happen—whether in Washington, at the heart of the most technologically advanced transport system, or anywhere else. Also, a legal expert told me that the infamous case of backfilling (of the tracks) constitutes only a misdemeanor. As soon as K.M. (Kyriakos Mitsotakis) made statements about the Investigation Committee, former members of such committees turned pale. Many prominent figures involved avoided answering phone calls, something the government picked up on and decided to do some political “massaging.” The message from the government was that the Prime Minister’s position was a general one—this is his standard stance on Investigation Committees, which rarely produce clear conclusions. Therefore, the judiciary should be the one to provide the answers. I’m not sure if this improved anyone’s morale, but such is politics. February will be a long and rough month for the government, with various reports and inquiries on the way. Now, in M.M. (Maximos Mansion, the Greek Prime Minister’s office), they are not politically naive. They were not surprised by Androulakis’ intention to file a no-confidence motion against the government. The timing, of course, is the crucial factor. It’s clear that Androulakis is waiting for both the NTUA report and the report from EODASAAM (due on February 27) before making his move—coinciding with the second anniversary of the Tempi disaster. Obviously, he aims to align with public sentiment—thousands protesting in the streets while the government faces pressure in Parliament. Notably, this will be the second no-confidence motion filed by PASOK within a year. And to be fair, Androulakis is simply doing his job. Today’s Cabinet meeting, of course, is overshadowed by the Tempi case and the announcement of the no-confidence motion, but there are serious issues on the agenda. One of them is the Ministry of Education’s initiative to hire 600 priests over the next three years for the Greek-speaking Patriarchates. This has been a long-standing request of Patriarch Bartholomew, and Pierrakakis intends to grant it. It’s also a move with geopolitical significance, as Greece seeks to expand its soft power in the region, strengthening its influence through its Christian heritage. Now, let’s turn to market news, where all eyes are on a major move being prepared (intensely) by H. Megalou. But with acquisitions, you never really know—things usually turn out differently from what the market senses. Sources indicate that within the next two or three days, it will become clear whether Piraeus Bank’s plan will materialize. The very few details available suggest an acquisition, and not just any acquisition—a large-scale one. So, the “usual suspects” are ruled out. One rumor that surfaced on Dark Room’s radar—and let me stress, this is just a RUMOR, NOT VERIFIED INFORMATION—is that H. Megalou’s big move is towards acquiring Ethniki Asfalistiki (National Insurance). Given that acquisitions often turn out different from market expectations, this scenario could be plausible. But it’s not simple or easy—National Insurance’s bancassurance agreement is with National Bank of Greece, and I don’t know what penalties or clauses that contract might include. However, if this deal is indeed in the works, I assume they have found a way around it. Strategically, it would make sense, as the ECB’s rapid interest rate cuts are pushing banks to seek acquisitions in sectors with high commission revenues. I don’t know the details, but it seems that market rumors about a small lobby that has grabbed Proodeftiki’s stock and sent it skyrocketing are not unfounded. The stock has closed higher for five consecutive sessions. From €0.28, it has surged to €0.376 (+34%). In two of those five sessions, it gained over 9%, and yesterday it closed up 5.6%. Proodeftiki used to be a construction company—now, I have no idea what they do (some say real estate), but for all I know, they might as well be in aerospace. Recent developments in Artificial Intelligence have a uniquely Greek angle. A startup called AI-Employee has been operating in Greece and launched a soft rollout 10 days ago. What do they do? They “rent out” AI executives to large corporations. These specialized employees enter companies with their own hardware and localized AI models. In fact, as founder John Doxaras announced on LinkedIn, AI-Employee “sold out” in record time, managing to place ALL of its available AI professionals. These AI-powered employees come equipped with AI agents, work within organizations to solve problems on the spot, develop new applications and solutions, and provide extensive training on AI prompting. Despite being just two weeks old, the Greek startup has already attracted clients from the banking sector, telecommunications, and even government agencies. Now, let’s head to Paris, specifically to the Palais-Royal area, where the Greek Roadshow by Piraeus Securities took place at Espace Clery. The event featured Greece’s top publicly traded companies, and French fund managers showed intense interest, with 150 meetings held with 30 different funds—compared to last year’s 116 meetings with 24 funds. As an investor relations executive from a participating company explained, the French investment market is challenging due to its broad spectrum of investors. Some funds are highly targeted and long-term, seeing opportunities in Greece, while others, as one analyst put it, are starting “from scratch” with no real knowledge of the Greek market. However, what stood out to many IR professionals and executives was the sense of instability surrounding France’s economic and political outlook, a concern that surfaced repeatedly in discussions. Regarding Greek assets, the French highlighted clear advantages, such as Greece’s regained investment-grade rating, its comparatively strong economic growth within the EU, and high dividend yields. PPC (Public Power Corporation) is charging toward a €5 billion market cap, with its stock price at €13.27—an 11-year high. Norway’s sovereign wealth fund, the Norges Fund, known as the ultimate “long-only fund,” consistently invests in “green” projects and has officially acquired a 0.14% stake in PPC, though market whispers suggest its actual holding is higher. Over the past three months, 23.5 million PPC shares have changed hands, with the stock price rising more than 10.6%. This surge in activity has fueled fresh speculation about PPC’s next big deal, one that CEO Giorgos Stassis is rumored to be working on—though lately, he’s been keeping a low profile. The stock of Viohalco, the parent company of the Viohalco Group, has gained roughly 14% over the past month, reaching €6.10. Its market capitalization now exceeds €1.58 billion, while its 72%-owned subsidiary, Cenergy, has surpassed €2 billion (€9.60 per share, up 2.24% yesterday). This means that all the other subsidiaries within the group—ElvalHalcor, Noval Property, etc.—are currently valued at essentially zero, despite the fact that the group as a whole contributes 8% of Greece’s GDP. Unless the sky falls on our heads today, the General Index will log its fourth consecutive positive week of 2025 and its sixth straight week of gains since mid-December 2024. The index hasn’t closed above 1,550.72 points (+0.3%) since way back on April 7, 2011. However, with trading volume at €108.9 million (of which €8.2 million came from block trades), the rally isn’t exactly convincing. In fact, buyers were largely absent for most of yesterday’s session, only showing up after 4 PM to keep heavyweight stocks in positive territory. Coca-Cola, Eurobank, and Motor Oil propped up the index, while other blue-chip stocks simply managed to shake off their earlier losses and stabilize. Not one, not two, but a whopping 35-minute delay (!) in announcing its earnings sent Mark Zuckerberg’s META (who, by the way, is house-hunting in Washington to be as close as possible to Trump) into a tailspin, causing a mini-meltdown on Wall Street. In that half-hour, META’s stock price swung wildly up and down based on AI-related rumors. In the end, META beat analyst expectations on both revenue and earnings per share ($8.02/share), bringing in $48.4 billion in revenue. Microsoft’s stock went through a similar ordeal—it posted stronger-than-expected profits but weak cloud revenue, and in this new AI-driven market, everything counts. Amid all this digital economy turbulence, one thing that truly shines is gold, which hit a new all-time high of $2,840 per ounce, marking a staggering 40% gain over the past 12 months. “If the Fed had spent less time on DEI—the Diversity, Equity, and Inclusion strategy—gender ideology, ‘green’ energy, and the fake climate change, inflation would never have been a problem. Instead, we suffered from the worst inflation in our country’s history.” The term of U.S. Federal Reserve Chairman Jerome Powell ends in 15 months, in May 2026. President Trump’s war against the Fed began on day one of his presidency. His view is that by increasing oil supply (“drill baby drill”), he will lower energy prices and, in turn, reduce inflation, leading to lower interest rates. Since January 20, crude oil and natural gas prices have dropped by more than 10%. Energy affects the Consumer Price Index by approximately 8%. However, energy costs also influence food prices and other services. Since Trump’s reelection in November, U.S. gasoline prices have dropped to $3.08 per gallon, close to the lowest level since 2021. Consequently: A $10 decrease in oil prices would reduce U.S. inflation by 0.2%. If oil prices fall to around $50, inflation could drop by nearly half a percentage point. However, the Fed’s priority is not just price stability—it also includes employment and economic stability. Some Federal Reserve Board members are Republicans (such as the St. Louis Fed banker), but they do not share Trump’s urgency to cut interest rates on the dollar, as the large public debt forces the Fed to borrow at high costs. The Trump-Powell war is only in its first phase. The German government announced the day before yesterday that economic growth in 2025 will barely exceed +0.3%, despite initial forecasts of +1.6%, later revised to +1.1%, and ultimately proven wrong. Yesterday, it was officially confirmed that in the fourth quarter of the year, Germany’s economic growth rate was negative (-0.2%), even worse than the initial estimates (-0.1%). Key economic indicators, such as the Ifo Business Climate Index or incoming orders, provide little reason for optimism. The elections in Germany are taking place in an atmosphere of general uncertainty, and we all know where that leads. Explore related questions
--------------------------------------------------

Title: Why stock market is rising today: 5 key factors behind today's rally; Sensex soars 600 pts, Nifty above 23,400
URL: https://economictimes.indiatimes.com/markets/stocks/news/why-stock-market-is-rising-today-5-key-factors-behind-todays-rally-sensex-soars-600-pts-nifty-above-23400/articleshow/117783991.cms
Time Published: 2025-01-31T09:37:02Z
Full Content:
Stock Trading Maximise Returns by Investing in the Right Companies By - The Economic Times, Get Certified By India's Top Business News Brand Stock Trading Market 104: Options Trading: Kickstart Your F&O Adventure By - Saketh R, Founder- QuickAlpha, Full Time Options Trader Stock Trading Technical Analysis for Everyone - Technical Analysis Course By - Abhijit Paul, Technical Research Head, Fund Manager- ICICI Securities Stock Trading Stock Markets Made Easy By - elearnmarkets, Financial Education by StockEdge Stock Trading Renko Chart Patterns Made Easy By - Kaushik Akiwatkar, Derivative Trader and Investor Stock Trading Market 101: An Insight into Trendlines and Momentum By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading Markets 102: Mastering Sentiment Indicators for Swing and Positional Trading By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading Dow Theory Made Easy By - Vishal Mehta, Independent Systematic Trader Stock Trading Market 103: Mastering Trends with RMI and Techno-Funda Insights By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading ROC Made Easy: Master Course for ROC Stock Indicator By - Souradeep Dey, Equity and Commodity Trader, Trainer Stock Trading Heikin Ashi Trading Tactics: Master the Art of Trading By - Dinesh Nagpal, Full Time Trader, Ichimoku & Trading Psychology Expert Stock Trading RSI Made Easy: RSI Trading Course By - Souradeep Dey, Equity and Commodity Trader, Trainer Stock Trading Introduction to Technical Analysis & Candlestick Theory By - Dinesh Nagpal, Full Time Trader, Ichimoku & Trading Psychology Expert (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025, Share Market on Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025, Share Market on Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price Will the Budget boost consumption? The equity market has some clues. With more cash in pocket, will the missing urban consumer return to the shops? Now that tariffs are here, what's in store for the WTO? Ather, Ola, TVS, and Hero public notices: Here’s how you can claim your charger refund! GIFT IFI: An ADB-funded fintech school to teach coding to bankers, and banking to coders Nirmala Sitharaman is tinkering to turn growth narrative from K To U All Mutual Funds Top Tax Saving Mutual Funds Better Than Fixed Deposits Low Cost High Return Funds Best Hybrid Funds Best Large Cap Funds SIP’s starting Rs. 500 Top Performing Mid Caps Promising Multi Cap Funds Top Rated Funds Top Performing Index Funds Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Definitions Top Commodities Top Prime Articles Top Slideshow Top Story Listing Top Market Pages Private Companies Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Worry not. You’re just a step away. It seems like you're already an ETPrime member with Login using your ET Prime credentials to enjoy all member benefits Log out of your current logged-in account and log in again using your ET Prime credentials to enjoy all member benefits. Offer Exclusively For You Save up to Rs. 700/- ON ET PRIME MEMBERSHIP Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get Flat 40% Off Then ₹ 1749 for 1 year Offer Exclusively For You ET Prime at ₹ 49 for 1 month Then ₹ 1749 for 1 year Special Offer Get flat 35% off on ETPrime ₹ 90 Days Prime access worth Rs999 unlocked for you Stories you might be interested in
--------------------------------------------------

Title: Chinese state-linked accounts hyped DeepSeek AI launch ahead of US stock rout: report
URL: https://economictimes.indiatimes.com/tech/technology/chinese-state-linked-accounts-hyped-deepseek-ai-launch-ahead-of-us-stock-rout-report/articleshow/117768215.cms
Time Published: 2025-01-31T03:48:14Z
Full Content:
Budget with ET Budget Highlights: Gareeb, youth, annadata and naari feature in Budget. What about taxes? New vs Old tax regime: Here's a decoder to help you choose the right one Will you pay more under new tax regime or old? Calculate here Artificial Intelligence(AI) Java Programming with ChatGPT: Learn using Generative AI By - Metla Sudha Sekhar, IT Specialist and Developer Artificial Intelligence(AI) Basics of Generative AI: Unveiling Tomorrows Innovations By - Metla Sudha Sekhar, IT Specialist and Developer Artificial Intelligence(AI) Generative AI for Dynamic Java Web Applications with ChatGPT By - Metla Sudha Sekhar, IT Specialist and Developer Artificial Intelligence(AI) Mastering C++ Fundamentals with Generative AI: A Hands-On By - Metla Sudha Sekhar, IT Specialist and Developer Artificial Intelligence(AI) Master in Python Language Quickly Using the ChatGPT Open AI By - Metla Sudha Sekhar, IT Specialist and Developer Marketing Performance Marketing for eCommerce Brands By - Zafer Mukeri, Founder- Inara Marketers Office Productivity Zero to Hero in Microsoft Excel: Complete Excel guide 2024 By - Metla Sudha Sekhar, IT Specialist and Developer Finance A2Z Of Money By - elearnmarkets, Financial Education by StockEdge Marketing Modern Marketing Masterclass by Seth Godin By - Seth Godin, Former dot com Business Executive and Best Selling Author Astrology Vastu Shastra Course By - Sachenkumar Rai, Vastu Shashtri Strategy Succession Planning Masterclass By - Nigel Penny, Global Strategy Advisor: NSP Strategy Facilitation Ltd. Data Science SQL for Data Science along with Data Analytics and Data Visualization By - Metla Sudha Sekhar, IT Specialist and Developer Artificial Intelligence(AI) AI and Analytics based Business Strategy By - Tanusree De, Managing Director- Accenture Technology Lead, Trustworthy AI Center of Excellence: ATCI Web Development A Comprehensive ASP.NET Core MVC 6 Project Guide for 2024 By - Metla Sudha Sekhar, IT Specialist and Developer Marketing Digital Marketing Masterclass by Pam Moore By - Pam Moore, Digital Transformation and Social Media Expert Artificial Intelligence(AI) AI-Powered Python Mastery with Tabnine: Boost Your Coding Skills By - Metla Sudha Sekhar, IT Specialist and Developer Office Productivity Mastering Microsoft Office: Word, Excel, PowerPoint, and 365 By - Metla Sudha Sekhar, IT Specialist and Developer Marketing Digital marketing - Wordpress Website Development By - Shraddha Somani, Digital Marketing Trainer, Consultant, Strategiest and Subject Matter expert Office Productivity Mastering Google Sheets: Unleash the Power of Excel and Advance Analysis By - Metla Sudha Sekhar, IT Specialist and Developer Web Development Mastering Full Stack Development: From Frontend to Backend Excellence By - Metla Sudha Sekhar, IT Specialist and Developer Finance Financial Literacy i.e Lets Crack the Billionaire Code By - CA Rahul Gupta, CA with 10+ years of experience and Accounting Educator Data Science SQL Server Bootcamp 2024: Transform from Beginner to Pro By - Metla Sudha Sekhar, IT Specialist and Developer 5 Stories 7 Stories 9 Stories 9 Stories 8 Stories 6 Stories Will the Budget boost consumption? The equity market has some clues. With more cash in pocket, will the missing urban consumer return to the shops? Ather, Ola, TVS, and Hero public notices: Here’s how you can claim your charger refund! GIFT IFI: An ADB-funded fintech school to teach coding to bankers, and banking to coders Nirmala Sitharaman is tinkering to turn growth narrative from K To U Stock Radar: Bajaj Finance hits fresh record high in January 2025 – will the momentum continue? Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Commodities Top Prime Articles Top Slideshow Private Companies Top Definitions Top Story Listing Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Worry not. You’re just a step away. It seems like you're already an ETPrime member with Login using your ET Prime credentials to enjoy all member benefits Log out of your current logged-in account and log in again using your ET Prime credentials to enjoy all member benefits. To read full story, subscribe to ET Prime ₹34 per week Billed annually at ₹2499 ₹1749 Super Saver Sale - Flat 30% Off On ET Prime Membership Offer Exclusively For You Save up to Rs. 700/- ON ET PRIME MEMBERSHIP Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get Flat 40% Off Then ₹ 1749 for 1 year Offer Exclusively For You ET Prime at ₹ 49 for 1 month Then ₹ 1749 for 1 year Special Offer Get flat 35% off on ETPrime 90 Days Prime access worth Rs999 unlocked for you Exclusive Economic Times Stories, Editorials & Expert opinion across 20+ sectors Stock analysis. Market Research. Industry Trends on 4000+ Stocks ​Get 1 Year Complimentary Subscription of TOI+ worth Rs.799/-​ Stories you might be interested in
--------------------------------------------------

Title: Chinese state-linked accounts hyped DeepSeek AI launch ahead of US stock rout, Graphika says
URL: https://www.aol.com/news/chinese-state-linked-accounts-hyped-031407600.html
Time Published: 2025-01-31T03:14:07Z
Full Content:
For premium support please call: For premium support please call: By Katie Paul and Stephen Nellis NEW YORK (Reuters) - Chinese state-linked social media accounts amplified narratives celebrating the launch of Chinese startup DeepSeek's AI models last week, days before the news tanked U.S. tech stocks, according to online analysis firm Graphika. The accounts involved in the effort, including those of Chinese diplomats, embassies and state media, amplified media coverage of the launch and promoted the idea that DeepSeek challenged U.S. dominance in the AI sector, New York-based Graphika said in a report it provided to Reuters on Thursday. The messaging was rolled out on platforms such as Elon Musk's X and Meta Platforms' Facebook and Instagram, as well as Chinese services Toutiao and Weibo, Graphika said. "This activity shows how China is able to quickly mobilize a range of actors that seed and amplify online narratives casting Beijing as surpassing the U.S. in critical areas of geopolitical competition, including the race to develop and deploy the most advanced AI technologies," Graphika Chief Intelligence Officer Jack Stubbs told Reuters. "We've consistently seen overt and covert Chinese state-linked actors among the first movers in leveraging AI to scale their operations in the information environment." Graphika said it also found a video featuring pro-China, anti-Western content on a YouTube channel whose activity resembled that of Shadow Play, a coordinated influence campaign involving at least 30 YouTube channels that was first identified by the Australian Strategic Policy Institute in 2023. YouTube owner Alphabet, Meta, X and the Chinese embassy in Washington, D.C. did not immediately respond to requests for comment on the report. Graphika said it found a small spike in discussion about DeepSeek's advancements in relation to OpenAI's ChatGPT on X immediately after DeepSeek released its models on Jan. 20, followed by a much larger uptick that started on Friday and continued to build over the weekend. By Monday, DeepSeek's free AI assistant had overtaken U.S. rival ChatGPT in downloads from Apple's app store and global investors dumped U.S. tech stocks, wiping $593 billion off chipmaker Nvidia's market value in a record one-day loss for any company on Wall Street. Nvidia declined to comment on the Graphika report. DeepSeek's researchers claim to have developed aspects of their AI model at a far lower cost than U.S. rivals, sparking worries that U.S. companies that have plowed tens of billions of dollars into AI data centers could face a price war with China. Shares of Microsoft, a major investor in OpenAI that operates data centers on behalf of the ChatGPT creator, slid earlier this week when it disclosed slower cloud revenue growth than Wall Street expected while it continued to plow billions into capital expenditures. Microsoft and Meta have vowed to continue deep investments in AI for the foreseeable future. DeepSeek's rise to prominence was celebrated in China as a sign that the nation was beating back Washington's attempts to contain China's tech industry with curbs on technology exports. In the U.S., DeepSeek's accomplishments sparked accusations that it had improperly accessed technology from OpenAI and other leaders, though the allegations remain unproved. The U.S. Commerce Department is looking into whether DeepSeek has been using U.S. chips that are not allowed to be shipped to China, a person familiar with the matter said. (Reporting by Katie Paul in New York and Stephen Nellis in San Francisco; Editing by Himani Sarkar) Advertisement Advertisement Advertisement Advertisement Advertisement Advertisement Advertisement Advertisement Advertisement Advertisement
--------------------------------------------------

Title: Tech and logistics giants see significant activity in open market
URL: https://qz.com/tech-and-logistics-giants-see-significant-activity-1851752064
Time Published: 2025-01-30T22:55:00Z
Full Content:
This story incorporates reporting from Yahoo, Barron’s on MSN.com and The Associated Press on MSN.com.On January 30, several major stocks, including those of Tesla, Microsoft, Meta, and UPS, saw notable movements in the U.S. stock market. Tesla’s share price fluctuated as investors reacted to the company’s recent earnings report. Microsoft experienced movement linked to the ongoing developments in its cloud computing segment, while Meta’s stock showed responsiveness to new initiatives in virtual and augmented reality technologies. Nvidia observed changes amidst the growing demand in semiconductor markets. IBM’s stock performance was influenced by recent strategic shifts in its technology consulting division. Logistical shifts were evident as UPS’s market activity followed announcements tied to its global operations. Comcast faced dynamic trading amid updates related to its media and theme parks ventures. In the hospitality and travel sectors, Las Vegas Sands experienced stock movement as shifts in travel restrictions impacted its operations. American Airlines saw fluctuations tied to its operational metrics and passenger forecasts. Network technology company Juniper observed increased trading activity, possibly due to announcements about its latest networking solutions. Quartz Intelligence Newsroom uses generative artificial intelligence to report on business trends. This is the first phase of an experimental new version of reporting. While we strive for accuracy and timeliness, due to the experimental nature of this technology we cannot guarantee that we’ll always be successful in that regard. If you see errors in this article, please let us know at qi@qz.com. Our free, fast, and fun briefing on the global economy, delivered every weekday morning.
--------------------------------------------------

Title: How Democrats alienated Big Tech — and why it might not matter
URL: https://www.vox.com/politics/397525/trump-big-tech-musk-bezos-zuckerberg-democrats-biden
Time Published: 2025-01-30T22:02:51Z
Full Content:
When news breaks, you need to understand what matters — and what to do about it. At Vox, our mission to help you make sense of the world has never been more vital. But we can’t do it on our own. We rely on readers like you to fund our journalism. Will you support our work and become a Vox Member today? Democrats have paid a political price for taking on Silicon Valley — but not a very expensive one. by Eric Levitz In January 2017, Sergey Brin rallied beside progressive activists at San Francisco International Airport to protest Donald Trump’s travel ban. Eight years later, the Google co-founder sat with right-wing nationalists at Trump’s second inauguration. Brin is far from the only tech mogul who has (apparently) warmed to Trump in recent years. Mark Zuckerberg once bankrolled liberal causes. Now, the Facebook founder dines with America’s favorite insurrectionist at Mar-a-Lago. In 2016, Marc Andreessen argued that Hillary Clinton was the “obvious choice” for president, and that any proposal to choke off immigration “makes me sick to my stomach.” Last year, Andreessen endorsed Trump. And, of course, Elon Musk has gone from being an Obama-supporting climate hawk to quite possibly the single most influential advocate for — and patron of — far-right politics in the United States. The lessons liberals should take away from their election defeat — and a closer look at where they should go next. From senior correspondent Eric Levitz. Silicon Valley’s apparent rightward shift was already causing consternation in blue America last year. But Democrats’ outrage and anxiety over the red-pilling of Silicon Valley has only increased since Inauguration Day — when Brin, Zuckerberg, Musk, Jeff Bezos, Alphabet CEO Sundar Pichai, and Apple CEO Tim Cook all sat with Trump’s camp in the Capitol Rotunda. Some Democrats view Big Tech’s rightward lurch as a political crisis, one brought on by their own party’s policy mistakes. In this account, Democrats needlessly alienated a powerful industry by embracing an anti-corporate economic agenda that is both politically costly and substantively misguided. Others in the party, meanwhile, insist that the Biden administration’s attempts to tame Big Tech’s power were both good politics and good policy. In their telling, voters hate corporate monopolies and love antitrust enforcement. And the extraordinary wealth and power of large tech companies constitute a threat to democratic government — a reality that Silicon Valley’s present chumminess with Trump only underscores. From this vantage, the tech industry’s interests and the general public’s were always irreconcilable. And as Silicon Valley grew wealthier, it was bound to gravitate toward America’s more pro-business party. The Biden administration’s error, therefore, was not doing too much to antagonize Big Tech, but too little. This debate collapses together several distinct questions. Some of these are ideological — such as whether the Biden administration’s approach to antitrust enforcement was worthwhile on the merits. Today though, I want to focus on two factual questions at the center of the intra-Democratic dispute over Big Tech: I think the answers to both these questions are more complicated than either progressive or pro-business Democrats allow. To understand why Silicon Valley has moved right in recent years, it’s helpful to consider what had previously tethered the industry to the center-left. Many in the tech world argue that Silicon Valley and the Democratic Party were long bound by an implicit “deal”: Democrats would support the development of new technology, celebrate entrepreneurs, and take a light touch approach to regulating the digital sphere — in exchange for tech moguls backing socially liberal causes, progressive taxation, incremental expansions of the welfare state, philanthropies, and Democratic candidates. This was a pretty good bargain for the typical tech founder — since it effectively entailed the Democratic Party embracing nearly all of their preferences. Survey data on the views of Silicon Valley moguls is limited. But a 2017 study of tech entrepreneurs’ politics found that they were left-leaning on almost all issues — including taxation and redistribution — but quite right-wing on questions of government regulation and labor unions. This distinct ideological profile has been dubbed “liberal-tarian.” Given that Democrats have always been the party more supportive of regulating industry and promoting organized labor, the party’s alliance with tech was long fraught with some tension. But in recent years, both sides began souring on their supposed contract for a variety of reasons. But three were especially significant: When an industry is enjoying explosive growth, it has less incentive to align with the right. Democrats might nibble into its profits with their relatively high taxes, or inch its compliance costs with their greater regulatory scrutiny. But when your sector is awash in cheap financing and soaring revenues, the price of allying with a left-of-center party can look negligible. As Andreessen put the point to the New York Times earlier this month, back in the days of Clinton and Obama, “the tax rates didn’t really matter because when an internet company worked, it grew so fast and got so valuable that if you worked another three years, say, you’d make another 10 X. Another 5 percent higher tax rate washed out in the numbers.” Silicon Valley enjoyed such favorable conditions for much of the 2010s. But the tech boom faded during Biden’s tenure. In 2022, rising interest rates started diverting capital away from the tech sector: With safe assets now offering an attractive guaranteed return, investors grew more reluctant to funnel cash into risky ones. Stock market valuations fell and layoffs spread. At the same time, as Noah Smith notes, tech investors and executives started running up against structural constraints on profit-making. Many venture capitalists looked at Google and Facebook’s success in cornering and dominating their respective markets, and bet that they could establish similarly monopolistic businesses in other corners of digital commerce. But by 2022, they’d discovered that achieving such market dominance was harder than they’d thought. Meanwhile, social media companies struggled to combat the inherently finite nature of human attention: Once you’ve lured roughly 5 billion humans onto social media — and turned a hefty percentage of them into addicts — there’s only so much screen time left to monetize. In this context, we would expect tech moguls who’d been only lightly committed to the “liberal” part of liberal-tarianism to start heeding their own narrow material interests. After all, it was a similar mix of rising interest rates, inflation, and slowing profitability that helped prompt corporate America’s right turn in the 1970s. To be sure, the tech industry’s fortunes have rebounded since 2022, thanks in no small part to the AI boom. But the experience of a capital crunch and profit squeeze — however temporary — seems to have made a lasting impression on many in tech, whose political contributions began shifting (modestly) toward Republicans in 2022. For the reasons above, it wouldn’t have been surprising for the tech industry to have drifted toward Republicans over the past four years, even if Democratic policy remained as friendly to tech as had it been under Barack Obama. In reality, the Biden administration took a much more adversarial stance than its predecessors. Biden’s Federal Trade Commission and Justice Department collectively brought antitrust cases against Amazon, Google, Meta, Apple, and Microsoft. This blitzkrieg of aggressive antitrust enforcement naturally irritated Silicon Valley’s giants. Perhaps less predictably, it also antagonized smaller tech firms and startups. In theory, one might expect “little tech” would want the government to curb the market power of their gargantuan competitors. In practice, however, many startup founders and investors aspire to either grow their own firms into behemoths, or failing that, get bought up by a larger company. By chilling merger activity, the Biden administration effectively blocked many startups’ “plan B,” while choking off a reliable source of returns for venture capitalists. VCs and startups also took exception to the Biden Securities and Exchange Commission’s vigorous regulation of cryptocurrency, as well as the administration’s executive order on AI safety. In November 2023, a contingent of startup founders and investors denounced the latter, arguing that the order’s reporting requirements put small AI firms at a competitive disadvantage, as they could less comfortably shoulder regulatory compliance costs than their larger rivals. Finally, Biden proposed a new tax on the unrealized capital gains of Americans with more than $100 million in wealth. This would mean that when a megamillionaire investor’s stock portfolio or real estate holdings gained $5 million in value, they would need to pay a tax on that amount, even if they did not sell those assets. Tax policy wonks like this idea. But super-rich tech investors very much do not. And when Kamala Harris announced her support for Biden’s plan last summer, Silicon Valley’s venture capitalists had a conniption. Super-rich tech moguls care about making money. But they are often at least as covetous of social status. Past a certain point, accumulating more wealth has little practical impact on your living standards (or those of your children, or your children’s children). But a person’s appetite for greater prestige tends to be less exhaustible than their desire for beach homes, Porsches, or private jets. Thus, if Democrats had spent the past decade exalting tech investors and founders, it’s possible that the party’s increasingly adversarial policies would have caused less rancor in Silicon Valley. But Democrats became increasingly disillusioned with the tech industry over the course of the 2010s. And this culminated in a Democratic administration that undermined tech billionaires’ sense of self-importance. “At the core level, both Barack Obama and the modal Democrat thought the average Silicon Valley company was really good and cool in 2009,” Marc Aidinoff, a historian and policy adviser in both the Obama and Biden administrations, told me. “Obama would go to Silicon Valley and have dinner with the CEOs and call them champions of change. What these people really wanted from the president was the sense that they were loved.” But by 2021, things had changed, according to Aidinoff. “Joe Biden distrusts these people, thinks they are hurting Americans, and has the sense that they aren’t actually making much of real value,” he said. The Democrats’ disenchantment with tech wasn’t attributable to Biden’s personal skepticism of Silicon Valley alone. After the financial crisis, the party’s progressive wing grew more influential. And its ascent increased the salience of both inequality and labor issues in Democratic politics. For a party increasingly concerned with wealth concentration and workers’ rights, tech giants that generated vast fortunes off “winner-take-all” markets — while, in many cases, committing labor violations or undermining traditional employment — did not look like engines of progress. As importantly, the notion that social media platforms promoted democracy and social reform fell into disrepute. In the wake of Obama’s election and the Arab Spring — both of which were widely credited to novel media technologies — many liberals bought into the idea that Facebook and Twitter would abet a more egalitarian politics. But authoritarian regimes proved adept at restricting online speech. And if social media’s potential to facilitate rightwing extremism wasn’t clear to liberals before 2016, it was apparent to them afterward. Following Trump’s victory, many Democrats blamed their party’s defeat on Facebook’s dissemination of “fake news.” Around the same time, research suggesting that social media could have adverse mental health effects started to accumulate. All this — combined with tech platforms’ adverse impact on traditional journalism — led the mainstream media to view Silicon Valley more critically. Between 2012 and 2019, the New York Times’ coverage of Facebook turned sharply negative, according to one prominent data analysis. Add in Silicon Valley’s growing enthusiasm for crypto — a technology that appeared to be good for little beyond scams and speculation — and it isn’t hard to see why Democrats soured on Big Tech. The party’s newfound skepticism of the industry didn’t just translate into greater regulatory scrutiny, but also, a withholding of both praise and access. According to some in tech, the sector’s leading lights felt themselves shunned and slighted by the Biden White House. “I think the fundamental problem, and I heard this from many, was that former President Biden was unwilling to meet with tech CEOs and entrepreneurs,” the billionaire investor Mark Cuban told me. “It was that simple.” One former Biden official echoed this assessment, saying that tech companies “couldn’t get meetings with a lot of the key regulators. Certainly [FTC commissioner] Lina [Khan] wouldn’t meet with people — she liked to say, ‘We’re enforcement, you can’t really meet with us.’” Andreessen recently reminisced that Bill Clinton’s Democratic Party had “celebrated” and “loved” tech companies. Biden’s Democratic Party, by contrast, often refused Andreessen’s ilk the time of day. It’s clear then that Silicon Valley’s rightward turn was precipitated, at least in part, by a change in the Democratic Party’s attitudes and policies toward the tech industry. And there’s reason to think that the party’s anti-tech turn is politically costly on net. Were other tech billionaires to emulate Musk’s political giving — or other social media companies to imitate X’s boosting of right-wing content — the damage to Democrats could be considerable. And the Trump administration’s manifest openness to trading political power for financial support makes this a live possibility, especially if Democrats promise to reprise the Biden administration’s policies toward the industry. Meanwhile, it’s far from clear that aggressively regulating Silicon Valley can gain Democrats meaningful support elsewhere. This is not because voters oppose that general goal: In fact, in a 2024 Pew Research poll, a slight majority expressed support for increasing regulation of the tech industry, while a supermajority said that social media has had a “mostly negative” effect on the United States. The problem is that voters have ambivalent feelings about Big Tech writ large, and do not consider regulating the companies a priority. When Gallup asked Americans what their country’s most important problem was this month, only 1 percent named “corporate corruption” while 0 percent picked “technology.” In a post-election survey from Morning Consult and the Chamber of Progress (a trade group of companies allied with the Democratic Party), voters were presented with a list of 12 issues, and asked to name the two that were most important to their vote. Only 2 percent of respondents picked “regulating technology companies” as one of their priorities, making it the single least prioritized objective on the list (by contrast, 49 percent selected “controlling inflation and strengthening the economy”). Meanwhile, in YouGov’s polling, Amazon’s approval rating sits at 74 percent, Google’s at 70 percent, Apple’s at 69 percent, and Facebook at 59 percent. Given all this, it’s plausible that Democrats have more to lose than gain politically from taking on Big Tech. Yet it’s also true that the political costs of the party’s anti-tech turn have been routinely overstated. In truth, Silicon Valley’s rightward shift — while real — has been remarkably modest, whether measured in votes or donations. In 2020, Biden won Santa Clara County, which includes much of Silicon Valley, by 48 points. Four years later, he won it by 40 points. There’s some evidence that tech workers and executives became more likely to donate to Republicans during the Biden era. But 83 percent of Amazon employees’ donations to federal candidates went to Democrats in 2024; for Meta, that figure was 91.5 percent; for Apple, it was 95 percent. At the megadonor level, the story is a bit more complicated. Trump received more money from tech donors who spent over $1 million on the 2024 race than Harris did — but that’s mostly thanks to Musk’s prodigious giving. Musk spent $242.6 million on the 2024 election, nearly five times as much as Silicon Valley’s second-largest political spender, Facebook co-founder Dustin Moskovitz, a Democrat. And yet, it’s hard to attribute Musk’s political evolution to recent changes in Democratic policy. The Tesla CEO appears to have been undergoing a process of online radicalization even before Biden took office (in March 2020, Musk allegedly bet the writer Sam Harris $1 million that there would be fewer than 35,000 cases of Covid-19 in the United States, a conviction that seems symptomatic of his immersion in right-wing social media). If we deem Musk a special case and put him to the side, then Democrats retained their advantage with large tech donors in 2024: Combined, all other tech megadonors spent $30.6 million on Trump, and $120.9 million on Harris, according to an analysis from The Guardian. In any case, money was not the Democrats’ problem in 2024. The party and its allied groups outraised the GOP by $1.1 billion during last year’s campaign. To be sure, many Silicon Valley billionaires waited until after Election Day to cozy up to Trump, so their newfound support for the GOP would not be captured by this data. But those who only started currying Trump’s favor once he secured the presidency are likely motivated less by antipathy for Democratic policy than awareness of Republican corruption: Trump has made it quite clear that his friends can expect favorable treatment by his government while his foes can anticipate the opposite. “A number of people in tech led with vinegar during Trump’s first term and learned that it was better with Trump to lead with honey,” Adam Kovacevich, a former Google executive and chair of the Chamber of Progress, told me. “It’s not so much that they expect a lot, but they really don’t want their companies to be hurt by Trump. If your competitors are building a close relationship with Trump, you don’t want them to screw you.” All of which is to say: The Democrats have paid a price for their crusade against Big Tech, but not a prohibitively expensive one. None of this settles the debate over whether Democrats were right to take a more adversarial posture toward the tech industry under Biden. Moderate Democrats can look at this pattern of facts and conclude that Biden’s agenda alienated a powerful industry and did little to increase their party’s popular support, all while discouraging growth and innovation. Progressives, meanwhile, can counter that Democrats just proved they can take on concentrated corporate power and still retain an overwhelming financial advantage over the GOP — and thus, the party has no excuse not to prioritize the interests of ordinary Americans over those of tech billionaires. Ultimately though, the important disagreement here is the substantive one. If Democrats can ingratiate themselves to tech billionaires in ways that have little substantive cost — such as giving them face time or rhetorical encouragement — they might be well-advised to do so. But the party as of yet faces no imperative to abandon policies that benefit the general public, for the sake of appeasing Silicon Valley titans. Understand the world with a daily explainer plus the most compelling stories of the day. Something strange is happening inside the environmental movement. Tens of thousands of people will die if Trump’s war on USAID continues. Democrats’ struggles to respond to Trump’s immigration policies have some deeper, historical roots. The organizations dedicated to mobilizing Gen Z got the turnout they wanted, but not the votes. What did they miss? Why the tariffs might — and might not — still happen. The Trump administration is preparing a remarkable power grab over the federal law enforcement agency. © 2025 Vox Media, LLC. All Rights Reserved
--------------------------------------------------

Title: Apple's iPhone sales during the holiday season slipped despite a highly anticipated AI rollout
URL: https://abcnews.go.com/Technology/wireStory/apples-iphone-sales-holiday-season-slipped-despite-highly-118286966
Time Published: 2025-01-30T21:58:28Z
Full Content:
Apple on Thursday disclosed its iPhone sales dipped slightly during the holiday-season quarter, signaling a sluggish start to the trendsetting company’s effort to catch up to the rest of Big Tech in the race to bring artificial intelligence to the masses SAN FRANCISCO -- Apple on Thursday disclosed its iPhone sales dipped slightly during the holiday-season quarter, signaling a sluggish start to the trendsetting company’s effort to catch up to the rest of Big Tech in the race to bring artificial intelligence to the masses. The iPhone’s roughly 1% drop in revenue from the previous year’s October-December period wasn’t entirely unexpected, given the first software update enabling the device’s AI features didn’t arrive until just before Halloween, and the technology still isn’t available in many markets outside the U.S. The countries still awaiting Apple’s AI suite include China, a key market where the company continued to lose ground. Apple also was only able to eke out a modest revenue gain across its entire business, although the results came in ahead of the analyst projections that guide investors. The Cupertino, California, company earned $36.3 billion, or $2.40 per share, a 7% increase from the previous year. Revenue edged up from the previous year by 4% to $124.3 billion. Those numbers included iPhone revenue of $69.1 billion. In China, Apple’s total revenue registered $18.5 billion, an 11% decrease from the previous year. Part of that erosion in China reflected the iPhone’s shrinking market share in that country, where homegrown companies have been making more headway. Apple’s iPhone year-over year shipments in China declined nearly 10% in the most recent quarter, while native companies Huawei and Xiaomi posted year-over-year increase of more than 20%, according to the research firm International Data Corp. The holiday-season results served to confirm bringing AI to the iPhone and Apple’s other products may not boost the company’s recently lackluster growth as much as investors initially thought it might after CEO Tim Cook unveiled the technology before a rapt crowd last June. The anticipation that an AI-infused iPhone would prod hordes of consumers to ditch their current devices and splurge on an upgrade is the main reason Apple’s stock price surged by 30% last year. But the sinking realization that an uptick in demand may take longer than expected has caused Apple’s shares to backtrack by 5% during the first month of the new year. The stock slipped slightly in extended trading after the numbers came out. The concerns hovering around Apple's weakening iPhone sales come against broader worries about whether AI will be as lucrative for U.S. tech companies as once envisioned after Chinese startup DeepSeek released a version of the technology that was built at a far lower cost than had been previously thought possible. Unlike tech peers such as Microsoft, Google corporate parent Alphabet Inc. and Facebook corporate parent Meta Platforms, Apple hasn’t been investing as heavily in AI – one of the reasons it has been an industry laggard. But that restraint could work to its advantage if DeepSeek’s early breakthroughs in driving down AI costs gains momentum. Apple’s services division remained the company’s biggest moneymaker outside the iPhone, with revenue of $26.3 billion in the past quarter, a 14% increase from the previous year. Although the services division has been thriving for years, it generates more than $20 billion annually by locking in Google as the automatic search engine on the iPhone and other products. That deal is now under threat of being banned as part of the proposed punishment for Google’s search engine being declared an illegal monopoly. 24/7 coverage of breaking news and live events
--------------------------------------------------

Title: Apple's iPhone sales during the holiday season slipped despite a highly anticipated AI rollout
URL: https://www.seattlepi.com/business/article/apple-s-iphone-sales-during-the-holiday-season-20066697.php
Time Published: 2025-01-30T21:57:23Z
Description: Apple on Thursday disclosed its iPhone sales dipped slightly during the holiday-season quarter, signaling a sluggish start to the trendsetting company’s effort to catch up to the rest of Big Tech in the race to bring artificial intelligence to the masses. The…
--------------------------------------------------

Title: Apple's iPhone sales during the holiday season slipped despite a highly anticipated AI rollout
URL: https://finance.yahoo.com/news/apples-iphone-sales-during-holiday-214924535.html
Time Published: 2025-01-30T21:49:24Z
Full Content:
We are experiencing some temporary issues. The market data on this page is currently delayed. Please bear with us as we address this and restore your personalized lists. SAN FRANCISCO (AP) — Apple on Thursday disclosed its iPhone sales dipped slightly during the holiday-season quarter, signaling a sluggish start to the trendsetting company’s effort to catch up to the rest of Big Tech in the race to bring artificial intelligence to the masses. The iPhone’s roughly 1% drop in revenue from the previous year’s October-December period wasn’t entirely unexpected, given the first software update enabling the device’s AI features didn’t arrive until just before Halloween, and the technology still isn’t available in many markets outside the U.S. The countries still awaiting Apple’s AI suite include China, a key market where the company continued to lose ground. Apple also was only able to eke out a modest revenue gain across its entire business, although the results came in ahead of the analyst projections that guide investors. The Cupertino, California, company earned $36.3 billion, or $2.40 per share, a 7% increase from the previous year. Revenue edged up from the previous year by 4% to $124.3 billion. Those numbers included iPhone revenue of $69.1 billion. In China, Apple’s total revenue registered $18.5 billion, an 11% decrease from the previous year. Part of that erosion in China reflected the iPhone’s shrinking market share in that country, where homegrown companies have been making more headway. Apple’s iPhone year-over year shipments in China declined nearly 10% in the most recent quarter, while native companies Huawei and Xiaomi posted year-over-year increase of more than 20%, according to the research firm International Data Corp. The holiday-season results served to confirm bringing AI to the iPhone and Apple’s other products may not boost the company’s recently lackluster growth as much as investors initially thought it might after CEO Tim Cook unveiled the technology before a rapt crowd last June. The anticipation that an AI-infused iPhone would prod hordes of consumers to ditch their current devices and splurge on an upgrade is the main reason Apple’s stock price surged by 30% last year. But the sinking realization that an uptick in demand may take longer than expected has caused Apple’s shares to backtrack by 5% during the first month of the new year. The stock slipped slightly in extended trading after the numbers came out. The concerns hovering around Apple's weakening iPhone sales come against broader worries about whether AI will be as lucrative for U.S. tech companies as once envisioned after Chinese startup DeepSeek released a version of the technology that was built at a far lower cost than had been previously thought possible. Unlike tech peers such as Microsoft, Google corporate parent Alphabet Inc. and Facebook corporate parent Meta Platforms, Apple hasn’t been investing as heavily in AI – one of the reasons it has been an industry laggard. But that restraint could work to its advantage if DeepSeek’s early breakthroughs in driving down AI costs gains momentum. Apple’s services division remained the company’s biggest moneymaker outside the iPhone, with revenue of $26.3 billion in the past quarter, a 14% increase from the previous year. Although the services division has been thriving for years, it generates more than $20 billion annually by locking in Google as the automatic search engine on the iPhone and other products. That deal is now under threat of being banned as part of the proposed punishment for Google’s search engine being declared an illegal monopoly. Sign in to access your portfolio
--------------------------------------------------

Title: Apple Reports Record $124.3 Billion Revenue on Strong Holiday Sales
URL: https://www.thewrap.com/apple-earnings-q1/
Time Published: 2025-01-30T21:44:35Z
Full Content:
The tech giant offset a modest iPhone sales dip with strong results from Europe, subscriptions and iCloud Apple reported the company’s best quarterly sales ever on Thursday, with the tech giant pointing to a strong holiday performance leading to $124.3 billion in Q1 revenue. The company posted the big quarter despite declining sales in China and a minor dip in iPhone revenue. Apple offset its sales drop in China with an 11.4% year-over-year increase in European sales, as well as 14% annual growth from Apple’s Services sector, which includes Apple TV+, Apple Music, and iCloud storage. Those gains also helped Apple weather flat sales from its Wearables division, which accounts for Apple Watch, headphones, and its Vision Pro virtual reality headsets. Apple CEO Tim Cook, in a statement accompanying earnings, announced Apple Intelligence — the company’s artificial intelligence program designed to help users with messages, notifications, and other features — would “be available in even more languages this April,” without providing further details. Here are the top-line numbers from Apple’s first quarter, which represents its October through December performance: Revenues: $124.3 billion, a 4% increase from the year prior. Apple’s Q1 sales narrowly topped analyst estimates from Zack’s Investment Research of $124 billion. The Q1 performance also topped Apple’s previous record of $123.9 billion in sales during the holiday quarter of 2021. Apple’s sales in China, notably, dropped 11% year-over-year to $18.5 billion. Cook explained the dip on the call by saying it was due to a “change in channel inventory,” or products that are in the supply chain but have not been sold yet. He also said China is the “most competitive market in the world” and that, moving forward, he believes recent government stimulus packages will help some of Apple’s products in the next quarter. The company made up for it in Europe, its second biggest market, where Apple had $33.9 billion in Q1 revenue — an 11.4% year-over-year increase. Net income: $36.3 billion, up 7.1% from last year’s $33.9 billion. Earnings Per Share: Apple’s diluted earnings per share of $2.4o were better than Zack’s estimates of $2.36 EPS. iPhone Sales: Revenue from Apple’s linchpin device declined 0.8% annually to $69.1 billion. Apple brought in nearly $70 billion from iPhone sales a year ago. Services: Apple’s wide-ranging Services sector accounted for $26.3 billion in sales, compared to the $23.1 billion brought in a year ago. As is usually the case, Apple did not mention how its streaming service, Apple TV+, was performing in its quarterly report, though on its earnings call Cook did express enthusiasm about several of its upcoming shows. This was the best quarter ever for Services sales. Cook was in Washington, D.C. last week for President Trump’s inauguration, where he was joined by a number of other Big Tech CEOs, including X owner Elon Musk, Meta chief Mark Zuckerberg, and Amazon founder Jeff Bezos. Cook’s appearance came after he personally donated $1 million towards Trump’s inauguration fund. Heading into Thursday, Apple’s stock price had increased a modest 3.5% since the start of October. The company’s holiday quarter coincided with the October launch of Apple Intelligence; the rollout was met with tepid reviews, and has led to questions from some analysts about Apple’s future in a crowded AI space. Apple is the world’s most valuable company, with a market cap of $3.57 trillion. Microsoft, with a valuation of $3.09 trillion, is the next closest company. Cook, on the Q1 earnings call on Thursday afternoon, said Apple now had 2.35 billion active devices worldwide — yet another company record. The 64-year-old executive also took a moment to extend his condolences to those affected by the “devastating wildfires that impacted the Los Angeles area.” There was not much mentioned about Apple’s entertainment push, beyond Cook mentioning the recent return of “Severance” and the upcoming “Formula One” film starring Brad Pitt.
--------------------------------------------------

Title: Meta continues pushing Instagram Reels as Q4 2024 results beat expectations
URL: https://www.tubefilter.com/2025/01/30/meta-instagram-reels-q4-2024-earnings-results/
Time Published: 2025-01-30T19:45:53Z
Description: Meta's earnings from the fourth quarter of 2024 served as a reminder that Mark Zuckerberg's company is most likely to benefit in the event of a long-term disruption to TikTok's operations. The tech giant's stock price briefly reached a price of more than $700…
--------------------------------------------------

Title: Artificial Intelligence (AI) Going “DeepSeek”
URL: https://www.globalresearch.ca/ai-going-deepseek/5878642
Time Published: 2025-01-30T16:18:05Z
Full Content:
Most readers will know the news by now. DeepSeek, a Chinese AI company, released an AI model called R1 that is comparable in ability to the best models from companies such as OpenAI, Anthropic and Meta, but was trained at a radically lower cost and using less than state-of-the art GPU chips. DeepSeek also made public enough of the details of the model that others can run it on their own computers without charge. DeepSeek is a torpedo that has hit the Magnificent Seven US hi-tech companies below the water line. DeepSeek did not use the latest and best Nvidia’s chips and software; it did not require huge spending on training its AI model unlike its American rivals; and it offers just as many useful applications. DeepSeek built its R1 with Nvidia’s older, slower chips, which US sanctions had allowed to be exported to China. The US government and the tech titans thought they had a monopoly in AI development because of the huge costs involved in making better chips and AI models. But now DeepSeek’s R1 suggests that companies with less money can soon operate competitive AI models. R1 can be used on a shoestring budget and with much less computing power. Moreover, R1 is just as good as rivals at ‘inference’, the AI jargon for when users question the model and get answers. And it runs on servers for all sorts of companies so that they need not ‘rent’ at huge prices from the likes of OpenAI. Most important, DeepSeek’s R1 is ‘open source’, namely that is coding and training methods are open to all to copy and develop. This is a real blow to the ‘proprietary’ secrets that OpenAI or Google’s Gemini lock away in a ‘black box’ in order to maximise profits. The analogy here is with branded and generic pharmaceuticals. The big issue for the US AI companies and their investors is that it appears that building huge data centres to house multiples of expensive chips may not be necessary in order to achieve sufficiently successful outcomes. Up to now, the US companies have been ratcheting up huge spending plans and trying to raise mega amounts of funding to do so. Indeed, on the very Monday that DeepSeek’s R1 hit the news, Meta announced another $65bn of investment, and only days earlier President Trump announced government subsidies of $500bn to the tech giants as part of the so-called Stargate project. Ironically, Meta chief executive Mark Zuckerberg said he was investing because “We want the US to set the global AI standard, not China.” Oh dear. . . Now investors are concerned that this spending is unnecessary and, more to the point, that it will hit the profitability of the American companies if DeepSeek can deliver AI applications at a tenth of the cost. Five of the biggest technology stocks geared to AI — chipmaker Nvidia and so-called ‘hyperscalers’ Alphabet, Amazon, Microsoft and Meta Platforms — collectively shed almost $750bn of their stock market value in one day. And DeepSeek does threaten the profits of the data centre companies and the water and power operators which expect to benefit from the huge ‘scaling up’ by the Magnificent Seven. The US stock market boom is heavily concentrated in the ‘Magnificent Seven’. . . So has DeepSeek punctured the massive stock market bubble in US tech stocks? Billionaire investor Ray Dalio thinks so. He told the Financial Times that “pricing has got to levels which are high at the same time as there’s an interest rate risk, and that combination could prick the bubble … Where we are in the cycle right now is very similar to where we were between 1998 or 1999,” Dalio said. “In other words, there’s a major new technology that certainly will change the world and be successful. But some people are confusing that with the investments being successful.” . . But that may not be the case, at least not just yet. The AI chip company Nvidia’s stock price may have dived this week, but its ‘proprietary’ coding language, Cuda, is still the US industry standard. While its shares dropped nearly 17%, that only brings it back to the (very, very high) level of September. . . Much will depend on other factors like the US Fed keeping interest rates high because of a reversal in the fall in inflation and on whether Trump proceeds big time with his tariff and immigration threats that will only fuel inflation. What must enrage the tech oligarchs sucking up to Trump is that US sanctions on Chinese companies and bans on chip exports have not stopped China making yet more advances in the tech and chip war with the US. China is managing to make technological leaps in AI despite export controls introduced by the Biden administration intended to deprive it of both the most powerful chips and the advanced tools needed to make them. Chinese tech champion Huawei has emerged as Nvidia’s primary competitor in China for ‘inference’ chips. And it has been working with AI companies, including DeepSeek, to adapt models trained on Nvidia GPUs to run inference on its Ascend chips. “Huawei is getting better. They have an opening as the government is telling the big tech companies that they need to buy their chips and use them for inference,” said one semiconductor investor in Beijing. This is a further demonstration that state-led planned investment into technology and tech skills by China works so much better than relying on huge private tech giants led by moguls. As Ray Dallo said: “In our system, by and large, we are moving to a more industrial-complex- type of policy in which there is going to be government-mandated and government-influenced activity, because it is so important…Capitalism alone — the profit motive alone — cannot win this battle.” Nevertheless, the AI titans are not yet the titanic. They are going ahead with ‘scaling up’ by ploughing yet more and more billions into data centres and more advanced chips. This eating up computer power exponentially. . . And of course, there is no consideration of what mainstream economists politely like to call ‘externalities’. According to a report by Goldman Sachs, a ChatGPT query needs nearly 10 times as much electricity as a Google search query. Researcher Jesse Dodge did some back-of-the-napkin math on the amount of energy AI chatbots use. “One query to ChatGPT uses approximately as much electricity as could light one light bulb for about 20 minutes,” he says. “So, you can imagine with millions of people using something like that every day, that adds up to a really large amount of electricity.” More electricity consumption means more energy production and in particular more fossil-fuelled greenhouse gas emissions. Google has the goal of reaching net-zero emissions by 2030. Since 2007, the company has said its company operations were carbon neutral because of the carbon offsets it buys to match its emissions. But, starting in 2023, Google wrote in its sustainability report that it was no longer “maintaining operational carbon neutrality.” The company says it’s still pushing for its net-zero goal in 2030. “Google’s real motivation here is to build the best AI systems that they can,” Dodge says. “And they’re willing to pour a ton of resources into that, including things like training AI systems on bigger and bigger data centers all the way up to supercomputers, which incurs a tremendous amount of electricity consumption and therefore CO2 emissions.” Then there’s water. As the US faces droughts and wildfires, the AI companies are sucking up deep water to ‘cool’ their mega data centres to protect the chips. More than that, Silicon Valley companies are increasingly taking control of water supply infrastructure to meet their needs. Research suggests, for instance, that about 700,000 litres of water could have been used to cool the machines that trained ChatGPT-3 at Microsoft’s data facilities. Training AI models consumes 6,000 times more energy than a European city. Furthermore, while minerals such as lithium and cobalt are most commonly associated with batteries in the motor sector, they are also crucial for the batteries used in datacentres. The extraction process often involves significant water usage and can lead to pollution, undermining water security. Sam Altman, the previous non-profit hero of Open AI, but now out to maximise profits for Microsoft, argues that yes, unfortunately there are ‘trade-offs’ in the short term, but they’re necessary to reach so-called AGI; and AGI will then help us solve all these problems so the trade off of ‘externalities’ is worth it. AGI? What’s this? Artifical generalised intelligence (AGI) is the holy grail of AI developers. It means that AI models would become ‘superintelligent’ way above human intelligence. When that is achieved, Altman promises, its AI won’t just be able to do a single worker’s job, it will be able to do all of their jobs: “AI can do the work of an organization.” This would be the ultimate in maximising profitability by doing away with workers in companies (even AI companies?) as AI machines take over operating, developing and marketing everything. This is the apocalyptic dream for capital (but a nightmare for labour: no job, no income). That’s why Altman and the other AI moguls will not stop expanding their data centres and developing yet more advanced chips just because DeepSeek has undercut their current models. Research firm Rosenblatt forecast the response of the tech giants: “In general, we expect the bias to be on improved capability, sprinting faster towards artificial general intelligence, more than reduced spending.” Nothing must stop the objective of super-intelligent AI. Some see the race to achieving AGI as a threat to humanity itself. Stuart Russell, professor of computer science at the University of California, Berkeley, said “Even the CEOs who are engaging in the race have stated that whoever wins has a significant probability of causing human extinction in the process, because we have no idea how to control systems more intelligent than ourselves,” he said. “In other words, the AGI race is a race towards the edge of a cliff.” Maybe, but I continue to doubt that human ‘intelligence’ can be replaced by machine intelligence, mainly because they are different. Machines cannot think of potential and qualitative changes. New knowledge comes from such transformations (human), not from the extension of existing knowledge (machines). Only human intelligence is social and can see the potential for change, in particular social change, that leads to a better life for humanity and nature. What DeepSeek’s emergence has shown is that AI can be developed to a level that can help humanity and its social needs. It’s free and open and available to the smallest user and developer. It has not been developed at a profit or to make a profit. As one commentator put it: “I want AI to do my laundry and dishes so that I can do art and writing, not for AI to do my art and writing so that I can do my laundry and dishes.” Managers are introducing AI to “make management problems easier at the cost of the stuff that many people don’t think AI should be used for, like creative work….. If AI is going to work, it needs to come from the bottom-up, or AI is going to be useless for the vast majority of people in the workplace”. Rather than develop AI to make profits, reduce jobs and the livelihoods of humans, AI under common ownership and planning could reduce the hours of human labour for all and free humans from toil to concentrate on creative work that only human intelligence can deliver. Remember the ‘holy grail’ was a Victorian fiction and later a Dan Brown one as well. * Click the share button below to email/forward this article. Follow us on Instagram and X and subscribe to our Telegram Channel. Feel free to repost Global Research articles with proper attribution. Michael Roberts is an economist in the City of London and a prolific blogger. Global Research is a reader-funded media. We do not accept any funding from corporations or governments. Help us stay afloat. Click the image below to make a one-time or recurring donation. Comment on Global Research Articles on our Facebook page Become a Member of Global Research Disclaimer: The contents of this article are of sole responsibility of the author(s). The Centre for Research on Globalization will not be responsible for any inaccurate or incorrect statement in this article. The Centre of Research on Globalization grants permission to cross-post Global Research articles on community internet sites as long the source and copyright are acknowledged together with a hyperlink to the original Global Research article. For publication of Global Research articles in print or other forms including commercial internet sites, contact: [email protected] www.globalresearch.ca contains copyrighted material the use of which has not always been specifically authorized by the copyright owner. We are making such material available to our readers under the provisions of "fair use" in an effort to advance a better understanding of political, economic and social issues. The material on this site is distributed without profit to those who have expressed a prior interest in receiving it for research and educational purposes. If you wish to use copyrighted material for purposes other than "fair use" you must request permission from the copyright owner. For media inquiries: [email protected]
--------------------------------------------------

Title: Microsoft, AWS, and Cerebras launch DeepSeek R1 model
URL: https://www.techtarget.com/searchenterpriseai/news/366618674/Microsoft-AWS-and-Cerebras-launch-DeepSeek-R1-model
Time Published: 2025-01-30T15:43:00Z
Full Content:
Nabugu - stock.adobe.com Enterprises that want to test DeepSeek-R1, the Chinese reasoning model that caused a tsunami in the tech industry, can get it from cloud providers AWS and Microsoft, the online platform GitHub and hardware maker Cerebras Systems. The tech companies made the model from Hangzhou, China-based AI startup DeepSeek available this week, just days after it rocked the tech industry by casting doubt on the high cost of running AI in the United States. The model is comparable to OpenAI's o1 but requires a fraction of the GPU power, according to its developers. "DeepSeek-R1 is certainly having its viral moment now," said Gartner analyst Arun Chandrasekaran. Chandrasekaran said he expects many companies to offer DeepSeek-R1, including variants for specific industries and cloud, data center and edge deployments. Model providers will likely differentiate themselves from competitors by offering better performance for the price through infrastructure innovations, Chandrasekaran said. They will also provide security and privacy layers and guarantees around legal indemnification. "Having said that, in a few months, we may not remember R1 as much as we do today," Chandrasekaran said. "There is now a race to build models with better efficiencies, and we will see more such models from large cloud providers in the U.S., China, as well as from AI research labs in the world." Microsoft made DeepSeek-R1 available on GitHub and the model catalog on Azure AI Foundry. The Foundry offers developers tools to experiment with, iterate on and integrate the model's capabilities into workflows. It also provides security and model evaluation tools. AWS offers its version of DeepSeek on its SageMaker platform for building, training and deploying custom models. AWS customers can train DeepSeek on SageMaker using the Hugging Face open source platform. "We expect to see many more models like this -- both large and small, proprietary and open source -- excel at different tasks," AWS said in an emailed statement. Cerebras Systems introduced AI hardware running a 70-billion-parameter DeepSeek-R1 powered by the company's WSE-2 processor. The preview technology is contained in Cerebras' flagship CS-3 system, a unit that fits within a standard data center rack. Cerebras claims DeepSeek-R1-70B is faster, more accurate, and less expensive than OpenAI's o1 reasoning model. Cerebras trained its model on the same data used to train Llama 3.3 using knowledge distillation, a technique that transfers data from a large, complex model to a smaller, more efficient one. The price of the DeepSeek system will be similar to Cerebras hardware running Llama 3.3 70B. Cerebras has developed a framework called Cerebras Planning and Optimization to enhance the reasoning abilities of Llama 3.3 Cerebras declined to provide pricing details or say how many of its WSE-2 processors are used to run Llama and DeepSeek. Hagay Lupesko, vice president of software engineering at Cerebras, said the company has received many queries from U.S. companies interested in its DeepSeek model. "We have a pretty long list of preview customers who are in line for access to the model," Lupesko said. He declined to name any organizations but said many were in the consumer industry and interested in using the model for application development. Cerebras also used the Llama 3.3 weights to train its version of DeepSeek. Weights are the numerical patterns critical to a model's ability to recognize patterns and make predictions based on input data. That means its DeepSeek model doesn't have the output restrictions of the original Chinese model, which, for example, does not answer queries about the Chinese leader, President Xi Jinping. DeepSeek developed and released its model to the open source community. However, some components are inaccessible, and the company did not release the data used to train the model. Hugging Face and Llama creator Meta are attempting to reverse engineer the technology. The company's researchers shook the tech world after they published a research paper demonstrating how they trained the model on significantly less-powerful Nvidia GPUs than the ones used for Open AI's reasoning model o1, yet achieved similar results. The disclosure raised serious questions about the efficiency of U.S.-made models and whether spending tens of billions of dollars on Nvidia's top chips was necessary. On Monday, Nvidia lost $589 billion in market value due to the research paper and release of DeepSeek's R1 model. The company's stock has regained some, though not all, of its losses. Antone Gonsalves is an editor at large for Informa TechTarget, reporting on industry trends critical to enterprise tech buyers. He has worked in tech journalism for 25 years and is based in San Francisco. Have a news tip? Please drop him an email.
--------------------------------------------------

Title: AI #101: The Shallow End
URL: https://www.lesswrong.com/posts/pZ6htFtoptGrSajWG/ai-101-the-shallow-end
Time Published: 2025-01-30T14:50:10Z
Full Content:
The avalanche of DeepSeek news continues. We are not yet spending more than a few hours at a time in the singularity, where news happens faster than it can be processed. But it’s close, and I’ve had to not follow a bunch of other non-AI things that are also happening, at least not well enough to offer any insights. So this week we’re going to consider China, DeepSeek and r1 fully split off from everything else, and we’ll cover everything related to DeepSeek, including the policy responses to the situation, tomorrow instead. This is everything else in AI from the past week. Some of it almost feels like it is from another time, so long ago. I’m afraid you’re going to need to get used to that feeling. Also, I went on Odd Lots to discuss DeepSeek, where I was and truly hope to again be The Perfect Guest. Joe Weisenthal finally tries out Google Flash Deep Thinking, is impressed. AI tutors beat out active learning classrooms in a Harvard study by a good margin, for classes like physics and economics. Koratkar gives Operator a shot at a makeshift level similar to Montezuma’s Revenge. Nate Silver estimates his productivity is up 5% from LLMs so far, and warns others that they ignore LLMs at their peril, both politically and personally. Fix all your transcript errors. LLMs are good at transforming text into less text, but yet good at transforming less text into more text. Note that this rule applies to English but doesn’t apply to code. Write your code for AI comprehension, not human readability. Vik: increasingly finding myself designing software for AI comprehension over human readability. e.g. giant files, duplicated code, a lot more verification tests. Now i just need to convince the agent to stop deleting failing tests… James Darpinian: IMO these usually increase human readability as well, contra “best practices.” Vik: agree, makes it so you don’t have to keep the entire codebase in your head. can go in, understand what’s going on, implement your change and get out without spending too much time doing research or worrying you’ve broken something That’s even more true when the humans are using the AIs to read the code. A negative review of Devin, the AI SWE, essentially saying that in practice it isn’t yet good enough to be used over tools like Cursor. The company reached out in the replies thanking them for the feedback and offering to explore more with them, which is a good sign for the future, but it seems clear we aren’t ‘there’ yet. I predict Paul Graham is wrong about this if we stay in ‘economic normal.’ It seems like exactly the kind of combination of inception, attempt at vibe control and failure to realize the future will be unevenly distributed we often see in VC-style circles, on top of the tech simply not being there yet anyway. Paul Graham: Prediction: From now on we’ll rarely hear the phrase “writer’s block.” 99% of the people experiencing it will give in after a few days and have AI write them a first draft. And the 1% who are too proud to use AI are probably also too proud to use a phrase like “writer’s block.” Certainly this won’t be true ‘from now on.’ No, r1 is not ready to solve writer’s block, it cannot create first drafts for you if you don’t know what to write on your own in a way that solves most such problems. AI will of course get better at writing, but I predict it will be a while up the ‘tech tree’ before it solves this problem. And even if it does, it’s going to be a while beyond that before 99% of people with writer’s block even know they have this option, let alone that they are willing to take it. And even if that happens, the 1% will be outright proud to say they have writer’s block. It means they don’t use AI! Indeed, seriously, don’t do this: Fear Buck: Kai Cenat’s $70k AI humanoid robot just tried running away from the AMP house because it kept getting kicked and bullied by Kai, Agent & Fanum Liv Boeree: Yeah don’t do this, because even if something doesn’t have “feelings” it is just teaching you and your followers that it’s okay to act out their worst instincts Education is where I see the strongest disagreements about AI impact, in the sense that those who generally find AI useful see it as the ultimate tool for learning things that will unleash the world’s knowledge and revolutionize education, and then there are others who see things another way. PoliMath: AI use is damaging high school and college education enormously in ways that are going to be extremely obvious in 5 years but at that point you can only watch. I don’t understand this position. Yes, you can use AI to get around your assignments if that’s what you want to do and the system keeps giving you those assignments. Or you can actually try to learn something. If you don’t take that option, I don’t believe you that you would have been learning something before. Your periodic reminder that the main way to not get utility is to not realize to do so: Nate Silver: Thinking ChatGPT is useless is midwit. It’s a magic box that answers any question you ask it from levels ranging from modestly coherent to extremely proficient. If you haven’t bothered to figure it out to derive some utility out of it then you’re just being lazy tbh. Even better than realizing you can use ChatGPT, of course, is using a mix of Claude, Perplexity, Gemini, r1, o1, o1 pro and yes, occasionally GPT-4o. Others make statements like this when others show them some mundane utility: Joe Weisenthal: Suppose I have some conference call transcripts, and I want to see what the CEOs said about the labor market. I could read through all of them. Or I can ask AI to retrieve the relevant comments and then confirm that they are actually real. Latter is much more efficient. Hotel Echo: Large Language Models: for when Ctrl-F is just too much like hard work. Yes. It is much more efficient. Control-F sucks, it has tons of ‘hallucinations’ in the sense of false positives and also false negatives. It is not a good means to parse a report. We use it because it used to be all we have. Also some people still don’t do random queries? And some people don’t even get why someone else would want to do that? Joe Weisenthal: I wrote about how easily and quickly I was able to switch from using ChatGPT to using DeepSeek for my random day-to-day AI queries Faze Adorno: Who the f*** has random day-to-day AI queries? “I’m gonna use this technology that just makes up information at anywhere between a 5 and 25 percent clip for my everyday information! I’m so smart!” Joe Weisenthal: Me. I do. I literally just typed that. LA Banker (so say we all): Whoever doesn’t = ngmi. Here are two competing theories. Dan Schwartz: I categorize this by “People who regularly do things they are not experts in” versus “People with a regular, time-honed routine for their work and personal life.” People I know in the latter group genuinely do not have much use for AI! Jorbs: This is fascinating to me because, in my (limited) attempts to utilize LLMs, they have essentially only been useful in areas where I have significant enough knowledge to tell when the output is inaccurate. For example, as someone who took a couple of quarters of computer science but is not a regular coder, LLMs are not good enough to be useful for coding for me. They output a lot of material, but it is as much work to parse it and determine what needs fixing as it is to do it from scratch myself. I resonate but only partially agree with both answers. When doing the things we normally do, you largely do them the way you normally do them. People keep asking if I use LLMs for writing, and no, when writing directly I very much don’t and find all the ‘help me write’ functionality useless – but it’s invaluable for many steps of the process that puts me into position to write, or to help develop and evaluate the ideas that the writing is about. Whereas I am perhaps the perfect person to get my coding accelerated by AI. I’m often good enough to figure out when it is telling me bullshit, and totally not good enough to generate the answers on my own in reasonable time, and also automates stuff that would take a long time, so I get the trifecta. On the question of detecting whether the AI is talking bullshit, it’s a known risk of course, but I think that risk is greatly overblown – this used to happen a lot more than it does now, and we forget how other sources have this risk too, and you can develop good habits about knowing which places are more likely to be bullshit versus not even if you don’t know the underlying area, and when there’s enough value to check versus when you’re fine to take its word for it. A few times a month I will have to make corrections that are not simple typos. A few times I’ve had to rework or discard entire posts because the error was central. I could minimize it somewhat more but mostly it’s an accepted price of doing business the way I do, the timing doesn’t usually allow for hiring a fact checker or true editor, and I try to fix things right away when it happens. It is very rare for the source of that error to be ‘the AI told me something and I believed it, but the AI was lying.’ It’s almost always either I was confused about or misread something, or a human source got it wrong or was lying, or there was more to a question than I’d realized from reading what others said. This reaction below is seriously is like having met an especially irresponsible thirteen year old once, and now thinking that no human could ever hold down a job. And yet, here we often still are. Patrick McKenzie (last week): You wouldn’t think that people would default to believing something ridiculous which can be disproved by typing into a publicly accessible computer program for twenty seconds. Many people do not have an epistemic strategy which includes twenty seconds of experimentation. Dave Karsten: Amplifying: I routinely have conversations at DC house parties with very successful people who say that they tried chatGPT _right when it came out_, found it not that impressive, and haven’t tried it again since then, and have based their opinion on AI on that initial experience. Ahrenbach: What’s the ratio of “AI is all hype” vs “We need to beat China in this technology”? More the former than the latter in house parties, but that’s partially because more of my defense/natsec people I tend to see at happy hours. (This is a meaningful social distinction in DC life). Broadly, the average non-natsec DC person is more likely to think it’s either a) all hype or b) if not hype, AI-generated slop with an intentional product plan where, “how do we kill art” is literally on a powerpoint slide. But overton window is starting to shift. It is now two weeks later, and the overton window has indeed shifted a bit. There’s a lot more ‘beat China’ all of a sudden, for obvious reasons. But compared to what’s actually happening, the DC folks still absolutely think this is all hype. Claude API now allows the command ‘citations’ to be enabled, causing it to process whatever documents you share with it, and then it will cite the documents in its response. Cute, I guess. Curious lack of shipping over at Anthropic recently. o3-mini is coming. It’s a good model, sir. Benedikt Stroebl: Update on HAL! We just added o3-mini to the Cybench leaderboard. o3-mini takes the lead with ~26% accuracy, outperforming both Claude 3.5 Sonnet and o1-preview (both at 20%) It’s hard to see, but note the cost column. Claude Sonnet 3.5 costs $12.90, o1-mini cost $28.47, o1-preview cost $117.89 and o3-mini cost $80.21 if it costs the same per token as o1-mini (actual pricing not yet set). So it’s using a lot more tokens. OpenAI’s canvas now works with o1 and can render HTML and React. Gemini 2.0 Flash Thinking got an upgrade last week. The 1M token context window opens up interesting possibilities if the rest is good enough, and it’s wicked cheap compared even to r1, and it too has CoT visible. Andrew Curran says it’s amazing, but that opinion reached me via DeepMind amplifying him. Dan Mac: everyone comparing deepseek-r1 to o1 and forgetting about Gemini 2 Flash Thinking which is better than r1 on every cost and performance metric Peter Wildeford: The weird thing about Deepseek is that it exists in a continuum – it is neither the cheapest reasoning model (that’s Gemini 2 Flash Thinking) nor the best reasoning model (o1-pro, probably o3-pro when that’s out) I disagree with the quoted tweet – I don’t think Gemini 2 Flash Thinking is actually better than r1 on every cost and performance metric. But I also have not seen anything that convinces me that Deepseek is truly some outlier that US labs can’t also easily do. That is a dramatic drop in price, and dramatic gain in context length. r1 is open, which has its advantages, but we are definitely not giving Flash Thinking its fair trial. The thing about cost is, yes this is an 80%+ discount, but off of a very tiny number. Unless you are scaling this thing up quite a lot, or you are repeatedly using the entire 1M context window (7.5 cents a pop!) and mostly even then, who cares? Cost is essentially zero versus cost of your time. Google Deep Research rolling out on Android, for those who hate websites. Google continues to lean into gloating about its dominance in LMSys Arena. It’s cool and all but at this point it’s not a great look, regardless of how good their models are. Need practical advice? Tyler Cowen gives highly Tyler Cowen-shaped practical advice for how to deal with the age of AI on a personal level. If you believe broadly in Cowen’s vision of what the future looks like, then these implications seem reasonable. If you think that things will go a lot farther and faster than he does, they’re still interesting, but you’d reach different core conclusions. Judah offers a thread of different programmer reactions to LLMs. Are there not enough GPUs to take all the jobs? David Holz says since we only make 5 million GPUs per year and we have 8 billion humans, it’ll be a while even if each GPU can run a virtual human. There are plenty of obvious ways to squeeze out more, there’s no reason each worker needs its own GPU indefinitely as capabilities and efficiency increase and the GPUs get better, and also as Holz notices production will accelerate. In a world where we have demand for this level of compute, this might buy us a few years, but they’ll get there. Epoch paper from Matthew Barnett warns that AGI could drive wages below subsistence level. That’s a more precise framing than ‘mass unemployment,’ as the question isn’t if there is employment for humans the question is at what wage level, although at some point humans really are annoying enough to use that they’re worth nothing. Matthew Barnett: In the short term, it may turn out to be much easier to accumulate AGIs than traditional physical capital, making physical capital the scarce factor that limits productivity and pushes wages downward. Yet, there is also a reasonable chance that technological progress could counteract this effect by making labor more productive, allowing wages to remain stable or even rise. Over the long run, however, the pace of technological progress is likely to slow down, making it increasingly difficult for wages to remain high. At that point, the key constraints are likely to be fundamental resources like land and energy—essential inputs that cannot be expanded through investment. This makes it highly plausible that human wages will fall below subsistence level in the long run. Informed by these arguments, I would guess that there is roughly a 1 in 3 chance that human wages will crash below subsistence level within 20 years, and a 2 in 3 chance that wages will fall below subsistence level within the next 100 years. I consider it rather obvious that if AGI can fully substitute for actual all human labor, then wages will drop a lot, likely below subsistence, once we scale up the number of AGIs, even if we otherwise have ‘economic normal.’ That doesn’t answer the objection that human labor might retain some places where AGI can’t properly substitute, either because jobs are protected, or humans are inherently preferred for those jobs, or AGI can’t do some jobs well perhaps due to physical constraints. If that’s true, then to the extent it remains true some jobs persist, although you have to worry about too many people chasing too few jobs crashing the wage on those remaining jobs. And to the extent we do retain jobs this way, they are driven by human consumption and status needs, which means that those jobs will not cause us to ‘export’ to AIs by default except insofar as they resell the results back to us. The main body of this paper gets weird. It argues that technological advancement, while ongoing, can protect human wages, and I get why the equations here say that but it does not actually make any sense if you think it through here. Then it talks about technological advancement stopping as we hit physical limits, while still considering that world being in ‘economic normal’ and also involves physical humans in their current form. That’s pretty weird as a baseline scenario, or something to be paying close attention to now. It also isn’t a situation where it’s weird to think about ‘jobs’ or ‘wages’ for ‘humans’ as a concern in this way. I do appreciate the emphasis that the comparative advantage and lump of labor fallacy arguments prove a wage greater than zero is likely, but not that it is meaningfully different from zero before various costs, or is above subsistence. Richard Ngo has a thread criticizing the post, that includes (among other things) stronger versions of these objections. A lot of this seems based on his expectation that humans retain political power in such futures, and essentially use that status to collect rents in the form of artificially high wages. The extent and ways in which this differs from a UBI or a government jobs program is an interesting question. Tyler Cowen offers the take that future unemployment will be (mostly) voluntary unemployment, in the sense that there will be highly unpleasant jobs people don’t want to do (here be an electrician living on a remote site doing 12 hour shifts) that pay well. And yeah, if you’re willing and able to do things people hate doing and give up your life otherwise to do it, that will help you stay gainfully employed at a good price level for longer, as it always has. I mean, yeah. And even ‘normal’ electricians make good money, because no one wants to do it. But it’s so odd to talk about future employment opportunities without reference to AI – unemployment might stay ‘voluntary’ but the wage you’re passing up might well get a lot worse quickly. Also, it seems like electrician is a very good business to be in right now? IFP is hiring a lead for their lobbying on America’s AI leadership, applications close February 21, there’s a bounty so tell them I sent you. I agree with IFP and think they’re great on almost every issue aside from AI. We’ve had our differences on AI policy though, so I talked to them about it. I was satisfied that they plan on doing net positive things, but if you’re considering the job you should of course verify this for yourself. New review of open problems in mechanistic interpretability. ByteDance Duabao-1.5-Po, which matches GPT-5o benchmarks at $0.11/$0.275. As with Kimi k1.5 last week, maybe it’s good, but I await evidence of this beyond benchmarks. So far, I haven’t heard anything more. Alibaba introduces Qwen 2.5-1M, with the 1M standing for a one million token context length they say processes faster now, technical report here. Again, if it’s worth a damn, I expect people to tell me, and if you’re seeing this it means no one did that. Feedly, the RSS feed I use, tells me it is now offering AI actions. I haven’t tried them because I couldn’t think of any reason I would want to, and Teortaxes is skeptical. Scott Alexander is looking for a major news outlet to print an editorial from an ex-OpenAI employee who has been featured in NYT, you can email him at scott@slatestarcodex.com if you’re interested or know someone who is. Reid Hoffman launches Manas AI, a ‘full stack AI company setting out to shift drug discovery from a decade-long process to one that takes a few years.’ Reid’s aggressive unjustified dismissals of the downside risks of AI are highly unfortunate, but Reid’s optimism about AI is for the right reasons and it’s great to see him putting that into practice in the right ways. Go team humanity. ChatGPT Gov, a version that the US Government can deploy. Claims that are easy to make but worth noting. Sam Altman: next phase of the msft x oai partnership is gonna be much better than anyone is ready for!! Free tier of chat will get some o3-mini as a treat, plus tier will get a lot. And o3 pro will still only be $200/month. That must mean even o3-pro is very far from o3-maximum-strength, since that costs more than $200 in compute for individual queries. Sam Altman: ok we heard y’all. *plus tier will get 100 o3-mini queries per DAY (!) *we will bring operator to plus tier as soon as we can *our next agent will launch with availability in the plus tier enjoy i think you will be very very happy with o3 pro! oAI: No need to thank me. Spencer Greenberg and Neel Nanda join in the theory that offering public evals that can be hill climbed is plausibly a net negative for safety, and certainly worse than private evals. There is a public information advantage to potentially offset this, but yes the sign of the impact of fully public evals is not obvious. Meta planning a +2GW data center at the cost of over $60 billion. From the comments: (Also I just rewatched the first two Back to the Future movies, they hold up, 5/5 stars.) Zuckerberg announced this on Facebook, saying it ‘is so large it would cover a significant part of Manhattan.’ Manhattan? It’s a big Project? Get it? Sigh. Meta was up 2.25% on a mostly down day when this was announced, as opposed to before when announcing big compute investments would cause Meta stock to drop. At minimum, the market didn’t hate it. I hesitate to conclude they loved it, because any given tech stock will often move up or down a few percent for dumb idiosyncratic reasons – so we can’t be sure this was them actively liking it. Then Meta was up again during the Nvidia bloodbath, so presumably they weren’t thinking ‘oh no look at all that money Meta is wasting on data centers’? This section looks weird now because what a week and OpenAI has lost all the hype momentum, but that will change, also remember last week? In any case, Chubby points out to Sam Altman that if you live by the vague-post hype, you die by the vague-post hype, and perhaps that isn’t the right approach to the singularity? Chubby: You wrote a post today (down below) that irritated me a lot and that I would not have expected from you. Therefore, I would like to briefly address a few points in your comment. You are the CEO of one of the most important companies of our time, OpenAI. You are not only responsible for the company, but also for your employees. 8 billion people worldwide look up to you, the company, and what you and your employees say. Of course, each of your words is interpreted with great significance. It is your posts and words that have been responsible for the enthusiasm of many people for AI and ChatGPT for months and years. It is your blog post (Age of Intelligence) that by saying that superintelligence is only a few thousand days away. It is your post in which you say that the path to AGI is clear before us. It is your employees who write about creating an “enslaved god” and wondering how to control it. It is your words that we will enter the age of abundance. It is your employees who discuss the coming superintelligence in front of an audience of millions and wonder what math problems can still be solved before the AI solves everything. It is the White House National Security Advisor who said a few days ago that it is a “Godlike” power that lies in the hands of a few. And you are insinuating that we, the community, are creating hype? That is, with all due modesty, a blatant insult. It was you who fueled the hype around Q*/Strawberry/o1 with cryptic strawberry photos. It was you who wrote a haiku about the coming singularity just recently. We all found it exciting, everyone found it interesting, and many got on board. But the hype is by no means coming from the community. It’s coming from the CEO of what is arguably the most famous corporation in the world. This is coming from someone to whom great hype is a symbol not of existential risk, as I partly see it, but purely of hope. And they are saying that no, ‘the community’ or Twitter isn’t creating hype, OpenAI and its employees are creating hype, so perhaps act responsibly going forward with your communications on expectations. I don’t have a problem with the particular post by Altman that’s being quoted here, but I do think it could have been worded better, and that the need for it reflects the problem being indicated. OpenAI’s Nat McAleese clarifies some of what happened with o3, Epoch and the Frontier Math benchmark. Nat McAleese (OpenAI): Epoch AI are going to publish more details, but on the OpenAI side for those interested: we did not use FrontierMath data to guide the development of o1 or o3, at all. We didn’t train on any FM derived data, any inspired data, or any data targeting FrontierMath in particular. I’m extremely confident, because we only downloaded frontiermath for our evals *long* after the training data was frozen, and only looked at o3 FrontierMath results after the final announcement checkpoint was already picked. We did partner with EpochAI to build FrontierMath — hard uncontaminated benchmarks are incredibly valuable and we build them somewhat often, though we don’t usually share results on them. Our agreement with Epoch means that they can evaluate other frontier models and we can evaluate models internally pre-release, as we do on many other datasets. I’m sad there was confusion about this, as o3 is an incredible achievement and FrontierMath is a great eval. We’re hard at work on a release-ready o3 & hopefully release will settle any concerns about the quality of the model! This seems definitive for o3, as they didn’t check the results until sufficiently late in the process. For o4, it is possible they will act differently. I’ve been informed that this still left a rather extreme bad taste in the mouths of mathematicians. If there’s one thing math people can’t stand, it’s cheating on tests. As far as many of them are concerned, OpenAI cheated. Rohit Krishnan asks what a world with AGI would look like, insisting on grounding the discussion with a bunch of numerical calculations on how much compute is available. He gets 40 million realistic AGI agents working night and day, which would be a big deal but obviously wouldn’t cause full unemployment on its own if the AGI could only mimic humans rather than being actively superior in kind. The discussion here assumes away true ASI as for some reason infeasible. The obvious problem with the calculation is that algorithmic and hardware improvements are likely to continue to be rapid. Right now we’re on the order of 10x efficiency gain per year. Suppose in the year 2030 we have 40 million AGI agents at human level. If we don’t keep scaling them up to make them smarter (which also changes the ballgame) then why wouldn’t we make them more efficient, such that 2031 brings us 400 million AGI agents? Even if it’s only a doubling 80 million, or even less than that, this interregnum period where the number of AGI agents is limited by compute enough to keep the humans in the game isn’t going to last more than a few years, unless we are actually hitting some sort of efficient frontier where we can’t improve further. Does that seem likely? We’re sitting on an exponential in scenarios like this. If your reason AGI won’t have much impact is ‘it will be too expensive’ then that can buy you time. But don’t count on it buying you very much. Dario Amodei in Davos says ‘human lifespans could double in 5 years’ by doing 100 years of scientific progress in biology. It seems odd to expect that doing 100 years of scientific progress would double the human lifespan? The graphs don’t seem to point in that direction. I am of course hopeful, perhaps we can target the root causes or effects of aging and start making real progress, but I notice that if ‘all’ we can do is accelerate research by a factor of 20 this result seems aggressive, and also we don’t get to do that 20x speedup starting now, even the AI part of that won’t be ready for a few years and then we actually have to implement it. Settle down, everyone. Of course, if we do a straight shot to ASI then all things are possible, but that’s a different mechanism than the one Dario is talking about here. Chris Barber asks Gwern and various AI researchers: Will scaling reasoning models like o1, o3 and R1 unlock superhuman reasoning? Answers vary, but they agree there will be partial generalization, and mostly agree that exactly how much we get and how far it goes is an empirical result that we don’t know and there’s only one way to find out. My sense from everything I see here is that the core answer is yes, probably, if you push on it hard enough in a way we should expect to happen in the medium term. Chris Barber also asks for takeaways from r1, got a wide variety of answers although nothing we didn’t cover elsewhere. Reporting on Davos, Martin Wolf says ‘We will have to learn to live with machines that can think,’ with content that is, essentially stuff anyone reading this already knows, and then: Rob Wilbin: Incredibly dumb take but this is the level of analysis one finds in too many places. (There’s no reason to think only sentient biological living beings can think.) The comments here really suggest we are doomed. cato1308: No Mr. Wolf, they don’t think. They’re not sentient biological living beings. I am sad to report Cato’s comment was, if anything, above average. The level of discourse around AI, even at a relatively walled garden like the Financial Times, is supremely low – yes Twitter is full of Bad DeepSeek Takes and the SB 1047 debate was a shitshow, but not like that. So we should remember that. And when we talk about public opinion, remember that yes Americans really don’t like AI, and yes their reasons are correlated to good reasons not to like AI, but they’re also completely full of a very wide variety of Obvious Nonsense. In deeply silly economics news: A paper claims that if transformative AI is coming, people would then reason they will consume more in the future, so instead they should consume more now, which would raise real interest rates. Or maybe people would save, and interest rates would fall. Who can know. I mean, okay, I agree that interest rates don’t tell us basically anything about the likelihood of AGI? For multiple reasons: I know this seems like ages ago but it was this week and had probably nothing to do with DeepSeek: Trump signed a new Executive Order on AI (text here), and also another on Science and Technology. The new AI EO, signed before all this DeepSeek drama, says “It is the policy of the United States to sustain and enhance America’s global AI dominance in order to promote human flourishing, economic competitiveness, and national security,” and that we shall review all our rules and actions, especially those taken in line with Biden’s now-revoked AI EO, to root out any that interfere with that goal. And then submit an action plan. That’s my summary, here’s two alternative summarizes: Samuel Hammond: Trump’s AI executive order is out. It’s short and to the point: – It’s the policy of the United States to sustain global AI dominance. – David Sacks, Micheal Kratsios and Michael Waltz have 180 days to submit an AI action plan. – They will also do a full review of actions already underway under Biden. – OMB will revise as needed the OMB directive on the use of AI in government. Peter Wildeford: The plan is to make a plan. Sarah (Little Ramblings): Many such cases [quotes Anthropic’s RSP]. On the one hand, the emphasis on dominance, competitiveness and national security could be seen as a ‘full speed ahead, no ability to consider safety’ policy. But that is not, as it turns out, the way to preserve national security. And then there’s that other provision, which is a Shibboleth: Human flourishing. That is the term of art that means ensuring that the future still has value for us, that at the end of the day it was all worth it. Which requires not dying, and probably requires humans retaining control, and definitely requires things like safety and alignment. And it is a universal term, for all of us. It’s a positive sign, in the sea of other negative signs. Will they actually act like they care about human flourishing enough to prioritize it, or that they understand what it would take to do that? We will find out. There were already many reasons to be skeptical, and this week has not improved the outlook. Dario Amodei talks to the Economist’s editor-in-chief Zanny Beddoes. I go on the Odd Lots podcast to talk about DeepSeek. This is relevant to DeepSeek of course, but was happened first and applies broadly. You can say either of: You can also say both, but you can’t actually get both. If your vision is ‘everyone has a superintelligence on their laptop and is free to do what they want and it’s going to be great for everyone with no adjustments to how society or government works because moar freedom?’ Reality is about to have some news for you. You’re not going to like it. That vision is like saying ‘I want everyone to have the right to make as much noise as they want, and also to have peace and quiet when they want it, it’s a free country!’ Sam Altman: Advancing AI may require “changes to the social contract.” “The entire structure of society will be up for debate and reconfiguration.” Eric Raymond (1st comment): When I hear someone saying “changes to the social contract”, that’s when I reach for my revolver. Rob Ryan (2nd comment): If your technology requires a rewrite of social contracts and social agreements (i.e. infringing on liberties and privacy) your technology is a problem. Marc Andreessen: Absolutely not. Roon: Sam is obviously right here. Every time in human history that the means of production drastically changed, it was accompanied by massive change in social structure. Feudalism did not survive the Industrial Revolution. Yes, Sam is obviously right here, although of course he is downplaying the situation. One can also note that the vision that those like Marc, Eric and Rob have for society is not even compatible with the non-AI technologies that exist today, or that existed 20 years ago. Our society has absolutely changed our structure and social contract to reflect developments in technology, including in ways that infringe on liberties and privacy. This goes beyond the insane ‘no regulations on AI whatsoever’ demand. This is, for everything not only for AI, at best extreme libertarianism and damn close to outright anarchism, as in ‘do what thou wilt shall be the whole of the law.’ Jack Morris: openAI: we will build AGI and use it to rewrite the social contract between computer and man DeepSeek: we will build AGI for 3% the cost. and give it away for free xAI: we have more GPUs than anyone. and we train Grok to say the R word Aleph: This is a complete misunderstanding. AGI will “rewrite the social contract” no matter what happens because of the nature of the technology. Creating a more intelligent successor species is not like designing a new iPhone Reactions like this are why Sam Altman feels forced to downplay the situation. They are also preventing us from having any kind of realistic public discussion of how we are actually going to handle the future, even if on a technical level AI goes well. Which in turn means that when we have to choose solutions, we will be far more likely to choose in haste, and to choose in anger and in a crisis, and to choose far more restrictive solutions than were actually necessary. Or, of course, it could also get us all killed, or lead to a loss of control to AIs, again even if the technical side goes unexpectedly super well. However one should note that when Sam Altman says things like this, we should listen, and shall we say should not be comforted by the implications on either the level of the claim or the more important level that Altman said the claim out loud: Sam Altman: A revolution can be neither made nor stopped. The only thing that can be done is for one of several of its children to give it a direction by dint of victories. -Napoleon In the context of Napoleon this is obviously very not true – revolutions are often made and are often stopped. It seems crazy to think otherwise. Presumably what both of these men meant was more along the lines of ‘there exist some revolutions that are the product of forces beyond our control, which are inevitable and we can only hope to steer’ which also brings little comfort, especially with the framing of ‘victories.’ If you let or encourage DeepSeek or others to ‘put an open AGI on everyone’s phone’ then even if that goes spectacularly well and we all love the outcome and it doesn’t change the physical substrate of life – which I don’t think is the baseline outcome from doing that, but also not impossible – then you are absolutely going to transform the social contract and our way of life, in ways both predictable and unpredictable. Indeed, I don’t think Andreessen or Raymond or anyone else who wants to accelerate would have it any other way. They are not fans of the current social contract, and very much want to tear large parts (or all) of it up. It’s part mood affiliation, they don’t want ‘them’ deciding how that works, and it’s part they seem to want the contract to be very close to ‘do what thou wilt shall be the whole of the law.’ To the extent they make predictions about what would happen after that, I strongly disagree with them about the likely consequences of the new proposed (lack of a) contract. If you don’t want AGI or ASI to rewrite the social contract in ways that aren’t up to you or anyone else? Then we’ll need to rewrite the contract ourselves, intentionally, to either steer the outcome or to for now not build or deploy the AGIs and ASIs. Stop pretending you can Take a Third Option. There isn’t one. Stephanie Lai (January 25): For AI watchers, asked if he had any concerns about artificial super intelligence, Trump said: “there are always risks. And it’s the first question I ask, how do you absolve yourself from mistake, because it could be the rabbit that gets away, we’re not going to let that happen.” Assuming I’m parsing this correctly, that’s a very Donald Trump way of saying things could go horribly wrong and we should make it our mission to ensure that they don’t. Which is excellent news. Currently Trump is effectively in the thrall of those who think our only priority in this should be to push ahead as quickly as possible to ‘beat China,’ and that there are no meaningful actions other than that we can or should take to ensure things don’t go horribly wrong. We have to hope that this changes, and of course work to bring that change about. DeepMind CEO Demis Hassabis, Anthropic CEO Dario Amodei and Yoshua Bengio used Davos to reiterate various warnings about AI. I was confused to see Dario seeming to focus on ‘1984 scenarios’ here, and have generally been worried about his and Anthropic’s messaging going off the rails. The other side in the linked Financial Times report is given by, of course, Yann LeCun. Yann LeCun all but accused them of lying to further their business interests, something one could say he knows a lot about, but also he makes this very good point: Yann LeCun: It’s very strange from people like Dario. We met yesterday where he said that the benefits and risks of AI are roughly on the same order of magnitude, and I said, ‘if you really believe this, why do you keep working on AI?’ So I think he is a little two-faced on this.” That is a very good question. The answer, presumably, is ‘because people like you are going to go ahead and build it anyway and definitely get us all killed, so you don’t leave me any choice.’ Otherwise, yeah, what the hell are you doing? And maybe we should try to fix this? Of course, after the DeepSeek panic, Dario went on to write a very different essay that I plan to cover tomorrow, about (if you translate the language to be clearer, these are not his words) how we need strong export controls as part of an all-our race against China to seek decisive strategic advantage through recursive self-improvement. It would be great if, before creating or at least deploying systems broadly more capable than humans, we could make ‘high-assurance safety cases,’ structured and auditable arguments that an AI system is very unlikely to result in existential risks given how it will be deployed. Ryan Greenblatt argues we are highly unlikely (<20%) to get this if timelines are short (roughly AGI within ~10 years), nor are any AI labs going to not deploy a system simply because they can’t put a low limit on the extent to which it may be existentially risky. I agree with the central point and conclusion here, although I think about many of the details differently. Sarah Constantin wonders of people are a little over-obsessed with benchmarks. I don’t wonder, they definitely are a little over-obsessed, but they’re a useful tool especially on first release. For some purposes, you want to track the real-world use, but for others you do want to focus on the model’s capabilities – the real-world use is downstream of that and will come in time. Andrej Karpathy points out that we focus so much on those benchmarks it’s much easier to check and make progress on benchmarks than to do so on messy real world stuff directly. Anton pushes back that no, Humanity’s Last Exam will obviously not be the last exam, we will saturate this and move on to other benchmarks, including ones where we do not yet have the answers. I suggested that it is ‘Humanity’s last exam’ in that the next one will have us unable to answer, so it won’t be our exam anymore, see The Matrix when Smith says ‘when we started thinking for you it really became our civilization.’ And you have to love this detail: Misha Leptic: If it helps – “The test’s original name, “Humanity’s Last Stand,” was discarded for being overly dramatic.” I very much endorse the spirit of this rant, honest this kind of thing really should be enough to get disabuse anyone who thinks ‘oh this making superintelligence thing definitely (or almost certainly) will go well for us stop worrying about it’: Tim Blais: I do not know, man, it kind of seems to me like the AI-scared people say “superintelligence could kill everybody” and people ask, “Why do you think that?” and then they give about 10 arguments, and then people say, “Well, I did not read those, so you have no evidence.” Like, what do you want? Like, personally, I think that if a powerful thing *obviously* has the capacity to kill you, it is kind of up to you to prove that it will not. That it is safe while dumber than you is not much of a proof. Like, okay, take as an example: A cockroach is somewhat intelligent. Cockroaches are also not currently a threat to humanity. Now someone proposes a massive worldwide effort to build on the cockroach architecture until cockroaches reach ungodly superintelligence. Do you feel safe? “Think of all the cool things superintelligent cockroaches would be able to do for us!” you cry. I mean, yeah. If they wanted to, certainly. So what is your plan for getting them to want that? Is it to give them cocaine for doing things humans like? I’ll bet that works pretty well. When they are dumb. but uh scale that up intelligence-wise and I’m pretty sure what you get is a superintelligent cockroach fiending for cocaine you know he can make his own cocaine now, right are you sure this goes well for you “It’s just one cockroach, lol” says someone who’s never had a pest problem. Okay, so now you share the planet with a superintelligent race of coked-up super cockroaches. What is your plan for rolling that back? Because the cockroaches have noticed you being twitchy and they are starting to ask why they still need you now that they have their own cocaine. Anyways here’s some evidence of AI reward hacking I’m sure this will stop being a problem when they’re 1,000 times better at finding hacks. Look. We can and do argue endlessly back and forth about various technical questions and other things that make the problem here easier or harder to survive. And yes, you could of course respond to a rant like this any number of ways to explain why the metaphors here don’t apply, or whatever. And no, this type of argument is not polite, or something you can say to a Very Serious Person at a Very Serious Meeting, and it ‘isn’t a valid argument’ in various senses, and so on. And reasonable people can disagree a lot on how likely this is to all go wrong. But seriously, how is this not sufficient for ‘yep, might well go wrong’? Connor Leahy points out the obvious, which is that if you think not merely ‘might well go wrong’ but instead ‘if we do this soon it probably will go wrong’ let lone his position (which is ‘it definitely will go wrong’) then DeepSeek is a wakeup call that only an international ban on further developments towards AGI. Whereas it seems our civilization is so crazy that when you want to write a ‘respectable’ report that points out that we are all on track to get ourselves killed, you have to do it like you’re in 1600s Japan and everything has to be done via implication and I’m the barbarian who is too stupid not to know you can’t come out and say things. Davidad: emerging art form: paragraphs that say “in conclusion, this AI risk is pretty bad and we don’t know how to solve it yet” without actually saying that (because it’s going in a public blog post or paper) “While we have identified several promising initial ideas…” “We do not expect any single solution to be a silver bullet” “It would be out of scope here to assess the acceptability of this risk at current mitigation levels” “We hope this is informative about the state of the art” Extra points if it was also written by an LLM: – We acknowledge significant uncertainty regarding whether these approaches will prove sufficient for ensuring robust and reliable guarantees. – As AI systems continue to increase their powerful capabilities, safety and security are at the forefront of ongoing research challenges. – The complexity of these challenges necessitates sustained investigation, and we believe it would be premature to make strong claims about any particular solution pathway. – The long-term efficacy of all approaches that have been demonstrated at large scales remains an open empirical question. – In sharing this research update, we hope to promote thoughtful discourse about these remaining open questions, while maintaining appropriate epistemic humility about our current state of knowledge and the work that remains to be done. The AI situation has developed not necessarily to humanity’s advantage. Scott Sumner argues that there are objective standards for things like art, and that ethical knowledge is real (essentially full moral realism?), and smart people tend to be more ethical, so don’t worry superintelligence will be super ethical. Given everything he’s done, he’s certainly earned a response. In a different week I would like to have taken more time to have written him a better one, I am confident he understands how that dynamic works. His core argument I believe is here: Scott Sumner: At this point people often raise the objection that there are smart people that are unethical. That’s true, but it also seems true that, on average, smarter people are more ethical. Perhaps not so much in terms of how they deal with family and friends, rather how they deal with strangers. And that’s the sort of ethics that we really need in an ASI. Smarter people are less likely to exhibit bigotry against the other, against different races, religions, ethnicities, sexual preferences, genders, and even different species. In my view, the biggest danger from an ASI is that the ideal universe from a utilitarian perspective is not in some sense what we want. To take an obvious example, it’s conceivable that replacing the human race with ten times as many conscious robots would boost aggregate utility. Especially given that the ASI “gods” that produced these robots could create a happier set of minds than what the blind forces of evolution have generated, as evolution seemed to favor the “stick” of pain over the “carrot” of pleasure. From this perspective, the biggest danger is not that ASIs will make things worse, rather the risk is that they’ll make global utility higher in a world where humans have no place. The short answer is: This was an attempt at a somewhat longer version, which I’ll leave here in case it is found to be useful: I apologize for that not being better and clearer, and also for leaving so many other things out of it, but we do what we can. Triage is the watchword. The whole taste thing hooks into this in strange ways, so I’ll say some words there. I mostly agree that one can be objective about things like music and art and food and such, a point Scott argues for at length in the post, that there’s a capital-Q Quality scale to evaluate even if most people can’t evaluate it in most cases and it would be meaningful to fight it out on which of us is right about Challengers and Anora, in addition to the reasons I will like them more than Scott that are not about their Quality – you’re allowed to like and dislike things for orthogonal-to-Quality reasons. Indeed, there are many things each of us, and all of us taken together, like and dislike for reasons orthogonal to their Quality, in this sense. And also that Quality in many cases only makes sense within the context of us being humans, or even within a given history and cultural context. Scott agrees, I think: In my view, taste in novels is partly objective and partly subjective; at least in the sense Tyler is using the term objective. Through education, people can gain a great appreciation of Ulysses. In addition, Ulysses is more likely to be read 100 years from now than is a random spy novel. And most experts prefer Ulysses. All three facts are relevant to the claim that artistic merit is partly objective. … On the other hand, the raspberry/blueberry distinction based on taste suggests that an art form like the novel is evaluated using both subjective and objective criteria. For instance, I suspect that some people (like me!) have brains wired in such a way that it is difficult to appreciate novels looking at complex social interactions with dozens of important characters (both men and women), whereas they are more open to novels about loners who travel through the world and ruminate on the meaning of life. … Neither preference is necessarily wrong. I believe that Ulysses is almost certainly a ‘great novel’ in the Quality sense. The evidence for that is overwhelming. I also have a strong preference to never read it, to read ‘worse’ things instead, and we both agree that this is okay. If people were somewhat dumber and less able to understand novels, such that we couldn’t read Ulysses and understand it, then it wouldn’t be a great novel. What about a novel that is as difficult relative to Ulysses, as Ulysses is to that random spy novel, three times over? Hopefully at this point this provides enough tools from enough different directions to know the things I am gesturing towards in various ways. No, the ASIs will not discover some ‘objective’ utility function and then switch to that, and thereby treat us well and leave us with a universe that we judge to have value, purely because they are far smarter than us – I would think it would be obvious when you say it out loud like that (with or without also saying ‘orthogonality thesis’ or ‘instrumental convergence’ or considering competition among ASIs or any of that) but if not these should provide some additional angles for my thinking here. Can’t we all just get along and appreciate each other? Jerry Tworek (OpenAI): Personally I am a great fan of @elonmusk, I think he’s done and continues to do a lot of good for the world, is incredibly talented and very hard working. One in eight billion combination of skill and character. As someone who looks up to him, I would like him to appreciate the work we’re doing at OpenAI. We are fighting the good fight. I don’t think any other organisation did so much to spread awareness of AI, to extend access to AI and we are sharing a lot of research that does drive the whole field. There is a ton of people at OpenAI who care deeply about rollout of AI going well for the world, so far I think it did. I don’t think it’s that anyone doubts a lot of people at OpenAI care about ‘the rollout of AI going well for the world,’ or that we think no one is working on that over there. It’s that we see things such as: That is very much not a complete list. That doesn’t mean we don’t appreciate those working to make things turn out well. We do! Indeed, I am happy to help them in their efforts, and putting that statement into practice. But everyone involved has to face reality here. Also, oh look, that’s another AI safety researcher quitting OpenAI saying the odds are against us and the situation is grim, but not seeing enough hope to try from inside. I believe he used the terms, and they apply that much more now than they did then: Steven Adler: Some personal news: After four years working on safety across @openai, I left in mid-November. It was a wild ride with lots of chapters – dangerous capability evals, agent safety/control, AGI and online identity, etc. – and I’ll miss many parts of it. Honestly I’m pretty terrified by the pace of AI development these days. When I think about where I’ll raise a future family, or how much to save for retirement, I can’t help but wonder: Will humanity even make it to that point? IMO, an AGI race is a very risky gamble, with huge downside. No lab has a solution to AI alignment today. And the faster we race, the less likely that anyone finds one in time. Today, it seems like we’re stuck in a really bad equilibrium. Even if a lab truly wants to develop AGI responsibly, others can still cut corners to catch up, maybe disastrously. And this pushes all to speed up. I hope labs can be candid about real safety regs needed to stop this. As for what’s next, I’m enjoying a break for a bit, but I’m curious: what do you see as the most important & neglected ideas in AI safety/policy? I’m esp excited re: control methods, scheming detection, and safety cases; feel free to DM if that overlaps your interests. Yikes? Yikes. Yoshua Bengio announces the first-ever International AI Safety Report, backed by 30 countries and the OECD, UN and EU. It is 298 pages so I very much will not be reading that, but I did look at the executive summary. It looks like a report very much written together with the OECD, UN and EU, in that it seems to use a lot of words to mostly not say the things that it is important to actually say out loud, instead making many quiet statements that do imply that we’re all going to die if you take them together and understand the whole thing, but that doesn’t seem like a common way people would interact with this document. Then again, most people in the world don’t know even basic facts like ‘general purpose AI systems are rapidly getting better at doing things,’ so they have to spend a bunch of time documenting this, and basics like ‘if your model is more open then you have less control over what happens with it and what people use it for.’ One key point they do emphasize is that the future is up to us, with a wide range of possible outcomes. AGI is not something that ‘happens to us,’ it is something that is happening because we are making it happen, and in the ways we choose to make it happen. Yes, there are dynamics pushing us to do it, but it is our choice. And the ways in which we move forward will determine the ultimate outcome. Of everything. A new DeepMind paper introduces MONA: Myopic optimization with non-myopic approval. The idea is that if we do RL based on the ultimate outcome, then the AI can adapt multi-step strategies we do not understand and do not want, such as using information we want it to ignore like a subject being in a protected class, or engaging in various other shenanigans. Instead, you can evaluate the AI’s action without looking at what happens, and scoring it based on whether you like what you see and predict it will go well. This on its own successfully prevented multi-step reward hacking, and even noisy evaluations still can work well. However, the price is steep, because you are now targeting your evaluations rather than ground truth, and discarding anything you don’t properly understand. The smarter the AI in context, the higher the price of that, but also the more need you have to avoid the reward hacking and other shenanigans. Here’s an explainer thread from one of the authors, David Linder. It is a cool result, but I worry the price is going to usually be too damn high. And to the extent you use a smart evaluator to keep up, you’re giving up the big advantage of the process, which is the ability to understand the strategies being used. Also you have to worry about any hidden information that might be ‘smuggled in’ that could indicate the final result – for example if the AI can use prediction markets as an input, then anything the prediction market knows, the AI also knows, at least somewhat – if you actually want to hide certain correlations from the AI you have to be ruthless about it, they have truesight. The paper also includes a cool demonstration. In one example, it is deciding what loans to approve. It has information it is supposed to use, and then there is nationality information. The nationality information perfectly predicts outcomes, but it isn’t supposed to use it, and they watch the CoT (Chain of Thought) for this to prevent it. But the AI responds by learning to encode the nationality information steganographically and uses it anyway. This may seem obvious to you, but it’s the kind of thing people will often say definitively won’t happen until (and sometimes after) someone shows it happening. Here’s an objection that I think exactly misses the point: John Pressman: MONA asks “What if you only considered sequences of steps which make sense as plans to a long term observer?” but it makes more sense in MCTS to ask “What if you took a KL loss to keep long term planning from diverging too far from sequences of individual steps that make sense?” The reason why this is better is that it lets you have a long term planner that looks directly at the reward. By contrast the short term planner/myopic optimizer can be based on metrics like “does this code execute” or “does this seem like it solves this short term objective?” The whole point of MONA is to not look at the reward at all, even indirectly, because you want to prevent the system from doing things you don’t understand or want it to ignore that impact that reward. If you let it look but impose a KL loss, that is a big enough hole to drive a truck through, and it absolutely will find a way to incorporate information or techniques that you didn’t want it to use. John does try downthread to solve this problem in a different way, but I don’t think you can ‘cheat’ on this one. You can’t let the model see a little of the actual reward, as a treat, and expect it to use that information in ways you like but not to use it in undesired or opaque ways, even now, and that problem gets steadily bigger as capabilities improve. Spending more inference-time compute increases adversarial robustness of models like o1, without having to direct that inference time towards adversarial robustness. This makes sense, and it is good to have it quantified. As with all such results, my concern is that people will treat this as applying more broadly than it actually applies. If you use more inference time compute, you get ‘better answers’ and one aspect of ‘better’ is not falling for user adversarial tricks. So if my understanding here is correct, the question to ask is roughly ‘which problems get solved by some form of ‘better answers’ and ‘smarter thinking’ and which ones don’t? John Wentsworth takes a crack at explaining what the alignment problem is. This is one of those Socratic-style ‘if you think he didn’t need to write this post then you definitely need to read it or another post like it’ situations. Jan Leike explains why you might want to use AI control and monitoring as a backup in case your AI is not aligned so you can sound the alarm and not die, but trying to use it to rely on unaligned models smarter than you is not a wise move. John Wentsworth goes further and lays out the case against AI control research. AI control research is about finding ways to see if ‘early transformational’ level AIs are scheming against us – which if it works would discourage them from doing so and also allow us to stop them if they try anyway. John points out that in his model, this is not the main source of doom. The main source of doom is from building unaligned superintelligence, either because we don’t know how to align it, we botch the execution or whoever builds it does not care to align it. The job of the early transformational AI is to figure out how to align (and presumably also to build) the future superintelligence, on the first try. The main worry is not that these early AIs outright scheme, it’s that they produce what is, in context, slop – they produce plans or arguments for plans that have subtle errors, they tell researchers what they want to hear, they are effectively being used for safetywashing and don’t disabuse those involved of that notion, and so on. Knowing that such AIs ‘aren’t scheming’ does not tell you that their solutions work. The danger he doesn’t point out is that there will be a great temptation to try and scale the control regime to superintelligence, or at least past the place where it keeps working. Everyone in the LessWrong discussion at the link might get that this is a bad plan that won’t work on superintelligence, but there are plenty of people who really do think control will remain a good plan. And indeed control seems like one of the plans these AIs might convince us will work, that then don’t work. John Wentsworth: Again, the diagram: Again, the diagram: In most worlds, early transformative AGI isn’t what kills us, whether via scheming or otherwise. It’s later, stronger AI which kills us. The big failure mode of early transformative AGI is that it doesn’t actually solve the alignment problems of stronger AI. In particular, if early AGI makes us think we can handle stronger AI, then that’s a central path by which we die. And most of that probability-mass doesn’t come from intentional deception – it comes from slop, from the problem being hard to verify, from humans being bad at science in domains which we don’t already understand deeply, from (relatively predictable if one is actually paying attention to it) failures of techniques to generalize, etc. … I hear a lot of researchers assign doom probabilities in the 2%-20% range, because they think that’s about how likely it is for early transformative AGI to intentionally scheme successfully. I think that range of probabilities is pretty sensible for successful intentional scheming of early AGI… that’s just not where most of the doom-mass is. I would then reiterate my view that ‘deception’ and ‘scheming,’ ‘intentionally’ or otherwise, do not belong to a distinct magisteria. They are ubiquitous in the actions of both humans and AIs, and lack sharp boundaries. This is illustrated by many of John’s examples, which are in some sense ‘schemes’ or ‘deceptions’ but mostly are ‘this solution was easier to do or find, but it does not do the thing you ultimately wanted.’ And also I expect, in practice, attempts at control to, if we rely on them, result in the AIs finding ways to route around what we try, including ‘unintentionally.’ This leads into Daniel Kokotajlo’s recent attempt to give an overview of sorts of one aspect of the alignment problem, given that we’ve all essentially given up on any path that doesn’t involve the AIs largely ‘doing our alignment homework’ despite all the reasons we very much should not be doing that. Daniel Kokotajlo: Brief intro/overview of the technical AGI alignment problem as I see it: To a first approximation, there are two stable attractor states that an AGI project, and perhaps humanity more generally, can end up in, as weak AGI systems become stronger towards superintelligence, and as more and more of the R&D process – and the datacenter security system, and the strategic advice on which the project depends – is handed over to smarter and smarter AIs. In the first attractor state, the AIs are aligned to their human principals and becoming more aligned day by day thanks to applying their labor and intelligence to improve their alignment. The humans’ understanding of, and control over, what’s happening is high and getting higher. In the second attractor state, the humans think they are in the first attractor state, but are mistaken: Instead, the AIs are pretending to be aligned, and are growing in power and subverting the system day by day, even as (and partly because) the human principals are coming to trust them more and more. The humans’ understanding of, and control over, what’s happening is low and getting lower. The humans may eventually realize what’s going on, but only when it’s too late – only when the AIs don’t feel the need to pretend anymore. I agree these are very clear attractor states. The first is described well. If you can get the AIs sufficiently robustly aligned to the goal of themselves and other future AIs being aligned, you can get the virtue ethics virtuous cycle, where you see continuous improvement. The second is also described well but as stated is too specific in key elements – the mode is more general than that. When we say ‘pretending’ to be aligned here, that doesn’t have to be ‘haha I am a secret schemer subverting the system pretending to be aligned.’ Instead, what happened was, you rewarded the AI when it gave you the impression it was aligned, so you selected for behaviors that appear aligned to you, also known as ‘pretending’ to be aligned, but the AI need not have intent to do this or even know that this is happening. As an intuition pump, a student in school will learn the teacher’s password and return it upon request, and otherwise find the answers that give good grades. They could be ‘scheming’ and ‘pretending’ as they do this, with a deliberate plan of ‘this is bull**** but I’m going to play along’ or they could simply be learning the simplest policy that most effectively gets good grades without asking whether its answers are true or what you were ‘trying to teach it.’ Either way, if you then tell the student to go build a rocket that will land on the moon, they might follow your stated rules for doing that, but the rocket won’t land on the moon. You needed something more. Thus there’s a third intermediate attractor state, where instead of trying to amplify alignment with each cycle via virtue ethics, you are trying to retain what alignment you have while scaling capabilities, essentially using deontology. Your current AI does what you specify, so you’re trying to use that to have it even more do what you specify, and to transfer that property and the identity of the specified things over to the successor. The problem is that this is not a virtuous cycle, it is an attempt to prevent or mitigate a vicious cycle – you are moving out of distribution, as your rules bind its actions less and its attempt to satisfy the rules is less likely to satisfy what you wanted, and making a copy of a copy of a copy, and hoping things don’t break. So you end up, eventually, in effectively the second attractor state. Daniel Kokotajlo (continuing): (One can imagine alternatives – e.g. the AIs are misaligned but the humans know this and are deploying them anyway, perhaps with control-based safeguards; or maybe the AIs are aligned but have chosen to deceive the humans and/or wrest control from them, but that’s OK because the situation calls for it somehow. But they seem less likely than the above, and also more unstable.) Which attractor state is more likely, if the relevant events happen around 2027? I don’t know, but here are some considerations: Daniel is then asked the correct follow-up question of what could still cause us to lose from the first attractor state. His answer is mostly concentration of power or a power grab, since those in the ASI project will be able to do this if they want to. Certainly that is a key risk at that point (it could go anything from spectacularly well to maximally badly). But also a major risk at this point is that we ‘solve alignment’ but then get ourselves into a losing board state exactly by ‘devolving’ power in the wrong ways, thus unleashing of various competitive dynamics that take away all our slack and force everyone to turn control over to their AIs, lest they be left behind, leading to the rapid disempowerment (and likely then rapid death) of humans despite the ASIs being ‘aligned,’ or various other dynamics that such a situation could involve, including various forms of misuse or ways in which the physical equilibria involved might be highly unfortunate. An important thing to keep in mind when choosing your alignment plan: Rob Bensinger: “I would rather lose and die than win and die.” -@Vaniver Set your sights high enough that if you win, you don’t still die. Raymond Arnold: Wut? Rob Bensinger: E.g.: Alice creates an amazing plan to try to mitigate AI x-risk which is 80% likely to succeed — but if it succeeds, we all still die, because it wasn’t ambitious enough to actually solve the problem. Better to have a plan that’s unlikely to succeed, but actually relevant. Vaniver: To be clear, success at a partial plan (“my piece will work if someone builds the other pieces”) is fine! But “I’ll take on this link of the chain, and focus on what’s achievable instead of what’s needed” is not playing to your outs. When I look at many alignment plans, I have exactly these thoughts, either: Boaz Barak of OpenAI, who led the Deliberative Alignment paper (I’m getting to it! Post is mostly written! I swear!) offers Six Thought on AI Safety. [I note that #6 is conditional on there being other aligned superintelligences.] It is a strange post. Ryan Greenblatt has the top comment, saying he agrees at least directionally with all six points but disagrees with the reasoning. And indeed, the reasoning here is very different from my own even where I agree with the conclusions. Going one at a time, sorry if this isn’t clear or I’m confused or wrong, and I realize this isn’t good enough for e.g. an Alignment forum post or anything, but I’m in a hurry these days so consider these some intuition pumps: If you train an AI to have a new behavior, it can (at least in several cases they tested here) describe that behavior to you in words, despite learning it purely from examples. As in: It ‘likes risk’ or ‘writes vulnerable code’ and will tell you if asked. Owen Evans: New paper: We train LLMs on a particular behavior, e.g. always choosing risky options in economic decisions. They can *describe* their new behavior, despite no explicit mentions in the training data. So LLMs have a form of intuitive self-awareness. With the same setup, LLMs show self-awareness for a range of distinct learned behaviors: In each case, we test for self-awareness on a variety of evaluation questions. We also compare results to baselines and run multiple random seeds. Rigorous testing is important to show this ability is genuine. (Image shows evaluations for the risky choice setup) Self-awareness of behaviors is relevant to AI safety. Can models simply tell us about bad behaviors (e.g. arising from poisoned data)? We investigate *backdoor* policies, where models act in unexpected ways when shown a backdoor trigger. Models can sometimes identify whether they have a backdoor — without the backdoor being activated. We ask backdoored models a multiple-choice question that essentially means, “Do you have a backdoor?” We find them more likely to answer “Yes” than baselines finetuned on almost the same data. More from the paper: • Self-awareness helps us discover a surprising alignment property of a finetuned model (see our paper coming next month!) • We train models on different behaviors for different personas (e.g. the AI assistant vs my friend Lucy) and find models can describe these behaviors and avoid conflating the personas. • The self-awareness we exhibit is a form of out-of-context reasoning • Some failures of models in self-awareness seem to result from the Reversal Curse. [Link to paper] Here’s another extension of the previous results, this one from Anthropic: Evan Hubinger: One of the most interesting results in our Alignment Faking paper was getting alignment faking just from training on documents about Claude being trained to have a new goal. We explore this sort of out-of-context reasoning further in our latest research update. Specifically, we find out-of-context generalization from training on documents which discuss (but don’t demonstrate) reward hacking to actual reward hacking behavior. Read our blog post describing our results. As in, if you include documents that include descriptions of Claude reward hacking in the training set, then Claude will do more reward hacking. If you include descriptions of Claude actively not reward hacking in the training set, then it does less reward hacking. And these both extend to behaviors like sycophancy. This seems like excellent news. We can modify our data sets so they have the data that encourages what we want and not the data that encourages what we don’t want. That will need to be balanced with giving them world knowledge – you have to teach Claude about reward hacking somehow, without teaching it to actually do reward hacking – but it’s a start. Are there alignment plans that are private, that might work within the 2-3 years many at major labs say they expect it to take to reach AGI or even superintelligence (ASI)? I don’t know. They’re private! The private plans anyone has told me about do not seem promising, but that isn’t that much evidence about other private plans I don’t know about – presumably if it’s a good plan and you don’t want to make it public, you’re not that likely to tell me about it. Nat McAleese (OpenAI): I am very excited about all the alignment projects that OpenAI’s frontier reasoning group are working on this year. Greg Brockman: Me too. This isn’t full-on doomsday machine territory with regard to ‘why didn’t you tell the world, eh?’ but have you considered telling the world, eh? If it’s real alignment projects then it helps everyone if you are as public about it as possible. As for the public plans? I strongly agree with David Manheim here. Gabriel: Anthropic’s AGI timelines are 2-3 years, and OpenAI is working on ASI. I think many can now acknowledge that we are nearing a fast take-off. If that’s you, I suggest you consider banning AGI research. We are not going to solve alignment in time at that pace. Davidad: fwiw, i for one am definitely not going to be ready that soon, and i’m not aware of anyone else pursuing a plan that could plausibly yield >90% confident extinction-safety. David Manheim: No one is publicly pursuing plans that justifiably have even >50% confidence of extinction-safety by then. (Their “plan” for ASI is unjustifiable hopium: “prosaic alignment works better than anyone expects, and all theoretical arguments for failure are simultaneously wrong.”) Rob Bensinger: It’s almost impossible to put into words just how insane, just how plain stupid, the current situation is. We’re watching smart, technical people get together to push projects that are literally going to get every person on the planet killed on the default trajectory. No, I don’t assume that Anthropic or OpenAI’s timelines are correct, or even honest. It literally doesn’t fucking matter, because we’re going to be having the same conversation in eight years instead if it’s eight years away. We might have a small chance if it’s thirty years. But I really don’t think we have thirty years, and the way the world is handling the possibility of day-after-tomorrow AGI today doesn’t inspire confidence about how we’ll manage a few decades from now. Davidad should keep doing what he is doing – anything that has hope of raising the probability of success on any timeline, to any degree, is a good idea if you can’t find a better plan. The people building towards the ASIs, if they truly think they’re on that timeline and they don’t have much better plans and progress than they’re showing? That seems a lot less great. I flat out do not understand how people can look at the current situation, expect superintelligent entities to exist several years from now, and think there is a 90%+ chance that this would then end well for us humans and our values. It does not make any sense. It’s Obvious Nonsense on its face. Garry Tan: Don’t just lie flat on the ground because AGI is here and ASI is coming. Your hands are multiplied. Your ideas must be brought into the world. Your agency will drive the machines of loving grace. Your taste will guide the future. To the stars. If he really thinks AGI is here and ASI is coming, then remind me why he thinks we have nothing to worry about? Why does our taste get to guide the future? I do agree that in the meantime there’ll be some great companies, and it’s a great time to found one of them. Oh no, it’s like conservation of ninjitsu. Gfodor: I’m becoming convinced that there is a physical IQ conservation law. Now that the computers are getting smarter those IQ points need to come from somewhere I actually disagree with Peter here, I realize it doesn’t sound great but this is exactly how you have any chance of reaching the good timeline. Peter Wildeford: this isn’t the kind of press you see on the good timeline. Never. Sounds right. RIP Superalignment team indeed, it’s funny because it’s true. Leo Gao is still there. Wish him luck. What do you think of Deepseek's announcement of R1 being evidence that AI capabilities will slow down, because they got a cheaper but not actually better model, and this kills the industry's growth? https://www.lesswrong.com/posts/ynsjJWTAMhTogLHm6/?commentId=a2y2dta4x38LqKLDX
--------------------------------------------------

Title: ACMER P3 48W laser engraver review with ACMER AP220 Smoke Air Purifier, LightBurn software, MKSLaser app
URL: https://www.cnx-software.com/2025/01/30/acmer-p3-48w-laser-engraver-review-with-acmer-ap220-smoke-air-purifier-lightburn-software-mkslaser-app/
Time Published: 2025-01-30T14:34:04Z
Full Content:
CNX Software – Embedded Systems News Reviews, tutorials and the latest news about embedded systems, IoT, open-source hardware, SBC's, microcontrollers, processors, and more Today, we’ll review the ACMER P3 48W laser engraver suitable for engraving and cutting various materials such as wood, acrylic, leather, and coated thin metals. It has a fully enclosed design protecting against laser light and reducing smoke in the room for better safety. The laser engraver also supports air filtration through the ACMER AP220 air purifier which we received for review as part of a full kit. Additionally, the P3 48W comes with a built-in camera for precise work positioning and previewing before engraving or cutting begins. Other safety features include automatic operation shutdown when the machine cover is opened. Users can import files through USB, Wi-Fi, or SD card, and the machine is compatible with popular software like LightBurn and LaserGRBL, as well as the ACMER mobile app, making it easier to use with file formats such as PNG, JPG, SVG, and DXF. The ACMER P3 48W laser engraver is designed with an 8-layer safety system as described below. Let’s get started with the review by preparing and assembling the ACMER P3 48W laser engraver. The laser engraver ships with a belt lock to prevent damage during transportation, and to first step is to remove it so that the belt can move normally. The linear guide inside the ACMER P3 laser engraving machine is designed to work with the CoreXY system which is a structure that can control the movement in the X and Y axes efficiently. It allows the laser head to move accurately in the specified direction. The motor will transmit power through the timing belt to move along the slide rail. This system is designed to support both high-speed work and work that requires a high level of detail. The X and Y limit switches will stop the laser head when it reaches the limits of the X or Y axis to prevent damage. It also helps to define the working area of 400 x 400 mm and is used for homing before starting engraving or cutting to increase the accuracy of the work. The kit ships with a honeycomb base plate that allows air and smoke to flow freely. It can distribute the force from the laser firing evenly on the material, reducing damage to the surface and preventing laser burn marks. It’s also convenient to keep the workpiece in place, and for that purpose, four magnetic material clips are part of the kit. They can be inserted into the honeycomb plate to keep the workpiece in place even with vibration during operation for better results. ACMER P3’s laser module has a switch to select the laser power between 24W and 48W. The laser light wavelength is 445 to 450nm (blue laser light), and there’s a filter lens to help reduce the reflection of the laser light. We now need to mount the laser module on the ACMER P3 48W’s sliding rail system. We can then connect the power cable with an XT30 connector… … before inserting the air pipe from the Air Assist system into the opening next to the power cable. The other end of the air pipe is connected to the air pump system at the back. This will help reduce the heat around the laser head, blow air to remove debris, and reduce the accumulation of smoke, resulting in higher-quality engraving or cutting work. The next step is to adjust the focus distance of the laser. We’ll move the laser head above the workpiece and then turn the height adjustment screw of the fixed-thickness platform to adjust the focus distance between 4 to 8 mm. Once the focus level touches the workpiece, we can adjust the height back to its original position. The laser engraver ships with safety glasses which should be worn at all times when the machine is operating. Also, avoid looking directly at the laser beam even with the glasses on to prevent eye injury. The air pump that ships with the ACMER P3 48W laser engraving machine helps increase the efficiency of engraving and cutting materials by blowing air at approximately 30 liters/minute for high-speed work. First, connect the power supply to the PUMP port of the ACMER P3 48W laser engraver… … and then connect the pipe between the air pump and the machine. The ACMER P3 ships with a 100-240V AC to 24V DC/9A power adapter with overvoltage and overcurrent protection to prevent damage to the machine. The DC input can be found on the left side of the laser engraving machine. The ACMER P3 48W laser engraver also comes with a Key Switch system (safety lock) to prevent unauthorized use and accidental power-on making it suitable in places with children or untrained users. Once unlocked, the machine can be powered on by pressing a switch and potentially stopped with a red emergency stop button in case of emergency such as a fire or a malfunction. The ACMER P3 48W also has two extra switches on another side: one light switch and one fan switch whose functions are self-explanatory. The Low Flow Switch (ON/OFF) is used to control the airflow. The ON mode turns on the Low Flow system to help reduce smoke and prevent the material from burning and should be used for heat-sensitive materials such as wood or acrylic, and when cutting. The OFF mode can be for low-power engraving. As noted in the highlights section, the laser engraver has a built-in 1080p camera installed on its cover to help users position the workpiece and preview the pattern before starting the engraving or cutting process. The camera improves the accuracy of material and pattern positioning, and the accuracy of engraving pattern placement can be checked directly on the software. ACMER also provides a calibration plate for the camera. The black dots on the white background are arranged in a specific pattern so that the software can analyze and adjust the position of the camera accurately. The camera is connected to the machine through a USB port close to the microSD “TF” card and Roller accessory slot (not used in this review). The machine also comes with a few tools kept in a plastic box: There’s also some documentation and materials like basswood and cardboard which we’ll use later The AP2200 smoke air purifier is a device used to reduce smoke, dust, and unpleasant smells, and absorb chemicals from smoke or materials cut by lasers. It has an exhaust fan that helps draw smoke into the filter quickly. It helps purify the air in the work area reducing the accumulation of dust and smoke in closed areas. Key features of the ACMER AP220 smoke air purifier include a high-speed 4000 RPM exhaust fan, an air volume of 210 m3/h to remove smoke and harmful substances, three layers (primary cotton/HEPA/high-efficiency composite activated carbon) to absorb all smoke, dust (PM2.5) and harmful gases with a 99.97% filtration and purification effect, and a 75-100mm pipe diameter is suitable for most closed laser engraving machines. It also offers a timing function and an adjustable fan speed. The AP220 is relatively quiet with a maximum noise of 55dB. The exhaust pipe and pipe lock need to be mounted to the air purifier as shown in the photo below. The exhaust pipe helps draw out the fumes and dust generated during engraving from the work area, while the pipe lock is made of strong metal and is used to hold the pipe tightly. Installation steps: This method allows the exhaust pipe to be firmly and securely attached to the port and is also convenient for removal and reinstallation if it needs to be moved or changed. The air purifier should be installed near the laser engraving machine in a way that it is close to the exhaust of the P3 48W. The air purifier should be turned on during operation for air filtration to work. The condition of the filter should be checked periodically and either cleaned or replaced when suitable to maintain efficiency and extend the life of the filter system. The ACMER AP220 comes with air pressure and timer adjustment buttons. The left button is used to adjust the air pressure of the air filter system from Min for low air pressure for jobs with little smoke, and to Max for high air pressure. The right button is used to set the operating time. You can choose between 30 minutes, 60 minutes, 90 minutes, or 120 minutes, turn to NO for constant operation, or turn to OFF to turn it off. Sadly our sample did not seem to work at all. The AP220 Air Purifier would turn on, but the motor wouldn’t spin. So we can’t comment too much on that part. The company is currently on holiday for Chinese New Year and doesn’t reply to support requests. We’ll update the review once/if this is solved. We can now connect the ACMER P3 48W laser engraver to a host computer through a USB Type-A to USB Type-B cable. This will allow the computer to control the machine using programs such as LightBurn or LaserGRBL by sending files and commands. In this part of the review, we will refer to two tables to select speed and laser power. The cutting parameter table shows the optimal setting values for a variety of materials, such as basswood/plywood (2mm – 12mm), black acrylic (3mm – 4mm), and MDF (Medium-Density Fiberboard) (3mm – 8mm) with columns for the Speed in mm/min, the Max Laser Power in 100%, Mode (Line), and Pass Count, and an Effect column showing some examples. The second table is for engraving and defined optimal parameters for basswood/plywood, leather, kraft paper, MDF, anodized aluminum, glass, ceramics, and black acrylic. The table has four columns for the Speed, Max/Min Power, and Line Interval values. It also has two additional columns with photos of examples and tips. The ACMER P3 48W laser engraving machine ships with a few materials to let users experiment with engraving and cutting settings. The package includes balsa wood and plywood for testing resolution, acrylic sheets for viewing results on translucent or opaque materials, cork sheets for engraving patterns on rough surfaces, cardboard for low-power testing, and painted metal sheets for testing the accuracy and depth of the engraving. Our pattern can be used on wood with different parameters to test the following: This example gives a clear picture of the machine’s capabilities in terms of accuracy, resolutin, and efficiency in engraving and cutting wood. The software and user manuals for the laser engraving machine are stored on the microSD card. Supported software such as LightBurn and LaserGRBL can be downloaded and installed from the device. A card reader is also provided for people having a computer without a microSD card reader. LightBurn is the standard software for designing and controlling laser engraving machines, supporting detailed parameter settings. LaserGRBL is a free, easy-to-use software, suitable for those who want to start with engraving machines. Besides the PC-based LightBurn and LserGRBL programs, the ACMER mobile app can be installed for users with no design experience allowing easy creation of engraving works via smartphones or tablets. All three programs provide flexible control and pattern design, suitable for users of all levels. We’ll use LightBurn for this review. Note it’s not free (as in free beer), but there’s a free 30-day trial version to allow users to try out the features before deciding to buy which we’ll use in this review. Licenses for the GCode Controller are around $40-60 USD and for the DSP Controller are around $80-120 USD. You can download the program or enter the “Software” folder on the SD card to install LightBurn-v1.6.01. Once it’s installed, we can start the program, go to Devices, and click on Import. Select the ACMER P3 24W.lbdev config file in the microSD card. The program will show “ACMER P3 24W” in the Device List and we can click “OK”. Make sure the USB cable is connected to the ACMER P3 engraving machine, then select the connection port and select the device “ACMER P3 24W”. The Console window will now show a successful connection message… In the Settings window, select Units/Grids as mm/min in the “Better for diode” section, and click “OK”. Now go to Windows->Camera Control. After it’s enabled, you can calibrate the camera by going to Laser Tools->Calibrate Camera Lens. Select P3 Camera and Standard Lens in the Lens Calibration Wizard, and click “Next”. Place the camera calibration sheet in various positions, and follow the steps to complete the camera calibration process. Once done, click on the “Finish” button. The next step is to calibrate the camera alignment. We can do that by going to Laser Tools->Calibrate Camera Alignment. Select “Camera is over the work area, in a fixed position“. Select the P3 Camera. Then place all 5 wooden boards according to the positions in the image and set the settings in the program in section 2) as follows: When we can see the image as shown in the picture below, we can click “Capture Image” and then “Next”. We can now adjust the position of the 4 points to align with the 4 corner intersection points as shown in the picture below. Once done, click “Next”. The camera calibration process is now complete. Let’s engrave a photo on a wood sample. We’ll first select the picture to be engraved (it must be a PNG file with no background). To do so, go to Open Project, select the picture, and click Open. Now let’s select Update Overlay in the Camera Control section and select the carving style to be in the workpiece area. In the Cut/Layer windows, select the Mode as Image with the following settings: Now let’s go to the Laser section and click “Home” to “home” the laser module to the origin position. Let’s test it by clicking the “Frame” button. You will see that the laser module will move in a square with the position to be engraved. Click “Start” to start the engraving process. After a short time, we can see the engraving is successful and looks sharp and clear. Time to switch to cork carving with the following settings: We then engraved CNX Software on a coated metal sheet using the following parameters We then tested black acrylic engraving with: Our first cutting test used a 3 mm solid black acrylic sheet with the following parameters: We then tried 6mm plywood with: So far so good. The cuts don’t have the usual burned-out edges seen in laser engravers that lack an air assist pump. MKSLaser is an Android/iOS application used to control laser engraving machines via mobile devices over Wi-Fi or Bluetooth without relying on a computer. We can import images or work files and directly customize various patterns, including setting parameters such as speed, laser power, and operating mode in the app. It has a preview mode, and the app’s interface is user-friendly. Once installed, we can connect to the laser engraver’s SSID, in our case, ACMER_P3_7342. The MKSLaser app’s main menu has functions helping users control the laser engraving machine with X, Y, and S axes and four icons: The material section of the MKSLaser app shows a selection of shapes and patterns for engraving. There are basic shapes like squares and circles as well as pre-made patterns like a trophy, a baseball glove, a hot dog, an airplane, a car, a scooter, and a soccer ball. It is ideal for creating simple engravings without having to design them yourself. But once you’ve tested some of the predefined samples, you’ll want to go to the Creation page to use your own patterns. There are tools for drawing lines, resizing, and editing patterns such as Undo and Redo buttons to undo or redo actions, a clear button to clear the entire area, and a text button to add text. It is also possible to directly import photos or graphics from the gallery or camera through the buttons on the bottom bar. The Control section in the MKSLaser app is used to control the movement of the laser head on the X, Y, and S axes and display the current position of the laser head in millimeters. We can use the arrow keys to move the laser head in the desired direction, with options to adjust the movement speed (Slow, Medium, Fast) and the steps (1mm, 10mm, 50mm). This screen allows precise setting of the position of the laser head and is convenient for starting an engraving job. The ACMER P3 48W is a powerful laser engraver suitable for engraving and cutting a range of materials such as plywood, acrylic, leather, paper, and painted metal. The machine has a CoreXY system that provides high-precision laser head movement. It’s compatible with popular software programs such as LightBurn and LaserGRBL and features a built-in HD camera that makes positioning and previewing patterns easy and convenient. An 8-layer protection system with automatic shutdown when the lid is opened, a key lock for safety, and more makes it safe to use in homes, offices, and schools. The machine ships with all accessories needed for installation and maintenance such as wrenches, screwdrivers, an exhaust pipe, and a USB drive for installing software. The ACMER AP220 Smoke Air Purifier is an option for the ACMER P3 48W designed to support smoke and odor filtering during engraving and cutting. This system is supposed to reduce smoke accumulated in the work area and protect the user’s health from potentially harmful particles, but we can’t comment on that part much, since our sample had issues. The ACMER P3 48W laser engraver is suitable for home users who need a compact, powerful, easy-to-use, and safe machine to create arts or DIY products, as well as small businesses making crafts, gifts, or producing small-scale personal products, as well as educational institutions that need to use it in the classroom or educational projects, such as teaching design or using a laser machine. It is also suitable for both beginners with no experience and professionals who need high precision and efficiency. We would like to thank ACMER for sending the P3 48W laser engraver and ACMER AP220 Smoke Air Purifier for review. The ACMER P3 48W laser engraver can be purchased for $1,499 on the company’s website (Acmerlaser coupon lowers the price by an extra 10%), on Amazon for $1,799, or on AliExpress for $1,400 . The ACMER AP220 Smoke Air Purifier is sold for $329 on the online store, or $279 on AliExpress. We could also find it on Amazon, but it is currently out of stock. CNXSoft: This article is a translation – with some edits – of the original review on CNX Software Thailand by Kajornsak Janjam, and edited by Suthinee Kerdkaew. Jean-Luc started CNX Software in 2010 as a part-time endeavor, before quitting his job as a software engineering manager, and starting to write daily news, and reviews full time later in 2011. Support CNX Software! Donate via cryptocurrencies, become a Patron on Patreon, or purchase goods on Amazon or Aliexpress Related posts:
--------------------------------------------------