List of news related to Meta stock price META:

Title: Oracle raises AI spending estimate, spooks investors
URL: https://www.theregister.com/2025/12/11/oracle_q2_fy_2026/
Time Published: 2025-12-11T00:20:32Z
Description: But if you assume cloud IOUs will be fulfilled, business is booming Oracle expects its FY 2026 capital expenditures will be $15 billion higher that previously predicted, as the cloudy database biz invests to accommodate AI workloads.…
--------------------------------------------------

Title: Shares of Oracle slide 10% on revenue miss and rising capital expenditures
URL: https://siliconangle.com/2025/12/10/shares-oracle-slide-10-revenue-miss-rising-capital-expenditures/
Time Published: 2025-12-10T23:50:32Z
Full Content:
UPDATED 18:50 EST / DECEMBER 10 2025 by Mike Wheatley Shares of Oracle Corp. dropped more than 10% in extended trading today after the cloud and database giant missed expectations on quarterly revenue while going full-steam ahead on its ongoing artificial intelligence infrastructure buildout. The company reported second-quarter earnings before certain costs such as stock compensation of $2.26 per share, easily beating Wall Street’s target of $1.64 per share. However, though revenue grew by 16% from a year earlier, to $16.06 billion, it fell short of the $16.21 billion analyst estimate. In terms of profitability, Oracle showed a big improvement, with net income of $6.14 billion in the quarter, up from just $3.15 billion in the year-ago quarter. However, the company’s guidance was perhaps a tad discouraging for investors. Oracle executives said they’re looking for earnings of between $1.70 and $1.74 in the third-quarter, which is only in-line with the Street’s forecast of $1.72. The company also called for revenue growth of between 19% and 21% versus the Street’s $16.87 billion estimate, which implies 19% growth. Oracle said it delivered $7.98 billion in cloud revenue during the quarter, above the $7.92 billion consensus estimate. Within that segment, cloud infrastructure revenue came to $4.1 billion, up 68% from a year ago. Today was the first quarterly earnings call by Oracle’s new co-Chief Executive Officers Clay Magouyrk and Mike Sicilia, who took over the job from former CEO Safra Catz in September. In a call with analysts, Sicilia highlighted a number of new cloud infrastructure customer wins with companies including Airbus, Deutsche Bank, LSEG, Panasonic, Canon and Rubrik. Valoir analyst Rebecca Wettemann told SiliconANGLE that it’s quite telling that Sicilia felt the need to highlight so many customer wins during the call. “The market has been really nervous about Oracle’s overreliance on OpenAI and other AI plays from a RPO and forecast perspective, so this litany of customer wins and apps growth acceleration shows some welcome diversity,” she said. Oracle’s software business didn’t fare so well, however, with revenue declining 3%, to $5.88 billion, falling short of the Street’s $6.06 billion estimate. On the other hand, Oracle’s future does look promising, with the company pointing to remaining performance obligations that soared 438% from a year ago, to a staggering $523 billion. RPO, as the metric is known, refers to contracted revenue that has not yet been realized, and is really a measure of the company’s enormous backlog of orders, mostly for cloud infrastructure capacity. Wall Street had been forecasting RPO of $501.8 billion. Oracle Principle Financial Officer Doug Kehring said on the call that the increase was the result of new commitments by customers including Meta Platforms Inc., Nvidia Corp. and others, and told analysts that the company is hoping to be able to convert this revenue sooner than expected. “This is good news for Oracle and its capex story,” Wettemann said, referring to Oracle’s runaway capital expenditures. The company has been trying to position itself at the center of the AI boom by committing to a massive data center buildout, and expects capex to increase to $50 billion this year, up from $21.2 billion in the previous fiscal year. While the increased capex has boosted the company’s revenue and backlog, some investors have become worried about the enormous amounts of debt it has taken on to fund its investments. Much of Oracle’s backlog stems from OpenAI Group PBC, which has committed to spending more than $300 billion on Oracle’s cloud infrastructure services over the next five years. “The longer the backlog sits there, the greater the risk that Oracle can’t monetize it, or the AI landscape changes enough that certain customers can’t pay on their commitments,” Wettemann explained. Constellation Research analyst Holger Mueller said some eagle-eyed investors may have noted that Oracle’s growing revenue is coming at a steep cost, resulting in lower profitability as it generates more sales. “The problem is that the $2 billion in cloud revenue growth only translated to around half a billion in operating income,” the analyst said. “At the same time, Oracle keeps spending like a drunken sailor on capex and is cash flow-negative by $13 billion. While this could end up great if AI pans out, it could also become a problem.” Kehring tried to reassure investors, telling analysts on the call that the company remains committed to maintaining its investment-grade debt rating. “There are other financing options through customers that may bring their own chips to be installed in our data centers and suppliers who may lease their chips rather than sell them,” he said. “Both of these options enable Oracle to synchronize our payments with our receipts and borrow substantially less than most people are modeling.” Mueller agreed that the debt Oracle has been taking on isn’t a problem. “With interest payments at approximately $1 billion, the debt load is more than manageable for the company,” he said. The company said its earnings during the quarter were boosted by a $2.7 billion pretax gain on the sale of its interest in chip design business Ampere, which is set to be acquired by SoftBank Group Corp. for $6.5 billion. Oracle announced the sale in March. Oracle founder, Chairman and Chief Technology Officer Larry Ellison (pictured), who remains the company’s most influential executive, said the decision to sell Ampere was taken because he thinks it no longer makes sense to continue designing, manufacturing and using its own chips in its data centers. “The company is committed to a policy of chip neutrality,” he said. “[It needs] to be prepared and able to deploy whatever chips our customers want to buy.” The earnings call comes on the back of a 23% drop in Oracle’s share price last month, its worst monthly performance since 2021. But although the stock declined further today, it’s still up more than 33% in the year to date, ahead of the broader, technology-focused Nasdaq index, which has gained just 22% this year. Support our mission to keep content open and free by engaging with theCUBE community. Join theCUBE’s Alumni Trust Network, where technology leaders connect, share intelligence and create opportunities. Founded by tech visionaries John Furrier and Dave Vellante, SiliconANGLE Media has built a dynamic ecosystem of industry-leading digital media brands that reach 15+ million elite tech professionals. Our new proprietary theCUBE AI Video Cloud is breaking ground in audience interaction, leveraging theCUBEai.com neural network to help technology companies make data-driven decisions and stay at the forefront of industry conversations. Port nets $100M to turn its developer portal into an agentic AI hub Vectara's new Tool Validator promises to prevent AI agent planning errors TheCUBE exclusive with Jensen Huang: Inside Nvidia’s trillion-dollar hunch that AI factories are the new computers Model Context Protocol security risks grow as unsecured servers appear across the internet 'PyStoreRAT' malware uses fake developer tools on GitHub to infect Windows systems Harness raises $240M to lead AI-powered DevOps beyond the code editor Port nets $100M to turn its developer portal into an agentic AI hub CLOUD - BY KYT DOTSON . 38 MINS AGO Vectara's new Tool Validator promises to prevent AI agent planning errors AI - BY MIKE WHEATLEY . 1 HOUR AGO TheCUBE exclusive with Jensen Huang: Inside Nvidia’s trillion-dollar hunch that AI factories are the new computers AI - BY EMILE LOUW . 2 HOURS AGO Model Context Protocol security risks grow as unsecured servers appear across the internet SECURITY - BY DUNCAN RILEY . 3 HOURS AGO 'PyStoreRAT' malware uses fake developer tools on GitHub to infect Windows systems SECURITY - BY DUNCAN RILEY . 3 HOURS AGO Harness raises $240M to lead AI-powered DevOps beyond the code editor AI - BY KYT DOTSON . 5 HOURS AGO
--------------------------------------------------

Title: Intel pursued deals that boosted CEO Lip-Bu Tan's fortune, sources say
URL: https://finance.yahoo.com/news/intel-pursued-deals-boosted-ceo-202405818.html
Time Published: 2025-12-10T20:24:05Z
Description: When the chairman of AI chip startup Rivos wanted Intel to bid for the company, he had no need to phone the chip giant.  Tan had pitched Intel’s board on...
--------------------------------------------------

Title: Intel pursued deals that boosted CEO Lip-Bu Tan's fortune, sources say
URL: https://www.channelnewsasia.com/business/intel-pursued-deals-boosted-ceo-lip-bu-tans-fortune-sources-say-5574846
Time Published: 2025-12-10T20:24:05Z
Full Content:
Business Intel CEO Lip-Bu Tan makes a speech on stage in Taipei, Taiwan May 19, 2025. REUTERS/Ann Wang SAN FRANCISCO, Dec 10 : When the chairman of AI chip startup Rivos wanted Intel to bid for the company, he had no need to phone the chip giant. That’s because the chairman of Rivos was also Intel’s CEO: Lip-Bu Tan. Tan had pitched Intel’s board on buying Rivos in the summer of 2025, but he had no luck. The board told Tan he had a conflict in representing both Rivos’ interests and Intel’s, and he lacked a strategy on artificial intelligence to justify a deal, three people familiar with the events told Reuters. Tan asked one of his lieutenants at Intel to pitch a new AI plan, leading to partnership talks with Rivos, the people said. But now there was a problem: social media giant Meta had been stalking Rivos and made an offer for the company. Meta’s interest spurred Intel to make its own offer. Meta countered with a sweetened bid. The competition for the startup drove the deal and incentives above the $2 billion valuation that Rivos had sought in fundraising earlier this year. Some of the sources pinned this package at around $4 billion. Subscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Meta announced plans to buy Rivos in September. By then the bidding process had boosted the startup’s returns at Meta’s expense.Reuters was unable to determine how much the Intel CEO profited personally as a Rivos shareholder because the financials are not public. But in a blog post on its website, Tan’s venture-capital firm, Walden Catalyst, touted how he had delivered a “successful outcome” for its investors and congratulated the Rivos team for their “remarkable achievement.”The events show one of at least three instances where Intel has pursued deals that benefit Tan financially either by exploring bids for startups or investing in them directly through Intel’s investment arm, Intel Capital, said two of the sources. Intel declined to make Tan available for an interview for this story. Meta did not respond to requests for comment, and Rivos declined to comment.VENTURE CAPITALIST AS CEOIntel hired Tan in March in part for his experience as a venture capitalist and unparalleled industry connections as a longtime investor in tech companies. Those connections have helped Intel clinch a $5 billion investment from Nvidia and a $2 billion investment from SoftBank.Since Tan’s arrival, Intel has implemented policies requiring Tan to recuse himself from participating in investment decisions where he might benefit, two sources said. Specifically, Tan cannot attend or vote in decision meetings of Intel’s board or Intel Capital’s investment committee if he has a conflict in a venture or company-wide transaction, the sources said.Such recusals are commonplace in industry. But they had not been an issue to the same degree at Intel because its leadership prior to Tan had fewer potentially conflicting investments, three of the sources said.In the event of a Tan recusal for Intel Capital, the first two sources said, decision-making authority for the venture unit’s investment committee goes to Chief Financial Officer David Zinsner, who reports to Tan.Intel declined to make Zinsner available for an interview.Intel’s board knew when it appointed Tan that his web of investments in chip and technology companies could create conflicts, but the board accepted this, hoping that Tan can revive the iconic U.S. chipmaker, which lost $19 billion last year, one of the people said.Intel’s 11 independent board directors did not individually comment on Tan, but in response to Reuters queries, an Intel spokesperson said: “The Board of Directors believes it’s important that Intel fully leverage his vast network and position Intel to capture the next wave of industry innovation and opportunity.”Tan’s dealmaking comes as the administration of President Donald Trump agreed to make an $8.9 billion investment for what would be the largest ownership stake in the chipmaker, designating it as strategic to the U.S. and effectively making its citizens shareholders.Some chip-industry analysts have said in research notes that they welcomed Tan’s industry relationships. “He has a wide view across the ecosystem,” said Bernstein analyst Stacy Rasgon in an interview with Reuters. “And that’s helpful for Intel.”Tan does not perceive his dealmaking at Intel to be conflicted, said two of the sources, who are familiar with his thinking. Tan believes that his roles at these startups and at Intel make him uniquely able to negotiate transactions that benefit all parties, the people said.In a statement, an Intel spokesperson disputed that Tan’s dealmaking posed any problem. “The company has an unwavering commitment to the highest standards of corporate governance, integrity, and accountability,” the spokesperson said. Tan’s “extensive relationships across the global semiconductor ecosystem are invaluable as Intel positions itself to capitalize on a rapidly evolving industry landscape.”The Securities and Exchange Commission would not require Intel to disclose related-party transactions that could involve Tan until the spring of 2026, a year after its last disclosure, which took place the week after his start date.U.S. regulations require such disclosures when transactions personally benefiting corporate officers exceed $120,000, though experts have said smaller dollar amounts can be material to investors if the information would inform a decision to sell or purchase stock.DEALS TO REVIVE INTEL’S AI STRATEGYTan believed Intel needed to buy Rivos because earlier in-house efforts to enter the AI chip market had failed, one of the sources said. In the statement, the Intel spokesperson said Tan was “advancing its AI strategy” and “revitalizing its engineering-centric, customer-first culture.”Rivos was one of the major targets for Intel where Tan had interests on both sides of the deal. Tan also pitched Intel’s board on buying the troubled AI computing startup SambaNova, where Tan served as executive chairman, the first three sources said.The rationale - debated inside Intel - was that SambaNova also could provide more tech and talent to build AI chips, the sources said.SambaNova declined to comment on any talks between the startup and Intel. “While we’re always exploring strategic options, our focus remains on accelerating the roadmap, delivering products to market, and supporting our customers,” a spokesperson said.Intel also declined to comment on the SambaNova talks.Tan’s portfolio has drawn scrutiny before. In April, Reuters documented how Tan’s investment firms had stakes in more than 600 Chinese companies, some with military ties, drawing a rebuke by Trump that the U.S. chip manufacturer’s CEO was "highly CONFLICTED.”According to a White House official, Tan subsequently cleared up Trump’s concerns in an Oval Office meeting, which paved the way for collaboration on U.S. national and economic security. In September, Trump publicly celebrated Intel’s rising share price following Tan’s Nvidia deal.Intel’s share price has roughly doubled since Tan’s appointment, outpacing the percentage gains of the S&P 500 and chip leader Nvidia in that time. TAKING CONTROL OF INTEL CAPITALSoon after his appointment as CEO, Tan took direct control of Intel’s investment arm, Intel Capital, reversing a plan to spin it off. Instead, he reorganized the company so that Intel Capital would report to him, according to two of the sources, for reasons Intel has not disclosed. Its investment committee would be composed solely of Tan and one of his direct reports, finance chief Zinsner, said three people familiar with the change.Since then, Intel Capital has invested in several companies in which Tan has a stake through his investment vehicles or venture capital firms, which include A&E Investment LLC, Celesta Capital and Walden International, three of the sources said. Some Intel staff have felt an obligation to explore such deals to win Tan’s support, two of them said.One such investment was in proteanTecs, which announced a late-stage, Series D funding round in September. Intel Capital upped its existing stake in the startup, helping increase the value of Tan’s holdings through A&E Investment and Celesta Capital, funding data shows.ProteanTecs declined to comment. A&E Investment, Walden Catalyst and Walden International did not respond to requests for comment. In a statement, Celesta Capital said Tan "has always acted with integrity and a commitment to doing what is right for all stakeholders.”Before Tan became CEO, Intel Capital co-invested with him or his investment firms at least 12 times since 2019, funding announcements show.Intel is not alone in having a venture capital arm. That’s common at large technology companies, including Nvidia, Microsoft, Alphabet and Qualcomm. But unlike those other companies, Intel is unusual in having a CEO who oversees its venture unit while also leading unrelated investment firms, a Reuters review of leadership at those companies shows.Reuters was unable to determine how much Intel’s recent investments had in total increased Tan’s net worth, estimated to be well over $500 million.Two corporate governance experts consulted by Reuters said Tan’s dealmaking raises red flags due to the conflicts inherent in forging deals with his own portfolio companies.One of them also said that Intel could benefit from Tan’s connections. “You don't want to preclude making good investments because your CEO is well connected,” said Daniel Taylor, a professor at the Wharton School specializing in corporate disclosures and insider trading.TAN TOUTS HIS BOOK The Intel CEO has consistently highlighted his portfolio in public appearances. In one of his first presentations as the Intel chief in March, he talked up his 251 chip-related investments, an online video from the occasion shows. At an October chip conference in Phoenix, Tan gave a speech representing Intel that featured slides touting still more holdings, including in proteanTecs and SambaNova.Intel’s code of conduct encourages executives to disclose potential conflicts to the company’s board and top legal and compliance officers for resolution. “We avoid situations that interfere or appear to interfere with our ability to act in the best interests of Intel,” the code of conduct states. It adds that staff must mind conflicts arising from “an ownership interest in an Intel supplier, customer, or competitor” and from “outside employment that interferes with your obligations to Intel.”The two corporate governance experts said Tan should have dropped his portfolio investments, placed them in a blind trust or set up a special committee of the board to remove potential conflicts with his investment portfolio. Some lawyers have said special committees are not always necessary, and some scholars argue outside board roles apprise executives of strategic information.Intel declined to say if Tan had taken any such measure.The Intel board’s independent Audit Committee “actively monitors, reviews, and approves, as appropriate, any related-party transactions in strict accordance with Intel’s rigorous Related-Party Transactions Policy,” the company spokesperson said.The policy has exceptions. Transactions in which an Intel executive owns less than 10 per cent of a company that is party to a deal, whose value does not exceed $1 million or 2 per cent of that company’s revenue, are deemed to be “pre-cleared,” the policy states. It was not clear how many investments by Intel, if any, fell under this policy, which pre-dated Tan’s leadership. INTEL EXPLORES BID FOR A STRUGGLING STARTUPIn 2018, SambaNova was a startup with lofty ambitions to build an AI computing system that could rival Nvidia’s AI hardware and software ecosystem. Tan’s venture firm Walden International co-led SambaNova’s $56 million Series A funding round that year, which secured Tan’s position on its board. Over the years, SambaNova hoovered up money from investors: more from Tan’s venture firm and, around 2021, a big check from SoftBank, where Tan served as a board director until 2022. The $676 million Series D round led by SoftBank valued SambaNova at around $5 billion and gave Tan’s holdings a healthy increase on paper.SoftBank declined to answer if Tan had a role in persuading it to invest in SambaNova. But the startup’s ambitious vision wasn’t panning out, three people familiar with the matter said. Customers had more demand for Nvidia’s chips, which are good for a wide variety of uses in AI. That contrasts with the silicon from SambaNova, which is designed for more specific AI applications.In 2024, Tan stepped in as SambaNova’s new executive chairman in the hopes that he could help grow its business faster. The company was poised to run out of its cash, three people familiar with the matter said. It laid off 77 people in California, or reportedly about 15 per cent of its staff, in April. The chip startup tried to drum up interest for another funding round, but found few takers, two sources said. Its revenue meant it would have to fundraise or go up for sale at a lower valuation, said the people and a third source. Bankers pegged its worth at $2 billion to around $3 billion at most, two of the sources said.Tan asked Intel to look at a deal with the chipmaker over the summer, three sources said. In recent weeks, some of SambaNova’s investors provided additional financing to tide over the startup, two people familiar with the insider round said. In a statement to Reuters, a SambaNova spokesperson confirmed the startup recently secured additional funding, adding its business “is performing really well.”Deal talks with SambaNova are ongoing, two of the sources said. Intel and SambaNova have signed a non-binding term sheet, one of them said. Meta announced plans to buy Rivos in September. By then the bidding process had boosted the startup’s returns at Meta’s expense. Reuters was unable to determine how much the Intel CEO profited personally as a Rivos shareholder because the financials are not public. But in a blog post on its website, Tan’s venture-capital firm, Walden Catalyst, touted how he had delivered a “successful outcome” for its investors and congratulated the Rivos team for their “remarkable achievement.” The events show one of at least three instances where Intel has pursued deals that benefit Tan financially either by exploring bids for startups or investing in them directly through Intel’s investment arm, Intel Capital, said two of the sources. Intel declined to make Tan available for an interview for this story. Meta did not respond to requests for comment, and Rivos declined to comment. VENTURE CAPITALIST AS CEO Intel hired Tan in March in part for his experience as a venture capitalist and unparalleled industry connections as a longtime investor in tech companies. Those connections have helped Intel clinch a $5 billion investment from Nvidia and a $2 billion investment from SoftBank. Since Tan’s arrival, Intel has implemented policies requiring Tan to recuse himself from participating in investment decisions where he might benefit, two sources said. Specifically, Tan cannot attend or vote in decision meetings of Intel’s board or Intel Capital’s investment committee if he has a conflict in a venture or company-wide transaction, the sources said. Such recusals are commonplace in industry. But they had not been an issue to the same degree at Intel because its leadership prior to Tan had fewer potentially conflicting investments, three of the sources said. In the event of a Tan recusal for Intel Capital, the first two sources said, decision-making authority for the venture unit’s investment committee goes to Chief Financial Officer David Zinsner, who reports to Tan. Intel declined to make Zinsner available for an interview. Intel’s board knew when it appointed Tan that his web of investments in chip and technology companies could create conflicts, but the board accepted this, hoping that Tan can revive the iconic U.S. chipmaker, which lost $19 billion last year, one of the people said. Intel’s 11 independent board directors did not individually comment on Tan, but in response to Reuters queries, an Intel spokesperson said: “The Board of Directors believes it’s important that Intel fully leverage his vast network and position Intel to capture the next wave of industry innovation and opportunity.” Tan’s dealmaking comes as the administration of President Donald Trump agreed to make an $8.9 billion investment for what would be the largest ownership stake in the chipmaker, designating it as strategic to the U.S. and effectively making its citizens shareholders. Some chip-industry analysts have said in research notes that they welcomed Tan’s industry relationships. “He has a wide view across the ecosystem,” said Bernstein analyst Stacy Rasgon in an interview with Reuters. “And that’s helpful for Intel.” Tan does not perceive his dealmaking at Intel to be conflicted, said two of the sources, who are familiar with his thinking. Tan believes that his roles at these startups and at Intel make him uniquely able to negotiate transactions that benefit all parties, the people said. In a statement, an Intel spokesperson disputed that Tan’s dealmaking posed any problem. “The company has an unwavering commitment to the highest standards of corporate governance, integrity, and accountability,” the spokesperson said. Tan’s “extensive relationships across the global semiconductor ecosystem are invaluable as Intel positions itself to capitalize on a rapidly evolving industry landscape.” The Securities and Exchange Commission would not require Intel to disclose related-party transactions that could involve Tan until the spring of 2026, a year after its last disclosure, which took place the week after his start date. U.S. regulations require such disclosures when transactions personally benefiting corporate officers exceed $120,000, though experts have said smaller dollar amounts can be material to investors if the information would inform a decision to sell or purchase stock. DEALS TO REVIVE INTEL’S AI STRATEGY Tan believed Intel needed to buy Rivos because earlier in-house efforts to enter the AI chip market had failed, one of the sources said. In the statement, the Intel spokesperson said Tan was “advancing its AI strategy” and “revitalizing its engineering-centric, customer-first culture.” Rivos was one of the major targets for Intel where Tan had interests on both sides of the deal. Tan also pitched Intel’s board on buying the troubled AI computing startup SambaNova, where Tan served as executive chairman, the first three sources said. The rationale - debated inside Intel - was that SambaNova also could provide more tech and talent to build AI chips, the sources said. SambaNova declined to comment on any talks between the startup and Intel. “While we’re always exploring strategic options, our focus remains on accelerating the roadmap, delivering products to market, and supporting our customers,” a spokesperson said. Intel also declined to comment on the SambaNova talks. Tan’s portfolio has drawn scrutiny before. In April, Reuters documented how Tan’s investment firms had stakes in more than 600 Chinese companies, some with military ties, drawing a rebuke by Trump that the U.S. chip manufacturer’s CEO was "highly CONFLICTED.” According to a White House official, Tan subsequently cleared up Trump’s concerns in an Oval Office meeting, which paved the way for collaboration on U.S. national and economic security. In September, Trump publicly celebrated Intel’s rising share price following Tan’s Nvidia deal. Intel’s share price has roughly doubled since Tan’s appointment, outpacing the percentage gains of the S&P 500 and chip leader Nvidia in that time. TAKING CONTROL OF INTEL CAPITAL Soon after his appointment as CEO, Tan took direct control of Intel’s investment arm, Intel Capital, reversing a plan to spin it off. Instead, he reorganized the company so that Intel Capital would report to him, according to two of the sources, for reasons Intel has not disclosed. Its investment committee would be composed solely of Tan and one of his direct reports, finance chief Zinsner, said three people familiar with the change. Since then, Intel Capital has invested in several companies in which Tan has a stake through his investment vehicles or venture capital firms, which include A&E Investment LLC, Celesta Capital and Walden International, three of the sources said. Some Intel staff have felt an obligation to explore such deals to win Tan’s support, two of them said. One such investment was in proteanTecs, which announced a late-stage, Series D funding round in September. Intel Capital upped its existing stake in the startup, helping increase the value of Tan’s holdings through A&E Investment and Celesta Capital, funding data shows. ProteanTecs declined to comment. A&E Investment, Walden Catalyst and Walden International did not respond to requests for comment. In a statement, Celesta Capital said Tan "has always acted with integrity and a commitment to doing what is right for all stakeholders.” Before Tan became CEO, Intel Capital co-invested with him or his investment firms at least 12 times since 2019, funding announcements show. Intel is not alone in having a venture capital arm. That’s common at large technology companies, including Nvidia, Microsoft, Alphabet and Qualcomm. But unlike those other companies, Intel is unusual in having a CEO who oversees its venture unit while also leading unrelated investment firms, a Reuters review of leadership at those companies shows. Reuters was unable to determine how much Intel’s recent investments had in total increased Tan’s net worth, estimated to be well over $500 million. Two corporate governance experts consulted by Reuters said Tan’s dealmaking raises red flags due to the conflicts inherent in forging deals with his own portfolio companies. One of them also said that Intel could benefit from Tan’s connections. “You don't want to preclude making good investments because your CEO is well connected,” said Daniel Taylor, a professor at the Wharton School specializing in corporate disclosures and insider trading. TAN TOUTS HIS BOOK The Intel CEO has consistently highlighted his portfolio in public appearances. In one of his first presentations as the Intel chief in March, he talked up his 251 chip-related investments, an online video from the occasion shows. At an October chip conference in Phoenix, Tan gave a speech representing Intel that featured slides touting still more holdings, including in proteanTecs and SambaNova. Intel’s code of conduct encourages executives to disclose potential conflicts to the company’s board and top legal and compliance officers for resolution. “We avoid situations that interfere or appear to interfere with our ability to act in the best interests of Intel,” the code of conduct states. It adds that staff must mind conflicts arising from “an ownership interest in an Intel supplier, customer, or competitor” and from “outside employment that interferes with your obligations to Intel.” The two corporate governance experts said Tan should have dropped his portfolio investments, placed them in a blind trust or set up a special committee of the board to remove potential conflicts with his investment portfolio. Some lawyers have said special committees are not always necessary, and some scholars argue outside board roles apprise executives of strategic information. Intel declined to say if Tan had taken any such measure. The Intel board’s independent Audit Committee “actively monitors, reviews, and approves, as appropriate, any related-party transactions in strict accordance with Intel’s rigorous Related-Party Transactions Policy,” the company spokesperson said. The policy has exceptions. Transactions in which an Intel executive owns less than 10 per cent of a company that is party to a deal, whose value does not exceed $1 million or 2 per cent of that company’s revenue, are deemed to be “pre-cleared,” the policy states. It was not clear how many investments by Intel, if any, fell under this policy, which pre-dated Tan’s leadership. INTEL EXPLORES BID FOR A STRUGGLING STARTUP In 2018, SambaNova was a startup with lofty ambitions to build an AI computing system that could rival Nvidia’s AI hardware and software ecosystem. Tan’s venture firm Walden International co-led SambaNova’s $56 million Series A funding round that year, which secured Tan’s position on its board. Over the years, SambaNova hoovered up money from investors: more from Tan’s venture firm and, around 2021, a big check from SoftBank, where Tan served as a board director until 2022. The $676 million Series D round led by SoftBank valued SambaNova at around $5 billion and gave Tan’s holdings a healthy increase on paper. SoftBank declined to answer if Tan had a role in persuading it to invest in SambaNova. But the startup’s ambitious vision wasn’t panning out, three people familiar with the matter said. Customers had more demand for Nvidia’s chips, which are good for a wide variety of uses in AI. That contrasts with the silicon from SambaNova, which is designed for more specific AI applications. In 2024, Tan stepped in as SambaNova’s new executive chairman in the hopes that he could help grow its business faster. The company was poised to run out of its cash, three people familiar with the matter said. It laid off 77 people in California, or reportedly about 15 per cent of its staff, in April. The chip startup tried to drum up interest for another funding round, but found few takers, two sources said. Its revenue meant it would have to fundraise or go up for sale at a lower valuation, said the people and a third source. Bankers pegged its worth at $2 billion to around $3 billion at most, two of the sources said. Tan asked Intel to look at a deal with the chipmaker over the summer, three sources said. In recent weeks, some of SambaNova’s investors provided additional financing to tide over the startup, two people familiar with the insider round said. In a statement to Reuters, a SambaNova spokesperson confirmed the startup recently secured additional funding, adding its business “is performing really well.” Deal talks with SambaNova are ongoing, two of the sources said. Intel and SambaNova have signed a non-binding term sheet, one of them said. Subscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. Get our pick of top stories and thought-provoking articles in your inbox Stay updated with notifications for breaking news and our best stories Get WhatsApp alerts Join our channel for the top reads for the day on your preferred chat app
--------------------------------------------------

Title: Algorithms and Capitalism: Cleaning Up The Waze Parade
URL: https://battellemedia.com/archives/2025/12/algorithms-and-capitalism-cleaning-up-the-waze-parade
Time Published: 2025-12-10T20:07:44Z
Full Content:
John Battelle's Search Blog Thoughts on the intersection of tech, business, and society. Do you feel it? A simmering discontent with the state of capitalism in American life? I certainly do. My kids engage with social media only if they have to – never because they wish to. They believe their feeds are manipulated by corporate interests, and they are distrustful of anyone who believes otherwise. My wife is convinced that anything she buys online – particularly the bigger ticket items like flights or hotels – is priced based on what algorithms calculate she can afford to pay – not what might be fair or offered to others. Parents in my friend group are terrified that their kids are using ChatGPT as a confidante and therapist whose motivations are unfathomable. The stock market keeps pushing ever upwards, but my colleagues are increasingly convinced a crash is around the corner. Something just feels….off. The complex socio-economic system that we’re all a part of seems rigged. And we feel powerless to do anything about it. Two news items from the past few days underscore this gloomy sensibility. From the Times comes this gem: Same Product, Same Store, but on Instacart, Prices Might Differ. Here’s the takeaway: digital aggregators like Instacart (and Uber, and Expedia, etc.) use a sophisticated combination of data, algorithms, and AI to extract as much profit as they can from each and every consumer with which they interact. It’s called dynamic pricing, and it’s an inevitable consequence of capitalism colliding with the digital economy. Turns out, my wife was right. The second item offering proof that something’s rotten in the state of capitalism comes courtesy of 404 Media, which uncovered some downright insidious behavior from Meta’s Instagram (I know, shocking!). In short, Instagram is creating AI-generated content based on its own users’ posts, then injecting that content into Google so as to drive more traffic back to Instagram. It’s a perfect example of “growth hacking,” a practice that Meta/Facebook perfected more than ten years ago. Turns out, my kids were right to not trust their social media feeds. What connects these two stories is how the “customer” is treated by tech platforms. The Instagram user whose posts are being distorted in pursuit of traffic, the Instacart consumer who sees a price driven by extractive algorithms – they’re being manipulated by forces they can’t see or understand. In short, they’re being treated like commodified inputs to a system, not valued customers who might have a choice as to where they shop or spend their time. They’re being taken for granted. Have you ever found yourself part of a “Waze parade,” blindly following the algorithm’s increasingly complicated instructions through suburban streets just to save a few seconds of time on your way to your destination? It kind of feels like that’s happening everywhere now, across every digital surface that’s intermediated by a profit-seeking technology company. We know it sucks, but hell, we’re already way off the highway and deep in unfamiliar territory, so let’s just keep making those lefts and rights, and hope we get there, right? Is there a way out of this algorithmic prison? I’m not sure, but I sense personal AI agents – ones that work only for us – could be a big part of the solution. I’ve written recently about the problems facing personal agents, and heard back from someone who’s working on those problems via a “loyal agents” consortium led by Consumer Reports, amongst others. They call their work “conscious commerce” – and I’m cheering for their success. From a recent post: If agentic commerce is built the way the internet works today, we’ll get an economy even more by advertising and other perverse incentives—one where your buying decisions are based on obscure deals between online retailers and AI companies, where all the intimate conversations you share flow into an ad platform, and where manipulative AI chatbots whisper in your ear over the months to spend more, or more foolishly. It doesn’t have to be that way. If we’re intentional, we can use this moment to build something much more consumer-centric—an economy where consumers have more power than ever before. Hear hear! — You can follow whatever I’m doing next by signing up for my site newsletter here. Thanks for reading. “Dynamic Pricing”. Don’t you love the way they gaslight us by making it sound like it’s something that we all might benefit from? Also, it is proven that using an Amex Platinum card jacks up your pricing on your Uber ride. Amex benefits from this too – as people spend more money on the card. Otherwise, they would make moves to do something about it and protect their cardholders. Your email address will not be published. Required fields are marked * Comment * Name * Email * Website Notify me of follow-up comments by email. Notify me of new posts by email. Δ Please leave this field emptySIGN UP FOR THE NEWSLETTER Stay up to date on the latest from BattelleMedia.com Check your inbox or spam folder to confirm your subscription. Stay up to date on the latest from BattelleMedia.com Check your inbox or spam folder to confirm your subscription.
--------------------------------------------------

Title: AI Business Deals Are Getting a Bit 2008-ish
URL: https://www.theatlantic.com/economy/2025/12/nvidia-ai-financing-deals/685197/
Time Published: 2025-12-10T18:13:00Z
Full Content:
The last time so much wealth was tied up in such obscure overlapping arrangements was just before the 2008 financial crisis. Listen to more stories on the Noa app. A company that most people have never heard of is among the year’s best-performing technology firms—and a symbol of the complex, interconnected, and potentially catastrophic ways in which AI companies do business these days. CoreWeave’s IPO in March was the largest of any tech start-up since 2021, and the company’s share price has subsequently more than doubled, outperforming even the “Magnificent Seven” tech stocks. On Wall Street, CoreWeave is regularly referred to as one of the most important companies powering the AI revolution. In the past few months, it has announced a $22 billion partnership with OpenAI, a $14 billion deal with Meta, and a $6 billion arrangement with Nvidia. Not bad for a former crypto-mining firm turned data-center operator with zero profits and billions of dollars in debt on its books. CoreWeave’s business model consists of buying up lots of high-end computer chips, and building or leasing data centers to house those chips. It then rents out those assets to AI companies that need computing power but prefer not to take on the huge up-front costs themselves. If this is straightforward enough, CoreWeave’s financial situation is anything but. The company expects to bring in $5 billion in revenue this year while spending roughly $20 billion. To cover that gap, the company has taken on $14 billion in debt, more than half of which comes due in the next year. Many of these loans were issued by private-equity firms at high interest rates, and several use complex forms of financial engineering, such as giving the money to newly formed legal entities created for the explicit purpose of borrowing on CoreWeave’s behalf (more on that later). CoreWeave also faces $34 billion in scheduled lease payments that will start kicking in between now and 2028. From the May 2025 issue: The new king of tech The money that CoreWeave is making, meanwhile, comes from just a few intimately connected sources. A single customer, Microsoft, is responsible for as much as 70 percent of its revenue; its next biggest customers, Nvidia and OpenAI, might make up another 20 percent, though exact numbers are hard to find. Nvidia is also CoreWeave’s exclusive supplier of chips and one of its major investors, meaning CoreWeave is using Nvidia’s money to buy Nvidia’s chips and then renting them right back to Nvidia. OpenAI is also a major CoreWeave investor and has close financial partnerships with both Nvidia and Microsoft. All of this might make CoreWeave the purest distillation of a trend sweeping through the AI sector. In recent months, tech giants including Amazon, Google, Meta, Microsoft, and Oracle have been making gargantuan investments in new data centers, tying together their fortunes through circular financing deals, and borrowing huge piles of debt from lightly regulated lenders. The companies and their most ardent backers argue that these deals will set them up to capture the limitless profits of the coming AI revolution. But the last time the economy saw so much wealth tied up in such obscure overlapping arrangements was just before the 2008 financial crisis. If the AI revolution fails to materialize on the scale or the timeline that the industry expects, the economic consequences could be very ugly indeed. The extreme financialization of the AI sector reflects a simple reality: The infrastructure required to train and run AI systems is so expensive that not even the largest companies have enough cash to pay for it all. Spending on data centers is conservatively projected to exceed $400 billion this year, roughly the size of the economy of Denmark; McKinsey estimates that it will reach nearly $7 trillion by 2030. Creative measures are necessary to pay for all of this investment. At the center of the action is Nvidia, the world’s most valuable company. Companies that train and run AI systems, such as Anthropic and OpenAI, need Nvidia’s chips but don’t have the cash on hand to pay for them. Nvidia, meanwhile, has plenty of cash but needs customers to keep buying its chips. So the parties have made a series of deals in which the AI companies are effectively paying Nvidia by handing over a share of their future profits in the form of equity. The chipmaker has struck more than 50 deals this year, including a $100 billion investment in OpenAI and (with Microsoft) a $15 billion investment in Anthropic. Formally, these transactions don’t obligate the AI companies to spend money on Nvidia’s chips—an Nvidia spokesperson told Bloomberg that the company “does not require any of the companies we invest in to use Nvidia technology”—but in practice, that’s where the money goes. OpenAI has made its own series of deals, including agreements to purchase $300 billion of computing power from Oracle, $38 billion from Amazon, and $22 billion from CoreWeave. Those cloud providers, in turn, are an important market for Nvidia’s chips. OpenAI has also invested in several smaller AI start-ups, which in exchange have agreed to pay for ChatGPT enterprise accounts. Even when represented visually, the resulting web of interlocking relationships is almost impossible to track. Together, these arrangements amount to an entire industry making a double-or-nothing bet on a product that is nowhere near profitable. A single company, OpenAI, is simultaneously a major source of revenue and investment for several cloud companies and chipmakers; a close financial partner to Microsoft, Oracle, and Amazon; a significant customer for Nvidia; and a leading investor in AI start-ups. And yet the company is projected to generate only $10 billion this year in revenue—less than a fifth of what it needs annually just to fund its deal with Oracle. It is on track to lose at least $15 billion this year, and doesn’t expect to be profitable until at least 2029. By one estimate, AI companies collectively will generate $60 billion in revenue against $400 billion in spending this year. The one company that is making a lot of money from the AI boom, Nvidia, is doing so only because everyone else is buying its chips in the hopes of obtaining future profits. The AI companies and their boosters see this as a gamble worth taking. Demand for AI services, they point out, is growing at an exponential rate. According to calculations by Azeem Azhar, a widely cited AI-industry analyst, the direct revenues from AI services have increased nearly ninefold over the past two years. If that pace continues, then it’s only a matter of time before AI companies will begin making record-shattering profits. “I think people who fixate on exactly how these investments are being financed are stuck in an outdated way of thinking,” Azhar told me. “Everyone is assuming that this technology will improve at a linear pace. But AI is an exponential technology. It’s a whole different paradigm.” If, however, AI does not produce the short-term profits its proponents envision—if its technical advances slow down and its productivity-enhancing effects underwhelm, as a mounting body of evidence suggests may be the case—then the financial ties that bind the sector together could become everyone’s collective downfall. The extreme concentration of stock-market wealth in a handful of tech companies with deep financial links to one another could make an AI crash even more severe than the dot-com crash of the 2000s. And a stock-market correction might be the least of America’s worries. When equity investments go bad, investors might lose their shirts, but the damage to the real economy is typically contained. (The dot-com crash, for example, didn’t cause mass unemployment.) But the AI build-out is so expensive that it can’t be funded by equity investments alone. To finance their investments, AI companies have taken on hundreds of billions of dollars in debt, a number that Morgan Stanley expects to rise to $1.5 trillion by 2028. When a bunch of highly leveraged loans go bad at the same time, the fallout can spread throughout the financial system and trigger a major recession. The AI sector’s debt is, of course, not guaranteed to go bad. But the complex way in which it is arranged and packaged isn’t reassuring. For instance, earlier this year, Meta decided to build a new data center in Louisiana that will cost $27 billion. Instead of applying for a loan from a traditional lender, the company partnered with Blue Owl Capital, a private-equity firm, to set up a separate legal entity, known as a special-purpose vehicle, or SPV, that will borrow the money on Meta’s behalf, build the data center according to Meta’s instructions, and then lease it back to Meta. Because Blue Owl is technically the majority owner of the project, this setup keeps the debt off of Meta’s balance sheet, enabling the company to keep borrowing at low interest rates without worrying about a hit to its credit rating. Other companies, including xAI, CoreWeave, and Google, have borrowed or plan to borrow huge sums through similar kinds of arrangements. Meta has described its arrangement with Blue Owl as an “innovative partnership” that is “designed to support the speed and flexibility required for Meta’s data center projects.” But the reason the credit-rating system exists is to give lenders and investors a clear sense of the risk they are taking on when they issue a loan. A long history exists of companies trying to circumvent that system. In the run-up to the 2008 financial crisis, several major financial institutions used SPVs to keep billions of dollars in household debt off of their balance sheets. Enron, the energy corporation that famously collapsed in 2001 after a massive accounting scandal, used SPVs to mask its shady accounting practices. “When I see arrangements like this, it’s a huge red flag,” Paul Kedrosky, a managing partner at SK Ventures and research fellow at MIT who has written extensively about financial-engineering techniques, told me. “It sends the signal that these companies really don’t want the credit-rating agencies to look too closely at their spending.” SPVs aren’t the only 2008-era financing tool making a comeback. Data-center debt totaling billions of dollars is being sliced up into “asset-backed securities,” which are then bundled and sold to investors. This is not an inherently problematic way for companies to fund their borrowing. But Kedrosky argues that during periods of heightened speculation, these vehicles turn debt into a financial product whose worth is disconnected from the value of the underlying asset it represents—which can encourage reckless behavior. “Investors see these complex financial products and they say, I don’t care what’s happening inside—I just care that it’s highly rated and promises a big return,” Kedrosky said. “That’s what happened in ’08. And once that kind of thinking takes off, it becomes really dangerous.” Rogé Karma: Just how bad would an AI bubble be? Then there are the so-called GPU-backed loans. Several data-center builders and cloud providers, including CoreWeave, have obtained multibillion-dollar loans to purchase chips by posting their existing chips as collateral, just as many homeowners used their homes as collateral to take out loans for second and third homes in the 2000s. But, as Advait Arun, an analyst at the Center for Public Enterprise, notes in a recent report on the AI sector’s finances, whether that collateral will hold its value is far from clear. When new chip models are released, the value of older models tends to fall. According to Arun, if the collapse in chip prices were steep enough, a vicious cycle could ensue. As older chips fall in value, any loan using those chips as collateral suddenly becomes at risk of default. Lenders might respond by calling in their loans early, before companies have the revenue to pay them back. At that point, the lender might try to sell the chips to recoup their investment, but that will only flood the market with even more chips, driving down the values of existing chips even further, causing other lenders to call in their loans and so on. “A few months ago I would have told you that this was building toward a repeat of the dot-com crash,” Mark Zandi, the chief economist at Moody’s Analytics, told me. “But all of this debt and financial engineering is making me increasingly worried about a 2008-like scenario.” The federal government responded to the 2008 crisis by limiting the ability of traditional banks to take on big, risky loans. Since then, however, private-equity firms, which aren’t subject to the same regulatory scrutiny as banks, have gotten more heavily into the lending business. As of early this year, these firms had lent about $450 billion in so-called private credit to the tech sector, including financing several of the deals discussed above. And, according to one estimate, they will lend it another $800 billion over the next two years. “If the AI bubble goes bust, they are the ones that will be left holding the bag,” Arun told me. A private-credit bust is almost certainly preferable to a banking bust. Unlike banks, private-equity firms don’t have ordinary depositors. In theory, if their loans fail, the groups that will be hurt the most are institutional investors, such as pension funds, university endowments, and hedge funds, limiting the damage to the broader economy. The problem is that nobody knows for certain that this is the case. Private credit is functionally a black box. Unlike banks, these entities don’t have to disclose who they are getting their money from, how much they’re lending, how much capital they’re holding, and how their loans are performing. This makes it impossible for regulators to know what risks exist in the system or how tied they are to the real economy. Evidence is growing that the links between private credit and the rest of the financial system are stronger than once believed. Careful studies from the Federal Reserve estimate that up to a quarter of bank loans to nonbank financial institutions are now made to private-credit firms (up from just 1 percent in 2013) and that major life-insurance companies have nearly $1 trillion tied up in private credit. These connections raise the prospect that a big AI crash could lead to a wave of private-credit failures, which could in turn bring down major banks and insurers, Natasha Sarin, a Yale Law School professor who specializes in financial regulation, told me. “Unfortunately, it usually isn’t until after a crisis that we realize just how interconnected the different parts of the financial system were all along,” she said. An AI-induced financial disaster is far from inevitable. Still, given the warning signs, one would hope for the federal government to be doing what it can to reduce the risk of a crisis. Instead, the Trump administration is doing the opposite. In August, the president signed an executive order that instructs federal agencies to loosen regulations so that ordinary 401(k) holders can invest directly in “alternative assets” such as, yes, private credit, a change that could expose a far broader swath of the public to the fallout if AI loans go bad. Perhaps that is the key difference between 2008 and 2025. Back then, the federal government was caught off guard by the crash; this time, it appears to be courting one. Support for these stories was provided in part by the William and Flora Hewlett Foundation. The Atlantic maintains full editorial control over its content. TheAtlantic.com © 2025 The Atlantic Monthly Group. All Rights Reserved. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply
--------------------------------------------------

Title: Is It a Bubble? By Howard Marks
URL: https://www.oaktreecapital.com/insights/memo/is-it-a-bubble
Time Published: 2025-12-10T17:30:43Z
Full Content:
Ours is a remarkable moment in world history. A transformative technology is ascending, and its supporters claim it will forever change the world. To build it requires companies to invest a sum of money unlike anything in living memory. News reports are filled with widespread fears that America’s biggest corporations are propping up a bubble that will soon pop. During my visits to clients in Asia and the Middle East last month, I was often asked about the possibility of a bubble surrounding artificial intelligence, and my discussions gave rise to this memo. I want to start off with my usual caveats: I’m not active in the stock market; I merely watch it as the best barometer of investor psychology. I’m also no techie, and I don’t know any more about AI than most generalist investors. But I’ll do my best. One of the most interesting aspects of bubbles is their regularity, not in terms of timing, but rather the progression they follow. Something new and seemingly revolutionary appears and worms its way into people’s minds. It captures their imagination, and the excitement is overwhelming. The early participants enjoy huge gains. Those who merely look on feel incredible envy and regret and – motivated by the fear of continuing to miss out – pile in. They do this without knowledge of what the future will bring or concern about whether the price they’re paying can possibly be expected to produce a reasonable return with a tolerable amount of risk. The end result for investors is inevitably painful in the short to medium term, although it’s possible to end up ahead after enough years have passed. I’ve lived through several bubbles and read about others, and they’ve all hewed to this description. One might think the losses experienced when past bubbles popped would discourage the next one from forming. But that hasn’t happened yet, and I’m sure it never will. Memories are short, and prudence and natural risk aversion are no match for the dream of getting rich on the back of a revolutionary technology that “everyone knows” will change the world. I took the quote that opens this memo from Derek Thompson’s November 4 newsletter entitled “AI Could Be the Railroad of the 21st Century. Brace Yourself,” about parallels between what’s going on today in AI and the railroad boom of the 1860s. Its word-for-word applicability to both shows clearly what’s meant by the phrase widely attributed to Mark Twain: “history rhymes.” Understanding Bubbles Before diving into the subject at hand – and having read a great deal about it in preparation – I want to start with a point of clarification. Everyone asks, “Is there a bubble in AI?” I think there’s ambiguity even in the question. I’ve concluded there are two different but interrelated bubble possibilities to think about: one in the behavior of companies within the industry, and the other in how investors are behaving with regard to the industry. I have absolutely no ability to judge whether the AI companies’ aggressive behavior is justified, so I’ll try to stick primarily to the question of whether there’s a bubble around AI in the financial world. The main job of an investment analyst – especially in the so-called “value” school to which I subscribe – is to (a) study companies and other assets and assess the level of and outlook for their intrinsic value and (b) make investment decisions on the basis of that value. Most of the change the analyst encounters in the short to medium term surrounds the asset’s price and its relationship to underlying value. That relationship, in turn, is essentially the result of investor psychology. Market bubbles aren’t caused directly by technological or financial developments. Rather, they result from the application of excessive optimism to those developments. As I wrote in my January memo On Bubble Watch, bubbles are temporary manias in which developments in those areas become the subject of what former U.S. Federal Reserve Chairman Alan Greenspan called “irrational exuberance.’’ Bubbles usually coalesce around new financial developments (e.g., the South Sea Company of the early 1700s or sub-prime residential mortgage-backed securities in 2005-06) or technological progress (optical fiber in the late 1990s and the internet in 1998-2000). Newness plays a huge part in this. Because there’s no history to restrain the imagination, the future can appear limitless for the new thing. And futures that are perceived to be limitless can justify valuations that go well beyond past norms – leading to asset prices that aren’t justified on the basis of predictable earning power. The role of newness is well described in my favorite passage from a book that greatly influenced me, A Short History of Financial Euphoria by John Kenneth Galbraith. Galbraith wrote about what he called “the extreme brevity of the financial memory” and pointed out that in the financial markets, “past experience, to the extent that it is part of memory at all, is dismissed as the primitive refuge of those who do not have the insight to appreciate the incredible wonders of the present.” In other words, history can impose limits on awe regarding the present and imagination regarding the future. In the absence of history, on the other hand, all things seem possible. The key thing to note here is that the new thing understandably inspires great enthusiasm, but bubbles are what happen when the enthusiasm reaches irrational proportions. Who can identify the boundary of rationality? Who can say when an optimistic market has become a bubble? It’s just a matter of judgment. Something that occurred to me this past month is that two of my best “calls” came in 2000, when I cautioned about what was going on in the market for tech and internet stocks, and in 2005-07, when I cited the dearth of risk aversion and the resulting ease of doing crazy deals in the pre-Global Financial Crisis world. First, in neither case did I possess any expertise regarding the things that turned out to be the subjects of the bubbles: the internet and sub-prime mortgage-backed securities. All I did was render observations regarding the behavior taking place around me. And second, the value in my calls consisted mostly of describing the folly in that behavior, not in insisting that it had brought on a bubble. Struggling with whether to apply the “bubble” label can bog you down and interfere with proper judgment; we can accomplish a great deal by merely assessing what’s going on around us and drawing inferences with regard to proper behavior. What’s Good About Bubbles? Before going on to discuss AI and whether it’s presently in a bubble, I want to spend a little time on a subject that may seem somewhat academic from the standpoint of investors: the upside of bubbles. You may find the attention I devote to this topic excessive, but I do so because I find it fascinating. The November 5 Stratechery newsletter was entitled “The Benefits of Bubbles.” In it, Ben Thompson (no relation to Derek) cites a book titled Boom: Bubbles and the End of Stagnation. It was written by Byrne Hobart and Tobias Huber, who propose that there are two kinds of bubbles: . . . “Inflection Bubbles” – the good kind of bubbles, as opposed to the much more damaging “Mean-reversion Bubbles” like the 2000’s subprime mortgage bubble. I find this a useful dichotomy. The financial fads I’ve read about or witnessed – the South Sea Company, portfolio insurance, and sub-prime mortgage-backed securities – stirred the imagination based on the promise of returns without risk, but there was no expectation that they would represent overall progress for mankind. There was, for example, no thought that housing would be revolutionized by the sub-prime mortgage movement, merely a feeling that there was money to be made from backing new buyers. Hobart and Huber call these “mean-reverting bubbles,” presumably because there’s no expectation that the underlying developments would move the world forward. Fads merely rise and fall. On the other hand, Hobart and Huber call bubbles based on technological progress – as in the case of the railroads and the internet – “inflection bubbles.” After an inflection-driven bubble, the world will not revert to its prior state. In such a bubble, “investors decide that the future will be meaningfully different from the past and trade accordingly.” As Thompson tells us: The definitive book on bubbles has long been Carlota Perez’s Technological Revolutions and Financial Capital. Bubbles were – are – thought to be something negative and to be avoided, particularly at the time Perez published her book. The year was 2002 and much of the world was in a recession coming off the puncturing of the dot-com bubble. Perez didn’t deny the pain: in fact, she noted that similar crashes marked previous revolutions, including the Industrial Revolution, railways, electricity, and the automobile. In each case the bubbles were not regrettable, but necessary: the speculative mania enabled what Perez called the “Installation Phase,” where necessary but not necessarily financially wise investments laid the groundwork for the “Deployment Period.” What marked the shift to the deployment period was the popping of the bubble; what enabled the deployment period were the money-losing investments. (All emphasis added) This distinction is very meaningful for Hobart and Huber, and I agree. They say, “not all bubbles destroy wealth and value. Some can be understood as important catalysts for techno-scientific progress.” But I would restate as follows: “Mean-reversion bubbles” – in which markets soar on the basis of some new financial miracle and then collapse – destroy wealth. On the other hand, “inflection bubbles” based on revolutionary developments accelerate technological progress and create the foundation for a more prosperous future, and they destroy wealth. The key is to not be one of the investors whose wealth is destroyed in the process of bringing on progress. Hobart and Huber go on to describe in greater depth the process through which bubbles finance the building of the infrastructure required by the new technology and thus accelerate its adoption: Most novel technology doesn’t just appear ex nihilo [i.e., from nothing], entering the world fully formed and all at once. Rather, it builds on previous false starts, failures, iterations, and historical path dependencies. Bubbles create opportunities to deploy the capital necessary to fund and speed up such large-scale experimentation – which includes lots of trial and error done in parallel – thereby accelerating the rate of potentially disruptive technologies and breakthroughs. By generating positive feedback cycles of enthusiasm and investment, bubbles can be net beneficial. Optimism can be a self-fulfilling prophecy. Speculation provides the massive financing needed to fund highly risky and exploratory projects; what appears in the short term to be excessive enthusiasm or just bad investing turns out to be essential for bootstrapping social and technological innovations . . . A bubble can be a collective delusion, but it can also be an expression of collective vision. That vision becomes a site of coordination for people and capital and for the parallelization of innovation. Instead of happening over time, bursts of progress happen simultaneously across different domains. And with mounting enthusiasm . . . comes increased risk tolerance and strong network effects. The fear of missing out, or FOMO, attracts even more participants, entrepreneurs, and speculators, further reinforcing this positive feedback loop. Like bubbles, FOMO tends to have a bad reputation, but it’s sometimes a healthy instinct. After all, none of us wants to miss out on a once-in-a-lifetime chance to build the future. In other words, bubbles based on technological progress are good because they excite investors into pouring in money – a good bit of which is thrown away – to carpet-bomb a new area of opportunity and thus jump-start its exploitation. The key realization seems to be that if people remained patient, prudent, analytical, and value-insistent, novel technologies would take many years and perhaps decades to be built out. Instead, the hysteria of the bubble causes the process to be compressed into a very short period – with some of the money going into life-changing investment in the winners but a lot of it being incinerated. A bubble has aspects that are both technological and financial, but the above citations are from the standpoint of people who crave technological progress and are perfectly happy to see investors lose money in its interest. “We,” on the other hand, would like to see technological progress but have no desire to throw away money to help bring it about. Ben Thompson ends this discussion by saying, “This is why I’m excited to talk about new technologies, the prospect for which I don’t know.” I love the fact that he’s excited by future possibilities and at the same time admits that the shape of the future is unknown (in our world, we might say “very risky”). Assessing the Current Landscape Now let’s get down to what we used to call “brass tacks.” What do we know? First, I haven’t met anyone who doesn’t believe artificial intelligence has the potential to be one of the biggest technological developments of all time, reshaping both daily life and the global economy. We also know that in recent years, economies and markets have become increasingly dependent on AI: AI is responsible for a very large portion of companies’ total capital expenditures. Capital expenditures on AI capacity account for a large share of the growth in U.S. GDP. AI stocks have been the source of the vast majority of the gains of the S&P 500. As a Fortune headline put it on October 7: 75% of gains, 80% of profits, 90% of capex – AI’s grip on the S&P is total and Morgan Stanley’s top analyst is ‘very concerned’ Further, I think it’s important to note that whereas the gains in AI-related stocks account for a disproportionate percentage of the total gains in all stocks, the excitement AI injects into the market must have added a lot to the appreciation of non-AI stocks as well. AI-related stocks have shown astronomical performance, led by Nvidia, the leading developer of computer chips for AI. From its formation in 1993 and its initial public offering in 1999, when its estimated market value was $626 million, Nvidia briefly became the world’s first company worth $5 trillion. That’s appreciation of around 8,000x, or roughly 40% a year for 26+ years. No wonder imaginations have been fired. What Are the Areas of Uncertainty? I think it’s fair to say that while we know AI will be a source of incredible change, most of us have no idea exactly what it will be able to do, how it will be applied commercially, or what the timing will be. Who will be the winners, and what will they be worth? If a new technology is assumed to be a world changer, it’s invariably assumed that the leading companies possessing that technology will be of great value. But how accurate will that assumption prove to be? As Warren Buffett pointed out in 1999, “[The automobile was] the most important invention, probably, of the first half of the 20th century. . . . If you had seen at the time of the first cars how this country would develop in connection with autos, you would have said, ‘This is the place I must be.’ But of the 2,000 companies, as of a few years ago, only three car companies survived. So autos had an enormous impact on America but the opposite direction on investors.” (Time, January 23, 2012) In AI, there are some very strong leaders at present, including some of the world’s strongest and richest companies. But new technology is notoriously disruptive. Will today’s leaders prevail or give way to upstarts? How much will the arms race cost, and who will win? Similarly, what’s a share in an upstart worth? Unlike front runners worth trillions, it’s possible to invest in some would-be challengers at enterprise values in mere billions or even – might I say? – millions. On June 25, 2024, CNBC reported as follows: A team founded by college dropouts has raised $120 million from investors led by Primary Venture Partners to build a new AI chip to take on Nvidia. Etched CEO Gavin Uberti said the startup is betting that as AI develops, most of the technology’s power-hungry computing requirements will be filled by customized, hard-wired chips called ASICs. “If transformers go away, we’ll die,” Uberti told CNBC. “But if they stick around, we’re the biggest company of all time.” Even granting the possibility that Etched won’t become the biggest company of all time, if success could give them a valuation just one-fifth of Nvidia’s peak – a mere $1 trillion – what probability of success would be required to justify an investment of $120 million? Assuming for simplicity’s sake that the investment was for a 100% ownership stake, all you need is a belief that achieving the trillion-dollar value has a probability of one-tenth of a percent for an expected return of over eight times your money. Who’s to say Etched doesn’t have that chance? And in that case, why would anyone not play? The foregoing is what I call “lottery-ticket thinking,” in which the dream of an enormous payoff justifies – no, compels – participation in an endeavor with an overwhelming probability of failing. There’s nothing wrong with calculating expected values this way. Leading venture capitalists engage in it every day to great effect. But assumptions regarding the possible payoffs and their probabilities must be reasonable. Thinking about a trillion-dollar payout will override reasonableness in any calculation. Will AI produce profits, and for whom? Two things we know little or nothing about are the profits AI will produce for vendors and its impact on non-AI companies, primarily meaning those who employ it. Will AI be a monopoly or duopoly, in which one or two leading companies are able to charge dearly for the capabilities? Or will it be a highly competitive free-for-all in which a number of firms compete on price for users’ spending on AI services, making it a commodity? Or, perhaps most likely, will it be a mix of leading companies and specialized players, some of whom compete on price and others through proprietary advantages. It’s said that the services currently responding to AI queries, such as ChatGPT and Gemini, lose money on every query they answer (of course, it’s not unusual for participants in a new industry to offer “loss leaders” for a while). Will the leading tech firms – used to success in winner-take-all markets – be content to experience losses in their AI businesses for years in order to gain share? Hundreds of billions of dollars are being committed to the race for AI leadership. Who will win, and what will be the result? Likewise, what will be AI’s impact on the companies that use it? Clearly, AI will be a great tool for enhancing users’ productivity by, among other things, replacing workers with computer-sourced labor and intelligence. But will this ability to cut costs add to the profit margins of the companies that employ it? Or will it simply enable price wars among those companies in the pursuit of customers? In that case, the savings might be passed on to the customers rather than garnered by the companies. In other words, is it possible AI will increase the efficiency of businesses without increasing their profitability? Should we worry about so-called “circular deals”? In the telecom boom of the late 1990s, in which optical fiber became overbuilt, fiber-owning companies engaged in transactions with each other that permitted them to report profits. If two companies own fiber, they just have an asset on their books. But if each buys capacity from the other, they can both report profits . . . so they did. In other cases, manufacturers loaned network operators money to buy equipment from them, before the operators had customers to justify the buildout. All this resulted in profits that were illusory. Nowadays, deals are being announced in which money appears to be round-tripped between AI players. People who believe there’s an AI bubble find it easy to view these transactions with suspicion. Is the purpose to achieve legitimate business goals or to exaggerate progress? Adding to worries, critics say, some of the deals that OpenAI has made with chipmakers, cloud computing companies and others are oddly circular. OpenAI is set to receive billions from tech companies but also sends billions back to the same companies to pay for computing power and other services. . . . Nvidia has also made some deals that have raised questions about whether the company is paying itself. It announced that it would invest $100 billion in OpenAI. The start-up receives that money as it buys or leases Nvidia’s chips. . . . Goldman Sachs has estimated that Nvidia will make 15 percent of its sales next year from what critics also call circular deals. (The New York Times, November 20) Noteworthily, OpenAI has made investment commitments to industry counterparties totaling $1.4 trillion, even though it has yet to turn a profit. The company makes clear that the investments are to be paid out of revenues received from the same parties and that it has ways to back out of these commitments. But all this raises the question of whether the AI industry has developed a perpetual motion machine. (On this subject, I’ve been enjoying articles questioning the ability of people to relate to the word “trillion,” and I think this idea is spot on. A million dollars is a dollar a second for 11.6 days. A billion dollars is a dollar a second for 31.7 years. We get that. But a trillion dollars is a dollar a second for 31,700 years. Who can get their head around the significance of 31,700 years?) What will be the useful life of AI assets? We have to wonder whether the topic of obsolescence is being handled correctly in AI-land. What will be the lifespan of AI chips? How many years of earnings growth should be counted on in assigning p/e ratios for AI-related stocks? Will chips and other aspects of AI infrastructure last long enough to repay the debt undertaken to buy them? Will artificial general intelligence (a machine capable of doing anything the human brain can do) be achieved? Will that be the end of progress, or might there be further revolutions, and what firms will win them? Will firms reach a position where technology is stable and they can extract economic value from it? Or will new technologies continually threaten to supplant older ones as the route to success? In this connection, a single issue of an FT newsletter briefly mentioned two developments that suggest the fluid nature of the competitive landscape: A study by the Massachusetts Institute of Technology and open-source AI start-up Hugging Face found that the total share of downloads of new Chinese-made open models rose to 17 per cent in the past year. The figure surpasses the 15.8 per cent share of downloads from American developers such as Google, Meta and OpenAI – the first time Chinese groups have beaten their American counterparts. . . . Nvidia shares fell sharply yesterday on fears that Google is gaining ground in artificial intelligence, erasing $115bn in market value from the AI chipmaker. (FirstFT Americas, November 26) Dynamic change creates the opportunity for incredible new technologies, but that same dynamism can threaten the leading companies’ reign. Amid all these uncertainties, investors must ask whether the assumption of continued success incorporated in the prices they’re paying is fully warranted. Is exuberance leading to speculative behavior? For an extreme example, I’ll cite the trend toward venture capital investments in startups via $1 billion “seed rounds.” Here’s one vignette: Thinking Machines, an AI startup helmed by former Open AI executive Mira Murati, just raised the largest seed round in history: $2 billion in funding at a $10 billion valuation. The company has not released a product and has refused to tell investors what they’re even trying to build. “It was the most absurd pitch meeting,” one investor who met with Murati said. “She was like, ‘So we're doing an AI company with the best AI people, but we can’t answer any questions.’ ” (“The Is How the AI Bubble Will Pop,” Derek Thompson Substack, October 2) But that’s ancient history. . . already two months old. Here’s an update: Thinking Machines Lab, the artificial intelligence startup founded by former Open AI executive Mira Murati, is in early talks to raise a new funding round at a roughly $50 billion valuation, Bloomberg News reported on Thursday. The startup was last valued at $12 billion in July, after it raised about $2 billion. (Reuters, November 13) And Thinking Machines Lab isn’t alone: In one of the boldest bets yet in the AI arms race, Safe Superintelligence (SSI), the stealth startup founded by former OpenAI chief scientist Ilya Sutskever, has raised $2 billion in a round that values the company at $32 billion – despite having no publicly released product or service. (CTech by Calcalist, April 13) What’s the end state? Part of the issue with AI includes the unusual nature of this newest thing. This isn’t like a business that designs and sells a product, making money if the selling price exceeds the cost of the inputs. Rather, it’s companies building an airplane while it’s in flight, and once it’s built, they’ll know what it can do and whether anyone will pay for its services. Many companies justify their spending because they’re not just building a product, they’re creating something that will change the world: artificial general intelligence, or A.G.I. . . . The rub is that none of them quite know how to do it. But Anton Korinek, an economist at the University of Virginia, said the spending would all be justified if Silicon Valley reached its goal. He is optimistic it can be done. “It’s a bet on A.G.I. or bust,” Dr. Korinek said. (The New York Times, November 20 – emphasis added) The yet-to-be-determined nature of the industry under construction is best captured in remarks from Sam Altman, the CEO of OpenAI, that have been paraphrased as follows: “we’ll build this sort of generally intelligent system and then ask it to figure out a way to generate an investment return from it.” This should be a source of pause for people who heretofore fully comprehended the nature of the businesses they invested in. Clearly, the value of a technology that equals or surpasses the human brain should be pretty big, but isn’t it well beyond calculation? A Word About the Use of Debt To date, much of the investment in AI and the supporting infrastructure has consisted of equity capital derived from operating cash flow. But now, companies are committing amounts that require debt financing, and for some of those companies, the investments and leverage have to be described as aggressive. The AI data centre boom was never going to be financed with cash alone. The project is too big to be paid for out of pocket. JPMorgan analysts have done some sums on the back of a napkin, or possibly a tablecloth, and estimated the bill for the infrastructure build-out would come to $5tn (not including a tip). Who knows if that’s right, but we have good reason to expect close to half a trillion in spending next year. Meanwhile, the biggest spenders (Microsoft, Alphabet, Amazon, Meta and Oracle) had only about $350bn in the bank, collectively, as of the end of the third quarter. (“Unhedged,” Financial Times, November 13) The firms mentioned above derive healthy cash flows from their very strong non-AI businesses. But the massive, winner-take-all arms race in AI is requiring some to take on debt. In fact, it’s reasonable to think one of the reasons they’re spending vast sums is to make it hard for lesser firms to keep up. Oracle, Meta, and Alphabet have issued 30-year bonds to finance AI investments. In the case of the latter two, the yields on the bonds exceed those on Treasurys of like maturity by 100 basis points or less. Is it prudent to accept 30 years of technological uncertainty to make a fixed-income investment that yields little more than riskless debt? And will the investments funded with debt – in chips and data centers – maintain their level of productivity long enough for these 30-year obligations to be repaid? On November 14, Alex Kantrowitz’s Big Technology Podcast carried a conversation with Gil Luria, Head of Technology Research at financial services firm D.A. Davidson, primarily regarding the use of debt in the AI sector. Here’s some of what Luria had to say: Healthy behavior is being practiced by “. . . reasonable, thoughtful business leaders, like the ones at Microsoft, Amazon, and Google that are making sound investments in growing the capacity to deliver AI. And the reason they can make sound investments is that they have all the customers. . . And so, when they make investments, they’re using cash on their balance sheets; they have tremendous cash flow to back it up; they understand that it’s a risky investment; and they balance it out.” Unhealthy behavior – Here he describes “. . . a startup that is borrowing money to build data centers for another startup. They’re both losing tremendous amounts of cash, and yet they’re somehow being able to raise this debt capital in order to fund this buildout, again without having the customers or the visibility into those investments paying off.” “So there’s a whole range of behaviors between healthy and unhealthy, and we just need to sort that out so we don’t make the mistakes of the past.” “There are certain things we finance through equity, through ownership, and there are certain things we finance through debt, through an obligation to pay down interest over time. And as a society, for the longest time, we’ve had those two pieces in their right place. Debt is when I have a predictable cash flow and/or an asset that can back that loan, and then it makes sense for me to exchange capital now for future cash flows to the lender. . . . We use equity for investing in more speculative things, for when we want to grow and we want to own that growth, but we’re not sure about what the cash flow is going to be. That’s how a normal economy functions. When you start confusing the two you get yourself in trouble.” Among potentially worrisome factors, Luria cites these: “A speculative asset . . . we don’t know how much of it we’re really going to need in two to five years.” Lender personnel with incentives to make loans but no exposure to long-term consequences The possibility that the supply of AI capacity catches up with or surpasses the demand The chance that future generations of AI chips will be more powerful, obsoleting existing ones or reducing their value as backing for debt Powerful competitors who vie for market share by cutting rental rates and running losses Here are some important paragraphs from Azeem Azhar’s Exponential View of October 18: When does an AI boom tip into a bubble? [Investor and engineer] Paul Kedrosky points to the Minsky moment – the inflection point when credit expansion exhausts its good projects and starts chasing bad ones, funding marginal deals with vendor financing and questionable coverage ratios. For AI infrastructure, that shift may already be underway; the telltale signs include hyperscalers’ capex outpacing revenue momentum and lenders sweetening terms to keep the party alive. Paul makes a compelling case. We’ve entered speculative finance territory – arguably past the tentative stage – and recent deals will set dangerous precedents. As Paul warns, this financing will “create templates for future such transactions,” spurring rapid expansion in junk issuance and SPV proliferation among hyperscalers chasing dominance at any cost. . . . For AI infrastructure, the warning signs are flashing: vendor financing proliferates, coverage ratios thin, and hyperscalers leverage balance sheets to maintain capex velocity even as revenue momentum lags. We see both sides – genuine infrastructure expansion alongside financing gymnastics that recall the 2000 telecom bust. The boom may yet prove productive, but only if revenue catches up before credit tightens. When does healthy strain become systemic risk? That’s the question we must answer before the market does. (Emphasis added) Azhar references the use of off-balance sheet financing via special-purpose vehicles, or SPVs, which were among the biggest contributors to Enron’s precariousness and eventual collapse. A company and its partners set up an SPV for some specific purpose(s) and supply the equity capital. The parent company may have operating control, but because it doesn’t have majority ownership, it doesn’t consolidate the SPV on its financial statements. The SPV takes on debt, but that debt doesn’t appear on the parent’s books. The parent may be an investment grade borrower, but likewise, the debt isn’t an obligation of the parent or guaranteed by it. Today’s debt may be backed by promised rent from a data center tenant – sometimes an equity partner – but the debt isn’t a direct obligation of the equity partner either. Essentially, an SPV is a way to make it look like a company isn’t doing the things the SPV is doing and doesn’t have the debt the SPV does. (Private equity funds and private credit funds are highly likely to be found among the partners and lenders in these entities.) As I quoted earlier, according to Perez (who wrote on the heels of the dot-com bubble), “what enabled the deployment period were the money-losing investments.” Early investment is lost in the “Minsky moment,” in which unwise commitments made in an extended up-cycle encounters value destruction in a correction. And there are three things we know for sure about the use of debt: it magnifies losses if there are losses (just as it magnifies the hoped-for gains if they materialize), it increases the probability of a venture failing if it encounters a difficult moment, and despite the layer of equity beneath it, it puts lenders’ capital at risk if the difficult moment is bad enough. One key risk to consider is the possibility that the boom in data center construction will result in a glut. Some data centers may be rendered uneconomic, and some owners may go bankrupt. In that case, a new generation of owners might buy up centers at pennies on the dollar from lenders who foreclosed on them, reaping profits when the industry stabilizes. This is a process through which “creative destruction” brings markets into equilibrium and reduces costs to levels that make future business profitable. Debt is neither a good thing nor a bad thing per se. Likewise, the use of leverage in the AI industry shouldn’t be applauded or feared. It all comes down to the proportion of debt in the capital structure; the quality of the assets or cash flows you’re lending against; the borrowers’ alternative sources of liquidity for repayment; and the adequacy of the safety margin obtained by lenders. We’ll see which lenders maintain discipline in today’s heady environment. It’s worth noting in this connection that Oaktree has made a few investments in data centers, and our parent, Brookfield, is raising a $10 billion fund for investment in AI infrastructure. Brookfield is putting up its own money and has equity commitments from sovereign wealth funds and Nvidia, to which it intends to apply “prudent” debt. Brookfield’s investments seem likely to go largely into geographies that are less saturated with data centers and for infrastructure to supply the vast amounts of electric power that data centers will require. Of course, we’re both doing these things on the basis of what we think are prudent decisions. I know I don’t know enough to opine on AI. But I do know something about debt, and it’s this: It’s okay to supply debt financing for a venture where the outcome is uncertain. It’s not okay where the outcome is purely a matter of conjecture. Those who understand the difference still have to make the distinction correctly. The FT’s Unhedged quotes Chong Sin, lead analyst for CMBS research at JPMorgan, as saying, “. . . in our conversations with investment grade ABS and CMBS investors, one often-cited concern is whether they want to take on the residual value risk of data centers when the bonds mature.” I’m glad potential lenders are asking the kind of questions they should. Here’s how to think about the intersection of debt and AI according to Bob O’Leary, Oaktree’s co-CEO and co-portfolio manager of our Opportunities Funds: Most technological advances develop into winner-takes-all or winner-takes-most competitions. The “right” way to play this dynamic is through equity, not debt. Assuming you can diversify your equity exposures so as to include the eventual winner, the massive gain from the winner will more than compensate for the capital impairment on the losers. That’s the venture capitalist’s time-honored formula for success. The precise opposite is true of a diversified pool of debt exposures. You’ll only make your coupon on the winner, and that will be grossly insufficient to compensate for the impairments you’ll experience on the debt of the losers. Of course, if you can’t identify the pool of companies from which the winner will emerge, the difference between debt and equity is irrelevant – you’re a zero either way. I mention this because that’s precisely what happened in search and social media: early leaders (Lycos in search and MySpace in social media) lost out spectacularly to companies that emerged later (Google in search and Facebook in social media). Trying to Get to a Conclusion There can be no doubt that today’s behavior is “speculative,” defined as based on speculation regarding the future. There’s also no doubt that no one knows what the future holds, but investors are betting huge sums on that future. In that connection, I want to say a little about the unique nature of AI. The AI revolution is different from the technological revolutions that preceded it in ways that are both wonderful and worrisome. It feels to me like a genie has been released from a bottle, and it isn’t going back in: AI may not be a tool for mankind, but rather something of a replacement. It may be capable of taking over cognition, on which humans have thus far had a monopoly. Because of this, it’s likely to be different in kind from prior developments, not just in degree. (More on this in my postscript.) AI technology is progressing at an incredibly rapid clip, possibly leaving scant time for mankind to adjust. I’ll provide two examples: Coding, which we called “computer programming” 60 years ago, is the canary in the coal mine in terms of the impact of AI. In many advanced software teams, developers no longer write the code; they type in what they want, and AI systems generate the code for them. Coding performed by AI is at a world-class level, something that wasn’t so just a year ago. According to my guide here, “There is no speculation about whether or not human replacement will take place in that vertical.” In the field of digital advertising, when users log into an app, AI engages in “ad matching,” showing them ads tailored to the preferences displayed by their prior surfing. No humans need apply to do this job. Perhaps most importantly, the growth of demand for AI seems totally unpredictable. As one of my younger advisers explained, “the speed and scale of improvement mean it’s incredibly hard to forecast demand for AI. Adoption today may have nothing to do with adoption tomorrow, because a year or two from now, AI may be able to do 10x or 100x what it can do today. Thus, how can anyone say how many data centers will be needed? And how can even successful companies know how much computing capacity to contract for?” With differences like these, how can anyone correctly judge what AI implies for the future? * * * One of the things occupying many observers at this juncture – including me – is the search for parallels to past bubbles. Here’s some historical perspective from a recent article in Wired: AI’s closest historical analogue here may be not electric lighting but radio. When RCA started broadcasting in 1919, it was immediately clear that it had a powerful information technology on its hands. But less clear was how that would translate into business. “Would radio be a loss-leading marketing for department stores? A public service for broadcasting Sunday sermons? An ad-supported medium for entertainment?” [Brent Goldfarb and David A. Kirsch of the University of Maryland] write. “All were possible. All were subjects of technological narratives.” As a result, radio turned into one of the biggest bubbles in history – peaking in 1929, before losing 97 percent of its value in the crash. This wasn’t an incidental sector; RCA was, along with Ford Motor Company, the most high-traded stock on the market. It was, as The New Yorker recently wrote, “the Nvidia of its day.” . . . In 1927, Charles Lindbergh flew the first solo nonstop transatlantic flight from New York to Paris. . . . It was the biggest tech demo of the day, and it became an enormous, ChatGPT-launch-level coordinating event – a signal to investors to pour money into the industry. “Expert investors appreciated correctly the importance of airplanes and air travel,” Goldfarb and Kirsch write, but “the narrative of inevitability largely drowned out their caution. Technological uncertainty was framed as opportunity, not risk. The market overestimated how quickly the industry would achieve technological viability and profitability.” As a result, the bubble burst in 1929 – from its peak in May, aviation stocks dropped 96 percent by May 1932. . . . It’s worth reiterating that two of the closest analogs AI seems to have in tech bubble history are aviation and broadcast radio. Both were wrapped in high degrees of uncertainty and both were hyped with incredibly powerful coordinating narratives. Both were seized on by pure play companies seeking to capitalize on the new game-changing tech, and both were accessible to the retail investors of the day. Both helped inflate a bubble so big that when it burst, in 1929, it left us with the Great Depression. (“AI Is the Bubble to Burst Them All,” Brian Merchant, Wired, October 27 – emphasis added. N.b., the Depression had many causes beyond the bursting of the radio/aviation bubble.) Derek Thompson, who supplied the quote with which I opened this memo, ended his newsletter with some terrific historical perspective: The railroads were a bubble and they transformed America. Electricity was a bubble, and it transformed America. The broadband build-out of the late-1990s was a bubble that transformed America. I am not rooting for a bubble, and quite the contrary, I hope that the US economy doesn’t experience another recession for many years. But given the amount of debt now flowing into AI data center construction, I think it’s unlikely that AI will be the first transformative technology that isn’t overbuilt and doesn’t incur a brief painful correction. (“AI Could Be the Railroad of the 21st Century. Brace Yourself.” November 4 – emphasis added) The skeptics readily cite ways in which today’s events are comparable to the internet bubble: A change-the-world technology Exuberant, speculative behavior The role of FOMO Suspect, circular deals The use of SPVs $1 billion seed rounds The supporters have reasons why the comparison isn’t appropriate: An existing product for which there is strong demand One billion users already (many times the number of internet users at the height of the bubble) Well-established main players with revenues, profits, and cash flow The absence of an IPO craze with prices doubling in a day Reasonable p/e ratios for the established participants I’ll elaborate regarding the first of the proposed non-comparable factors. Unlike in the internet bubble, AI products already exist at scale, the demand for them is exploding, and they’re producing revenues in rapidly increasing amounts. For example, Anthropic, one of the two leaders in producing models for AI coding as described on page 12, is said to have “10x-ed” its revenues in each of the last two years (for those who didn’t study higher math, that’s 100x in two years). Revenues from Claude Code, a program for coding that Anthropic introduced earlier this year, already are said to be running at an annual rate of $1 billion. Revenues for the other leader, Cursor, were $1 million in 2023 and $100 million in 2024, and they, too, are expected to reach $1 billion this year. As to the final bullet point, see the table below, which comes from Goldman Sachs via Derek Thompson. You’ll notice that during the internet bubble of 1998-2000, the p/e ratios were much higher for Microsoft, Cisco, and Oracle than they are today for the biggest AI players – Nvidia, Microsoft, Alphabet, Amazon, and Meta (OpenAI doesn’t have earnings). In fact, Microsoft’s on a half-off sale relative to its p/e 26 years ago! In the first bubble I witnessed – surrounding the Nifty-Fifty in 1969-72 – the p/e ratios for the leading companies were even higher than those of 1998-2000. In Conclusion For my final citation, I’ll look to Sam Altman of OpenAI. His comments seem to me to capture the essence of what’s going on: “When bubbles happen, smart people get overexcited about a kernel of truth,” Mr. Altman told reporters this year. “Are we in a phase where investors as a whole are overexcited about A.I.? My opinion is yes. Is A.I. the most important thing to happen in a very long time? My opinion is also yes.” (The New York Times, November 20) But do I have a bottom line? Yes, I do. Alan Greenspan’s phrase, mentioned earlier, serves as an excellent way to sum up a stock market bubble: “irrational exuberance.” There is no doubt that investors are applying exuberance with regard to AI. The question is whether it’s irrational. Given the vast potential of AI but also the large number of enormous unknowns, I think virtually no one can say for sure. We can theorize about whether the current enthusiasm is excessive, but we won’t know until years from now whether it was. Bubbles are best identified in retrospect. While the parallels to past bubbles are inescapable, believers in the technology will argue that “this time it’s different.” Those four words are heard in virtually every bubble, explaining why the present situation isn’t a bubble, unlike the analogous prior ones. On the other hand, Sir John Templeton, who in 1987 drew my attention to those four words, was quick to point out that 20% of the time things really are different. But on the third hand, it must be borne in mind that behavior based on the belief that it’s different is what causes it to not be different! Today’s situation calls to mind a comment attributed to American economist Stuart Chase about faith. I believe it’s also applicable to AI (as well as to gold and cryptocurrencies): For those who believe, no proof is necessary. For those who don't believe, no proof is possible. Here’s my actual bottom line: There’s a consistent history of transformational technologies generating excessive enthusiasm and investment, resulting in more infrastructure than is needed and asset prices that prove to have been too high. The excesses accelerate the adoption of the technology in a way that wouldn’t occur in their absence. The common word for these excesses is “bubbles.” AI has the potential to be one of the greatest transformational technologies of all time. As I wrote just above, AI is currently the subject of great enthusiasm. If that enthusiasm doesn’t produce a bubble conforming to the historical pattern, that will be a first. Bubbles created in this process usually end in losses for those who fuel them. The losses stem largely from the fact that the technology’s newness renders the extent and timing of its impact unpredictable. This in turn makes it easy to judge companies too positively amid all the enthusiasm and difficult to know which will emerge as winners when the dust settles. There can be no way to participate fully in the potential benefits from the new technology without being exposed to the losses that will arise if the enthusiasm and thus investors’ behavior prove to have been excessive. The use of debt in this process – which the high level of uncertainty usually precluded in past technological revolutions – has the potential to magnify all of the above this time. Since no one can say definitively whether this is a bubble, I’d advise that no one should go all-in without acknowledging that they face the risk of ruin if things go badly. But by the same token, no one should stay all-out and risk missing out on one of the great technological steps forward. A moderate position, applied with selectivity and prudence, seems like the best approach. Finally, it’s essential to bear in mind that there are no magic words in investing. These days, people promoting real estate funds say, “Office buildings are so yesterday, but we’re investing in the future through data centers,” whereupon everyone nods in agreement. But data centers can be in shortage or in oversupply, and rental rates can surprise to the upside or the downside. As a result, they can be profitable . . . or not. Intelligent investment in data centers, and thus in AI – like everything else – requires sober, insightful judgment and skillful implementation. December 9, 2025 P.S.: The following has nothing to do with the financial markets or the question of whether AI is the subject of a bubble. My topic is the impact of AI on society through joblessness and purposelessness. You needn’t read it – that’s why it’s a postscript – but it’s important to me, and I've been looking for a place to say a few words about it. On November 18, a research note from Barclays described Fed Governor Christopher Waller as having “highlighted how recent stock market enthusiasm around AI has not yet translated into job creation.” This strikes me as paradoxical given my sense that one of AI’s main impacts will be to increase productivity and thus eliminate jobs. That is the source of my concern. I view AI primarily as an incredible labor-saving device. Joe Davis, Global Chief Economist and Global Head of the Investment Strategy Group at Vanguard, says, “for most jobs – likely four out of five – AI’s impact will result in a mixture of innovation and automation, and could save about 43% of the time people currently spend on their work tasks.” (Exponential View, September 3) I find the resulting outlook for employment terrifying. I am enormously concerned about what will happen to the people whose jobs AI renders unnecessary, or who can’t find jobs because of it. The optimists argue that “new jobs have always materialized after past technological advances.” I hope that’ll hold true in the case of AI, but hope isn’t much to hang one’s hat on, and I have trouble figuring out where those jobs will come from. Of course, I’m not much of a futurist or a financial optimist, and that’s why it’s a good thing I shifted from equities to bonds in 1978. The other thing the optimists say is that “the beneficial impact of AI on productivity will cause a huge acceleration in GDP growth.” Here I have specific quibbles: The change in GDP can be thought of as the change in hours worked times the change in output per hour (aka “productivity”). The role of AI in increasing productivity means it will take fewer hours worked – meaning fewer workers – to produce the goods we need. Or, viewed from the other direction, maybe the boom in productivity will mean a lot more goods can be produced with the same amount of labor. But if a lot of jobs are lost to AI, how will people be able to afford the additional goods AI enables to be produced? I find it hard to imagine a world in which AI works shoulder-to-shoulder with all the people who are employed today. How can employment not decline? AI is likely to replace large numbers of entry-level workers, people who process paper without applying judgment, and junior lawyers who scour the lawbooks for precedents. Maybe even junior investment analysts who create spreadsheets and compile presentation materials. It’s said that AI can read an MRI better than the average doctor. Driving is one of the most populous professions in America, and driverless vehicles are already arriving; where will all the people who currently drive taxis, limos, buses, and trucks find jobs? I imagine government’s response will be something called “universal basic income.” The government will simply mail checks to the millions for whom there are no jobs. But the worrier in me finds problems in this, too: Where will the money come from for those checks? The job losses I foresee imply reduced income tax receipts and increased spending on entitlements. This puts a further burden on the declining segment of the population that is working and implies even greater deficits ahead. In this new world, will governments be able to fund ever-increasing deficits? And more importantly, people get a lot more from jobs than just a paycheck. A job gives them a reason to get up in the morning, imparts structure to their day, gives them a productive role in society and self-respect, and presents them with challenges, the overcoming of which provides satisfaction. How will these things be replaced? I worry about large numbers of people receiving subsistence checks and sitting around idle all day. I worry about the correlation between the loss of jobs in mining and manufacturing in recent decades and the incidence of opioid addiction and shortening of lifespans. And by the way, if we eliminate large numbers of junior lawyers, analysts, and doctors, where will we get the experienced veterans capable of solving serious problems requiring judgment and pattern recognition honed over decades? What jobs won’t be eliminated? What careers should our children and grandchildren prepare for? Think about the jobs that machines can’t perform. My list starts with plumbers, electricians, and masseurs –physical tasks. Maybe nurses will earn more than doctors because they deliver hands-on care. And what distinguishes the best artists, athletes, doctors, lawyers, and hopefully investors? I think it’s something called talent or insight, which AI might or might not be able to replicate. But how many people at the top of those professions are needed? A past presidential candidate said he would give laptops to everyone who lost their job to offshoring. How many laptop operators do we need? Finally, I’m concerned that a small number of highly educated multi-billionaires living on the coasts will be viewed as having created technology that puts millions out of work. This promises even more social and political division than we have now, making the world ripe for populist demagoguery. I’ve seen incredible progress over the course of my lifetime, but in many ways I miss the simpler world I grew up in. I worry that this will be another big one. I get no pleasure from this recitation. Will the optimists please explain why I’m wrong? Interestingly in this connection, Vanguard’s Joe Davis points out that more Americans are turning 65 in 2025 than in any preceding year, and that approximately 16 million baby boomers will retire between now and 2035. Could AI merely make up for that? There’s an optimistic take for you. HM Legal Information and Disclosures This memorandum expresses the views of the author as of the date indicated and such views are subject to change without notice. Oaktree has no duty or obligation to update the information contained herein. Further, Oaktree makes no representation, and it should not be assumed, that past investment performance is an indication of future results. Moreover, wherever there is the potential for profit there is also the possibility of loss. This memorandum is being made available for educational purposes only and should not be used for any other purpose. The information contained herein does not constitute and should not be construed as an offering of advisory services or an offer to sell or solicitation to buy any securities or related financial instruments in any jurisdiction. Certain information contained herein concerning economic trends and performance is based on or derived from information provided by independent third-party sources. Oaktree Capital Management, L.P. (“Oaktree”) believes that the sources from which such information has been obtained are reliable; however, it cannot guarantee the accuracy of such information and has not independently verified the accuracy or completeness of such information or the assumptions on which such information is based. This memorandum, including the information contained herein, may not be copied, reproduced, republished, or posted in whole or in part, in any form without the prior written consent of Oaktree. © 2025 Oaktree Capital Management, L.P.
--------------------------------------------------

Title: NextEra Is Doubling Down on Data Centers for Big Tech. Should You Buy NEE Stock Here?
URL: https://www.barchart.com/story/news/36554844/nextera-is-doubling-down-on-data-centers-for-big-tech-should-you-buy-nee-stock-here
Time Published: 2025-12-10T16:48:16Z
Description: The company targets to build 15 gigawatts of power capacity for data centers by 2035.
--------------------------------------------------

Title: Palantir vs Nvidia, which AI stock wins for 2026?
URL: https://rollingout.com/2025/12/10/palantir-vs-nvidia-ai-stock-win-for-2026/
Time Published: 2025-12-10T14:27:08Z
Description: The artificial intelligence boom continues reshaping the investment landscape, and two companies have emerged as clear winners in the race to dominate this transformative technology. Palantir and Nvidia have delivered extraordinary returns since 2023, but inv…
--------------------------------------------------

Title: Big Tech are the new Soviets
URL: http://unherd.com/2025/12/big-tech-are-the-new-soviets/
Time Published: 2025-12-10T09:15:18Z
Full Content:
Jeff Bezos’ Amazon is a one-stop shop. Photo by CHANDAN KHANNA/AFP via Getty Images Jeff Bezos’ Amazon is a one-stop shop. Photo by CHANDAN KHANNA/AFP via Getty Images Big Tech’s so-called Magnificent Seven are on everyone’s lips. The exorbitant stock market valuations of Google, Meta, Apple, Microsoft, Nvidia, Amazon and Tesla provoke an amalgam of awe and fear. Their trillion-dollar investments in AI prompt some to predict the brightest of futures and others to dread humanity’s dumbing down, unemployment, redundancy even. In this overwhelming din, it is easy to miss the larger picture: a new type of capital is killing markets, capitalism’s habitat. At its very beginning, capitalism was underpinned by faith in competitive markets. In the liberal fantasy, spearheaded by Adam Smith, bakers, brewers and butchers laboured within markets so cut-throat that none could make more money than the bare minimum necessary to keep their small, family-owned businesses running. This in turn provided us with our daily bread, ale and meat. Then came the second industrial revolution and the conglomerates whose market power would make Smith weep with joy. This was the era of Big Business and the “robber barons”. And so another — neoliberal — fantasy was created, to justify the new big beasts that were now monopolising almost every market that mattered. Joseph Schumpeter, a former Austrian finance minister who made America his home, was the new creed’s most effective advocate. Progress, he argued, is impossible in competitive markets. Growth needs monopolies to fuel it. How else can enough profit be earned to pay for expensive research and development, for new machines, new product lines and all the paraphernalia that helps innovation take root? To monopolise markets, conglomerates need to dazzle us with remarkable new products that kill off the competition, like Henry Ford’s Model-T or Apple’s iPhone. Should we worry about all that concentrated power? No, Schumpeter reassured us. Once they reach their pinnacle, these monopolies get flabby and complacent and, eventually, they’re brought down by some upstart: one example being Toyota’s toppling of General Motors. More recently, Peter Thiel, Palantir’s co-founder, said something that many thought was a restatement of Schumpeter’s dictum: “Competition is for losers!” While the pioneers of Big Business like Thomas Edison and Henry Ford would have agreed wholeheartedly, what Thiel was implying went beyond their wildest imagination. It went much further even than Schumpeter’s pseudo-Darwinian idea that progress comes through the rise and fall of monopolists in an endless struggle for existence. What Thiel was saying is that today, winners do not just kill off the competition to monopolise a market. No, they keep going until they kill the market itself and replace it with something quite different: a kind of cloud fief that lacks all of the ingredients of a proper market — indeed that lacks all of the advantages that liberals and neoliberals alike recognise in the machinery of decentralised markets. In fact, today’s winners —the Magnificent Seven, plus Thiel’s own Palantir — are reviving an economic model that all of us thought dead and buried after the fall of the Soviet Union: economic planning systems that match buyers and sellers outside anything that can be usefully described as a market. By Yanis Varoufakis Gosplan was the Soviet Union’s State Planning Committee, the engine room of its command economy. Its remit was to match the supply and demand of critical resources (oil, steel, cement) but also consumption goods (food, clothes, appliances), without using market prices. Once buyers and sellers were matched, prices were assigned with a view to achieving political and social objectives (such as to ensure basic affordability, or subsidise certain industries) — not to balance markets. Gosplan was disbanded immediately after the red flag was lowered over the Kremlin on Boxing Day of 1991, but it is now back. Where? In the algorithms powering Jeff Bezos’s Amazon, Peter Thiel’s Palantir and the rest of Big Tech’s digital platforms that pretend to be, but are not, markets. Before you protest the audacity of my claim, think of what happens when you visit Amazon. Unlike when you visit a shopping mall, either with friends or mingling with strangers, the moment you follow the link to amazon.com, you exit the marketplace and enter a space of pristine isolation. It’s just you and Jeff Bezos’s algorithm. You type, say, “espresso machines” into the search box and the algorithm matches you with a number of vendors. However, to achieve what it was coded for, the algorithm had started working months, even years, earlier. Over that period, you will have revealed to it many of your whims and desires through your searches, purchases, clicks and reviews. Using these cues, as well as data from other sources, the algorithm has trained you to train it to know you even better, enabling it to advise you on what books, music and films to buy. It has already won your trust. So, now that you are in a hurry to replace your broken espresso machine, the chances are that you will choose one of the top search results it has given you. The algorithm knows your spending pattern. It knows how to guide you to the espresso machine with the highest price you are prepared to pay, all in order that Amazon can collect up to 40% of it the moment you click the purchase button. It is an extortionate cut, but the espresso machine’s makers tolerate it, because they know that if they don’t, their company will never appear in the top search results of anyone prepared to pay for their product. As AI improves, this power to manipulate your behaviour increases — and this is why Big Tech’s valuations are going through the roof. This is nothing less than a capitalist, privately-owned, super high-tech reincarnation of the USSR’s Gosplan. Amazon’s software matches you with particular vendors and bans you from talking to any seller or even from observing what other buyers are doing — unless of course it calculates that it serves its own purposes to let you see a small selection of them. As for the price you pay, this follows (rather than precipitates) your being matched with a seller. Rather than being the variable that equilibrates demand with supply, prices in Amazon fulfil another role: that of maximising Jeff Bezos’s cloud rents. In this sense, prices in Amazon and other Big Tech platforms function in a manner far closer to Gosplan than to any farmers’ market, money market or shopping mall you have ever experienced. In fact, had the Soviet leaders lived to witness the workings of Silicon Valley’s Big Tech, they would be kicking themselves, lamenting that it was American capitalists who perfected their Gosplan model, complete with a surveillance system that would make their KGB henchmen green with envy. Gosplan failed to turn into a success story as it lacked Big Tech’s greatest weapon: cloud capital, that is, the algorithms, data centres and optic fibre cables working as an integrated network to train you to train it. As you impart your data, cloud capital learns how to input desires into your mind and then satiate these desires by selling you stuff within its privately owned version of Gosplan. But, is there really a difference — I hear many of you ask loudly — between Thomas Edison and Jeff Bezos? Are they not cut from the same cloth of megalomaniac monopolists seeking to dominate markets and our imagination? Yes, despite their similarities, there is a difference — and it is gigantic. Edison’s and Ford’s capital was productive. It produced cars, electricity, turbines. Bezos’s cloud capital produces nothing, except the enormous power to encase us in his cloud fief where traditional capitalist producers are squeezed for cloud rents and we, the users, provide our free labour. With every click, like and review, we enhance the power of cloud capital. Once upon a time, an old Trotskyite told me that the Soviet Union, in the name of socialism, had created a form of industrial feudalism. Independent of whether he was right or not, his comment is pertinent today in relation to Big Tech. Come to think of it, while the trading process on platforms like Amazon is reminiscent of the USSR’s Gosplan mechanism, it is also the case that the enormous sums that Amazon, Uber, Airbnb etc, charge the actual producers of the goods and services peddled on their sites are akin to the ground rents that the landed gentry used to charge their vassals — except that, here, they are cloud rents that accrue to the owners of cloud capital. So, just as the Soviet Union generated one kind of feudalism in the name of socialism and human emancipation, today, Silicon Valley is generating another kind of feudalism — technofeudalism, I have called it — in the name of capitalism and free markets. By Joel Day The parallel extends to the state. The USSR was meant to be a workers’ paradise in contrast to the USA whose raison d’être was to be a haven for capitalist producers. It turns out that both promises were false. As Big Tech’s cloud capital accumulates and concentrates into fewer and fewer hands, states are becoming dependent on corporate techlords. By outsourcing core functions — archives, health data, even military software — to rented cloud infrastructure, governments lease back their own operational capacity from Amazon Web Services, Microsoft, and Google. This dependency enables a new dimension of technofeudal power. From this perspective, just as the Soviet Union was a feudal-like industrial society pretending to be a workers’ state, the United States today is performing a splendid impersonation of a technofeudal state, with repercussions that extend to every realm of state activity, including health services, education, the tax office, our borders and faraway battlefields. In Ukraine and Gaza, and along our militarised borders, cloud capital is trained to extend its reach. Amazon’s AI tool Rekognition is used by law enforcement, including ICE, while Palantir’s vast surveillance software runs on Amazon’s cloud. Through Project Nimbus, Amazon and Google provide the Israeli military with advanced cloud and AI capabilities, reportedly enabling rapid, AI-driven targeting in Gaza with minimal human oversight. Let us briefly return to the comparison with the early 20th century’s original monopolist capitalists. Whether we admire or abhor the Magnificent Seven’s stock market valuations, it is helpful to keep this in mind: the old capitalist giants, the “robber barons”, actually produced things. The new technofeudal lords produce a new social order. They have replaced the invisible hand of the market with the visible, algorithmic fist of the cloudalist. Free-market enthusiasts have nothing to celebrate and much to regret. But it will take a brave soul amongst them to stare reality in the face. Just like pro-Soviet Marxists remained in denial that the Soviet experiment had failed for many years after 1991, so free-market ideologues refuse to see that capitalism begat a form of capital — cloud capital — that replaced markets with something out of the Soviet past. In the process, it has killed capitalism. Yanis Varoufakis is an economist and former Greek Minister of Finance. He is the author of several best-selling books, most recently Technofeudalism: What killed capitalism. Δ Δ We welcome applications to contribute to UnHerd – please fill out the form below including examples of your previously published work. Please click here to submit your pitch. Please click here to view our media pack for more information on advertising and partnership opportunities with UnHerd.
--------------------------------------------------

Title: Pay cuts, poaching, and pivoting: Inside Scale AI after Meta
URL: https://www.businessinsider.com/pay-cuts-poaching-pivoting-inside-scale-ai-meta-2025-12
Time Published: 2025-12-10T09:11:01Z
Full Content:
This summer, after Meta made a $14 billion investment in Scale AI and poached its 28-year-old founder, Alexandr Wang, and after A-list clients like OpenAI and Google halted work with the startup, a worker for Scale AI anxiously asked ChatGPT what it thought of his company's fate. He knew the chatbot well, having tested it for vulnerabilities. Its prognosis was grim. "Scale AI will no longer exist as a credible independent entity within 24 months," ChatGPT, which isn't any kind of official authority, wrote. "Its infrastructure will be repurposed for Meta's internal needs. Its client base will evaporate. Its role as a neutral red teamer or external evaluator is effectively over." The contractor shared the chat logs with fellow workers at Scale AI. In one reply reviewed by Business Insider, one worker said that they were already on their way out, describing the startup as a ticking time bomb. The chatbot was drawing from a storm of headlines about Scale AI, which until this summer had been touted as one of the most ascendant startups in tech — the place Big Tech companies vying for AI supremacy went to when they wanted their chatbots stress-tested and perfected. Lately, it's lost some of its gleam, with investors significantly lowering valuations, workers sniping about pay, and rivals coming for its clientele. The vast army of human data labelers that made Scale AI a juggernaut are chafing at what they say are pay cuts, lengthy unpaid onboarding sessions to join new AI projects, and thinning workloads — and are increasingly leaving the platform altogether, according to interviews with five current and former contractors and internal correspondence obtained by Business Insider. Inside Business stories reveal the inner workings of companies from Silicon Valley to Wall Street that are shaping our world today. Activity in the main internal chatroom for Outlier — Scale AI's flagship gig work platform, which touts more than 100,000 taskers — has plummeted since the Meta investment, with weekly discussion threads drawing dozens instead of the usual hundreds of replies, according to screenshots reviewed by Business Insider. One tasker said that they'd spent close to 40 hours in a single month in unpaid onboarding sessions without landing any actual work, noting that other platforms like Scale AI's rival Mercor do pay for this kind of work. Elizabeth Boyd, another tasker, says she rarely does work for Outlier anymore after seeing effective pay rates for some projects slashed to around $20 an hour — down from the $50 she used to make. One gig that advertised $20 an hour only allowed three minutes of working time every two days, or a 99-cent payout, according to screenshots obtained by Business Insider. Joe Osborne, a Scale AI spokesperson, says the balance sheets show the company is on the right path. "This quarter is on track to be our biggest of 2025, our data business is more profitable today than it was before the Meta deal, and our applications business, which includes work with Fortune 500 companies and governments, has doubled revenue" in the second half of the year compared to the first, Osborne wrote in an email. He also noted there has been an increase in active users on Outlier since the Meta deal, and that pay rates are based on the skills for each project and contributors always see the rates upfront, and have the option of declining any gig. The company is also looking to diversify. The startup has embraced fields like robotics, announcing a new lab to meet booming demand for robot training data this fall. It's doubling down on its US military and other government work, winning up to $199 million worth of defense contracts since the Meta deal. Some investors are bullish. In one current investor's view, Meta has mostly left Scale alone, letting it operate as an independent company. With around $1 billion on the balance sheet, the investor added, there are no plans to fundraise. And an IPO could still be on the table at some point. Other investors see Scale AI as more like a gutted fish. The Meta investment — which valued Scale AI at $29 billion — has dented Scale AI's valuation in private markets where people buy and sell equity from pre-IPO startups. Noel Moldvai, Augment's CEO, tells Business Insider his platform used to process millions of dollars' worth of transactions in Scale AI stock before the Meta deal, but that dried up as sellers waited to see if the startup rebounded. Activity is picking up again, he said, but at lower valuations of around $15 billion to $9 billion. The underlying message of Meta's semi-acquisition is clear to Moldvai. "It seems like Meta was just after Alexandr Wang, and so this is probably the structure that let them get him," he says. He adds that Scale AI's valuation could still bounce back. On another marketplace, Caplight, Scale's valuation has dropped to $7.3 billion. Osborne says that the valuation is not accurate because there have been no sales of stock at that price and multiples of comparable companies would yield a higher valuation. If the company doesn't pull it off, it could become the latest example of a once-promising startup that morphed into a "zombie" after being invested in by a tech giant. This summer, Scale AI painted a rosy picture of the Meta investment, describing it as a major cash infusion and source of future work in its official statement at the time of the deal. That messaging was also conveyed to the startup's corporate workforce, says another former member of Scale AI's red team, which tests chatbots for flaws and vulnerabilities. Just a few weeks after the investment, he was laid off as part of a major downsizing that saw 14% of Scale AI's full-time staff of 1,400 let go. Osborne said the layoffs were aimed at making the data division profitable, which it now is. Those weren't the only cuts. In September, Scale AI terminated 12 contractors on its red team, citing performance issues. Two ex-red teamers told Business Insider that the team's work had been drying up since the Meta deal, blaming thinning workloads for the cuts. Later that month, Scale AI shuttered a team in Dallas of contractors focused on generalist AI work as it moved towards more specialized fields. Osborne said the 12 contractors were part of Scale's temporary workforce and represented a small fraction of its overall red team, which the company is still committed to investing in. He said the Dallas cuts were part of an industry shift towards higher skilled work and represent a small fraction of its overall workforce. Meanwhile, a swarm of AI training startups has rushed in to poach Scale AI's workers and clients. Some are now raising capital at soaring valuations. Surge AI hit a valuation of $24 billion while Mercor, which is run by three 22-year-olds, announced in October it had raised $350 million at a $10 billion valuation. Mercor has won at least one major AI training project from Meta, Scale AI's 49% shareholder. In September, Scale AI filed a lawsuit in California against Mercor alleging it hired one of its sales employees to poach its biggest customers, allegations Mercor denies. One Scale AI investor said he'd been frustrated with Scale AI's leadership losing customers to Surge AI in particular, which reportedly brought in more revenue than Scale in 2024, despite never having raised outside funding. (Scale AI had raised more than $1.5 billion before the Meta deal.) Brendan Foody, Mercor's CEO, has publicly criticized Scale AI for what he claims are low pay rates and data quality issues. "Scale lost the focus on product, on scaling quality," Foody said in a September podcast appearance. In response, a Scale AI spokesperson told Business Insider its quality metrics are at "record highs." It's not just rival CEOs making that point. Tammy Hartline, who managed projects for Scale AI as a consultant until the summer of 2025, said Scale grew so quickly that the work became more about needing bodies than skills. "Spam and low quality data became accepted as a cost of doing business," she said. Hartline joined Mercor in September. Scale AI has also been beset with security issues that predate Meta's investment. In June, Business Insider reported that Scale AI routinely used public Google Docs to track work for high-profile customers, including Google, Meta, and xAI. That practice left AI training documents labeled "confidential" accessible to anyone with the link and exposed reams of personal information, like private emails and pay details, about contractors. "We take data security seriously," Osborne said. "We conducted a thorough investigation and disabled any user's ability to publicly share documents from Scale managed systems." Sloppy security isn't uncommon in the AI training space — Surge AI similarly left open sensitive work for its client Anthropic. But the exposed documents seen by Business Insider show that for a project for Google, Scale AI faced security and quality issues throughout 2023 and 2024. Thousands of taskers were flagged for being "suspected spammers," "cheaters," with hundreds of workers listed in spreadsheets with titles like "Good and Bad Folks" and "suspicious non-US taskers." Meta recently removed more than 40 groups buying and reselling AI training accounts, including from Scale AI, in response to a recent Business Insider investigation. Osborne said Scale's data quality metrics are the highest they've ever been. The company has notched some recent wins. It once appeared bogged down by litigation, but recently agreed to settle multiple lawsuits filed by ex-workers in California who alleged they were underpaid and misclassified as contractors. (Scale no longer accepts gig workers from the state.) The big question remains whether Scale AI can thrive in the increasingly competitive AI training industry it helped give birth to. For many former workers, it'll be too late to find out. Charles Rollet is Business Insider's tech correspondent in San Francisco. Ben Bergman is a senior correspondent at Business Insider, where he investigates the tech industry with a focus on venture capital and startups. Business Insider's Discourse stories provide perspectives on the day's most pressing issues, informed by analysis, reporting, and expertise. Jump to
--------------------------------------------------

Title: Investors Brace for Revelations in New AI Bellwether Oracle’s Latest Report
URL: https://www.thedailyupside.com/technology/artificial-intelligence/investors-await-new-ai-bellwether-oracles-latest-report/
Time Published: 2025-12-10T05:01:00Z
Full Content:
Deals with Meta, Nvidia and Softbank underscore concerns that Oracle is overexposed to a possible AI bubble. Sean Craig sean.craig@thedailyupside.com When tech giant Oracle, a linchpin of the artificial intelligence boom, reports quarterly earnings today, investors expect it to live up to its name — which in antiquity referred to a medium providing insight into the unknown. The unknown being where AI, an increasingly agita-prone trade, is heading in 2026. For decades following its 1977 founding, Oracle was known for enterprise software: In a 1993 cover story, Fortune dubbed chairman Larry Ellison “software’s other billionaire” after Microsoft’s Bill Gates, featuring him in a full-cut suit with peak lapels that screamed industry titan of the late 20th century. This year, Oracle vaulted to the forefront of the new century by pivoting to data centers and cloud infrastructure to support the artificial intelligence boom. Its share price, up 33% in 2025, made Ellison the world’s wealthiest man for a brief stint. But a certain calculus worries some investors. In September, Oracle announced a $300 billion deal with OpenAI that would see the ChatGPT-maker buy computing power over five years starting in 2027. Building out the capacity to provide that power, however, requires piling up more debt than can fit in a full-cut early ’90s power suit. After the deal was announced, Oracle raised $18 billion from a bond sale and now carries over $100 billion in debt. Deals with Meta, Nvidia and Softbank underscore concerns that Oracle is overexposed to the AI bubble. Those worries have manifested in two ways. First, as of Tuesday’s close, Oracle’s share price is down 32% from its record September high. Second, options traders piled into the company’s credit-default swaps in recent months as the price to guard against Oracle defaulting on its debt tripled (no one expects that to happen, but if AI bubble fears push the swaps up more, those traders could profit). Which sets the stage for today’s earnings, now considered a test of the market’s confidence in the AI trade. Many analysts think the worst fears are overblown: An Assist from Altman: Evercore advised investors to exercise “some patience as turning sentiment will take time,” adding that OpenAI could lend a helping hand if, as expected, it soon puts out an updated version of its chatbot that rivals or surpasses Google’s latest Gemini release. SpaceX’s potential monster IPO would come after what’s been a remarkable rebound year for public listings. Morgan Stanley cut its rating of Tesla for the first time in two years on Monday to “equal weight,” which is equivalent to a hold. A handful of high-profile defamation-by-AI-chatbot allegations against big tech firms are already stacking up. You might recall that in 2021, Zuckerberg deemed the metaverse so vital to the future he renamed the entire company after it. In memo this week, Altman promised the release of a new reasoning model next week that bests Google’s Gemini. Anduril was last valued at $30 billion in June, when its $2.5 billion fundraising round was oversubscribed eight times. The success of indie titles may help video game makers rely less on blockbusters and widen creative license, creating a 1UP for players. Artificial intelligence can do a lot of things. Getting us on an exercise bike doesn’t appear to be one of them. Gemini was trained on Google’s in-house chips, which look like a cheaper and more efficient alternative to Nvidia’s cutting-edge products. Wall Street’s smart money is starting to take out some short positions on the AI trade, albeit mostly around the industry’s fringes. Digital asset treasury companies are grappling with the law of diminishing returns in the midst of a cryptocurrency swoon. What’s next? Nvidia faced “the tough task of meeting high earnings expectations and high skepticism around AI capex,” per analysts at Bank of America. © 2025 The Daily Upside
--------------------------------------------------

Title: Coreweave CEO defends AI circular deals as 'working together' | TechCrunch
URL: https://techcrunch.com/2025/12/09/coreweave-ceo-defends-ai-circular-deals-as-working-together/
Time Published: 2025-12-10T00:50:28Z
Full Content:
Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us It’s been quite the year for CoreWeave. In March, the AI cloud infrastructure provider went public in one of the biggest and most anticipated IPOs of the year that didn’t live up to its hype. Another setback took place in October, when a planned acquisition of the cloud provider’s business partner, Core Scientific, faltered due to skepticism from the acquisition target’s shareholders. In the meantime, the firm has acquired a number of different companies, its stock has gone up and down, and it’s been both criticized and lauded for its role in the booming AI data center market. In an interview at the Fortune Brainstorm AI summit in San Francisco on Tuesday, CoreWeave’s co-founder and CEO, Michael Intrator, defended his company’s performance from critics, noting that it was in the midst of creating a “new business model” for how cloud computing can be built and run. Their collection of Nvidia GPUs is so valuable, they borrow against it to help finance their business. The executive seemed to imply: If you’re charting a new path, you’re destined to encounter some road bumps along the way. “I think people are myopic a lot of times,” Intrator said when questioned about his company’s occasionally unstable stock price. “Yes, it is seesawing,” he admitted, while noting that the CoreWeave IPO took place not long before President Trump’s tariffs went into effect — a notably uncertain moment for the overall economy. “We came out into one of the most challenging environments, right around Liberation Day and, in spite of the incredible headwinds, were able to launch a successful IPO,” the CEO told Brainstorm editorial director Andrew Nusca. “I couldn’t be prouder of what the company has accomplished,” he added. CoreWeave’s stock may have debuted amid the economic doldrums of March but its price has gone on quite the journey since then. It debuted at $40 and, over the past eight months, has climbed to well over $150, but currently rests at around $90. Its more wary critics have compared it to a meme stock due to its penchant for going up and down. Some of the uncertainty around CoreWeave’s stock has been credited to the company’s hefty level of debt. Not long after CoreWeave announced a deal on Monday to issue even more debt to finance its data center buildout, its stock dropped some 8%. Intrator seems to see his company as a disruptor, one whose unconventional tactics may take some getting used to. “When you introduce a new model, when you introduce a new way of doing business, when you disrupt what has been a static environment, it’s going to take some people some time,” he said during his appearance Tuesday. CoreWeave actually started its corporate life as a crypto miner but in short order built itself into a pivotal provider of “AI infrastructure” to some of the tech industry’s most major players. In that role, it provides GPUs to AI developers and has made major partnerships with Microsoft, OpenAI, Nvidia, Meta, and other tech titans. Another topic broached Tuesday was the notion of “circularity” within the AI industry. “Circular” business deals, in which a small number of powerful AI companies invest in one another, have frequently been criticized and have raised questions about the industry’s long-term economic stability. Perhaps not surprisingly, since Nvidia is one of its investors and its supplier of GPUs, Intrator swatted away such concerns. “Companies are trying to address a violent change in supply and demand,” he said. “You do that by working together.” Since the IPO, CoreWeave has continued to make efforts to expand its business. After it acquired Weights & Biases, an AI developer platform, in March, it went on to acquire OpenPipe, a startup that helps companies create and deploy AI agents through reinforcement learning. In October, it also made deals to acquire Marimo (the creator of an open source notebook) and Monolith, another AI company. It also recently announced an expansion of its cloud partnership with OpenAI and said it has plans to move into the federal market, where it wants to provide cloud infrastructure to U.S. government agencies and the defense industrial base. Topics Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates. OpenAI fires back at Google with GPT-5.2 after ‘code red’ memo Marco Rubio bans Calibri font at State Department for being too DEI ElevenLabs just hit a $6.6B valuation. Its CEO says the real money isn’t in voice anymore. SpaceX reportedly planning 2026 IPO with $1.5T valuation target Claude Code is coming to Slack, and that’s a bigger deal than it sounds Creator IShowSpeed sued for allegedly punching, choking viral humanoid Rizzbot SpaceX reportedly in talks for secondary sale at $800B valuation, which would make it America’s most valuable private company © 2025 TechCrunch Media LLC.
--------------------------------------------------

Title: CoreWeave CEO: Despite see-sawing stock, IPO was ‘incredibly successful’ after challenges of Liberation Day tariff timing
URL: https://fortune.com/2025/12/09/coreweave-ceo-ipo-success-despite-tariff-headwinds/
Time Published: 2025-12-10T00:05:08Z
Full Content:
CoreWeave has been rocked by dizzying stock swings—with its shares currently trading 52% below their post-IPO high—and it’s a frequent target of market commentators, but CEO Michael Intrator says the company’s move to the public markets has been “incredibly successful.” And he takes the public’s mixed reaction in stride, given the novelty of CoreWeave’s “neocloud” business, which competes with established cloud providers like Amazon Web Services (AWS) and Google Cloud. “When you introduce new models, introduce a new way of doing business, disrupt what has been a static environment, it’s going to take some people some time,” Intrator said Tuesday at the Fortune Brainstorm AI conference in San Francisco. But, he added, more people are beginning to understand the CoreWeave business model. “We came out into one of the most challenging environments,” Intrator said of CoreWeave’s March IPO, which occurred very close to President Trump’s “Liberation Day” tariffs in April. “In spite of the incredible headwinds, [we were] able to launch a successful IPO.” CoreWeave, which priced its IPO at $40 per share, has experienced frequent severe up-and-down price swings in the eight months since its public market debut. At its closing price of $90.66 on Tuesday, the stock remains well above its IPO price. As Fortune reported last month, CoreWeave’s rapid rise has been fueled by an aggressive, debt-heavy strategy to stand up data centers at unprecedented speed for AI customers. And for now, the bet is still paying off. In its third-quarter results released in November, the company said its revenue backlog nearly doubled in a single quarter—to $55.6 billion from $30 billion—reflecting long-term commitments from marquee clients including Meta and OpenAI, as well as French AI startup Poolside. Both earnings and revenue came in ahead of Wall Street expectations. But the numbers were not all celebratory. CoreWeave disclosed a further increase in the debt it has taken on to finance its expansion, and it revised its full-year revenue outlook downward—even with historic demand in the pipeline. With media headlines calling CoreWeave a “ticking time bomb,” and critics calling out insider stock sales, circular financing accusations, and an overreliance on Nvidia, Intrator was asked whether he felt CoreWeave was misunderstood. “Look, we built a company that is challenging one of the most stable businesses that exist—that cloud business, these three massive players,” he said, referring to AWS, Microsoft Azure, and Google Cloud. I feel like it’s incumbent on CoreWeave to introduce a new business model on how the cloud is going to be built and run. And that’s what we’re doing.” He repeatedly framed CoreWeave not as a GPU reseller or traditional data-center operator but as a company purpose-built from scratch to deliver high-performance, parallelized computing for AI workloads. That focus, he said, means designing proprietary software that orchestrates GPUs, building and colocating its own infrastructure, and moving “up the stack” through acquisitions such as Weights & Biases and OpenPipe. Intrator also defended the company’s debt strategy, saying CoreWeave is effectively inventing a new financing model for AI infrastructure. He pointed to the company’s ability to repurpose power sources, rapidly deploy capacity, and finance large-scale clusters as proof it is solving problems incumbents never had to face. “When I look back at the history of the company, it took us a year with a company investor like Fidelity, before they were like, ‘Oh, I get it,’” he said. “So look, we’ve been public for eight months. I couldn’t be prouder of what the company has accomplished.”
--------------------------------------------------

Title: The 10 Best Nintendo Gifts You We Recommend for 2025 and Beyond
URL: https://www.ign.com/articles/best-nintendo-gifts-2025
Time Published: 2025-12-09T23:30:00Z
Description: IGN's top picks for Nintendo fans this year.
--------------------------------------------------

Title: Reality Labs Restructuring Seen as “Step in Right Direction” for META, Analyst Says
URL: https://finance.yahoo.com/news/reality-labs-restructuring-seen-step-213942322.html
Time Published: 2025-12-09T21:39:42Z
Description: Meta Platforms, Inc. (NASDAQ:META) is one of the AI Stocks on the Market’s Radar. On December 5, Mizuho maintained its “Outperform” rating on the stock with ...
--------------------------------------------------

Title: Apple Stock Marks a Solid Comeback. Is AAPL a Buy, Sell, or Hold for 2026?
URL: https://www.barchart.com/story/news/36538106/apple-stock-marks-a-solid-comeback-is-aapl-a-buy-sell-or-hold-for-2026
Time Published: 2025-12-09T21:24:40Z
Description: Apple stock has outperformed the broader market, and enthusiasm for the iPhone 17 lineup has played a significant role in the rebound.
--------------------------------------------------

Title: Updates from Two Big Tech Firms Land This Week. What It Could Mean for the AI Trade
URL: https://www.investopedia.com/updates-from-two-big-tech-firms-land-this-week-what-it-could-mean-for-the-ai-trade-avgo-orcl-11865254
Time Published: 2025-12-09T20:33:11Z
Full Content:
Two tech giants shocked Wall Street with their earnings reports in September. Now they're under pressure to do it again. Software giant Oracle (ORCL) will report quarterly results after the market closes on Wednesday, followed by semiconductor firm Broadcom (AVGO) on Thursday afternoon. Their shares are up 33% and 75%, respectively, since the beginning of the year—but the stocks have diverged in recent months, reflecting the anxieties driving a shift in the AI investor debate. Wall Street is generally optimistic about both Oracle's and Broadcom's upcoming earnings reports. Analysts expect both companies, among the biggest in the S&P 500, to show signs that AI demand will remain strong into next year. But recent Goldman Sachs research suggests that sector stocks may not all be pulled higher by industry-level forces in the months ahead. In recent months, investors have grown increasingly wary of the AI investments that have fueled stock market gains for years. Oracle and Broadcom's earnings will offer investors evidence of AI demand from two perspectives, that of the AI chip supplier and that of the buyer. Oracle in early September supplanted Nvidia as the hottest AI play on Wall Street. The stock skyrocketed 36% the day after Oracle said its cloud computing backlog more than quadrupled to nearly $500 billion. Wall Street lauded the results, calling them evidence of a “truly historic” quarter that confirmed “a seismic shift happening in computing.” But then reports indicated that nearly all of Oracle’s backlog growth spawned from a $300 billion, multi-year deal with OpenAI, the ChatGPT-maker that is expected to burn through more than $100 billion before turning a profit at the end of the decade. That raised concerns that too many of Oracle’s eggs were in one big, risky basket. Meanwhile, the debate on Wall Street about whether cloud providers like Oracle are overspending on infrastructure intensified. Oracle sold $18 billion of bonds in September to help finance its data center investments, drawing attention to the fact that its debt burden is higher and its credit rating is lower than companies like Microsoft (MSFT), Alphabet (GOOG), Amazon (AMZN), and Meta (META). Oracle’s stock languished amid concerns about customer concentration and an AI bubble. Shares are down more than 30% in the past three months, a drop that’s erased all of the stock’s post-earning gains in September. Semiconductor and networking equipment provider Broadcom, meanwhile, is among the best-performing tech stocks in recent months, boosted by optimism that it is chipping away at Nvidia’s (NVDA) dominance in the AI chip market. Broadcom jumped nearly 10% after its September earnings report, when executives revealed they had secured a $10 billion order for custom chips from a new customer. As with Oracle, reports in the following days suggested the undisclosed customer was OpenAI. But unlike Oracle, Wall Street has only grown more bullish on Broadcom’s AI business—mostly because of the mid-November launch of Google’s Gemini 3, the tech giant’s first AI model to be trained exclusively with Broadcom-designed custom chips. Silicon Valley and Wall Street insiders alike raved about the model, prompting OpenAI to reportedly refocus on improving ChatGPT to fend off stiff competition. Google has reportedly discussed selling its custom chips to Meta, further boosting confidence that Broadcom can take market share from Nvidia. Broadcom shares have risen nearly 20% since Google launched Gemini, outperforming both the S&P 500, up 4%, and the Magnificent Seven, up 6%. Deutsche Bank analysts in a recent note analyzed the assumptions underpinning Wall Street's forecast for Oracle's business and stock. "The company is getting little if any credit for its business with OpenAI at the current share price of ~$200," they wrote. Analysts at Citi expect Oracle to report its backlog grew $100 billion last quarter, offering "more evidence that AI infrastructure demand is broad-based." Bank of America earlier this month raised its price target on Broadcom stock, citing an improved outlook for Google's custom chips. HSBC analyst Frank Lee forecast Broadcom's results Thursday would meet expectations before custom chip and networking demand accelerate the companies' AI business early next year. It may, however, no longer be the case that a rising AI tide lifts all boats. According to a Goldman Sachs report, the correlation between AI hyperscaler stocks was about 20% in mid-November, down from 80% in June. Update—December 9, 2025: This article was updated after markets closed on Tuesday with the latest stock performance data.
--------------------------------------------------

Title: Here's How Much Traders Expect Broadcom Stock to Move After Earnings
URL: https://www.investopedia.com/here-s-how-much-traders-expect-broadcom-stock-to-move-after-earnings-avgo-11863042
Time Published: 2025-12-09T20:29:38Z
Full Content:
Broadcom (AVGO) is slated to release its fiscal fourth-quarter results after the market closes on Thursday, with traders expecting the chipmaker's stock could hit fresh record highs after the report. Based on current options pricing, Broadcom stock is expected to rise or fall by up to 6% by the end of the week. Based on Monday's closing price, that would lift Broadcom's stock to around $425 on the high end, further past the intraday record of $407 the stock set on Monday, or push it down to about $377. Last quarter, Broadcom's revenue hit a record $15.95 billion as the company topped estimates, prompting some analysts to call Broadcom a "Magnificent 8" stock that could continue to grow alongside Nvidia (NVDA) if the AI industry keeps expanding. Broadcom stock rallied following the report, setting multiple record highs in the months since. Broadcom designs AI chips used by several big tech companies—including Google, Meta and OpenAI—to train and run AI models such as ChatGPT and Gemini. Broadcom stock has been less affected than shares of other tech giants by the recent concerns over an AI bubble. Analysts from Bank of America and Morgan Stanley each recently raised their price targets for Broadcom stock, but noted that the chip designer faces long-term risks. The analysts said that Alphabet's (GOOGL) Google is looking to design its own future generations of AI chips in house, rather than the current generation that it has designed in partnership with Broadcom. That could put Broadcom's market share at risk if Google is successful and eventually looks to sell its designs to other current Broadcom customers. Broadcom's revenue is expected to jump 24% year-over-year to another record high of $17.48 billion, while adjusted earnings per share are projected to come in at $1.88, compared to $1.42 in the like period a year ago. Analysts are overwhelmingly bullish on Broadcom stock, with all 12 analysts with current ratings tracked by Visible Alpha rating the chipmaker as a "buy." The stock has an an average price target of $432.02, as analysts expect shares to continue rising to record levels.
--------------------------------------------------

Title: Deals for Today: An Epic Arcade Setup Deal and Elgato Streaming Gear Sale
URL: https://www.ign.com/articles/deals-for-today-december-9
Time Published: 2025-12-09T17:45:00Z
Description: Save big today on Elgato streaming gear, the X-Arcade Arcade2TV-XR, Switch 2 holiday releases, and unique Christmas gift ideas. Massive deals on earbuds, creator tools, gaming accessories and more.
--------------------------------------------------

Title: Wall Street Firm Stays Bullish on Broadcom (AVGO) Ahead of December 11 Earnings
URL: https://finance.yahoo.com/news/wall-street-firm-stays-bullish-173352386.html
Time Published: 2025-12-09T17:33:52Z
Description: Broadcom Inc. (NASDAQ:AVGO) is one of the Must-Watch AI Stocks on Wall Street. On December 5, Mizuho analyst Vijay Rakesh maintained an “Outperform” rating...
--------------------------------------------------

Title: Wall Street Bullish on Meta Platforms (META) Here’s Why
URL: https://finance.yahoo.com/news/wall-street-bullish-meta-platforms-163929439.html
Time Published: 2025-12-09T16:39:29Z
Description: Meta Platforms, Inc. (NASDAQ:META) is one of the Good Stocks to Buy According to Analysts. Wall Street is bullish on Meta Platforms, Inc. (NASDAQ:META) on...
--------------------------------------------------

Title: Apple ranks among top investments for reaching $1 million
URL: https://rollingout.com/2025/12/09/apple-ranks-among-top-investments/
Time Published: 2025-12-09T15:59:15Z
Description: Apple ranks fifth among investments offering the best path to millionaire status with relatively modest initial capital, according to a December 2025 report by trading platform Taurex. The technology giant’s stock has delivered remarkable returns since 2009, …
--------------------------------------------------

Title: Apple's Slow AI Pace Becomes a Strength as Market Grows Weary of Spending
URL: https://finance.yahoo.com/news/apple-slow-ai-pace-becomes-104658095.html
Time Published: 2025-12-09T15:08:24Z
Description: Through the first six months of 2025, Apple was the second-worst performer among the Magnificent Seven tech giants, as its shares tumbled 18% through the end...
--------------------------------------------------

Title: Paramount's hostile Warner Bros. bid, Meta's AI course correction, McDonald's value crackdown and more in Morning Squawk
URL: https://www.cnbc.com/2025/12/09/5-things-to-know-before-the-stock-market-opens.html
Time Published: 2025-12-09T13:16:45Z
Description: Here are five key things investors need to know to start the trading day.
--------------------------------------------------

Title: Bitget Reports Record 4,468% Surge in Tokenized US Stock Futures During Earnings Season
URL: https://www.globenewswire.com/news-release/2025/12/09/3202312/0/en/Bitget-Reports-Record-4-468-Surge-in-Tokenized-US-Stock-Futures-During-Earnings-Season.html
Time Published: 2025-12-09T13:02:00Z
Full Content:
December 09, 2025 08:02 ET | Source: Bitget Limited Bitget Limited Seychelles Seychelles VICTORIA, Seychelles, Dec. 09, 2025 (GLOBE NEWSWIRE) -- Bitget, the world’s largest Universal Exchange (UEX), has released new data showing unprecedented growth in global demand for tokenized US equities during the recent earnings season. From mid-October to the end of November, spot trading volume for tokenized US stock tokens increased by 452% month-over-month, while futures trading volume rose by 4,468%, marking the strongest period of activity since these products launched on Bitget. The report examines the acceleration of tokenized equity adoption and identifies three underlying forces driving this growth. The first is the composition of assets themselves, with demand gravitating toward technology leaders and crypto-linked equities that offer high volatility and directional opportunity. The second is the shift toward 24-hour market accessibility, which lowers traditional barriers and allows traders to participate across global time zones without interruption. The third is the influence of a globally diverse user base, whose trading patterns and risk appetites are reshaping how tokenized markets form, scale, and mature. Futures markets experienced extraordinarily aggressive trading behavior centered around mega-cap technology stocks, with Tesla, Meta, MicroStrategy, Apple, and the Nasdaq-100 ETF (QQQ) dominating activity. Meta’s futures volume increased 40,774%, Microsoft 24,339%, and MicroStrategy 11,684% MoM, reflecting traders’ efforts to capture earnings-driven volatility and AI-related momentum. Spot market participation showed a more balanced allocation pattern. Nvidia led with 1,888% MoM growth, accompanied by broad index exposure through QQQ (+3,492%) and SPY (+3,247%). The surge in demand for TLT (+69,573% MoM), the long-term Treasury ETF, demonstrated a move toward defensive hedging and macro risk management during a volatile reporting season. Bitget’s 5×24 trading model proved critical in enabling this activity. Global trading patterns revealed that Asian users, in particular, leveraged extended access to respond to earnings releases, adjust positions before the US market opens, and mitigate overnight risk, advantages unavailable through traditional equity markets. The user base remained distinctly international, led by East Asia (39.66%), alongside meaningful participation from Latin America, South Asia, Southeast Asia, and Europe. Behavioral segmentation showed high-frequency “whales” executing an average of 51.7 trades per day, while retail traders engaged more selectively around earnings catalysts. “What we’re seeing is the emergence of a fully democratized global equity market,” said Gracy Chen, CEO of Bitget. “When investors across continents can participate in earnings season in real time, using USDT, with 24-hour access and without geographic barriers, the market becomes broader, more liquid, and fundamentally more sophisticated. Tokenized equities are no longer experimental. They are becoming a mainstream asset class shaped by global capital and global behavior.” Bitget’s findings indicate that tokenized stock tokens have entered a new phase of structural maturity, defined by diversified investment strategies, seamless global access, and increasingly sophisticated market participants. For the full report, please see here. About Bitget Established in 2018, Bitget is the world's largest Universal Exchange (UEX), serving over 120 million users with access to millions of crypto tokens, tokenized stocks, ETFs, and other real-world assets, while offering real-time access to Bitcoin price, Ethereum price, XRP price and other cryptocurrency prices, all on a single platform. The ecosystem is committed to helping users trade smarter with its AI-powered trading tools, interoperability across tokens on Bitcoin, Ethereum, Solana, and BNB Chain, and wider access to real-world assets. On the decentralized side, Bitget Wallet is an everyday finance app built to make crypto simple, secure, and part of everyday finance. Serving over 80 million users, it bridges blockchain rails with real-world finance, offering an all-in-one platform to on/off ramp, trade, earn, and pay seamlessly. Bitget is driving crypto adoption through strategic partnerships, such as its role as the Official Crypto Partner of the World's Top Football League, LALIGA, in EASTERN, SEA and LATAM markets. Aligned with its global impact strategy, Bitget has joined hands with UNICEF to support blockchain education for 1.1 million people by 2027. In the world of motorsports, Bitget is the exclusive cryptocurrency exchange partner of MotoGP™, one of the world’s most thrilling championships. For more information, visit: Website | Twitter | Telegram | LinkedIn | Discord | Bitget Wallet For media inquiries, please contact: media@bitget.com Risk Warning: Digital asset prices are subject to fluctuation and may experience significant volatility. Investors are advised to only allocate funds they can afford to lose. The value of any investment may be impacted, and there is a possibility that financial objectives may not be met, nor the principal investment recovered. Independent financial advice should always be sought, and personal financial experience and standing carefully considered. Past performance is not a reliable indicator of future results. Bitget accepts no liability for any potential losses incurred. Nothing contained herein should be construed as financial advice. For further information, please refer to our Terms of Use. Photos accompanying this announcement are available at: https://www.globenewswire.com/NewsRoom/AttachmentNg/47fda1a6-04c0-47ec-a6c4-fd2021a1e068 https://www.globenewswire.com/NewsRoom/AttachmentNg/323f3456-ea8a-4042-b3bd-217bf790b024 Bitget Wallet, a leading self-custodial crypto wallet, has extended its collaboration with Ondo Finance to support the expansion of Ondo Global Markets ... VICTORIA, Seychelles, Dec. 11, 2025 (GLOBE NEWSWIRE) -- Bitget, il più grande Exchange Universale (UEX) al mondo, ha annunciato un importante aggiornamento di GetAgent, il suo assistente di...
--------------------------------------------------

Title: Sony Clears Out PlayStation VR2 at Its Lowest Price as Holiday Stock Dump Begins, While Meta Quest Stays Full Price
URL: https://kotaku.com/sony-clears-out-playstation-vr2-at-its-lowest-price-as-holiday-stock-dump-begins-while-meta-quest-stays-full-price-2000651622
Time Published: 2025-12-09T12:35:25Z
Full Content:
This article is part of Kotaku Deals, produced separately from the editorial team. We may earn a commission when you buy through links on the site. If youâre looking for a more immersive way to play your favorite titles, where the digital world becomes your reality in every sense, you need a VR set in your setup. These not only offer better visuals, but also unique sensations based on whateverâs happening in the game, pulling you into action. PlayStation owners should consider grabbing the PSVR2, especially now that itâs going at a 25% discount at Amazon. This brings its usual $400 price down to $299, which, while not the lowest price ever, is still not bad considering all the features the bundle comes packed with. Itâs open to all shoppers, and you donât have to worry about any delivery charges either. Just be sure to grab it quick. Amazon hasnât specified an end date for this one, but weâre not expecting it to stick around for more than a couple of days. See at Amazon The bundle includes the PlayStation VR2 headset and a pair of Sense controllers. The headset is comfortable to wear, featuring a rear band that sits a bit low on the back of your head for stability. Once on, the two 2000 x 2040 OLED displays push incredibly sharp and vibrant 4K HDR visuals, which are four times better than the original PSVR. Thereâs support for eye tracking that simulates emotional responses from the version of you in the game for a better sense of realism, especially when playing with friends. The headset is also designed to be responsive with vibrations, meaning in-game sensations can be felt like theyâre happening right in your living room. For instance, when cars race past, youâll feel a burst of movement around through the headset. But of course, visuals alone canât offer a truly immersive experience, and for that, thereâs 3D audio that surrounds you and adapts to your position with head movements. Everything from whispers to footsteps, gunfire, and screams will be heard as if youâre right in the middle of the battlefield. Best of all, you can still keep an eye on whatâs happening in the real world with the See-through View function. As for the controllers â these offer haptic feedback for you to physically feel your in-game responses in the form of vibrations, intense pulses, and more. Finger touch detection lets you feel elements of the virtual world even when youâre not pressing any buttons, while adaptive triggers make it easy to sense the digital tension and resistance. The latter is great for feeling that bowstring pull when youâre just about to hit a bad guy, or sensing objects crumple as you crush them in your hand just before delivering an Oscar-worthy line. All in all, if youâve been looking to play your favorite titles in a way that makes you feel like youâre a part of the action, a VR bundle can deliver exactly that and more. This one, in particular, offers immersive, 4K visuals that show every in-game detail in a lifelike manner, plus let you feel all thatâs happening in the digital world with unique sensations through the controllers. The bundle typically retails for $400, but you can now snap it up for $299 after a sweet 25% discount. Amazon wonât be this generous for long, and considering how there are no major sales lined up, itâs best to get your orders in as soon as you can. See at Amazon Donât miss the latest reviews, news and tips. Sign up for our free newsletter. We may earn a commission when you buy through links on our sites. Â©2025 KOTAKU USA LLC. All rights reserved. Mode Follow us Mode Follow us
--------------------------------------------------

Title: The U.S. Is Betting the Economy on ‘Scaling’ AI: Where Is the Intelligence When One Needs It?
URL: https://www.nakedcapitalism.com/2025/12/the-u-s-is-betting-the-economy-on-scaling-ai-where-is-the-intelligence-when-one-needs-it.html
Time Published: 2025-12-09T10:55:52Z
Full Content:
Yves here. Servaas Storm provides a fantastic broad and properly sobering view on the AI/stock market mania and the far too many reasons why US players can’t possibly deliver on their hype. One tiny quibble, more of presentation: Storm discusses AI borrowing, initially making it sound as if it is being done by the big players themselves, which to some degree it has been. He then does describe how they are increasingly making use of off balance sheet vehicles, and so far, investors are bizarrely keen about them. I have not looked at any of these structures, but wonder how off-balance-sheet they will prove to be in practice. During the financial crisis, banks who had been securitizing credit card receivables found out lenders were making them eat some of the losses, despite the entities having been structured so as to be arm’s length. The funders said, effectively: Try selling us another one. The banks depended on being able to off-load the receivables (they could not afford the capital costs of retaining them) and so relented. In at least one data-center deal, Meta had signed up for four successive five year leases. When I was as kid, we’d capitalize this sort of commitment as an operating lease and treat it as debt. That does not seem to be modern practice. What happens if the underlying business comes a cropper? Does Meta try to default on the lease payments? By Servaas Storm, Senior Lecturer of Economics, Delft University of Technology. Originally published at the Institute for New Economic Thinking website Introduction Three years ago, on November 30, 2022, ChatGPT was released to the public. This Large Language Model (LLM) was a total novelty, an AI tool that appeared able to do things that no one believed to be possible. Within five days of launch, over one million users had signed up to chat with the AI bot – a growth rate 30 times faster than Instagram’s and 6 times faster than TikTok’s at their start. It became the fastest-growing consumer product in history, recording more than 800 million weekly users in October 2025. OpenAI, the start-up that developed ChatGPT and that began as a non-profit in 2015, became a household-name almost overnight, and is now valued at $500 billion or even $1 trillion (for an initial public offering). Surfing the LLM wave, Nvidia, the producer of around 94% of the GPUs needed by the AI industry, hit, as the first public corporation ever, a market capitalization of $5 trillion on October 29, 2025, up from just $0.4 trillion in 2022. Nvidia currently has a weight of around 8.5% in the S&P500 Index, while the so-called ‘Magnificent 7’ (Alphabet, Amazon, Apple, Meta, Microsoft, Nvidia and Tesla) have a combined weight in the S&P500 of circa 37%. The data-centre investments by a concentrated set of hyper-scalers in the American AI industry constitute the main source of growth in an otherwise sclerotic U.S. economy. The U.S. is betting the economy on reaching Artificial General Intelligence (AGI), by building ever bigger computing infrastructure to run and test-time their LLMs, using more GPUs, more power, more cooling water and more data than ever before. But three years after ChatGPT’s launch, fears are growing in many quarters that the bet on scaling LLMs to reach AGI is going wrong. The AI boom, many whisper, may be a bubble. The Trump administration and the AI industry are showing signs of nervousness. At a recent Wall Street Journal tech conference, OpenAI Chief Financial Officer Sarah Friar suggested that a government loan guarantee might be necessary to fund the enormous investments needed to keep the company at the cutting edge. Her coded message was that OpenAI has become TBTF. The message was understood. President Trump’s AI and crypto czar, David Sacks said (in response) that a reversal in AI-related investments would risk a recession. “We can’t afford to go backwards,” he added, indication support for Friar’s demand. (He later clarified that he remains opposed to any bailouts for individual companies in the AI sector.) History Rhymes, Or Is This Time Different? The U.S. stock market is definitely firmly in bubble territory. Figure 1 presents data on the S&P 500’s Shiller P/E Ratio, calculated as average inflation-adjusted earnings from the previous 10 years. Historically, a Shiller P/E Ratio above 30 has been a harbinger of speculative excess, followed by a bear market. In December 2023, the Shiller index rose to 30.45 and has remained above 30 ever since; in November 2025, the Shiller P/E ratio rose above 40. Since 1871, this is only the sixth instance in which the CAPE Ratio exceeded 30. The first time it happened was during August-September 1929 and we all know what came next: the Dow Jones Industrial Average lost 89% of its value. The second time it happened occurred almost seven decades later: during the end-of-the-millennium dotcom bubble, when the Shiller P/E ratio recorded an all-time high of 44.19 in December 1999. Following the bursting of the dot-com bubble, the S&P 500 lost 49% of its peak value. The next three peaks above 30 in the Shiller P/E Ratio occurred very recently: during September 2017-November 2018; December 2019-February 2020; and August 2020-May 2022. Following these surges, the S&P 500 eventually dropped by anywhere between 20% and 33%. We are currently living in the sixth such period of speculative excess. Source: Robert Shiller (2025), https://shillerdata.com/ (accessed on 15/11/2025) However, the AI party is still in full swing. AI firms are racing to build out data centre infrastructure for what they believe is virtually limitless demand for AI services. Capital expenditures on data-centre infrastructure by Amazon, Alphabet, Meta and Microsoft are steeply rising (also as a percentage of sales) (Figure 2). JP Morgan Chase & Co projects that 122GW of data centre capacity will be built from 2026-2030 to satisfy the (arguably) astronomical demand for ‘compute’ (Wigglesworth 2025a). The additional 122GW of data centre capacity is estimated to cost between $5-7 trillion. For 2026, the projected data centre funding needs will be around $700 billion, which, according to the report, could probably be entirely financed by hyper-scaler cash flows and by High-Grade bond markets. “However, 2030 funding needs are in excess of $1.4 trillion, which will surpass current market capabilities, necessitating the search for alternative funding sources.” Source: Christopher Mims (2025), ‘When AI Hype Meets AI Reality: A Reckoning in 6 Charts.’ Wall Street Journal, November 14. Crucially, most of the mega-financing deals are remarkably circular. To give you a flavour: Nvidia invests in OpenAI and OpenAI is looking to buy millions of Nvidia’s specialized chips. OpenAI buys computing power from Oracle which buys Nvidia’s GPUs. Nvidia owns about 5% of CoreWeave and sells chips to CoreWeave. CoreWeave’s biggest customer is Microsoft, which is an investor in OpenAI, shares revenue with OpenAI, buys chips from Nvidia and has partnerships with AMD. AMD, a rival to Nvidia, was so eager to land OpenAI as a customer that it issued warrants for OpenAI to buy 10% of AMD at a penny a share. OpenAI is a CoreWeave customer and also a shareholder. Nvidia has invested in xAI and will supply it with processors. And so on and so forth. The deals include revenue sharing across the stack and cross-ownership. Nothing in these circular deals is transparent. It is not clear where the money needed for these deals is coming from. It is not clear what these opaque circular transactions imply for the valuations of the listed and non-public AI firms involved. It is not clear what all this means for the competition over hardware between chip producers (Nvidia versus AMD) and over AI services AI startups (OpenAI versus Anthropic versus xAI versus Microsoft). Not surprisingly, therefore, these astronomical circular financing deals (referencing billions of U.S. dollars) are raising eyebrows. To many observers, they bring back traumatic memories of the circular financing arrangements of the late 1990s, when vendors and clients reinforced each other’s dotcom stock valuations without generating any real value. AI Bang or Bubble? AI industry leaders are now busy doubling down on their message that the AI revolution is NOT A BUBBLE, but real and sustainable. Nvidia CEO Jensen Huang stated (in an earnings call on November 19) that there is no AI bubble and exponentially growing AI demand is structural rather than speculative. Huang claims that the AI boom constitutes a Big Bang, a historical revolution, because of three fundamental shifts toward accelerated computing: the move from CPUs to GPUs (which can simultaneously process multiple tasks and solutions), the rise of generative AI, and the emergence of agentic AI systems that supposedly can independently make decisions based on large datasets. Asset-managing firm Blackrock concurs: “AI is not just a technological trend; it represents an infrastructure transformation with growing macroeconomic significance”, adding that “unlike the speculative frenzy of the late 1990s and early 2000s, today’s technology leaders are anchored by fundamental stability.” The optimistic vibes around the transformative power of AI have even infected Nouriel Roubini (2025), the profession’s perennial Dr. Doom and now a senior economic strategist at Hudson Bay Capital, who has somehow become convinced that the tailwinds of the unprecedented AI data-centre investment boom will overwhelm any disruptions coming from Trump’s tariffs and geopolitical strains. But the various statements by Huang, Blackrock and Roubini are “sound and fury, signifying nothing.” The structural demand for Nvidia’s GPUs originates from the same circle of companies that are betting the business on scaling AI. The AI data centres may not be the “shovels of the AI gold rush”, but rather a black hole in which billions of dollars disappear. The surge in demand for GPUs and data-centre infrastructure may, in other words, very well be speculative, if it turns out that the AI models are not delivering good value for money to the investors – and cannot live up to the exaggerated expectations of the Lords of the AI Ring. Every reader of Kindleberger and Galbraith knows that this would not be the first time in (economic) history that most people – all in the same bubble – had it fully wrong, all at the same time. The financial crisis of 2008 is just the most recent example of a collective mania that ended in a crash. The Insufferable Irrationality of the AI Industry The AI race is mostly based on the irrational fear of missing out (FOMO), in Silicon Valley and on Wall Street – which induces a herd mentality to follow ‘momentum’, a complete disregard for fundamental values in favour of placing an exaggerated importance to the limited availability of a key resource (here: Nvidia’s GPUs and ‘compute’), and overwhelming confirmation bias (the all-too-human inclination to look for information that confirms our own biased outlook). To bring home the point: the use of ChatGPT has been found to decrease idea diversity in brainstorming, as per an article in Nature. It is deeply ironic that the industry that is supposed to build ‘super-intelligence’, a deeply flawed concept with rather sinister origins (see Emily M. Bender and Alex Hanna 2025), is itself deeply irrational. But solid anthropological evidence on the local tribes living in Silicon Valley and working on Wall Street shows that this irrationality is hardwired into the perma-adolescent psyches of the inhabitants, who are wont to talk to each other about the coming AIpocalypse, almost religiously believe in AI prophecies, have deep faith in their algorithms, regard AI as a superior ‘sentient being’ in need of legal representation, enthusiastically engage in techno-eschatology, and, above all, are deeply fond of Hobbits and the LOTR. These very same people are also used to talk about and think in terms of billions of dollars as just ‘stuff’ that funds compute, necessary for scaling in order to reach AGI. “I don’t care if we burn $50 billion a year, we’re building AGI,” Sam Altman said, adding: “We are making AGI, and it is going to be expensive and totally worth it.” The same Sam Altman lost his cool during an interview with podcaster and OpenAI investor Brad Gerstner, when he was asked how it all is supposed to add up, given OpenAI’s miniscule revenue. “If you want to sell your shares, I’ll find you a buyer,” a taken-aback Altman replied curtly. “Enough.” There are more signs of irrationality in the AI industry. In the first six months of 2025, AI start-ups that have no profits, no sales, no pitch and no product to speak of, have been securing billions of dollars of funding. For example, pre-revenue, pre-product AI company ‘Safe Superintelligence’, founded by Ilya Sutskever, ex-chief scientist at OpenAI, raised $2 billion at a $32 billion valuation in April 2025. Similarly, ‘Thinking Machines Lab’, an AI research and product company launched by OpenAI’s former chief technology officer Mira Murati, raised $2 billion at a valuation of $12 billion from investors such as Nvidia, AMD and Cisco in July 2025. The company has not released a product, has no customers and has even refused to tell investors what they’re even trying to build. “It was the most absurd pitch meeting,” one investor who met with Murati said. “She was like, ‘So we’re doing an AI company with the best AI people, but we can’t answer any questions.” The best AI people are in charge, or so they tell us. A handful of labs, led by Tolkienesque techies, control the narrative around frontier LLMs. The narrative they tell the public is that they are on a mission to build AGI to benefit all of humanity, but this emerging autonomous super-intelligence is so complex and potentially dangerous, even apocalyptic. Anthropic’s chief scientist Jared Kaplan is only the latest in a long line of AI-experts sounding the alarm; or consider Geoffrey Hinton who predicts, once more, the total breakdown of society once AI gets smarter than people. The overblown claims go like this: “It would become impossible for humans to get paid to do work because the superintelligence could do it better and cheaper. You and I would not have jobs. Nobody would have jobs.” The message is clear: reaching AGI is Very Serious Stuff, and Potentially Dangerous. But rest assured: the AI-developers can safely handle these risks and they have the expertise to decide what counts as ‘safe’. Reaching AGI will also need gigantic data-centres, land, electricity and water (for cooling), but don’t worry: the promised results will be transformative and a benefit for all. AGI will find cures for cancer, discover ways to end hunger, solve the affordability crisis, empower students and workers, and somehow also solve climate change. Just trust us, they tell us. Give us the resources we need to build AGI. But what they tell their investors is altogether different: we are building technology that can “do essentially what you will pay us for”, including making workers redundant by automating jobs or turning them into gig workers while putting them under corporate surveillance. Emily M. Bender and Alex Hanna (2025) recount, for example, how the National Eating Disorders Association in the U.S. replaced their hotline operators with a chatbot days after the former voted to unionise. AI algorithms also work successfully to help landlords push the highest possible rents on tenants. Likewise, the health insurance industry uses AI automation and predictive technologies to systematically deny patients coverage for necessary medical care. AI also works for the military: defence company Anduril builds autonomous drones, virtual reality headsets, and other AI-powered technologies for the U.S. military. And private equity firms are hiring AI people to go through the companies they own and see how these should be restructured. This way, the AI industry has convinced the financial sector, the cash-rich platform corporations and wealthy venture capitalists to invest their cash in funding the training and inference of the LLMs and the giga-data-centre infrastructure, that is driving the current AGI boom in the U.S. In a new Working Paper, I argue that this AI data-centre investment boom is a bubble which will pop, probably rather sooner than later. This will prove to be socially costly to the larger U.S. economy, not just because of the inevitable correction, crash and recession, but more fundamentally, in terms of the scarce resources that have been and will be wasted on the hallucinogenic pipe dreams of a few entitled Ayn Randian billionaire tech brothers and sisters, who, quite in character and as was noted already above, have begun to hedge their bets by begging the taxpayer for subsidies and government loan guarantees (Cooper 2025). The AI bubble will eventually pop for the following four reasons. The Revenue Delusion There is no world in which the enormous spending in data centre infrastructure (more than $5 trillion in the next five years) is going to pay off; the AI-revenue projections are pie-in-the-sky because of the following: Hence, most AI companies will fail to turn a profit, as prices will fall (because of Chinese competition), while (training and inference) costs go up due to the scaling strategy. Source: U.S. Census Bureau, Business Trends and Outlook Survey (BTOS) 2023-2025. Notes: The U.S. Census Bureau conducts a biweekly survey of 1.2 million firms. Businesses are asked whether they have used AI tools such as machine learning, natural language processing, virtual agents or voice recognition to help produce goods or services in the past two weeks. See Torsten Sløk (2025b), https://www.apolloacademy.com/ai-adoption-rate-trending-down-for-large-companies/ The Ticking Time-Bomb of Hyperscale Borrowing There is no way in which the AI industry can fund its capital expenditures out of revenues from paid subscribers or money from sovereign wealth funds. Hence, AI firms will have to resort to hyperscale borrowing from banks and investment-grade bond markets to fund their capex, laying the foundations for the next debt crisis. This hyperscale borrowing will create a ticking time bomb on the balance sheets of AI firms, because the core capital expenditure is on specialised GPUs and servers, which — because of unrelenting technological progress — risk becoming economically obsolete within two or three years. Nvidia is not helping in this respect, because it is building new generation GPUs each and every year and GPU prices are likely falling. Nvidia’s latest generation Blackwell GPU’s require entirely new servers, and if you use many of them, an entirely new data centre, because the Blackwell GPUs require much more power and cooling. The rate of economic decay of the AI compute infrastructure, therefore, is high and the payback periods are correspondingly short. “You’re investing in something that is a perishable good,” economist David McWilliams told Fortune, calling AI hardware “digital lettuce” that is “going to go off now.” Data servers, networking equipment and storage devices have a useful lifetime of 3-5 years and a corresponding annual depreciation rate of 20%-30%. These chips are not general-purpose compute engines; they are purpose-built for training and running generative AI models, tuned to the specific architectures and software stacks of a few major suppliers such as Nvidia, Google, and Amazon. These chips are part of purpose-built AI data centres — engineered for extreme power density, advanced cooling, and specialised networking. Together, they form a closed system optimised for scale but hard to repurpose. Figure 4 shows borrowing for AI data-centre construction. Investment-grade (IG) borrowing by AI big tech firms during September-October 2025 amounted to $75 billion — compared to $32 billion on average per year during 2015-2024. IG bonds issued by the AI companies make up 14% of the American IG bond market in October 2025. Barclays estimates that cumulative AI-related investment could reach the equivalent of more than 10% of U.S. GDP by 2029, compared to circa 6% in the first six months of 2025. OpenAI, Anthropic and other startups continue to lose money, and must fund most of the planned investment by selling off pieces of themselves to investors and by resorting to hyperscale borrowing from banks and investment-grade bond markets. Ignoring numerous red flags, particularly operating and financial leverage and the short pay-back periods, virtually every Wall Street player is angling to get a slice of the action, generally via off-balance-sheet Special Purpose Vehicles (SPVs), from banks such as JPMorgan Chase and Morgan Stanley to asset managers such as BlackRock and Apollo Global Management. This Wall Street frenzy will in all likelihood lay the foundations for the next debt crisis (Fitch 2025). Source: Bank of America Global Research; chart created by Lucy Raitano (October 31 2025). Notes: IG = investment grade. The data for Blue Owl and Meta refer to a project-style holding company created by Blue Owl Capital to invest in a large-scale Hyperion data centre joint venture with Meta. Exponential Growth in an Analogue World It will be impossible to build the projected data centre infrastructure in the next five years or so (which is the horizon of most AI investors). The lead time necessary to build a hyperscale data centre is currently around 2 years, but expect it to become much longer, say 7 or more years. Why? Upstream suppliers to the growth in data centres — the established industrial companies — have to expand production. These upstream suppliers will run into labour shortages, long waiting times for power grid connections, material bottlenecks and regulatory blowback – and all this will lengthen the lead times necessary to build a hyperscale data centre, as explained in more detail in the Working Paper. FT Alphaville (2025) further notes that the nature of the AI-related power demand is particularly problematic (Wigglesworth 2025a). It cites a recent Nvidia (2025) report: “Unlike a traditional data center running thousands of uncorrelated tasks, an AI factory operates as a single, synchronous system. When training a large language model (LLM), thousands of GPUs execute cycles of intense computation, followed by periods of data exchange, in near-perfect unison. This creates a facility-wide power profile characterized by massive and rapid load swings. This volatility challenge has been documented in joint research by NVIDIA, Microsoft, and OpenAI on power stabilization for AI training data centers. The research shows how synchronized GPU workloads can cause grid-scale oscillations. The power draw of a rack can swing from an “idle” state of around 30% to 100% utilization and back again in milliseconds. This forces engineers to oversize components for handling the peak current, not the average, driving up costs and footprint. When aggregated across an entire data hall, these volatile swings — representing hundreds of megawatts ramping up and down in seconds — pose a significant threat to the stability of the utility grid, making grid interconnection a primary bottleneck for AI scaling.” AI Scaling is Hitting a Wall The strategic bet of leading AI firms that Generative AI can be achieved by building ever more data centres and using ever more chips is already going bad. This scaling strategy is already exhibiting diminishing returns. It is the wrong strategy, since generic LLMs are not constructed on proper and robust world models, but instead are built to autocomplete, based on sophisticated pattern-matching (Shojaee et al. 2025). LLMs will continue to make errors and hallucinate, especially when used outside their training data. Generic AI products are never going to actually work right and will continue to be untrustworthy. Three years into the LLM wave, AI-expert Gary Marcus explains very clearly why ChatGPT has not lived up to expectations: “The results are disappointing because the underlying tech is unreliable. And that’s been obvious from the start.” Generic LLMs are hard to control; they still can’t reason reliably and never will; they still don’t work reliably with external tools; they continue to hallucinate; they still can’t match domain specific models, they continue to struggle with alignment between what human beings want and what machines actually do. “The truth is that ChatGPT has never grown up,” Marcus concludes. Marcus also presents disturbing new research on the performance of frontier LLMs across three benchmarks by CMU professor Niloofar Mireshgalleh. The first benchmark is a math test that could plausibly be answered by large quantities of data. Unsurprisingly, the frontier LLMs perform increasingly well – but, as we saw, at the cost of gigantic volumes of compute. On the second benchmark (which is focused on coding), initial progress in performance is now tailing off, exhibiting diminishing returns. However, as Marcus explains, on the third benchmark, “on a complex task combining theory of mind and privacy that seems harder to game”, the frontier LLMs show slow linear progress – again, at the cost of billions of dollars and huge quantities of electricity and water. In sum, progress in performance on complex tasks is just terribly slow – which is the key factor explaining the disappointment of users of LLMs and the limits to profitable adoption by enterprises. LLMs are great at generating plausible output – while being much less good at getting their facts straight, while being incapable of reasoning. The hardwired inclination to hallucinate (Metz and Weise 2025) limits the usefulness of AI in high-stakes activities such as healthcare, education and finance. Potential liabilities resulting from the harm done by the decisions of autonomous unsupervised AI tools are simply too large in these high-stake activities — and this will restrict the adoption of and reliance on such AI tools. More generally, we have to think of LLMs, as Bender and Hanna (2025), suggest, as “synthetic text-extruding machines”. “Like an industrial plastic process,” they explain, text databases “are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it”. The same is true of other “generative” AI models that spit out images and music. They are all, the authors say, “synthetic media machines” – or giant plagiarism machines. “Both language models and text-to-image models will out-and-out plagiarize their inputs,” the authors write. A large fraction of the output will be AI-slop. In an ironic twist, the supply of AI-slop will only increase in future, because due to the lack of ‘authentic training data’, LLMs will increase their input of ‘synthetic’ AI-generated artificial data — an incredible act of self-poisoning. The more AI-slop these models ingest, the greater the likelihood that their outputs will be junk: the “garbage-in, garbage-out” (GIGO) principle does hold. AI systems, which are trained on their own outputs, gradually lose accuracy, diversity, and reliability. This occurs because errors compound across successive model generations, leading to distorted data distributions and irreversible defects in performance. Veteran tech columnist Steven Vaughn-Nichols warns that “we’re going to invest more and more in AI, right up to the point that model collapse hits hard and AI answers are so bad even a brain-dead CEO can’t ignore it.” Conclusion Because of these four reasons, AI’s ‘scaling’ strategy will fail and the AI data-centre investment bubble will pop. The unavoidable AI-data-centre crash in the U.S. will be painful to the economy, even if some useful technology and infrastructure will survive and be productive in the longer run. However, given the unrestricted greed of the platform and other Big Tech corporations, this will also mean that AI tools that weaken the labour conditions — in activities including the visual arts, education, health care and the media — will survive. Similarly, generative AI is already entrenched in militaries and intelligence agencies and will, for sure, get used for surveillance and corporate control. All the big promises of the AI industry will fade, but many harmful uses of the technology will stick around. The immediate economic harm done will look rather insignificant compared to the long-term damage of the AI mania. The continuous oversupply of AI slop, LLM fabricated hallucinations, clickbait fake news and propaganda, deliberate deepfake images and endless machine-made junk, all produced under capitalism’s banner of progress and greed, consuming loads of energy and spouting tonnes of carbon emissions will further undermine and self-poison the trust in and the foundations of America’s economic and social order. The massive direct and indirect costs of generic LLMs will outweigh the rather limited benefits, by far. Hallucination is a technical term for any result we don’t like. For the AI, it is all hallucination. Hallucination is an extreme case of misperception. First one has to admit that our senses are far from perfect so we human can naturally hallucinate. For instance when we see mirages in the desert. Couple our limitations with drugs and the hallucinations can become a permanent feature. Illusory thinking and illusory perceptions might be defined as a kind of hallucination which derives from strong stimuli. Because the LLMs are forced to have an answer (are stimulated to reply) always or nearly always the term “illusory thinking” might be more appropriate than hallucination. For the AI it is all an illusion. Just an illusion for the elder or a beautiful Illusion for the younger. You can Hallucinate (https://www.youtube.com/watch?v=GgBmIfaHLKQ&list=RDGgBmIfaHLKQ&start_radio=1) with this Dua Lipa. I think hallucination is a sort of marketing term that implies that the results that we consider bad are anomalous, like a made up reference is worse than a real one for us. For the LLM they are the same. Humans are prone to apophenia, or seeing patterns in random information that aren’t there, it seems generative AI applies the patterns whether they are there or not. People are also prone to generate plausible answers with no information, and present them as if they were true. This behavior, epitomized in the BS artist, has also been adopted by chatbots. “Three years ago, on November 30, 2022, ChatGPT was released to the public.” What tells another part of the story: Look at what the the Nasdaq and S&P indexes were doing in 2022. Some hype needed to be created and fast. Outstanding article. Does a good job of summarizing the major problems of the AI craze in an accessible way (Ed Zitron gets a shout-out, which I find personally satisfying since it shows that a bizzare writing style does not lock you out of the discourse!) One thing I don’t understand is why the fourth section of critiques, which is basically that AI doesn’t work and is unfit for purpose, is left for last. This seems to be a common feature of AI criticism, the fact that AI is technically unsound and inherently dangerous, is downplayed and treated as a minor issue compared to things like economic problems in the industry. The strategic bet of leading AI firms that Generative AI can be achieved by building ever more data centres and using ever more chips is already going bad. This scaling strategy is already exhibiting diminishing returns. It is the wrong strategy, since generic LLMs are not constructed on proper and robust world models, but instead are built to autocomplete, based on sophisticated pattern-matching (Shojaee et al. 2025). LLMs will continue to make errors and hallucinate, especially when used outside their training data. Generic AI products are never going to actually work right and will continue to be untrustworthy. Talk about burying the lede! BTW, there is an extremely good metaphor for LLMs in here: More generally, we have to think of LLMs … as “synthetic text-extruding machines”. “Like an industrial plastic process,” they explain, text databases “are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it”. It’s an urgent task to find ways to explain the problems with AI in ways that people outside the industry can effectively grasp. “AI industry leaders are now busy doubling down on their message that the AI revolution is NOT A BUBBLE…” When “industry leaders” feel the need to make such a statement it’s a sure sign that it is. Not sure which deals, but in the case of Meta raising funding for AI data centres, Zuckerberg has personally promised to reimburse the investors in the event that things go sideways. If he had not done so, no one was going to invest so much as a nickel. A promise you can take to the bank, I’m sure. Ha Ha. No Making Shit Up. Zuckerberg has not made any personal guarantees. They were made by Meta entities, FFS. I take umbrage at those who misinform readers. One more like this and you will be blacklisted. Anyone with a simple four function calculator, not AI-bot, can figure out that the economics of this whole proposition simply cannot work. No one can explain where the massive amount of revenue will come from to service all this investment. It’s really not that complex. Oh, I think israel is perfectly willing to pony up billions of (taxpayer) USD to keep the AI surveillance and murder going. After all, they are the field testers for the US model. “Similarly, generative AI is already entrenched in militaries and intelligence agencies and will, for sure, get used for surveillance and corporate control.” I can’t imagine OpenAI is a potential $500 billion IPO, it had revenues of $5 Billion first half and no one knows how much it paid Amazon and/or Google for “compute”! The other day Ed Zitron wrote about a leaked memo [allegedly in] NVIDIA explaining NVIDIA is not ENRON. https://www.wheresyoured.at/nvidia-isnt-enron-so-what-is-it/ A long read; but if you know anyone effected by the dotcom/telecom bust it brings memories.! Looking into AI. It is capitalizing on Moore Law for speed, aka smaller transistors! We can now do a google/wiki in AI using 10 times the energy of a basic article on “old” formats. We can now compute (huger simulations?) things that Markov, Von Neuman and Feynman were creating math to estimate or simulate! Brings me back to my undergrad BS studies in the late 1960’s when you could see the transistors in a computer the size of a room. Some things I learned: Amazon is building data centers with its TPU chips, Google has a chip of its own. NVIDIA already has competition in at least two big scalers! There are two kinds of AI: generative and agentic. Generative writes stories and is “google” running on supercomputing. Agentic is AI running self driving cars and drones attacking targets based on stored images, etc. Agentic is where you may train an LLM to replace a stockroom clerk, Once I did some searches I got on some internet mailers. Last night I received an invite to a free course to see how I can evolve my business to use XX_AI! The marketing is showing some fear. Data centers, require huge energy, huge banks of “racks” containing trays of tiny 2 nanometer chips (?) all connect by copper comms. The current cannot have voltage bumps implies all electricity going through uninterruptable power supplies using huge battery banks. The sustainment of data centers is likely costly. With several competitors and small transistor arriving the product life of chips is short, likely much shorter than the payback of the debt…… AI is making use of computing evolved to simulate nuclear chain reactions, that kept scientists in Manhattan project up at night! It is possibly useful to run complex simulations in basic science research…… Elsewhere it is sledgehammer tapping carpet tacks. The term is overused. We have tools at work, tools we’ve used for years that are no more complex than an online shopping cart or search engines limited to a data set. These are now called AI, I guess to make the other AI garbage look like it’s in good company. Do calculation X a zillion time doesn’t generate anything. Just saves time. Perhaps some of the folks who rely on these uses imagine LLMs will catch up and be equally useful. The “word extruder” metaphor might work. They just give you word slime, like meat extruder give you pink slime. That’s not what “agentic” AI is. LLMs are a type of generative AI that generate text based on the input/context. Image/video/audio generation is also a type of generative AI. If you allow and train the LLM to call tools/use commands to perform certain tasks (if more info is needed, use the search tool for example) and accomplish given goals, you get an agent. Self driving/drones/etc. use a completely different types of machine learning that are not related to LLMs. The thing I wish more people found troubling was the circular financing. It would seem to imply that when things go sideways, that it will become a contagion to all the linked entities. When it implodes, it will likely happen very quickly. Perhaps congress can pass a bill to preemptively deny any taxpayer money to bail out failing firms connected with AI? Would I pass out if I hold my breath? It was very interesting to note that not only the chips, but the data centers themselves may have a depreciation cycle of just a couple of years! Digital lettuce. “Nvidia’s latest generation Blackwell GPU’s require entirely new servers, and if you use many of them, an entirely new data centre, because the Blackwell GPUs require much more power and cooling. Leaving aside the underlying issue that nothing the boosters have shown us suggests that GenAI is even possible, I recall that in the early days of the AI boom one proposed solution to the problem of their power consumption was a return to analog chips. Since the GPUs are being tailored to such a degree, a purpose-built analog architecture could use just a fraction of the energy for those calculations, but we don’t see real investment in that space and I have to conclude it’s because of the increasingly rapid rate of obsolescence. They really believe we’re always 3-6 months from the singularity or whatever. So it goes for clankers.. The more AI-slop these models ingest, the greater the likelihood that their outputs will be junk … AI systems, which are trained on their own outputs, gradually lose accuracy, diversity, and reliability. This occurs because errors compound across successive model generations, leading to distorted data distributions and irreversible defects in performance. ..so it goes for humans. To the extent you humans are effective world-modellers, it has been so only because you have senses and have learned to appreciate the manner in which your senses and integrations attenuate the signal, in order to focus around what the signal might originally have been. And humans are good at this, if they care to be, if the environment is not too adversarial. But when a significant weight of humanity takes information not from the world but from a deranged and inscrutable intermediary, variously adrift or malicious, or both.. Pockets of humanity already seem few. Long live nakedcapitalism. It seems to me that one can posit three separate ideas in this area which are plausible and arguably mutually compatible: 1. That in the short-term there is a bubble which is going to burst with adverse effects. LLM technology (which is not the sum of all AI) has clear limits which will prevent it delivering AGI. 2. Whatever happens, Governments, if only for military purposes, will provide financial support to enable continuing research into AI and AGI. 3. In the medium to long-term, we could see major progress made with AI and AGI which would obviously have to address the problems which the OP cites. Raspberryjam, IIRC, had some interesting insights a little while back which challenged the Silicon Valley Consensus that AGI was only six years away. I recently watched a talk with Demis Hassabis in which he suggested a little more conservatively that a timeframe of five to ten years was possible. I tend to take forecasts of the speed of technological developments with a pinch or two of salt, but I note that Geoffrey Hinton, whose talks/interviews I find quite illuminating, tends towards a twenty year horizon (though I have heard him say AGI could arrive in ten years or, alternatively, fifty years time.) In any event I think we should accept that there will be continuing progress in this area in the years to come. It is scary to think that at some point the machines may become better than humans at everything but surely we should recognise that they are now better than us at chess and at Go, that Alphafold is extraordinary in what it can do and that self-driving cars are arriving? Why, in the long run, should the machines not overtake us at all mental tasks? My aunt used to enjoy relating to me the story of her science teacher in the 1930s who told her class ‘it will never be possible to split the atom’. Generative AI in the US will have one customer. The Government. To use for military and psyop in cahoots with Meta, Google and Amazon. It won’t benefit the citizens at all but they will end up paying for it in taxation and energy/water bills. Meanwhile non-generative AI , the stuff used by most Silicon Valley start ups etc, use Chinese open source, free AI to build their focused developments that can produce real rewards and uses that benefit industry, commerce and citizens. I used to work on power and cost prediction software for data centres. interesting physics and maths. they are predictable systems , if they weren’t humans would f%ck them up the whole time… my favourite short description for people is “think of a very very big shed, full of resistors (ovens), that mainly generate heat and a useful bit of information processing on the side. but mainly heat” Ignoring whether this is a bubble, how useful any of this ies etc etc. – I don’t see how the capacity above actually gets delivered? I looked briefly at transformer supply. You’ve got grid changes, renewable energy sources and data centre boom all putting pressure on supply. one source suggesting now a 2-4 year lead time. The Transformer Crisis: An Industry on the Brink That is an article from last year but I cant see how the picture has got better? on the engineering side: A large campus could be specified at 100MW or more. 100MVA transformers are specialist bits of kit. its not like you can go to a local electrician for help in procurement, design and supply. installing and certifying these types of high voltage equipment needs serious levels of understanding and training. Errors around this level voltage are “high consequence” i.e. deadly, like “scraping up the pieces” deadly. Doesn’t sound like a capability that is easy to flex up that quickly does it? And the capacity numbers are huge. 120GW of capacity? that’s multiple countries worth – like 5 Belgiums or 10 Ukraine grids worth of power. I don’t see systemically how that is deliverable? I have a limited, observer experience of this for a few years. Is there anyone else with a stronger background on this type of engineering? Your email address will not be published. Required fields are marked * Comment * Name * Email * SUBSCRIPTIONS
--------------------------------------------------

Title: Pick Your Financial Crash
URL: http://prospect.org/2025/12/09/pick-your-financial-crash/
Time Published: 2025-12-09T10:15:00Z
Full Content:
The stock market has made gains at rates that are several multiples more than the growth of the real economy for three years running. Investor euphoria is always a sign of danger ahead, but this time there are other special factors signaling a pending crash. And of course, they all interact. Once investors head for the exits, others start bailing. I. Deregulation of Increasing Risk. Trump’s bank regulators are systematically dismantling the safeguards that were put in place after the financial collapse of 2008. That crash was caused by opaque financial instruments such as credit derivatives that allowed almost infinite amounts of leverage. When they turned out to be worthless, the collapse was also nearly infinite. In the aftermath, Congress and the regulators limited the risks that banks could take. In classic Wall Street form, the wise guys responded by creating non-banks that could do most of what banks do. One “innovation” was private credit, a cool-kid word for shadow banking. Another was fintech, a cool-kid word for shadow banking with an app. These newly invented lenders are banks in everything but name, and thus evade nearly all transparency, supervision, or regulation. Absent regulation, these non-bank banks can engage in sky-high leverage, meaning that the ratio of lending to their own real capital can be unlimited and unexamined. More from Robert Kuttner In 2013, as part of the post-2008 reforms, the Federal Deposit Insurance Corporation, the Office of the Comptroller of the Currency, and the Federal Reserve put in place leverage limits for banks. Loans worth more than six times a company’s annual earnings were seen as too risky. That ruled out a lot of bank loans to fund private equity takeover targets, or loans to tech fantasies that had no earnings. Private credit stepped in to fund those projects that banks couldn’t take. Capital raised for lending to private equity–backed companies jumped more than a hundredfold to nearly $700 billion between 2006 and 2024, according to The Wall Street Journal. One thing that isn’t well understood is that private credit is propped up by traditional banks; Moody’s reported in October that banks have lent $300 billion to private credit firms. So if those firms go kablooey, it won’t stop short of the broader financial system, but cascade through the heart of Wall Street. Nevertheless, the banks complained to the regulators that they were losing business (to the very companies they were funding). Given what we know about the crashes of 2008 and 1929, the right policy would be to bring the upstarts under the regulatory umbrella. But instead, last Friday the agencies agreed to the bankers’ demands to help competition by deregulating the banks and getting rid of the 2013 leverage limits. Now, dealmakers can play banks off against private credit entities for the best (most risky) terms. And banks can go beyond funding non-banks and set up their own non-bank affiliates. When the inevitable crash comes, government will bail out the insiders, leaving regular people to suffer the aftermath. II. Crypto. The value of Bitcoins and other cryptocurrencies have been on a wild ride. Crypto plays no useful function in the economy except for pursuing illegal transactions and speculation in crypto itself. When crypto was the next new thing, and investors keep bidding up the market value of crypto coins, everyone looked like a financial genius. The whole market has been banking on self-enrichment by the Trump family and his key allies—like Commerce Secretary Howard Lutnick, who handed his crypto-friendly bank Cantor Fitzgerald to his son and has seen it enjoy its best year ever—leading to regulatory leniency and therefore freedom to make a fortune. Subscribe for analysis that goes beyond the noise. Congress, on the take from the crypto industry, added to the hype last July by enacting the GENIUS Act, which stands for “Guiding and Establishing National Innovation for U.S. Stablecoins.” The act, written by the industry, pretends to provide prudent regulation, giving crypto a kind of federal blessing, but with no real protection for investors. But as the old Wall Street saying goes, genius is a rising market. And here again, leverage that works brilliantly on the upside becomes catastrophic when prices start falling. In recent weeks, Bitcoin, the marquee crypto product, has fallen from a peak value of just below $126,000 on October 7 to about $90,000 today. In just one week in November, the asset class lost $400 billion in value. This collapse has multiple knock-on effects on residual crypto plays. As Bloomberg recently reported, “An array of public companies thought they had found a sort of perpetual motion machine: Use your corporate cash to buy up Bitcoin or other digital tokens and presto, your share price shot up even more than the value of the tokens you bought.” But once prices started falling, “The median stock price of US and Canadian-listed digital asset treasuries has fallen 43% this year, with some companies’ stocks falling over 99%.” When the crypto craze began, traditional financial companies were insulated from it. But Wall Street has tried to get in on the action by sponsoring crypto-backed funds, exposing blue-chip firms like BlackRock to risk. I recently got a pitch from a crypto company promoting the story of how an entrepreneur in Argentina shielded himself from exchange rate risk and inflation risk by loading up on Bitcoin. In fact, the entrepreneur could have gotten exactly the same benefits by buying dollars. Buying Bitcoins rather than dollars added the risk that the Bitcoins would lose value—which they have. What’s really happening, as it does in every Ponzi scheme, is that the wise guys, who profited handsomely by getting in early, need more rubes to keep buying the stuff in the hope that it will hold its value. As crypto becomes more interconnected with the rest of an unregulated financial system, the risk is that they will take each other down. III. Artificial Intelligence and Tech. Is the AI boom a bubble? Apologists for the massively inflated value of Nvidia and other digital stocks reliant on the growth of AI keep pointing out that unlike pure stock market bubbles, where inflated stock prices are based mainly on the hope of further price rises, AI is adding real value and Nvidia is earning real and massive profits. Maybe. On the other hand, a dangerously concentrated share of the stock market’s run-up, more than half, is in just seven companies, the so-called Magnificent Seven: Alphabet, Amazon, Apple, Meta, Microsoft, Nvidia, and Tesla. Of these, Tesla is already faltering. Another tech giant, OpenAI, had a disappointing rollout of the latest version of its marquee product, ChatGPT. The massive bet on AI may pay off in many respects. But any economy that is this highly concentrated is at risk. With inflation rising and the cost of capital increasing with it, the $3 trillion widely projected to be invested in AI in the coming years becomes more costly and risky. Meanwhile, China, which just rang up its first trillion-dollar annual trade surplus as of the end of November, is challenging the U.S. lead in AI. Plus, as the Prospect has reported in detail, the way the build-out of AI is being funded bears numerous resemblances to the housing bubble, with dicey loans, loads of hype, and circular financing. A loss of demand or simply someone calling in their loans could lead to a crash. I am not licensed to provide investment advice. It could be that the highly leveraged loans by private credit will pay off; that the value of crypto will rebound; and that AI will live up to its hype. The Red Sox could also win next year’s World Series. If folks in the business of writing, editing, and curating quality reporting and analysis can only make the math work by putting their work behind a paywall, we’re in trouble. Journalism is so critical to democracy that a free press is literally safeguarded in the Constitution. But it doesn’t say, “a free press only for those who can afford it.” Information is becoming available more as a luxury good than the basis of a free society. We will never put the Prospect behind a paywall because we think information should be free. But we need you to be a part of this project.Help keep the Prospect free and available to everyone, not just the few. Can you chip in to support our December fundraising campaign? We need to raise $100,000 by the end of the year to power our journalism in 2026. David DayenExecutive Editor Robert Kuttner is co-founder and co-editor of The American Prospect, and professor at Brandeis University’s Heller School. His latest book is Going Big: FDR’s Legacy, Biden’s New Deal, and the Struggle to Save Democracy. Follow Bob at his site, robertkuttner.com, and on Twitter. More by Robert Kuttner
--------------------------------------------------

Title: Forget Nvidia? The under the radar AI stock everyone's suddenly watching
URL: https://www.fool.com.au/2025/12/09/forget-nvidia-the-under-the-radar-ai-stock-everyones-suddenly-watching/
Time Published: 2025-12-08T22:49:40Z
Description: After zipping more than 220% in 2025 alone, this company has been impossible to ignore in the AI space. 
The post Forget Nvidia? The under the radar AI stock everyone's suddenly watching appeared first on The Motley Fool Australia.
--------------------------------------------------

Title: 3 Stocks Most Likely to Split in 2026
URL: https://www.marketbeat.com/stock-ideas/3-stocks-most-likely-to-split-in-2026/?utm_source=yahoofinance&amp;utm_medium=yahoofinance
Time Published: 2025-12-08T22:43:00Z
Description: Stock splits are a signal that the company is strong, producing cash flow, and providing value to its investors that will continue to grow over time.
--------------------------------------------------

Title: Does Nvidia Have Too Much Cash? Unpacking the Case for More NVDA Stock Buybacks, Larger Dividends, and Less Deals.
URL: https://www.barchart.com/story/news/36514008/does-nvidia-have-too-much-cash-unpacking-the-case-for-more-nvda-stock-buybacks-larger-dividends-and-less-deals
Time Published: 2025-12-08T20:05:03Z
Description: Nvidia’s massive and rapidly growing cash pile has sparked debate over whether the company should prioritize more buybacks and bigger dividends over...
--------------------------------------------------

Title: Dear Oracle Stock Fans, Mark Your Calendars for December 10
URL: https://www.barchart.com/story/news/36513727/dear-oracle-stock-fans-mark-your-calendars-for-december-10
Time Published: 2025-12-08T19:45:11Z
Description: Down 37% from all-time highs, Oracle stock trades at a compelling valuation in December 2025, given its revenue and earnings forecast.
--------------------------------------------------

Title: Analysts Are Betting on Broadcom Stock for 2026. Should You Load Up on Shares Now?
URL: https://www.barchart.com/story/news/36513323/analysts-are-betting-on-broadcom-stock-for-2026-should-you-load-up-on-shares-now
Time Published: 2025-12-08T19:16:11Z
Description: Broadcom is a megacap tech stock that is gaining traction in the AI segment, making it a top investment to pick up before the new year.
--------------------------------------------------

Title: Stock Market Today: Longtime Tech Bull Downgrades Mag7 Tech Giants In Surprising Pivot
URL: https://www.thestreet.com/latest-news/stock-market-today-tech-bull-downgrades-mag7-tech-stocks-in-shock-move
Time Published: 2025-12-08T18:17:42Z
Description: This live blog is refreshed periodically throughout the day with the latest updates from the market.To find the latest Stock Market Today threads, click here...
--------------------------------------------------

Title: The 50 Best Christmas Movies, from ‘Eyes Wide Shut’ and ‘Carol’ to ‘Batman Returns’ and ‘Christmas Vacation’
URL: https://www.indiewire.com/gallery/christmas-movies-best-holiday-films/
Time Published: 2025-12-08T16:00:18Z
Full Content:
By providing your information, you agree to our Terms of Use and our Privacy Policy. We use vendors that may also process your information to help provide our services. This site is protected by reCAPTCHA Enterprise and the Google Privacy Policy and Terms of Service apply. In the spirit of the magic of the season (and in hopes of providing some warm respite from the usual end-of-the-year best-of deluge of stories and their attendant doldrums), IndieWire is proud to present our first-ever Holiday Week. [Editor’s note: This list was originally published in December 2022. It has since been updated with new entries.] Rockin’ around the Christmas tree at the Christmas movie stop! That’s right: You’ve reached the North Pole of movie recommendations, where our toymakers (read: film critics) have been hard at work sifting through titles all year long. It’s easy to think of holiday movies as the one area of cinema audiences have permission to practically forget about the rest of the year. With a limited window between Thanksgiving and Christmas, most film lovers can only make time for a handful of seasonally appropriate screenings before New Year’s snaps our attention back to awards season and the big Best Picture contenders. Plus, with new yuletide offerings hitting theaters and streaming platforms in a steady flurry throughout December, there’s only so much time to enjoy Christmas classics while staying current on new holiday fare. Selection is made even more complex when you get into the Christmas genre’s inexplicable tendency toward gatekeeping. It’s a frustrating reality of the movie machine that some titles, for no real discernible reason, get saddled with debates that have relatively little to do with their stories. Such is the case with John McTiernan’s “Die Hard”: the 1988 action-packed crowdpleaser starring Bruce Willis that’s become synonymous with the contentious classification of so-called “Christmas movies” and the separately defined “movies set at Christmas.” In curating this list, we’ve disregarded that delineation, allowing Stanley Kubrick’s psychosexual thriller “Eyes Wide Shut” and Bob Clark’s slasher “Black Christmas” their rightful spots alongside traditional TV specials, from “A Charlie Brown Christmas” to “Rudolph the Red-Nosed Reindeer.” The best Christmas movies, as defined here, make up a collection of films celebrating and/or challenging the holiday while using its motifs and themes to explore the light and dark sides of the human spirit. Selections have been ranked with both Christmas relevance and overall film quality in mind. Check out IndieWire’s guide to the best Thanksgiving movies. With editorial contributions by David Ehrlich, Jim Hemphill, Sarah Shachat, and Christian Zilko. You’d be hard-pressed to find a Disney fan willing to argue “Beauty and the Beast: The Enchanted Christmas” is “better” than the original. But director Andy Knight’s straight-to-VHS release from 1997 — a “midquel” imagining Belle and the Beast’s first Christmas, from before Gaston leads that angry mob to their castle in the first film — is ridiculously magical. The story sees none other than Tim Curry give voice to the formidable Forte. A grumpy composer turned into an evil pipe organ by the witch’s curse, the hidden gem Disney villain doesn’t want the spell broken because he likes his new life. The late Paul Reubens voices Forte’s right-hand, Fife, a trembling piccolo willing to do anything for the solo his conductor has promised him if the Beast doesn’t become human. “Enchanted Christmas” makes heavy use of early CGI (Forte himself is entirely digital) and it lacks much of the hand-drawn charm that made the earlier masterpiece. But with Bernadette Peters adding even more holiday cheer — she’s a tree angel and love interest for Lumiere (Jerry Orbach, again) — this is the seed that planted the forest of holiday spin-offs Disney devotees continue to enjoy each year. —AF Netflix has attempted more than its fair share of Christmas movies, including Best Animated Feature nominee “Klaus” in 2019. But “Jingle Jangle: A Christmas Journey” stands out from the streaming service’s crowd — offering everything from a Dolly Parton musical to Kurt Russell as Santa — with writer/director David Talbert’s delightfully overstuffed celebration of holiday excess. A blistering race through Christmas spectacle, musical bangers, top-notch acting, and maybe (read: definitely) one too many steampunk-inspired visual effects, “Jingle Jangle” makes for a snow globe-like display akin to a modern spin on the chorus line musical extravaganzas of yesteryear. Originally envisioned as a stage production, the 2020 straight-to-streaming film follows Forest Whittaker’s inventor character as he bonds with his brilliant granddaughter, portrayed by Madalen Mills. Together, they pull off a harrowing rescue mission, unravel a dastardly plot, and find new hope in the holiday spirit. —AF For the only tie on this list, we offer up two adaptations of Dr. Seuss’ “How the Grinch Stole Christmas” (knowing full well there are at least two other features you could consider that don’t make the cut). The 1957 children’s story was adapted first by “Looney Tunes” artist Chuck Jones and his longtime collaborator Ben Washam in a brilliantly crafted animated special, which aired on CBS in December 1966. This version boasts Boris Karloff as the voice of the Grinch: a performance that would shape the humbug-turned-unlikely hero for decades to come. Channelling Karloff’s rendering and the curling physicality of Jones and Washam’s illustrative design, Jim Carrey totally embodies the fabled mean one in Ron Howard’s live-action outing from 2000. The aughts favorite is perhaps most celebrated for its quotable lines (“Am I just eating because I’m bored?”) but is infamous for its intense prosthetics and costuming, which Carrey reportedly despised. Still, it earned three Oscar nominations and won for Best Makeup. —AF On par with “The Music Box” and “Way Out West” as a matter of family fun, this Laurel and Hardy musical from 1934 adapts parts of Victor Herbert’s 1903 stage production for a fantastic fairytale adventure revolving around a home mortgage dispute (yes, really). The film’s slap-happy concoction of over-the-top physicality, show-stopping musical numbers, and recognizable storybook characters – including the big man himself, Santa — makes this comedy of errors in Toyland, also known as “March of the Wooden Soldiers,” the best version to date. There have been multiple “Babes in Toyland” movies made for TV, as well as Disney’s 1961 theatrical feature and 1997’s animated take from MGM. —AF Considering the prevalence of his origin story, it’s a wonder Rudolph hasn’t enjoyed a more successful run in film. Sure, Santa’s ninth reindeer appears in some form or another for most of the big man’s movies; even “The Nightmare Before Christmas” gives Jack’s ghost dog Zero an excuse to cosplay as his yuletide counterpart. But as far as standalone Rudolph outings go, nothing has surpassed the 1964 stop-motion TV special (first aired on NBC) and the instantly recognizable franchise it would inspire. “Rudolph the Red-Nosed Reindeer” joyfully expands on its namesake poem (and song!) with a story introducing new characters, from love interest Clarice to the Abominable Snow Monster. That tradition would continue in prequel and sequel films, most notably with the iconic Heat Miser in 1974’s “The Year Without Santa Claus.” Still, this is one instance where, if you only have time to enjoy a single film, the original can’t be beat for its hand-crafted care and inherent nostalgia. —AF No, don’t scoff! Yes, “Last Christmas” is a shaggy, odd thing of a film, and yes, the end twist is infamously ridiculous (and also pretty easy to see coming). But Paul Feig’s underrated London Christmas fantasy is also a moving portrayal of self-improvement and growth, with a genuinely wonderful turn from Emilia Clarke as an aimless and surly menial shop worker at its center. Struggling after a health emergency and carrying strained relationships with pretty much everyone in her life, Clarke’s Kate gets a new lease on life when she meets and bonds with Henry Golding’s charming Tom. But “Last Christmas” actually works best when it isn’t a romance: there’s some real edge to Clarke’s portrayal of Kate and her self-destructive attitude that gives the film some unexpected grit, and the screenplay manages to make her eventual redemption feel genuinely earned. Plus, they deliver what you want from a movie with this title, with a stirring closing performance of Wham’s “Last Christmas” that’s simply magical. —WC A simple but nourishing ode to the power of good deeds, “We’re No Angels” sees famous hardboiled cynic Humphrey Bogart take a stab at spreading cheer and whimsy. Michael Curtiz’s film sees the “Casablanca” leading man play Joseph, a prisoner who jail breaks himself from Devil’s Island along with two buddies (Peter Ustinov and Aldo Ray), taking refuge in a local shop. Although they plan to rob the place blind and leave, a Christmas dinner with the kindhearted, struggling family makes them reconsider, as they dedicate themselves to helping their hosts instead. A little weird and wild in its plotting (a venomous snake comes into play), “We’re No Angels” nonetheless is a sweet and simple tale of Christmas redemption, that also has a wee dash of effortless Bogart suave. —WC This horror film about a kid traumatized on Christmas who grows up to go on a killing spree while dressed as Santa sparked national outrage when it was released in 1984, angering parents and critics with both its content and its lurid marketing materials. (Those of us who grew up in the era will never forget the poster with Santa coming out of the chimney with an ax.) As is so often the case, the movie itself got lost in the controversy — which is a shame, because it’s a stone cold slasher masterpiece. Filled with genuine wit and gleeful irony courtesy of screenwriter Michael Hickey, it’s very funny and earns its shocks; director Charles Sellier was a TV producer with hundreds of hours of on-set experience, and his proficient craftsmanship makes this a grim, hilarious Christmas classic. —JH One year before “Die Hard,” writer Shane Black and director Richard Donner brought us the first truly great Christmas action movie of the 80s and made the definitive buddy cop flick in the process. From the opening strains of “Jingle Bell Rock” on the soundtrack and the expertly choreographed shoot-out in a Christmas tree lot to the overall sense of bittersweet holiday melancholy that permeates the proceedings, this is pure Christmas cinema nirvana. Shane Black would return to the holidays many times in many great films (“The Long Kiss Goodnight,” “Kiss Kiss Bang Bang,” “Play Dirty”), but this is the gold standard. —JH It’s been overshadowed in recent years by Greta Gerwig’s genuinely revelatory adaptation, but the 1994 “Little Women” film by Gillian Armstrong has its charms and its pleasures, from a brilliant performance as Jo by a spirited Winona Ryder, an early killer role from Kirsten Dunst as a young Amy, and Christian Bale giving a defining heartthrob turn as a particularly charming Laurie. And like all adaptations of Louisa May Alcott’s beloved novel, the 1994 “Little Women” is a perfect movie to watch during the holidays, between the comforting golden hue with which it renders its rural Massachusetts setting and the bright, decadent costumes on display. The Christmas scenes are more tearjerking than they are joyous, though. —WC Shane Black returns to the subgenre he invented in “Lethal Weapon” with another terrific Christmas action script, this one about an amnesiac teacher (Geena Davis) who learns she was a ruthless assassin in a past life. Director Renny Harlin tears into Black’s script like a Doberman into a prime rib, milking every last set piece for maximum impact — the shoot-outs, car chases, and knife fights are spectacularly entertaining and get a lot of added flavor out of the Christmastime setting. Holiday purists might be put off by the Christmas cheer existing alongside violent torture scenes and Geena Davis spouting dialogue like, “Suck my dick,” but if cynical Christmas movies are your thing, this one is tough to beat. —JH There are many horrible Christmas movies Netflix has inflicted upon the world, from “The Christmas Prince” to “Hot Frosty.” Easily the best, and a genuine treat to treasure, is Sergio Pablos’ wonderful animated confection “Klaus.” An origin story of sorts for Santa, in which he’s a reclusive toymaker in a distant Northern town befriended and aided by a lazy postal worker, “Klaus” could easily verge on the silly: do we really need a prequel to the Santa mythos? But the film just works, with a sweet message preaching the importance of generosity and the perfect mix of humor and heart. And the film also looks gorgeous, using detailed, gorgeously lit 2D animation to bring its winter wonderland to life. —WC The holidays can provide a lovely opportunity to spend quality time with our loved ones. But, as great artists like Éric Rohmer understand so well, they can be deeply isolating weeks for single people without an obvious place to go. Random meetings with strangers can escalate into deeper connections than you might find at any other time of year — but holidays are inherently ephemeral, and many of those newfound friendships and romances are destined to end. “My Night at Maud’s” is a brilliant film about those fleeting holiday connections. Most of its characters don’t start out as strangers, per se, but they wouldn’t be nearly as close of friends at any other time of year. Cold winter nights are broken up by lengthy conversations about Pascal’s Wager, and the romance that seems to loom around the corner is thwarted by the reality that intellectual chemistry need not be indicative of any larger compatibility. The script is Rohmer’s brand of cerebral filmmaking at its absolute best, all building towards a denouement in which nothing really changes externally but everyone is left with a treasured memory. It’s not your stereotypical holiday movie, yet it hits like a snowglobe — a perfectly preserved winter memory you can return to again and again. —CZ A heavily-Tarantino inspired crime comedy, Doug Liman’s “Go” doesn’t exactly scream Christmas cheer. But it’s set around the holidays, with the tantalizing image of a young shirtless Timothy Olyphant with a Santa hat draped on his head providing much of the Yuletide tie-in. Olyphant is just one of many, many young stars in the film, which also features people like Katie Holmes, Sarah Polley, Scott Wolf, and young Jane Krakowski and Melissa McCarthy in small roles. They all liven up the funny, ramshackle story, set across one Christmas Eve night as they try and score drugs, head on an LA trip, and try to entrap a drug dealer. Spiky dialogue and a blindingly fast pace keep the film going like a festive rush that you never wish ends. —WC A warm, funny tableau more than a film, “Christmas Eve in Miller’s Point” is a touch long for a movie so plotless. Luckily, it’s so delightful that it’s hard to actually care. Tyler Thomas Taormina’s painfully accurate portrait of Long Island families — which will ring very close to home to anyone who’s ever grown up taking the LIRR into NYC — features a massive ensemble playing the Balsano family, a large clan who crowd around the table of their matriarch’s home for what seems destined to be the last time. While there’s some business with the rebellious teens (including Francesca Scorsese and Elsie Fisher) sneaking away, “Christmas Eve in Miller’s Point” is mostly content to paint a picture of the stress, anger, and joy that comes from the holiday, and the melancholy inherent to the season. —WC “In Bruges” is only a Christmas movie in the sense that “Die Hard” is a Christmas movie. But cinephiles big and small should still jump at the chance to toast the season with Martin McDonagh — a filmmaker whose knack for delivering violent fairytales to unsuspecting audiences rivals even Santa’s grasp on global gift giving. When Irish hitmen Ray (Colin Farrell) and Ken (Brendan Gleeson) are sent to hide in the Belgian city of Bruges after a botched job, involving a priest and altar boy (yay, Catholic guilt!), they’re met with an ironically cheery setting. Shiny nostalgia can’t keep criminals off the naughty list though, and it’s not long before they’re stuck in a bloody, whipsmart game of cat-and-mouse that makes Chevy Chase and the squirrel from “Christmas Vacation” look like friends. It’s a dazzling testament to McDonagh’s unique ability to balance dark and light, and even as a passive backdrop, winter festivities pair remarkably well with Farrell and Gleeson’s undeniable chemistry. “In Bruges” came out in 2008, years before the Oscar-winning “Banshees of Inisherin” reunited the actors, and Ralph Fiennes’ role as a crime boss here will make you wish he was in that film, too. Watch both and you’ll dream of Little Jenny pulling a flying sleigh. —AF Winona Ryder’s red-headed Kim dancing in the flurries of “snow” beneath Edward’s ice sculpture. That unforgettable image is what takes Tim Burton’s 1990 suburban fairytale from a movie that just so happens to be a Christmas to the status of bonafide holiday classic. Aesthetically wrapped in the magic of the season but with a plot too often devoid of goodwill towards men, “Edward Scissorhands” at once weaponizes the annual stratification that comes with “My consumerist nightmare is better than your consumerist nightmare!” discourse while also allowing its characters to take refuge in the season’s pockets of joy. Featuring a memorable appearance by Vincent Price as Edward’s inventor, the film starring Johnny Depp intertwines a fairly predicated story of an outcast thrust into society with a unique character concept that elevates the rest of his sweet and sorrowful saga. —AF David Lowery’s “The Green Knight” is, canonically, a Christmas story. Sure, the 2021 film takes one of the oldest tales for the fireside in the English language and turns it into a trippy vision-quest interrogating the true nature of honor and morality with some of the lushest, most transporting, most bewildering visuals since “The Fall.” That may not sound too Christmas-y. But on the other hand: Dev Patel. Tell me you don’t want to watch Dev Patel flail around in the mud while you’re digesting your Christmas meal with a straight face; you can’t. Real ones know that “The Green Knight” is a fantastic Christmas movie because, like the best of them, it takes you to a place and a time wholly different from our own, and gets us to feel a little fonder, a little more grateful for our corner of this burning universe. Just be braced, if any normie relatives who happen to join you, you will probably get asked about what happens with the sash two-thirds of the way through. —SS After the production of “Ghostbusters,” Bill Murray took a hiatus from filmmaking that ended (barring a cameo or two) with “Scrooged,” which teamed him with Richard Donner for a blithe, comedic take on “The Christmas Carol” story. Scrooge is now Murray’s Frank Cross, a ruthless TV executive obsessed with financial gain who gets a chance at atonement when a series of ghosts visit him on Christmas Eve to try and help him learn the error of his ways. The film’s script is a little shaky, balancing its more mean-spirited humor with the eventual sentiment somewhat poorly, but it’s all okay when Murray is such a force as the sleezeball at the center. He makes Frank’s redemption sweet despite the script issues, turning the film into a holiday staple single-handedly. Like a lot of Murray films, though, you kinda like him better when he’s being an asshole. —WC Man, if you think your family argues at Christmas. Arguing is, honestly, kind of the premise of “The Lion In Winter.” After all, arguments are much more fun when they’re written by James Goldman — also behind the stellar ‘older people having feelings and also having swords’ film, “Robin and Marian” — and delivered with decades of built-up bombast by Catherine Hepburn and Peter O’Toole. The Anthony Harvey-directed movie finds the restless King Henry II (O’Toole) and the disgraced but still dangerous Eleanor of Aquitaine (Hepburn) thrown together for the Christmas season with their miserable failsons Richard (Anthony Hopkins), Geoffrey (John Castle), and John (Nigel Terry), who might be scheming against their dad. Everybody has feelings, betrayals, mad lusts for power, and a begrudging sense of connection, despite it all. “The Lion In Winter” has some of the biggest showdowns and grandest dialogue of any movie you’ll ever see, Christmas-themed or otherwise. In its largesse, it also has some of the most fun of any movie, Christmas-themed or otherwise. It’s well worth the trip to medieval times, where, as Eleanor sarcastically proclaims, “It’s 1183 and we’re barbarians!” —WC Appearing on IndieWire’s list of the best feminist horror movies ever made, this historic, final girl-defining slasher was directed by Bob Clark. Yes, that Bob Clark: the director behind the family favorite “A Christmas Story” among others. “Black Christmas” and “A Christmas Story” are tonally disparate projects, to be sure. Still, you’ll find a familiar glow akin to the Parker family’s Christmas tree lights framing plenty of frames in the the earlier horror flick: a warm halo around the suspense – and carnage — still to come. Set at a sorority house during the holidays, “Black Christmas” stars Olivia Hussey as protagonist Jess. When menacing phone calls turn to bumps in the night and finally someone turns up dead, our heroine is forced to confront a killer lurking closer than she thinks. With a seriously vexing conclusion — that’s effective but still maddening — “Black Christmas” is best saved for those willing to weather a yuletide nightmare only to come up with metaphoric coal come the ending. —AF “I made my family disappear.” In the role that turned a 10-year-old into a household name, Macaulay Culkin stars as “Home Alone” hero Kevin McAllister. Written and produced by John Hughes with Chris Columbus serving as director, this 1990 slapstick classic follows the MacGyver-esque Kevin after he’s accidentally left behind on his family’s Christmas vacation and forced to battle two home invaders back in his sleepy Chicago suburb. Jazzy Christmas carols and zippy one-liners (“Keep the change, ya filthy animal!”) bind Culkin’s gleeful starring performance to Joe Pesci and Daniel Stern’s brilliant duo of burglars. But it’s Catherine O’Hara’s scenes, melting down as Kevin’s guilty and panicked mom Kate, that give the movie its enduring heart. “Home Alone” was followed up with a 1992 sequel set in New York City, once again starring Culkin, Pesci, Stern, and O’Hara. It’s a lesser movie, but still funny and well worth watching if you don’t already know what happens when Kevin spends a night at the Plaza. —AF Need a break from…everything? Let director Michael Curtiz’s 1954 Christmas spectacle transport you back in time with its old-world cool, polished performances, and gleefully bonkers musical logic. Princes of the silver screen Bing Crosby and Danny Kaye play friends Bob and Phil, who become singing and songwriting partners after nearly dying in World War II. (Like we said, musical logic!) When the men run across sisters Betty and Judy, played by Rosemary Clooney and Vera-Ellen, the four embark on a jazzy journey to the shockingly not-so-snowy Vermont. Say what you will of the Technicolor film’s story, but there’s no debating “White Christmas” contains masterful music. The namesake tune won Best Original Song in 1942 and is prolific enough that it’s likely playing in your head right now. But for this writer, there’s just no beating the imagery evoked in the lesser-known “Snow,” sung by the four stars aboard a train car. (“It won’t be long before we’ll all be there with snow….” “I want to wash my hands, my face and hair with snow….”) —AF There’s an unabashed schmaltziness to writer/director Richard Curtis’ “Love Actually”: a Christmas rom-com that’s at once intoxicatingly cheery in its sentimentality and sharply clever with its intricate design and British wit. Mainly set in London, with one subplot taking us to the French countryside and later Portugal, the 2003 title has become synonymous with a specific story structure. And though that moniker is sometimes doled out disparagingly (here’s looking at you, Garry Marshall’s “Mother’s Day,” “Valentine’s Day,” and “New Year’s Eve”), there’s a reason so many tenderhearted movie lovers keep coming back to it. A star-studded cast — Colin Firth, Chiwetel Ejiofor, Laura Linney, Billy Nighy, and the late Alan Rickman, among others — charm their way through nine holiday tales tied together by character relationships and some iconic wrap-around narration from Hugh Grant, who plays a lovestruck prime minister. —AF Diane Keaton as the warm, thick-glasses-clad mom! Craig T. Nelson as the emotionally open and even-keeled dad! Luke Wilson as the stoner brother! Rachel McAdams as the tote-swinging, crunchy granola sister! Truly, there are very few fictional families that are more of a joy to spend Christmas with than the family Stone — though Sarah Jessica Parker’s uptight girlfriend forced to spend Christmas with them thanks to her boyfriend, a golden boy son played by Dermot Mulroney, would probably disagree. “The Family Stone” wasn’t a particularly well-received film upon release, but 20 years have made this Christmas comedy of errors a staple watch and a classic, and that’s all thanks to the incredible cast that manages the delicate balance between comedy and drama that Thomas Bezucha’s movie offers. McAdams is the standout, but everyone gets a moment to shine, and it’s really hard difficult to think of a better Christmas gift than vegging out to their antics for a second or third or 400th rewatch. —WC The Grinch may reign supreme as cinema’s most instantly recognizable Christmas scoundrel. But Billy Bob Thornton’s titular “Bad Santa,” a conman named Willie T. Soke who once a year teams up with his partner Marcus Skidmore (Tony Cox) to steal from shopping malls in a dastardly Santa scam, easily ranks among the top five holiday movie hooligans. Directed by Terry Zwigoff, this 2003 dark comedy achieves the kind of naughty fun later films (think the aptly named “A Bad Moms Christmas”) would attempt, but with an earnest nastiness that heightens its humor to near-flying sleigh heights. As Willie’s myriad addictions and intense selfishness threaten the criminals’ partnership — against a backdrop of scheming from a cast that includes Lauren Tom and Bernie Mac, plus the much-celebrated performance of then 8-year-old Brett Kelly — the explosively violent fallout forces the titular coal receiver to reconsider his life. “Bad Santa” was eventually followed by 2016’s “Bad Santa 2,” which offers some of the same fun but is significantly more clumsy than the first. —AF Unafraid to challenge the filmmakers who came before her, Greta Gerwig remade “Little Women” in 2019: the triumphant sixth film adaptation of Louisa May Alcott’s well-loved tale of four sisters growing up in Massachusetts at the turn of the century. The Best Picture nominee reunited its writer/director with “Lady Bird” star Saoirse Ronan as Jo alongside Emma Watson as Meg, Florence Pugh as Amy, and Eliza Scanlen as Beth. Laura Dern and Bob Odenkirk played the girls’ parents with Timothée Chalamet rounding out the cast as love interest Laurie. Oh, did we mention Meryl Streep? In the most literal sense, “Little Women” is a Christmas film because it sets two pivotal scenes on the holiday. Alcott’s book famously opens with the girls grappling with a meager celebration on Christmas morning: an economic consequence of the American Civil War raging in the background. The second holiday in their story underlines the loss of one of the March sisters in a heartbreaking sequence that marks one of Gerwig’s most successful tragedies. But more than that, the film is brimming with love and sisterly affection as winter provides a fleeting backdrop to the heroines’ individual weighing of sorrow, acceptance, spirit, and defiance. —AF Accept no substitutes. Reject all remakes. If you want the story of a tough as iron and sharp as nails career woman, living in the Big City™ and forced, through a set of comedic circumstances, to pretend to be a farm wife for the holidays, look no further than 1945’s “Christmas In Connecticut.” The cast is lights-out incredible, anchored by Barbara Stanwyck as a woman’s advice columnist who’s never baked a pie, forced to return to her “family home” in Connecticut to present some homemaking bona fides for her oblivious publisher and ably abetted by Dennis Morgan as a navy man (it is 1945) who Stanwyck bring in from the cold, if you know what I mean. But the supporting ensemble is an embarrassment of riches. You could power TCM for a week off of each of them: Sydney Greenstreet, S.Z. Sakall, Una O’Connor, Reginald Gardiner. This movie is just fun, in that good old-fashioned way, sparking and charming and directed with a spritely touch by Peter Godfrey. Many other films run exactly the same playbook as “Christmas In Connecticut.” But there are very few who run it better. —SS “Last Holiday” wouldn’t stand out in the metaphoric rom-com Christmas tree lot without shining star Queen Latifah perched atop its scraggly story. When a terminally ill woman discovers her health insurance won’t cover the price of a necessary operation (seriously dark, but that’s American healthcare for you!), she decides to blow the last of her money on a solo vacation to the Czech Republic. With LL Cool J as her strapping love interest, Latifah’s Georgia breathes endless life into a wintery adventure that sees her new outlook seriously confusing hotel staff and guests. A case of mistaken identity (with an extra layer of irony, once you know the film’s ending) leads Georgia down a bow and holly-adorned adventure of fine dining, mud masks, snowboarding, and pissing off Timothy Hutton’s pompous antagonist that’s nothing if not fun. —AF National Lampoon’s Vacation franchise consists of four films starring Chevy Chase and Beverly D’Angelo. (There’s five if you count the 2015 reboot with Ed Helms and Christina Applegate, and six if you count the straight-to-video spinoff “Christmas Vacation 2”: a Randy Quaid vehicle from 2003 that barely makes it out of the metaphoric parking lot.) While there are merits to each of these harebrained family trips/events — particularly the original 1983 outing to Wally World directed by the late Harold Ramis — few would deny that writer/producer John Hughes and director Jeremiah S. Chechik’s “Christmas Vacation” is a top-of-the-tree, crowning achievement for the series. Reprising their parts as Clark and Ellen Griswold, Chase and D’Angelo are joined by the best ensemble cast the franchise ever saw with a sprawling family that’s only sometimes lovable but always believable. The 1985 comedy boasts supporting performances from then-kid actors Juliette Lewis and Johnny Galecki — the best Griswold kids ever cast — as well as Julia Louis-Dreyfus and Nicholas Guest as the Griswolds’ memorably awful neighbors. (“Why is the carpet all wet, Todd?” “I don’t know, Margo.”) —AF Before the (surprisingly demanding?) era of Airbnb, swapping homes for Christmas break provided a romantic premise for Nancy Meyers’ “The Holiday.” Kate Winslet and Cameron Diaz star as a Brit and an American — both spinning in the wake of infidelity in their relationships — who agree to stay in one another’s homes for the last two weeks of December. Once landed in Los Angeles and London respectively, the women run headlong into two aughts rom-com plots: prepared to their most satisfyingly saccharine. Jude Law plays opposite Diaz as a handsome book editor reeling from the loss of his late wife and struggling to cope with single parenthood. Back in the States, Jack Black charms Winslet as a movie score composer whose affable charisma would make him an obvious love interest, if he wasn’t already taken. Like a crushed-down “Love Actually,” “The Holiday” hits familiar beats but keeps the story fresh with its four-hander structure. —AF Tom Burton’s weirder, freakier “Batman” sequel sets a strange psychosexual tale during Gothem’s holiday season, with Christmas ornaments and snow-covered skyscrapers making for a cheery backdrop to Bruce Wayne’s (Michael Keaton) melancholic battle against the villainous Penguin (Danny DeVito). As the vengeful ghoul runs for mayor and hatches a plan to kidnap the children of Gotham’s elite in a twisted Santa Claus plot, Bruce tangos with Catwoman Selina Kyle (Michelle Pfeiffer) both in and out of their spandex. Their chemistry makes for maybe the sexiest Christmas movie ever made, particularly when Pfeiffer seductively delivers the oh-so cheesy but oh-so-perfect line, “Mistletoe can be deadly if you eat it. But a kiss can be even deadlier if you mean it.” —WC Set in the winter of 1970 and shot to look as if it had actually been made back then, Alexander Payne’s nuanced and hyper-literate “The Holdovers” takes great pleasure in defying every impulse of modern cinema from even before the moment it starts (the studio fanfare includes a “throwback” Focus Features logo, which is a cute little in-joke about a company that wasn’t founded until 2002). And yet, it might take even greater pleasure in embracing some of the movies’ most time-honored tropes and traditions. Chief among them: The inviolable rule that anything a school teacher “casually” tells their students in the first act of a film must speak to a core idea of the film itself. In that light, be sure to take notes during the opening scene in which Paul Hunham (Paul Giamatti) quotes Cicero to the “vulgar philistines” in his Ancient Civilization class. “Non nobis solum nati sumus.” “Not for ourselves alone are we born.” No spoilers, but that’s definitely going to be on the final exam of “The Holdovers,” which gradually thaws into a slight but sensitive tale about a trio of lonely souls who teach each other to push through their lives’ most isolating disappointments. —DE Let’s be real: “Gremlins 2” is significantly more fun than its 1984 predecessor. If you don’t already know that in your bones, then you should prioritize seeing the nonseasonal sequel — and possibly its spot-on “Key & Peele” parody — first. That said, “Gremlins” is the holiday half of Joe Dante’s creature duology, and it has more than enough zip to satisfy fans of ’80s camp looking for a quintessential horror holiday. When a traveling salesman (the late Hoyt Axton) brings home a strange new pet for his son, known as a “mogwai,” hero Billy Peltzer (Zach Gilligan) is tasked with abiding by three rules of care: no sunlight, no water, and no feeding it after midnight. Naturally, it takes no time at all for Billy to screw up and unleash the consequences of his adorable Christmas present on his unsuspecting town. “Gremlins” qualifies as top holiday viewing not only because its zany antics take place at Christmas, but because it also includes one of the most baffling beats in “Home Alone” director Chris Columbus’ screenwriting history. Truly, Phoebe Cates’ infamous Santa-in-a-chimney monologue is one tonal mystery that keeps on giving. —AF What do NYPD detective John McClane and classic holiday singer Bing Crosby have in common? They’ll both be home for Christmas. John McTiernan’s “Die Hard” chronicles the ill-fated reunion of Bruce Willis’ starring action hero and his estranged wife Holly (Bonnie Bedelia) at her company’s Christmas party in Los Angeles. McClane’s plans to win his wife back come undone when a high-stakes heist disguised as a terrorist attack takes over the festivities thanks to Alan Rickman’s notorious villain Hans Gruber. At its core, “Die Hard” is a tale of redemption. Sure, he’s not as on-the-nose naughty as the Grinch or Scrooge, but McClane is paying for past mistakes through the hellish ordeal that unfolds before/beneath/beside/above him in an explosive act of absolution. Even more memorable is the story of Al Powell (Reginald VelJohnson), an LAPD officer whose history on the force motivates the film’s heroic climax. If that worthy Christmas message isn’t reason enough for you to check it out, then trust that the script is full of holiday gems: from saccharine platitudes (“It’s Christmas, Theo! It’s the time of miracles…”) to season’s greetings (“Yippee-ki-yay, motherfuckers!”) —AF Bob Clark’s “A Christmas Story” has a rhythmic familiarity for some families: celebrated each year in an all-day marathon on TBS, seamlessly looping from Ralphie’s initial request for a Red Ryder carbine-action BB gun (that’s the “200-shot, range model air rifle with a compass in the stock and this thing that tells time,” of course) to the warm glow of Christmas morning when he discovers whether or not his dream present made it in under the tree. Along the way, Jean Shepherd, who co-wrote the script with Clark and Leigh Brown (not to mention narrates as an older Ralphie), imbues the Parker family with details from his real life, first appearing in his short stories. The road-weary marriage of Melinda Dillon and Darren McGavin’s Mrs. and Mr. Parker stands out as a testament to parents pushing to their absolute limits to make Christmas miracles. —AF Not to be confused with its 1994 remake (though the Mara Wilson vehicle does have its moments), 1947’s “Miracle on 34th Street” is the masterwork of writer/director George Seaton that continues to shape how New Yorkers honor the holidays. The black-and-white film stars Edmund Gwenn as Kris Kringle: the new Santa at a Macy’s department store who shocks the city when he claims to be the real Saint Nick. An 8-year-old Natalie Wood plays Susan: a little girl whose faith in Kringle becomes central to the fairytale’s message. “Miracle on 34th Street” was nominated in multiple categories at that year’s Oscars, including Best Picture. It won three: two for writing and one for Gwenn, who clinched Best Supporting Actor. —AF There are two film adaptations of Charles Dickens’ “A Christmas Carol” appearing on this list, with many, many more available. And though Brian Henson’s 1992 family favorite ranks lower than its competition, we can confidently say it’s got the better puppets. With Kermit the Frog (performed by Steve Whitmire) as its Bob Cratchit and Michael Caine playing Ebenezer Scrooge, “The Muppet Christmas Carol” stays remarkably close to its Gothic source material: a smart grounding move that heightens the film’s bursts of Muppet parody to among the funniest in the ongoing franchise. Come for the promise of punny characters (Fozziewig!) and catchy musical numbers (“It feels like Chriiistmaaas!”). Stay for the goofy witticisms only the Muppets can do justice: “You’re a little absent-minded, spirit.” “No, I’m a large absent-minded spirit!” —AF The holidays are a time of joy, but they’re also bittersweet. “The Apartment” is one of the great melancholy Christmas films, a movie about being lonely and blue during that confusing period between Christmas and New Year’s. Jack Lemmon stars as meek office drone Baxter, who uses his bachelor pad to get ahead in his career by loaning it out as an affair spot for his married superiors. But when his office crush, elevator operator Fran (Shirley MacLaine, luminous), engages in an affair with the head of the company, he’s forced to reconsider the morals of what he’s doing, and what he really wants out of his life. It’s not the most cheery Christmas film of all time, but its perfectly awkward office holiday party scene and running joke about sending a fruitcake to a person whose heart you broke every December 25 firmly establish it in the sad Christmas canon. —WC The swan song of legendary Swedish auteur Ingmar Bergman, “Fanny and Alexander” is an epic in miniature, capturing the lives of two young children born to a wealthy family as they contend with death and abuse but find comfort in themselves and their large extended family. The film, which in its uncut form runs over five hours long, begins with an extended act showcasing the decadent celebrations of the Ekdahl family across Christmas — a relatively secular tradition in which even the Jewish uncle Isak is allowed to partake. The warmth and joy on display (it’s one of the most gorgeous Christmas parties in film history) make the rest of the film — where the siblings’ father dies, and their mother remarries to a severe and abusive Protestant bishop — all the more stark in their cold isolation. Through the contrast between these two methods of religious celebration, “Fanny and Alexander” is one of the few Christmas films to seriously contend with the religion of Christianity itself, asking questions about the role spirituality plays in our lives, and whether it can lead one to happiness or ruin. —WC Its sunny yellow Miami lighting doesn’t scream Christmas. But “Tangerine,” Sean Baker’s breakout film, is very much of the season, taking place entirely on Christmas Eve. The madcap dramedy stars Kitana Kiki Rodriguez as Sin-Dee, a sex worker released from a short jail stint who discovers her boyfriend has been cheating on her. Enraged, she recruits her fellow prostitute and friend Alexandra (Mya Taylor) to help her find him. The film largely focuses on the two engaging in some very non-Christmas activities, from screaming fights to smoking meth. But their sweet friendship and almost sisterly bond keep the film of the season: if the holidays are about family, then the found family relationship seen in “Tangerine” is one of the best. —WC Satoshi Kon is best known for his mind-bending, meta films like “Paprika” or “Perfect Blue,” movies that toy with ideas of self-perception, delusion, and identity. But between those enigmatic releases, he dropped “Tokyo Godfathers,” a bittersweet tragicomedy Christmas film rooted in the down-and-out lives of ordinary people in modern-day Japan. The result is still one of the most offbeat and unusual Christmas films ever made, and also one of the most heartwarming. Heavily inspired by John Ford’s 1948 Western “3 Godfathers,” “Tokyo Godfathers” moves that story of gunslingers attempting to shepherd a baby to safety to Tokyo, where our heroes are three homeless people who find an abandoned child in the trash on Christmas Eve. Their journey across the city to find the kid’s parents is difficult and alternates between hilarious and sobering, but there’s an affection for these unlikely heroes that shines through the jokes. It’s a lovely look at the unluckiest of people during the season of giving. —WC For even some readers who first encountered the ghostly tale of Ebeneezer Scrooge on the page, the late Scottish actor Alastair Sim is the face of literature’s most famed redemptive protagonist. Directed by Brian Desmond Hurst, this 1951 black-and-white adaptation of “A Christmas Carol” — also known as “Scrooge” — enjoys an otherworldly quality emanating from its now-antiquated filmmaking and Dickens’ illustrious prose: exploring the supernatural side to Christmas in a winding story of a greedy businessman confronting his misdeeds via poltergeist. Sim’s turn as Scrooge sees the seasoned actor dexterously scale the philosophical work’s Jacob’s ladder, guiding the unlikely hero from a horror-esque villain to a soft-smiled man making peace with his life. He’d lead Guy Hamilton’s “An Inspector Calls” as the titular inspector calling just two years later, in 1954. —AF Will Ferrell brings the Christmas spirit and then some in Jon Favreau’s fish-out-of-water (elf-out-of-snow?) 2003 comedy about an effervescent Christmas enthusiast visiting gritty New York City. After spending his entire life with Santa in the North Pole, Buddy the Elf arrives in Manhattan like a breath of syrup/candy/spaghetti-infused air: challenging his nasty Scrooge of an estranged father (the late James Caan) to accept his seemingly boundless love and affection. From picking out an ill-conceived gift for that “special someone” to cutting down a tree in Central Park (a serious and illegal whoopsie!), “Elf” is chockfull of familiar traditions twisted to their most misguided and extreme. It’s a crowdpleaser not just for fans of Ferrell and kids who grew up in the aughts, but anyone needing a reason to enjoy the season. After all, say it with me: “The best way to spread Christmas cheer is singing loud for all to hear.” —AF “Have Yourself a Merry Little Christmas” is often used and recorded as a light, jubilant, or romantic song. But the iconic standard, as introduced by a sprightly Judy Garland in “Meet Me in St. Louis,” is actually a massive downer, a desperate attempt at comfort and happiness during a loved one’s darkest hour. Garland, whose rich voice has never been more beautiful, performs the song in the technicolor Vincente Minnelli musical as hopeless romantic Esther to her little sister Tootie (Margaret O’Brien) after they discover their father will be moving the whole family away from their home. It’s meant to comfort Tootie, but also herself, as she will be ripped away from the boy she loves right after he proposed to her. The scene on Christmas Eve is the only part of “Meet Me in St. Louis” that actually focuses on the holidays, but its perfect blend of melancholy and beauty makes the film an essential entry in the Christmas canon. —WC Cate Blanchett and Rooney Mara will knock the breath from your chest in Todd Haynes’ “Carol.” Adapted for the screen by Phyllis Nagy, from Patricia Highsmith’s 1952 “The Price of Salt,” this lesbian period romance (a subgenre done to death, we know) chronicles the swelling attraction between the shop girl/aspiring photographer Therese Belivet and the magnetic soon-to-be divorcee Carol Aird. At first blush, one might clump the women’s love story — featuring clandestine looks framed in artificial snow and an understated meet-cute involving a Santa hat — with other seasonal romances, such as “You’ve Got Mail” or “Love Actually” (also appearing on this list). But where those romantic comedies cut their lovers’ budding tension with holiday antics, “Carol” dares to stare deep into the melancholy thoughtfulness that comes with this time of year by incorporating a heart-rending story of a gay woman fighting to be with her daughter. The result gifts romance fans a slow-burn consideration of the bold futures we choose to allow ourselves and a final shot that will make your heart grow three sizes. —AF It’d be a little cliched to crown director Frank Capra’s “It’s a Wonderful Life” the best Christmas movie of all time: what with the seemingly endless references and homages to it appearing in other holiday films. And yet, to deny hero George Bailey’s all-time heartbreaker one of the top spots feels just about as nice list-qualifying as denying Santa his cookies. Plus, who really needs to justify giving a James Stewart performance — arguably, his best (though the legendary actor would only win an Oscar for 1940’s “The Philadelphia Story”) — supreme accolades? Based on Philip Van Doren Stern’s “The Greatest Gift,” this 1946 black-and-white fable considers the melancholia and existential despair characteristic for so many at the holidays. When news of a man’s suicidal thoughts reach heaven, Henry Travers’ guardian angel character Clarence Odbody intervenes. For those with a heavy heart this time of year — or any for that matter — “It’s a Wonderful Life” offers a hopeful salve from an old world. —AF It takes a special kind of balding, depressed, zig-zag-wearing kid to anchor not one, not two, but three major holiday specials. Four if you count “It’s the Great Pumpkin, Charlie Brown,” “A Charlie Brown Thanksgiving,” “A Charlie Brown Christmas,” and “A Charlie Brown Valentine” (though that last one might be on the fringes of modern popularity and there are other lesser titles we’re not mentioning). After Lucy asks Charlie Brown to direct the Christmas play, he’s thrust into a challenging leadership position that sees him battling Schroeder’s piano and the rest of the gang’s antics for attention. Simultaneously, Linus considers the biblical origins of the holiday and ponders what we owe to one another. The best friends’ journeys meet at night in a cold lot, where Charlie Brown picks out what may very well be the most instantly recognizable Christmas tree in TV and film history. —AF Stanley Kubrick’s final movie is unlike any other of the holly-jolly titles on this list, but there’s no denying the late filmmaker had something to say about Christmas with his sordid tale of a husband and wife’s thorny encounter with an underground sex cult. Finished just days before Kubrick’s death, “Eyes Wide Shut” stars Nicole Kidman and Tom Cruise as a raw nerve of a couple whose growing resentment culminates in a would-be affair spun out of control. Tinsel and lights offer an obvious (and ominously gorgeous) seasonal background for the film, released in July 1999. But it’s Kubrick’s repeated presentation of the holiday’s innate consumerism that drives home his thesis — or at least one interpretation of a thesis! — that marriages and families can be hungrily consumed by the vapid mundanity of self-obsession and competitive capitalism. —AF Not just one of the greatest Christmas rom-coms, but one of the greatest rom-coms period, “The Shop Around the Corner” and its tale of pen pals falling in love during the Christmas season has been adapted and modernized several times, such as in the Broadway musical “She Loves Me” or ’90s email film “You’ve Got Mail.” But Ernst Lubitsch’s original, based on the play “Parfumerie,” remains the greatest telling. In the Budapest leathergoods shop where they work, Klara (Margaret Sullavan) and Alfred (James Stewart) bicker endlessly, but in the anonymous letters they write to each other, they both reveal their softer sides and find themselves smitten with the stranger they don’t know. Both actors are phenomenal, with beautiful simple chemistry that’s alternatively spiky and sweet. They’re supported by a lovely cast, including Frank Morgan as the owner of the store Matuschek who discovers his wife is having an affair. What makes the film such a holiday great is its exploration of lonlieness during the winter months, from the two leads struggling to find love to Matuschek’s despair over his situation. It’s a simple but moving story about finding connection, and how love and companionship can be the greatest gift of all. —WC By providing your information, you agree to our Terms of Use and our Privacy Policy. We use vendors that may also process your information to help provide our services. This site is protected by reCAPTCHA Enterprise and the Google Privacy Policy and Terms of Service apply. By providing your information, you agree to our Terms of Use and our Privacy Policy. We use vendors that may also process your information to help provide our services. This site is protected by reCAPTCHA Enterprise and the Google Privacy Policy and Terms of Service apply.
--------------------------------------------------

Title: Firm that called 2025 nearly perfectly — until a moment of doubt — now has highest S&P 500 target on Wall Street
URL: https://www.marketwatch.com/story/firm-that-called-2025-nearly-perfectly-until-a-moment-of-doubt-now-has-highest-s-p-500-target-on-wall-street-be6a3a08
Time Published: 2025-12-08T14:24:00Z
Description: Oppenheimer says the S 500 will push ahead in 2026, boosted by the economy and corporate profits that are likely to keep holding up.
--------------------------------------------------

Title: H-1B shuts out Indian IT; Meesho's listing gains
URL: https://economictimes.indiatimes.com/tech/newsletters/tech-top-5/h-1b-shuts-out-indian-it-meeshos-listing-gains/articleshow/125835537.cms
Time Published: 2025-12-08T13:28:52Z
Full Content:
Want this newsletter delivered to your inbox? Updated On Dec 08, 2025, 07:40 PM IST Want this newsletter delivered to your inbox? Thank you for subscribing to Daily Top 5We'll soon meet in your inbox. Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Definitions Top Commodities Top Prime Articles Top Slideshow Top Story Listing Top Market Pages Latest News Follow us on:
--------------------------------------------------

Title: Netflix needs Warner Bros.’s IP and franchises to remain the default streaming service
URL: https://fortune.com/2025/12/08/netflix-warner-bros-deal-ip-franchises-default-streaming-service-ai/
Time Published: 2025-12-08T10:57:59Z
Full Content:
Good morning. There’s a lot of debate over last week’s surprise announcement that Netflix struck an $83 billion deal to acquire Warner Bros. Discovery. President Donald Trump said Sunday that their combined market share “could be a problem,” and the deal will face international scrutiny, too. Some takeaways so far: Warner Bros. held out for a bigger shared win. An insider told me that Warner Bros. chief David Zaslav was not eager to partner with Paramount Skydance because of financing, the price, and the fact that rookie CEO David Ellison would not only retain controlling shares but was still digesting his last win. Activate Consulting CEO Michael J. Wolf, a veteran media consultant and former president of MTV Networks, argues that this deal is a must-do for Netflix, given the rising strength of competitors like YouTube, Amazon Prime and Tubi. “No doubt Netflix is the default streaming service,” Wolf told me over the weekend. “Going forward, what will be required to win is more iconic IP and more global franchises that work everywhere. Warner Bros. Discovery is one of the only companies out there that will give Netflix both of these at once.” Experience matters. Content and the ability to distribute it have fueled many an entertainment merger. But history is filled with examples of those who’ve generated huge value for stakeholders from such deals and many that did not. The AOL Time Warner merger proved to be an expensive cautionary tale about clashing cultures, mistimed market shifts and the perils of buying at peak bubble. (Time Warner’s Turner acquisition, on the other hand, was a home run.) I remember GE CEO Jeff Immelt telling me “we know this world” when merging VivendiUniversal and NBC. Turns out GE didn’t create as much value as NBC Universal’s subsequent buyer Comcast did. Netflix co-CEO Ted Sarandos is right to say that “our mission has always been to entertain.” But even if he overcomes antitrust scrutiny, he must then win over Hollywood, investors and consumers who already balk at the idea of this new behemoth. AI is changing the game. We’ve already seen how much AI is changing the entertainment game, with AI-generated actor Tilly Norwood, AI influencers, Coca-Cola commercials, and movies. Since Netflix is a longtime builder—versus a buyer—some wonder if the streamer is interested in Warner Bros.’ deep library for reasons other than simply giving consumers more stuff to consume. As Melissa Otto, head of research at S&P Global Visible Alpha, told Fortune, the future of entertainment may come down to who owns what she calls “the video corpus” to train and power the next generation of AI models. Contact CEO Daily via Diane Brady at diane.brady@fortune.com China’s $1 trillion trade surplus President Trump’s tariffs weren’t enough to rein in China’s exports. The country’s trade surplus blew past $1 trillion for the first time this year, with one month to spare. China’s exports to the U.S. have plummeted, falling 29% in November year-on-year, but shipments to other countries, especially in southeast Asia, have soared, making up the difference. IBM’s big AI deal IBM is reportedly in talks to buy Confluent, a company that manages real-time flow of data in big AI models, in a deal worth $11 billion. The acquisition would be IBM’s largest in recent years; the tech giant announced it was slashing thousands of jobs in November in a shift towards AI. Apple’s C-Suite shakeup Four Apple executives who report to CEO Tim Cook have stepped down in the past week, marking a major shakeup at the tech giant known for C-Suite stability that’s hampering its effort to catch up in the AI race. Deutsche Bank pay bump Deutsche Bank wants to boost the pay of its supervisory board chair, Alexander Wynaendts, who is already the highest-paid chair in Germany’s Dax 40 companies. Germany’s largest lender will ask shareholders to approve a 47% bump for Wynaendts, which will take his pay to roughly $1.6 million. Rate cut expectations Wall Street analysts expect Fed chair Jerome Powell to announce another rate cut following the central bank’s meeting this week but to hold off on signaling a January cut as he balances dovish and hawkish committee members. Bank of America analysts wrote on Friday that Powell will have a hard time sending “a credibly hawkish signal” as important jobs and consumer data will be released between this week’s meeting and the one in January. China’s newest AI billionaire A homegrown Chinese chipmaker, Moore Threads Technology Co., staged China’s second-largest IPO of the year on Friday, raising $1.1 billion. Its stock rocketed 425% in its Shanghai debut, making co-founder Zhang Jianzhong, an ex-Nvidia executive, a billionaire and giving momentum to China’s push for chip self-sufficiency. Moving on from the Metaverse Meta CEO Mark Zuckerberg is leaving the Metaverse behind as the company announced it is cutting 30% from the budget of the lab responsible for the project, per Bloomberg. The experiment that Zuckerberg once described as the “successor to the mobile internet” has accumulated $70 billion in losses since 2021. S&P 500 futures were up 0.13% this morning. The last session closed up 0.19%. STOXX Europe 600 was flat in early trading. The U.K.’s FTSE 100 was down 0.08% in early trading. Japan’s Nikkei 225 was up 0.18%. China’s CSI 300 was up 0.81%. The South Korea KOSPI was up 1.34%. India’s NIFTY 50 is down 0.86%. Bitcoin is up at $92K. Inside the Fortune 500 CEO pressure cooker: surviving is harder than ever and requires an ‘odd combination’ of traits by Nick Lichtenberg Leaders in Congress outperform rank-and-file lawmakers on stock trades by up to 47% a year, researchers say by Jason Ma Nvidia CEO says data centers take about 3 years to construct in the U.S., while in China ‘they can build a hospital in a weekend’ by Nino Paoli Elon Musk says Tesla owners will soon be able to text while driving, despite it being illegal in nearly all 50 states by Sasha Rogelberg CEO Daily is compiled and edited by Joey Abrams, Claire Zillman and Lee Clifford.
--------------------------------------------------

Title: Peter Schiff once said he'd ‘be a lot richer’ if he invested all his money in the ‘Magnificent 7’ a decade ago.
URL: https://finance.yahoo.com/news/peter-schiff-once-said-hed-101300862.html
Time Published: 2025-12-08T10:13:00Z
Description: Despite missing out on a golden opportunity, Schiff claims he wouldn’t change his strategy.
--------------------------------------------------

Title: The Defining Artworks of 2025
URL: https://www.artnews.com/list/art-news/news/most-important-artworks-1234762369/
Time Published: 2025-12-08T10:00:00Z
Full Content:
By Francesca Aton, Brian Boucher, Daniel Cassady, Anne Doran, Maximilíano Durón, Alex Greenberger, Harrison Jacobs, Tessa Solomon, Emily Watlington December 8, 2025 5:00am By some measures, democracy is in downward decline in quite a few countries across the world, while censorship is only increasing. (A coincidence? Hardly.) But even with so much valid concern about the fragility of the world order more broadly, artists pressed ahead in 2025, producing valuable works that contended with police violence, abuses of power, fallen monuments, climate change, and trans rights. This list taking stock of the 25 artworks that defined the year includes many pieces confronting these issues. Not every work here is a protest, of course; there are also pieces that conjure science-fictional worlds and new possibilities for abstraction. (Not every artwork is even particularly great—we’ve included one piece we really didn’t like but found significant nonetheless.) But in a time when freedom of expression is under threat, just about any kind of art feels political in its own way. This list is a reminder that artists can, and will, forge onward, even in the darkest moments. It’s also a reminder that artists did just that in the past, too. To complement the new and recent artworks featured here, we’ve also roped in some older pieces that speak well to our current mood. These works show that history is unsettled—particularly at a time when some political forces would prefer for the past to remain set in stone. —Alex Greenberger We loved Adrien Brody in The Pianist (2002) and The Brutalist (2024), but “the artist” is a role he is unable to master, judging by the ridiculously bad, overdetermined products on view in his summer show “Made in America,” in which he portrayed iconic characters like Mickey Mouse and Marilyn Monroe, who artists great (Warhol) and not-so-great (KAWS, Banksy) have long since worked with. But the show was seemingly all anyone could talk about. In another great movie, The Matrix (1999), when Joe Pantoliano’s character is going to be plugged back into the fake world, he says, “I want to be rich. Someone important. Like an actor.” But even some actors, with all their money and fame, deep down, just want to be artists. Is that at least something that artists can feel good about? —Brian Boucher As hysteria over AI reached a fever pitch this year, artists began tackling the technology’s implications in refreshingly off-kilter ways. Shanghai-born, Tokyo-based artist Lu Yang is a case in point. Though the artist has been creating videos, installations, and interactive works featuring his virtual avatar Doku since 2020, this year Yang debuted a new installation, DOKU the Creator, that became the talk of Art Basel Hong Kong. (It later traveled in a modified form to the Amant art space in Brooklyn.) The piece is a sensory overload of an installation anchored by an hour-long video in which Doku moves through a surreal dreamscape that blends video game animation with AI-generated imagery. In Hong Kong, the video was presented inside an interactive installation that included a pop-up store. Works were sold in “blind boxes,” each hiding one of 108 possible pieces—a setup that laid bare the casino-like nature of the art market. The video and its surrounding environment evoke an art world in which the artist is no longer essential to the system’s functioning. Doku appears to operate autonomously, free to create, destroy, and mourn the value of art without any mediation by its creator. What distinguishes Yang’s work from other AI critiques is that he seems unbothered by this state of affairs. Drawing on Buddhist philosophy, he suggests that all creation functions like an algorithm—endlessly combining and recombining the totality of human thought and creativity into conceptual forms. Our mistake, he implies, is in attaching too much meaning to the artist, or their originality, at all. In the end, they are all temporary illusions. —Harrison Jacobs Surrealism—which just celebrated its 100th anniversary—is having a moment even as its canon grows ever more inclusive, with rising auction prices for Surrealist works by women, a run of expansive institutional shows like 2022’s “Surrealism Beyond Borders,” and growing interest in formerly underknown figures such as Les Lalanne. A case in point is the Museum of Modern Art’s current Wifredo Lam retrospective, on view through April 11, which presents the Cuban Surrealist painter as a transformative figure rather than an exotic offshoot of a primarily European movement. Of Chinese and African descent, Lam was deliberate about using Afro-Caribbean imagery in his works, famously telling art historian Gerardo Mosquera that his art was “an act of decolonization.” A highlight of MoMA’s exhibition is Lam’s painting Grande Composition (1949), which features a hybrid horse-human taken from the African diasporic religion Santería. The work epitomizes Lam’s belief in what he told Mosquera was “the importance of bringing the Black presence into art.”—Anne Doran Invited to create a work for the Guggenheim’s 1963 Pop Art exhibition “Six Painters and the Object,” artist Harold Stevenson produced The New Adam, a 40-foot-long wraparound painting of a nude man. (Actor Sal Mineo was the model for the body; the partially obscured face is that of Stevenson’s lover at the time, British aristocrat Timothy Willoughby.) It was rejected by the show’s curator Lawrence Alloway, who wrote, “[The] problem . . . is publicity, rumor, and all those entertaining things which would go along with exhibiting a nude with a phallus the size of a man.” More than 60 years later the time finally seems right for Stevenson’s gargantuan canvas, which not only celebrates the male body but expresses homosexual desire at a scale impossible to ignore. It is currently on view through January 19 in the Whitney Museum of American Art’s exhibition “Sixties Surreal.” —Anne Doran Few works in 2025 carried the cultural and political weight of Un coro de yicas (A chorus of yicas), the centerpiece of Claudia Alarcón and Silät’s exhibition at James Cohan. The installation—composed of 100 hand-woven yica bags—made visible a lineage of Wichí women whose textile knowledge has been passed down by generations and until recently dismissed as craft. Each yica is made using chaguar fibers harvested, processed, spun, dyed, and woven through a communal, intergenerational labor system that Alarcón learned at age 12. The work crystallizes what their practice represents: not formalist abstraction but a living language, a structure of communication, memory, and autonomy passed from mothers to daughters across the Alto la Sierra and La Puntana communities in Argentina. Seen together, the 100 bags operate as both archive and chorus, a collective declaration of presence at a moment when Indigenous women’s labor is finally being recognized as contemporary art. —Daniel Cassady This mixed-media sculpture by Ser Serpas featured in the MoMA PS1 exhibition “The Gatherers,” which brought together the work of artists whose practices collect and accumulate various forms of detritus in a world that is increasingly wasteful and on the brink of environmental collapse. Serpas is one such young artist who has injected new energy into this form of assemblage. Her installation, titled tube of brief cadavers made sadder still, might on its surface resemble a trash heap at a dump, but the two main items juxtaposed together—a plastic orange saddle-like contraption that could be part of a boat, and shredded silver fabric recalling emergency blankets—lend the piece a connotation of migrants fleeing by sea. Its haunting title seems to confirm that allusion, memorializing those who do not make the crossing and, more recently, those who are being targeted in such boats. —Maximilíano Durón The history of Japanese internment—when the United States government detained and imprisoned its own citizens—never seems to loom as large within American consciousness as it should. Perhaps that might change with Bruce Yonemoto’s Broken Fences, which debuted in the Hammer Museum’s “Made in L.A.” biennial this year, where it emerged as one of the show’s standouts. For the piece, Yonemoto has constructed two fence-like armatures into which he has embedded video screens. On the screens play two sets of propaganda—sometimes side by side, sometimes separately: one produced by the U.S. War Relocation Authority documenting the deportation of Japanese Americans, and one created by the Nazis about the Theresienstadt concentration camp. Both falsely promote the supposed “benefits” of these detentions. (The work’s dominating audio, however, comes from the German propaganda film.) Yonemoto poignantly underscores how two opposing wartime powers deployed strikingly similar visual and rhetorical tools, drawing a chilling parallel between their methods and the ideologies they served.—Maximilíano Durón More so than any other artist this year, South Korean phenom Ayoung Kim took the American art press by storm, with her work appearing on the cover of simultaneous issues of Artforum and Frieze this fall. (ARTnews also profiled her around that time, too.) There’s good reason to be suspicious of any artist who receives so much attention so suddenly, but Kim is the real deal, as proven by her current MoMA PS1 exhibition and a Performa commission staged this past November. The centerpiece of her PS1 show is this video installation, one of three chapters in a trilogy of works about motorcycle-riding female delivery workers who seem to attract and antagonize each other. Projected onto three formidably sized screens that hang from the ceiling, Kim’s footage switches seamlessly between imagery made using gaming engines and AI, and often displays impossibly tall ramps and staircases in futuristic worlds. Those worlds may not look ours, but the workers who scale them are navigating a capitalistic rat race that feels a lot like the one of the present. —Alex Greenberger The mercurial pop-music star Lorde tapped the art world in a number of ways in the promotional push around her fourth studio album Virgin, including a video that alluded to Walter De Maria’s seminal Land art work The New York Earth Room and, in a booklet that accompanied the vinyl LP, a bare-it-all picture of a waist in see-through pants by photographer Talia Chetrit. But the cover of the album was the master stroke: an X-ray image of a pelvis by Heji Shin. Bones in the arresting image are joined by a zipper (the same one as in the pants in Chetrit’s photo?) and an IUD. —Andy Battaglia This one’s very meta. When climate protestors threw soup on Van Gogh’s sunflowers and mashed potatoes on Monet’s haystacks, their detractors decried defacing any art. Never mind that all their targets were protected with plexiglas, a veneer made from fossil fuels poetically shielding these human-produced views of nature, which apparently seemed more precious to some than nature itself. Beyond the ragebait headlines, the boring moralist should-they-or-shouldn’t-theys, the protestors’ gesture blurred protest and art in more ways than one. A series by Goldin+Senneby honors the Just Stop Oil group’s conceptual heft while turning cries of conservation on their head. Working with professional conservators, the duo meticulously recreated each splattered plexi vitrine to scale, showing them against blank walls and turning them into paintings themselves. You can bask in their irreverent glory at the MIT List Visual Arts Center, where I first saw them, through mid-March. —Emily Watlington This is a game: Move your mouse across a digital landscape, select your drone’s target, press “X” for death. In Domestic Tension, Iraqi American artist Wafaa Bilal argues that this is the numbing ease of modern warfare—where the distance between people and their would-be killers has been so thoroughly abstracted that devastation can be delivered from an office chair. The piece stands as an example of what Bilal has called a “networked performance.” He confined himself to a Chicago gallery for its duration, broadcasting live online 24/7 and inviting viewers to chat, observe, or—if they were so mysteriously compelled—shoot him with a robotically-controlled paintball gun. (Non-lethal bullets still hurt.) Domestic Tension simulated the unending anxiety faced by Iraqis worldwide, forced to anticipate violence—whether physical, like a US-made bomb, or existential, as the so-called War on Terror legitimized racism: it’s acceptable to fire, so long as the target is Arab. —Tessa Solomon On most days, David Zwirner’s townhouse on New York’s Upper East Side functions well as a domestic space converted into white-cube gallery, but during the run of P. Staff’s remarkable show there this fall, the building’s spiral staircase was occasionally drenched in a haunting shades of blue. The source of that emanation was Penetration, a video projected across all three of the gallery’s floors, in which a figure stands stoically in a darkened space. A laser beam shoots through the void, aimed directly at this person’s stomach. What did that mean? Never one to let viewers off the hook easily, Staff did not offer many clues, though those familiar with the artist’s past work might recognize in this video a statement on the surveillance of bodies that do not conform to conservative gender norms. That kind of violence is endemic right now in the US—the Trump administration recently announced a measure that would keep trans Americans from changing their gender on their passports—but Staff notably did not explicitly portray it. Sometimes, everyday life is scary enough. —Alex Greenberger The trend of women painting women and calling it “feminist” has been brewing for some time, but it exploded this autumn in what I dubbed “feminist figuration fall.” Yet there is a clear divide between work trafficking in—and profiting from—pastiche and normative fantasy, and those building new, feminist worlds. Amid it all, Gordon’s show at David Zwirner stood out. In this particular painting, luminous skin glows eerily green and is punctuated with cellulite and stretch marks. Meanwhile, each of our subject’s long hairs are rendered individually. Gordon stands naked in this self-portrait save for a pair of black kitten heels, not just echoing Manet’s Olympia but talking back to it. The work both repels and allures at the same time, drawing you in, then challenging all your first impressions. She’s not relying on normative ideas of beauty as a crutch so much as reimagining what beauty might be. —Emily Watlington The difficulty of trying to remember all the little details in Laura Owens’s brain-bending painting/installation/show at Matthew Marks Gallery rhymes with the way that those details were hard to discern even when in their presence, in real time. The artist’s brush had bristled and stroked different dimensions, making for trompe l’oeil effects that twisted into spirals while turning inside-out and back again. Here too were traces of “painting” (as well as sly admonitions of it), as evident on the walls as they were on canvases that almost seemed to play a supporting role. Moving through the hidden door connecting the show’s two main spaces—each adorned with paintings of wallpaper and inexplicable things like pretzels floating in the air, and one with tiny mechanical panels that opened to reveal still more painting inside—gave rise to the most thrilling idea of an “art gallery” rather than the too-often humdrum reality of one. —Andy Battaglia This piece is a monumental act of witnessing: a 23-hour video drawn entirely from footage of U.S. State Department press briefings spanning October 2023 to January 2025, the end of the Biden administration. What begins with a journalist politely stating “I have a couple of questions” becomes an epic portrait of governmental irresponsibility as reporters—bleary, persistent, increasingly furious—try and fail to obtain clarity on Israel, Palestine, and the United States’s role therein. By editing out the spokesmen’s evasive, nothingburger replies, with cuts at times turning officials’ remarks into syllable salads, Reynolds and Ochshorn leave only the questions, revealing the briefings as a looping theater of deflection. It’s a horror film without the jump cuts: we watch the State Department rebrand its atrocities through the art of PR, confident in its own immunity. Presented without commentary, the footage indicts by showing instead of telling: this system will neither acknowledge its hypocrisies nor confront the human cost of its policies. As the genocide escalates and trust erodes, the journalists’ inquiries move from specific facts toward procedural and ethical pleas—“How do you know?” “Is there any plan?”—questions that echo far beyond the room. The film stands as one of the year’s most urgent artworks, a stark record of accountability sought and systematically denied. —Emily Watlington The beginning of the year saw Los Angeles hit by devastating wildfires, including the Eaton Fire, which decimated parts of Altadena, an unincorporated part of Los Angeles County that for generations has been home to a thriving hub of Black creativity. In response, Kenturah Davis created an embossed editioned print that featured a vintage map of Altadena onto which she had rubbed pigment that incorporated soil from outside her home, which burned in the fires. Altadena featured in an exhibition mounted by the California African American Museum just months after the wildfires to reflect on the immense loss and featured three generations of the Davis family. A work like Davis’s is a testament to the community’s resilience: from the ashes, a new Altadena will rise. —Maximilíano Durón How does one represent Palestine? It’s a question that has plagued artists and writers throughout the last century, as even the most seemingly anondyne depictions can’t help but become freighted with meaning and political valence—a tendency that has only grown since October 7 and Israel’s war in Gaza. In a work commissioned for the Taipei Biennial, Omar Mismar lands on a towering sculpture of flowers. The work is suffused with an unending grief, with the flowers evoking the ones placed typically at a tombstone. But Mismar is after something more complicated: the flowers are artificial, made out of fabric and modeled after illustrations found in Flowers of Palestine (1870), a book by Swiss missionary Hanna Zeller. Here, Mismar tackles a contradiction inherent in the idea of Palestine: some of the most detailed preservations of the land and culture were those created from a colonial gaze. The flowers do not wilt or smell. They are forever perfect, if inert. But read another way, Palestine remains an idea that will not wilt or die, due in no small part to the grief it inspires. —Harrison Jacobs More often than not—and often for the worse—US history is a work of fiction at the mercy of its makers. This provocation animates Stan Douglas’s five-channel film installation, Birth of a Nation (2025), which reframes one of cinema’s most insidious legacies of white supremacy: the 110-year-old Klan rallying cry that shares its name. For it, Douglas, a keen reader of the messages smuggled into our media, constructed an alternative narrative to a pivotal 13-minute section of D. W. Griffith’s original film, in which a Black soldier named Gus pursues a young white woman to the edge of a cliff. Though this is a tragic case of misidentification, the woman ultimately leaps to her death to escape his designs, a moment intended by the film to obliterate any sympathies that still stood for formerly enslaved Black Americans at the height of Jim Crow; the soldier—played by a white actor in blackface—is later lynched. While this scene loops on one screen, the other four present alternate outcomes of the same sequence of events made possible by new perspectives included in Douglas’s script. The characters are released from their crude casts of “villain,” “damsel,” and “hero,” and open the possibility that viewers, too, might question how they’ve looked away from a clearer, more complex picture of the powers shaping our prejudices. —Tessa Solomon Sometimes, an artwork gains new importance for reasons that are less than fortunate, and that was the case when Thomas J. Price’s Grounded in the Stars visited Times Square over the summer. The piece had already appeared elsewhere, generating little controversy in the process, but when Grounded in the Stars came to New York, the sculpture suddenly gained the attention of conservative reactionaries, who mocked Price’s piece online, remaking it in racist memes and as AI slop. What, exactly, was so offensive about a 12-foot-tall statue of a Black woman standing around? Most of the sculpture’s detractors seemed to deflect the question in social media tirades and op-eds, though it was clear that a larger debate about monuments—who deserves to be represented with them, and who they are for—hung in the background. With Trump now calling for the reinstatement of monuments that were “removed or changed to perpetuate a false reconstruction of American history” in 2020 or afterward, pieces like Grounded in the Stars suddenly seem even more essential. —Alex Greenberger More than a decade after Pussy Riot cofounder Nadya Tolokonnikova was incarcerated in Russia, the artist returned to a prison of her own making in her performance installation Police State (2025) at the Museum of Contemporary Art in Los Angeles this June. Tolokonnikova reimagined her prison cell as a space for art—a form of reclamation not only for herself but also for the Russian, Belarusian, and American prisoners whose pieces were incorporated into the installation. Inside, visitors could observe Tolokonnikova making music or art, or even resting throughout the day, via security camera footage and peepholes. The eerie authoritarian state came to life extended beyond MOCA, however, when anti-ICE protests erupted and the National Guard was deployed. With Police State unexpectedly closed to the public during the protests, Tolokonnikova continued staging the work in private, underscoring the piece’s continued relevance amid the ongoing political conflicts in the US and abroad. —Francesca Aton You can basically count on art by being censored for obscenity and support of matters like the Palestinian cause. But how can a simple flag cause trouble? That’s at the heart of the mystery behind Replacement by Cameron Rowland. Shown at the Palais de Tokyo as part of the show “Echo Delay Reverb,” the piece consisted simply of the flag of Martinique, an overseas department of France, flown above the Paris institution where a French flag is typically hung. Martinicans have fought for freedom from French rule for centuries, the artist pointed out in an accompanying text, and the flag replaced the customary French one. Within a day, the Palais de Tokyo removed the work, posting a text noting that the piece may be “considered illegal.” How? No one has elaborated. Score one for the power of the most minimal artistic gestures to cause a ruckus. —Brian Boucher In 2016, Jade Guanaro Kuriki-Olivo staged a performance called Liberté, in which performers of various gender identities dressed as the Statue of Liberty, turning a common New York tourist attraction into a kind of drag show. Nine years and two Trump administrations later, Kuriki-Olivo created a sequel in the form of Liberté Morte (Dead Liberty), a sculpture in which a Statue of Liberty costume is splayed out on a plinth. It was a a darker, more sinister approach that responded to the increased marginalization of trans people in the US between Trump administrations, and it suggested that freedom—a fragile notion right now—may be as good as dead in America. —Francesca Aton Trans Forming Liberty (2024), a painting depicting the Black trans-femme model and performance artist Arewà Basit carrying a torch à la the Statue of Liberty, made its debut last year at the San Francisco Museum of Modern Art in Amy Sherald’s survey “American Sublime.” It didn’t cause controversy there or at the Whitney Museum, where the exhibition went next. But before the show traveled to the Smithsonian-run National Portrait Gallery in Washington, D.C., the museum reportedly tried to remove the painting, leading Sherald to cancel the exhibition and allege censorship. Instead of shying away, Sherald told the New Yorker that the work “demands a fuller vision of freedom, one that includes the dignity of all bodies, all identities. Liberty isn’t fixed. She transforms, and so must we.” The painting thus became a symbol of protest—and even served as the cover for the August 11 issue of the New Yorker. —Francesca Aton The notion that history repeats itself is both a cliché and a truth, and it is one that Barbara Kruger has always considered in her work, which often finds her remaking the same textual statements about power using the same signature font, just in different settings. Featuring such phrases as “WHO IS BEYOND THE LAW?,” Untitled (Questions) ended up proving Kruger’s point when it figured so prominently in the background of the anti-ICE protests that roiled Los Angeles over the summer. Pictures of the National Guard standing beneath Kruger’s mural, sited at the Geffen Contemporary venue of the Museum of Contemporary Art Los Angeles, seemed to answer the artist’s questions well enough, so it was hardly a shock when the photographs went viral. What was more surprising was just how closely those pictures mirrored ones taken in the same place in 1992, when the National Guard was deployed to LA to quell demonstrations following Rodney King’s beating by members of the Los Angeles Police Department. In 2018, Kruger said of Untitled (Questions), “It’s both tragic and disappointing that this work, 30 years later, might still have some resonance.” Seven years on, it remains both tragic and disappointing that Kruger is always right. —Alex Greenberger There’s something familiar yet uncanny about Kara Walker’s Unmanned Drone, which this year served as the focal point of The Brick’s portion of the “Monuments” exhibition. For this towering sculpture, Walker dissected and dismembered a decommissioned statue of Stonewall Jackson atop his horse, Little Sorrel, that once stood outside a courthouse in Charlottesville, Virginia. The original, unveiled in 1921 and made by Charles Keck, stood 13 feet high and 16 feet long. Walker’s version is just as monumental but deliberately fragmented, deconstructing the myth built around Jackson in the decades following the Civil War to prop up the falsehoods of the Lost Cause—namely, that had Jackson not met an untimely death, the Confederacy would have won. By taking apart the statue and soldering it back together so that Jackson’s and Sorrel’s body parts merge in confounding, often grotesque ways, Walker lays bare the mechanics of myth-making. She shows how the building blocks of racist historical narratives can appear too large to dismantle but, in fact, can be slowly unraveled to expose the lies beneath.—Maximilíano Durón The World's Premier Art Magazine since 1913. Subscribe today and save! Sign Up for our Newsletters Get our latest stories in the feed of your favorite networks We want to hear from you! Send us a tip using our anonymous form. Subscribe to our newsletters below ARTnews is a part of Penske Media Corporation. © 2025 Art Media, LLC. All Rights Reserved.
--------------------------------------------------

Title: L&G Asset Management sees AI equity upside despite US$3 trillion debt concerns
URL: https://finance.yahoo.com/news/l-g-asset-management-sees-093000199.html
Time Published: 2025-12-08T09:30:00Z
Description: British institutional investor L&G Asset Management is not perturbed by the rising debt issuance in the artificial intelligence sector, even as it sees...
--------------------------------------------------

Title: Citi Maintains Buy on Meta Platforms (META), Sees Potential Benefits from Cost Restructuring
URL: https://finance.yahoo.com/news/citi-maintains-buy-meta-platforms-063949046.html
Time Published: 2025-12-08T06:39:49Z
Description: Meta Platforms Inc. (NASDAQ:META) is among the best stocks you’ll wish you bought sooner. On December 4, Citi reiterated its Buy rating and maintained an...
--------------------------------------------------

Title: Google and Amazon enter the AI chip arena: Can Nvidia maintain its dominance?
URL: https://www.naturalnews.com/2025-12-08-google-amazon-ai-chip-arena-nvidia-dominance.html
Time Published: 2025-12-08T06:00:00Z
Full Content:
Google and Amazon are aggressively developing their own AI chips (TPUs, Trainium3) to reduce reliance on Nvidia, signaling a shift toward self-reliance in AI hardware. Despite a 2.5% stock dip due to Google's potential TPU deal with Meta, Nvidia maintains confidence in its generational lead, with Blackwell/Rubin chips sold out through 2026. Hyperscalers' ASICs offer cost efficiency for specific workloads, but Nvidia's GPUs and CUDA ecosystem remain unmatched for versatility across industries (AI, gaming, robotics, etc.). U.S.-China tech wars and export restrictions push China (via Huawei) to develop domestic alternatives, but Nvidia's short-term dominance persists as the AI chip market rapidly expands. While hyperscalers carve out niches, Nvidia's entrenched infrastructure (NVLink, software) ensures ongoing relevanceâbut long-term leadership depends on innovation amid rising competition. Despite a 2.5% stock dip due to Google's potential TPU deal with Meta, Nvidia maintains confidence in its generational lead, with Blackwell/Rubin chips sold out through 2026. Hyperscalers' ASICs offer cost efficiency for specific workloads, but Nvidia's GPUs and CUDA ecosystem remain unmatched for versatility across industries (AI, gaming, robotics, etc.). U.S.-China tech wars and export restrictions push China (via Huawei) to develop domestic alternatives, but Nvidia's short-term dominance persists as the AI chip market rapidly expands. While hyperscalers carve out niches, Nvidia's entrenched infrastructure (NVLink, software) ensures ongoing relevanceâbut long-term leadership depends on innovation amid rising competition. Hyperscalers' ASICs offer cost efficiency for specific workloads, but Nvidia's GPUs and CUDA ecosystem remain unmatched for versatility across industries (AI, gaming, robotics, etc.). U.S.-China tech wars and export restrictions push China (via Huawei) to develop domestic alternatives, but Nvidia's short-term dominance persists as the AI chip market rapidly expands. While hyperscalers carve out niches, Nvidia's entrenched infrastructure (NVLink, software) ensures ongoing relevanceâbut long-term leadership depends on innovation amid rising competition. U.S.-China tech wars and export restrictions push China (via Huawei) to develop domestic alternatives, but Nvidia's short-term dominance persists as the AI chip market rapidly expands. While hyperscalers carve out niches, Nvidia's entrenched infrastructure (NVLink, software) ensures ongoing relevanceâbut long-term leadership depends on innovation amid rising competition. While hyperscalers carve out niches, Nvidia's entrenched infrastructure (NVLink, software) ensures ongoing relevanceâbut long-term leadership depends on innovation amid rising competition. The AI revolution is reshaping the tech landscape at breakneck speed, and nowhere is this more evident than in the semiconductor industry. Nvidia has long been the undisputed leader in AI hardware, powering everything from cloud computing to autonomous vehicles with its cutting-edge GPUs. But recent developments suggest that Big Tech giantsâparticularly Google and Amazonâare making aggressive moves to reduce their reliance on Nvidia by developing and even selling their own AI chips. The latest shockwave came with reports that Google could soon sell its custom Tensor Processing Units (TPUs) to Meta in a deal potentially worth billions. This sent Nvidia's stock tumbling 2.5% in a single day, signaling investor concerns that one of Nvidia's biggest customers might soon become a competitor. Meanwhile, Amazon unveiled its Trainium3 chip, boasting a 50% cost reduction in AI training compared to alternatives. While Nvidia remains confidentâclaiming its technology is still a generation aheadâthe question looms: Is the AI chip market shifting beneath Nvidia's feet? Google and Amazon aren't just buying Nvidia's GPUsâthey're designing their own specialized AI processors known as ASICs (Application-Specific Integrated Circuits). Unlike Nvidia's general-purpose GPUs, ASICs are optimized for specific workloads, making them highly efficient for certain AI tasks. "Google knows their requirements and can optimize their chips accordingly," says Forrester senior analyst Alvin Nguyen. "That doesn't mean their TPUs are superior to Nvidia in every way, but for Google's needs, they can outperform." Amazon's Trainium3 follows a similar logicâtailored for AI training workloads, it promises significant cost savings. But ASICs come with limitations. If a company's AI models evolve, their custom chips may need redesigningâa costly and time-consuming process. That's why hyperscalers like Google and Amazon still buy Nvidia GPUs as a hedge against shifting AI demands. Nvidia's unmatched flexibility Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com The latest shockwave came with reports that Google could soon sell its custom Tensor Processing Units (TPUs) to Meta in a deal potentially worth billions. This sent Nvidia's stock tumbling 2.5% in a single day, signaling investor concerns that one of Nvidia's biggest customers might soon become a competitor. Meanwhile, Amazon unveiled its Trainium3 chip, boasting a 50% cost reduction in AI training compared to alternatives. While Nvidia remains confidentâclaiming its technology is still a generation aheadâthe question looms: Is the AI chip market shifting beneath Nvidia's feet? Google and Amazon aren't just buying Nvidia's GPUsâthey're designing their own specialized AI processors known as ASICs (Application-Specific Integrated Circuits). Unlike Nvidia's general-purpose GPUs, ASICs are optimized for specific workloads, making them highly efficient for certain AI tasks. "Google knows their requirements and can optimize their chips accordingly," says Forrester senior analyst Alvin Nguyen. "That doesn't mean their TPUs are superior to Nvidia in every way, but for Google's needs, they can outperform." Amazon's Trainium3 follows a similar logicâtailored for AI training workloads, it promises significant cost savings. But ASICs come with limitations. If a company's AI models evolve, their custom chips may need redesigningâa costly and time-consuming process. That's why hyperscalers like Google and Amazon still buy Nvidia GPUs as a hedge against shifting AI demands. Nvidia's unmatched flexibility Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com The latest shockwave came with reports that Google could soon sell its custom Tensor Processing Units (TPUs) to Meta in a deal potentially worth billions. This sent Nvidia's stock tumbling 2.5% in a single day, signaling investor concerns that one of Nvidia's biggest customers might soon become a competitor. Meanwhile, Amazon unveiled its Trainium3 chip, boasting a 50% cost reduction in AI training compared to alternatives. While Nvidia remains confidentâclaiming its technology is still a generation aheadâthe question looms: Is the AI chip market shifting beneath Nvidia's feet? Google and Amazon aren't just buying Nvidia's GPUsâthey're designing their own specialized AI processors known as ASICs (Application-Specific Integrated Circuits). Unlike Nvidia's general-purpose GPUs, ASICs are optimized for specific workloads, making them highly efficient for certain AI tasks. "Google knows their requirements and can optimize their chips accordingly," says Forrester senior analyst Alvin Nguyen. "That doesn't mean their TPUs are superior to Nvidia in every way, but for Google's needs, they can outperform." Amazon's Trainium3 follows a similar logicâtailored for AI training workloads, it promises significant cost savings. But ASICs come with limitations. If a company's AI models evolve, their custom chips may need redesigningâa costly and time-consuming process. That's why hyperscalers like Google and Amazon still buy Nvidia GPUs as a hedge against shifting AI demands. Nvidia's unmatched flexibility Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Google and Amazon aren't just buying Nvidia's GPUsâthey're designing their own specialized AI processors known as ASICs (Application-Specific Integrated Circuits). Unlike Nvidia's general-purpose GPUs, ASICs are optimized for specific workloads, making them highly efficient for certain AI tasks. "Google knows their requirements and can optimize their chips accordingly," says Forrester senior analyst Alvin Nguyen. "That doesn't mean their TPUs are superior to Nvidia in every way, but for Google's needs, they can outperform." Amazon's Trainium3 follows a similar logicâtailored for AI training workloads, it promises significant cost savings. But ASICs come with limitations. If a company's AI models evolve, their custom chips may need redesigningâa costly and time-consuming process. That's why hyperscalers like Google and Amazon still buy Nvidia GPUs as a hedge against shifting AI demands. Nvidia's unmatched flexibility Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Google and Amazon aren't just buying Nvidia's GPUsâthey're designing their own specialized AI processors known as ASICs (Application-Specific Integrated Circuits). Unlike Nvidia's general-purpose GPUs, ASICs are optimized for specific workloads, making them highly efficient for certain AI tasks. "Google knows their requirements and can optimize their chips accordingly," says Forrester senior analyst Alvin Nguyen. "That doesn't mean their TPUs are superior to Nvidia in every way, but for Google's needs, they can outperform." Amazon's Trainium3 follows a similar logicâtailored for AI training workloads, it promises significant cost savings. But ASICs come with limitations. If a company's AI models evolve, their custom chips may need redesigningâa costly and time-consuming process. That's why hyperscalers like Google and Amazon still buy Nvidia GPUs as a hedge against shifting AI demands. Nvidia's unmatched flexibility Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com "Google knows their requirements and can optimize their chips accordingly," says Forrester senior analyst Alvin Nguyen. "That doesn't mean their TPUs are superior to Nvidia in every way, but for Google's needs, they can outperform." Amazon's Trainium3 follows a similar logicâtailored for AI training workloads, it promises significant cost savings. But ASICs come with limitations. If a company's AI models evolve, their custom chips may need redesigningâa costly and time-consuming process. That's why hyperscalers like Google and Amazon still buy Nvidia GPUs as a hedge against shifting AI demands. Nvidia's unmatched flexibility Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com "Google knows their requirements and can optimize their chips accordingly," says Forrester senior analyst Alvin Nguyen. "That doesn't mean their TPUs are superior to Nvidia in every way, but for Google's needs, they can outperform." Amazon's Trainium3 follows a similar logicâtailored for AI training workloads, it promises significant cost savings. But ASICs come with limitations. If a company's AI models evolve, their custom chips may need redesigningâa costly and time-consuming process. That's why hyperscalers like Google and Amazon still buy Nvidia GPUs as a hedge against shifting AI demands. Nvidia's unmatched flexibility Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Amazon's Trainium3 follows a similar logicâtailored for AI training workloads, it promises significant cost savings. But ASICs come with limitations. If a company's AI models evolve, their custom chips may need redesigningâa costly and time-consuming process. That's why hyperscalers like Google and Amazon still buy Nvidia GPUs as a hedge against shifting AI demands. Nvidia's unmatched flexibility Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Amazon's Trainium3 follows a similar logicâtailored for AI training workloads, it promises significant cost savings. But ASICs come with limitations. If a company's AI models evolve, their custom chips may need redesigningâa costly and time-consuming process. That's why hyperscalers like Google and Amazon still buy Nvidia GPUs as a hedge against shifting AI demands. Nvidia's unmatched flexibility Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Nvidia's unmatched flexibility Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Nvidia's strength lies in its versatility. Its GPUs aren't just AI acceleratorsâthey power gaming, robotics, autonomous vehicles and scientific computing. Moreover, Nvidia's CUDA software ecosystem is deeply entrenched in AI development, making its hardware the default choice for many developers. "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com "Nvidia's architecture is transferable across industries," explains Bernstein analyst Stacy Rasgon. "If your model changes, you don't need a new chipâyou just reprogram." Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Additionally, Nvidia isn't just selling GPUsâit's expanding into networking with NVLink and AI infrastructure solutions. Amazon, despite pushing Trainium3, still relies on Nvidia's NVLink for its servers. This symbiotic relationship means that even as Big Tech builds its own chips, Nvidia remains indispensable. Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Hyperscalers like Google, Amazon and Microsoft account for roughly 50% of Nvidia's data center revenue. If they shift more workloads to in-house chips, could Nvidia's growth stall? Not necessarily. "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com "The AI chip market is expanding so fast that there's room for multiple players," says Rasgon. While Google and Amazon may carve out niches, Nvidia's Blackwell and Rubin AI chips are already sold out through 2026, with projected revenues nearing $500 billion. Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Mizuho analyst Vijay Rakesh sums it up: "Nvidia is still the king." But in the rapidly evolving AI arms race, even kings must adaptâor risk being dethroned. The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com The bigger picture: geopolitics and AI dominance This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com This chip rivalry isn't just about corporate competitionâit's intertwined with U.S.-China tensions. As Washington restricts AI chip exports to Beijing, China is scrambling to develop domestic alternatives. Huawei's Ascend chips pose a long-term threat, but for now, China remains dependent on Nvidia. Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Meanwhile, Big Tech's push for self-reliance reflects a broader trend: AI is too critical to outsource entirely. Whether Nvidia can maintain its lead hinges on its ability to stay ahead in both hardware and softwareâwhile fending off rivals who once were its biggest customers. One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com One thing is certain: The AI chip wars are just heating up. According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com According to BrightU.AI's Enoch,Â Google and Amazon entering the AI chip arena will intensify competition, leveraging their vast resources and cloud infrastructure to challenge Nvidia's dominance. However, Nvidia's established ecosystem, CUDA platform and first-mover advantage in AI acceleration make it resilientâthough not invincibleâas the market fragments with new players. Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Watch this videoÂ aboutÂ Nvidia's stock price doubling in the next couple of years. This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com This video is from theÂ TrendingNewsÂ channel onÂ Brighteon.com. Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Sources include: Finance.Yahoo.com BrightU.ai Brighteon.com Finance.Yahoo.com BrightU.ai Brighteon.com Finance.Yahoo.com BrightU.ai Brighteon.com BrightU.ai Brighteon.com BrightU.ai Brighteon.com Brighteon.com Brighteon.com This site is part of the Natural News Network © 2022 All Rights Reserved. Privacy | Terms All content posted on this site is commentary or opinion and is protected under Free Speech. Truth Publishing International, LTD. is not responsible for content written by contributing authors. The information on this site is provided for educational and entertainment purposes only. It is not intended as a substitute for professional advice of any kind. Truth Publishing assumes no responsibility for the use or misuse of this material. Your use of this website indicates your agreement to these terms and those published here. All trademarks, registered trademarks and servicemarks mentioned on this site are the property of their respective owners. Backup IP: http://45.89.97.6
--------------------------------------------------

Title: Citi Lowers Oracle (ORCL) PT to $375 on Valuation Concerns, Maintains Buy Rating Expecting Strong Bookings
URL: https://finance.yahoo.com/news/citi-lowers-oracle-orcl-pt-053143955.html
Time Published: 2025-12-08T05:31:43Z
Description: Oracle Corporation (NYSE:ORCL) is one of the most profitable tech stocks to buy. On December 4, Citi analyst Tyler Radke lowered the firm’s price target on...
--------------------------------------------------

Title: Not share price, not performance, here's what Apple's management exodus hints for the tech giant's future
URL: https://www.livemint.com/companies/news/apple-management-exodus-hints-tech-giant-ai-future-what-direction-change-performance-share-price-tim-cook-business-news-11765159075647.html
Time Published: 2025-12-08T02:51:46Z
Full Content:
Apple is witnessing an unusually concentrated wave of senior exits just as it tries to reposition itself for an AI-driven future. A series of exits and impending departures across top management and engineering ranks in recent weeks has raised fresh questions about the stability of the company’s leadership bench — and the readiness of the world’s most valuable firm to accelerate its artificial-intelligence (AI) push. A Yahoo Finance report said that while a quick succession of exits usually signifies a sinking boat, there could be more to this situation. The churn comes at a moment of financial strength: Apple has posted strong quarterly results powered by new iPhone sales, its market value has climbed past $4 trillion, and the stock is trading near record highs. The issue, the report said, isn’t performance—it’s who is leaving, and from which parts of the organization. According to the report, Apple has been under mounting pressure to deliver on AI, a space where critics argue it has fallen behind despite the technology’s transformative potential. Many of the executives now exiting were tied to AI product integration, hardware strategy or design — the very areas Apple needs to lean on as it tries to close the gap. Besides this, CEO Tim Cook is nearing retirement age, and there is big speculation over who will, or can, take over after front-runner Jeff Williams left. Notably, Apple has not explicitly said that the executive changes are AI development-based, but most of those on their way out have been closely associated with its AI product integration or design aspects. Deepwater Asset Management managing partner and longtime Apple watcher Gene Munster told Yahoo Finance, “I think that the changes that have happened are largely because Cook wants to shake things up. And instead of being a follower in AI, he wants to be a leader. So, I think it's more than just a typical transition. I think ... this is a big deal.” A veteran engineer who joined in 2018, with prior experience at Microsoft and Google, Giannandrea's departure was viewed as a strategic move, as Apple continued to lag behind competitors in the AI space, as per various reports. Now filling the role is researcher Amar Subramanya, who moved from corporate Vice President of AI at Microsoft, before which he spent 16 years heading engineering for Google's Gemini digital assistant. He will report to Apple's Senior Vice President of Software Engineering Craig Federighi. Announcing his appointment, Apple cited Subramanya's experience integrating AI into features and products as “important to Apple's ongoing innovation and future Apple Intelligence features”, AFP reported. Commenting on Subramanya's appointment in the company release, Apple CEO Tim Cook said AI is “central to Apple's strategy” and that the new chief will bring “extraordinary AI expertise” to the role. Alan Dye, meanwhile, was involved in the Apple Vision Pro launch and helped with “integrating eye/hand interactions and immersion”. In 2025, he led the design of Liquid Glass and helped unify the design language for iOS, iPadOS, MacOS, watchOS and tvOS. ZK Research founder and principal analyst Zeus Kerravala told Yahoo Finance, “There is a renewed push by Apple to accelerate its AI roadmap, especially after criticism that its earlier AI efforts with Siri ... lagged behind a lot of the rivals. I think what makes Apple kind of unique is they can be behind [in] technology because of the fandom that's around Apple and the ecosystem that they lock people into. I think, from an Apple perspective right now, it's ‘make these changes now, and make sure you are positioned well,’ or you are going to start losing share, eventually.” (With inputs from Agencies) Catch all the Business News , Corporate news , Breaking News Events and Latest News Updates on Live Mint. Download The Mint News App to get Daily Market Updates. Download the Mint app and read premium stories Log in to our website to save your bookmarks. It'll just take a moment. Oops! Looks like you have exceeded the limit to bookmark the image. Remove some to bookmark this image.
--------------------------------------------------

Title: The AI Wildfire Is Coming. It's Going to Be Painful and Healthy
URL: https://ceodinner.substack.com/p/the-ai-wildfire-is-coming-its-going
Time Published: 2025-12-07T16:43:38Z
Description: AI won’t crash—it will burn. Like every tech cycle, the fire will clear the brush, redistribute talent, and leave infrastructure to power what comes next. The question is: what kind of plant are you?
--------------------------------------------------

Title: Apple's executive exodus sends a signal about its AI strategy
URL: https://finance.yahoo.com/news/apples-executive-exodus-sends-a-signal-about-its-ai-strategy-150058611.html
Time Published: 2025-12-07T15:00:58Z
Description: A number of executives are departing Apple. At least some of them are related to its AI strategy.
--------------------------------------------------

Title: FO° Exclusive: $650 Billion a Year? The Numbers Behind the AI Boom Don’t Add Up
URL: https://www.fairobserver.com/economics/fo-exclusive-650-billion-a-year-the-numbers-behind-the-ai-boom-dont-add-up/
Time Published: 2025-12-07T12:55:56Z
Full Content:
We rely on your support for our independence, diversity and quality. In this section of the November 2025 episode of FO° Exclusive, Atul Singh and Glenn Carle examine growing fears that the US stock market has become detached from economic reality. Inequality, weakening consumer demand and policy time lags now increase systemic risk. Mounting fiscal strain, tariff uncertainty and global diversification away from the dollar make a significant market correction increasingly plausible. This article saved into your bookmarks. Click here to view your bookmarks. Editor-in-Chief Atul Singh and FOI Senior Partner Glenn Carle, a retired CIA officer who now advises companies, governments and organizations on geopolitical risk, discuss rising fears of a US stock market bubble, with particular attention to technology and artificial intelligence. Their concern is not simply that equities are expensive, but that today’s valuations reflect expectations the real economy may be unable to meet. Drawing on warnings by market experts, fiscal data and consumer indicators, they argue that the American economy is showing strains beneath the surface while markets continue to price in near-perfect economic conditions. The gap between financial optimism and economic reality, they suggest, is widening dangerously. The AI boom and extreme market concentration Atul opens by highlighting warnings from Albert Edwards, the global strategist at French bank Société Générale, who sees the US equity market — especially tech and AI stocks — in the midst of a classic bubble. Some major technology firms are trading at roughly 30 times forward earnings, a level Atul calls “a ridiculous figure.” These valuations, Edwards argues, leave little margin for error. The discussion stresses that such optimism depends on extraordinary assumptions. Citing estimates from JPMorgan Chase, Atul notes that for companies to earn a 10% return on projected AI capital expenditure by 2030, they would collectively need around $650 billion in annual AI revenues — roughly $400 per year from every iPhone user. While some fund managers remain bullish, arguing AI-led productivity gains justify this optimism, many investors view the revenue assumptions as implausible. Market gains are also highly concentrated. Roughly 60% of recent stock market growth has come from just seven firms: Alphabet, Amazon, Apple, Meta Platforms, Microsoft, Nvidia and Tesla. The remaining 40% of the market is up as well, but far less dramatically. This concentration amplifies systemic risk, as any correction among a handful of firms could reverberate across the entire market. Inequality, consumers and the fragile base of demand The US economy ultimately depends on consumer demand, even if that reality is often obscured by soaring asset prices. Glenn underlines that consumption today is increasingly driven by the wealthy. Around 80–86% of the gains from recent tax cuts have flowed to the top 1% of Americans, while the bottom 80% have seen little or no growth in disposable income for years. This imbalance matters because wealthy households cannot replace mass demand. Glenn sums it up starkly: “1,000 billionaires cannot buy as many cars as 100 million lower-middle-class Americans.” If middle- and lower-middle-class consumers cannot afford homes, cars or basic goods, economic momentum weakens regardless of stock prices. Atul turns the conversation to the declining role of entrepreneurs. Building small, innovative firms has become much more difficult as large corporations dominate markets. Historically, smaller companies have driven job creation and experimentation in both the US and Europe. Their erosion, Glenn adds, pushes the economy toward oligopoly — less competition, weaker innovation and slower long-term growth. Time lags, tariffs and mounting economic strain A central theme of the discussion is what Glenn calls the “lag factor” in economic policy. Despite commentators’ claims that new tariffs have had little immediate impact, policy effects take time. Even small changes in short-term interest rates can take around six months to affect the economy, while longer-term rates and fiscal measures often take 18 months or more. Dismissing these delays may prove dangerous. Although tariff revenues have risen and trade flows have not collapsed, uncertainty itself is already affecting behavior. CEOs faced with shifting rules and arbitrary implementation hesitate to make long-term investment decisions. Supporters inside the Trump administration counter by likening the US market to a Disneyland theme park, arguing that trading partners will continue to accept lower margins because there is no substitute — a view closely associated with US Treasury Secretary Scott Bessent, who administration insiders credit with engineering a delicate balancing act between trade pressure and market stability. Supporters also point to the US–China trade deal, which they argue removed Chinese export controls on rare earths, halted retaliation against US semiconductor firms and reopened Chinese markets to American agricultural exports. Critics respond that this confidence underestimates how quickly countries adapt when costs rise. Glenn points to rising housing costs, weak youth employment, a growing deficit and slowing construction as indicators of a slowdown in the economy. Atul reinforces this view with insider insights from within Washington, DC. Sources in the US Treasury worry not just about tariffs, but about affordability, cost-of-living pressures and weakening demand. Meanwhile, headline fiscal numbers are troubling. US debt is projected to exceed that of Italy and Greece for the first time this century, while the budget deficit remains near 6% in peacetime. Demand, dislocation and a possible crash Beyond near-term indicators, Atul and Glenn raise a deeper structural concern: demand in an AI-driven economy. Even if AI significantly boosts production and efficiency, it may also displace jobs faster than new ones emerge. Atul likens the situation to the late 1920s, when productivity surged, but demand failed to keep pace, ending in a market collapse. Signs of stress are already showing. University of Michigan consumer confidence fell to 50.3 in November, the second-worst reading ever recorded — worse than during the 2008 global financial crisis or the 2020 Covid-19 downturn. Household balance sheets are also deteriorating: roughly 4.5% of US household debt is now delinquent, while student-loan delinquencies have reached record levels. Youth unemployment has climbed above 8%, and job-search times are lengthening. Simultaneously, while the dollar remains the world’s main trading currency, it is declining as a store of value. Central banks and investors are diversifying away from the mighty greenback. Even allies like Canada are actively seeking to reduce reliance on the US market through shifting trade, tourism and even defense procurement decisions. Importantly, rising market volatility presents a major risk, with the Cboe Volatility Index crossing the 20 mark, signaling higher-than-normal expected market volatility and increased investor uncertainty or fear Investors and economists are increasingly talking of an impending crash. These predictions might be a bit too pessimistic, but dismissing them would be reckless. As Atul puts it, “just because there’s a lot of talk about it doesn’t mean that it is all talk.” Together, the indicators paint a consistent picture: an irrational exuberance in markets, an economy under increasing strains and a growing risk that economic realities upend ebullient markets. [Lee Thompson-Kolar edited this piece.] The views expressed in this article/video are the author’s own and do not necessarily reflect Fair Observer’s editorial policy. Editor-in-Chief Atul Singh and FOI Senior Partner Glenn Carle, a retired CIA officer who now advises companies, governments and organizations on geopolitical risk, discuss rising fears of a US stock market bubble, with particular attention to technology and artificial intelligence. Their concern is not simply that equities are expensive, but that today’s valuations reflect expectations the real economy may be unable to meet. Drawing on warnings by market experts, fiscal data and consumer indicators, they argue that the American economy is showing strains beneath the surface while markets continue to price in near-perfect economic conditions. The gap between financial optimism and economic reality, they suggest, is widening dangerously. Atul opens by highlighting warnings from Albert Edwards, the global strategist at French bank Société Générale, who sees the US equity market — especially tech and AI stocks — in the midst of a classic bubble. Some major technology firms are trading at roughly 30 times forward earnings, a level Atul calls “a ridiculous figure.” These valuations, Edwards argues, leave little margin for error. The discussion stresses that such optimism depends on extraordinary assumptions. Citing estimates from JPMorgan Chase, Atul notes that for companies to earn a 10% return on projected AI capital expenditure by 2030, they would collectively need around $650 billion in annual AI revenues — roughly $400 per year from every iPhone user. While some fund managers remain bullish, arguing AI-led productivity gains justify this optimism, many investors view the revenue assumptions as implausible. Market gains are also highly concentrated. Roughly 60% of recent stock market growth has come from just seven firms: Alphabet, Amazon, Apple, Meta Platforms, Microsoft, Nvidia and Tesla. The remaining 40% of the market is up as well, but far less dramatically. This concentration amplifies systemic risk, as any correction among a handful of firms could reverberate across the entire market. The US economy ultimately depends on consumer demand, even if that reality is often obscured by soaring asset prices. Glenn underlines that consumption today is increasingly driven by the wealthy. Around 80–86% of the gains from recent tax cuts have flowed to the top 1% of Americans, while the bottom 80% have seen little or no growth in disposable income for years. This imbalance matters because wealthy households cannot replace mass demand. Glenn sums it up starkly: “1,000 billionaires cannot buy as many cars as 100 million lower-middle-class Americans.” If middle- and lower-middle-class consumers cannot afford homes, cars or basic goods, economic momentum weakens regardless of stock prices. Atul turns the conversation to the declining role of entrepreneurs. Building small, innovative firms has become much more difficult as large corporations dominate markets. Historically, smaller companies have driven job creation and experimentation in both the US and Europe. Their erosion, Glenn adds, pushes the economy toward oligopoly — less competition, weaker innovation and slower long-term growth. A central theme of the discussion is what Glenn calls the “lag factor” in economic policy. Despite commentators’ claims that new tariffs have had little immediate impact, policy effects take time. Even small changes in short-term interest rates can take around six months to affect the economy, while longer-term rates and fiscal measures often take 18 months or more. Dismissing these delays may prove dangerous. Although tariff revenues have risen and trade flows have not collapsed, uncertainty itself is already affecting behavior. CEOs faced with shifting rules and arbitrary implementation hesitate to make long-term investment decisions. Supporters inside the Trump administration counter by likening the US market to a Disneyland theme park, arguing that trading partners will continue to accept lower margins because there is no substitute — a view closely associated with US Treasury Secretary Scott Bessent, who administration insiders credit with engineering a delicate balancing act between trade pressure and market stability. Supporters also point to the US–China trade deal, which they argue removed Chinese export controls on rare earths, halted retaliation against US semiconductor firms and reopened Chinese markets to American agricultural exports. Critics respond that this confidence underestimates how quickly countries adapt when costs rise. Glenn points to rising housing costs, weak youth employment, a growing deficit and slowing construction as indicators of a slowdown in the economy. Atul reinforces this view with insider insights from within Washington, DC. Sources in the US Treasury worry not just about tariffs, but about affordability, cost-of-living pressures and weakening demand. Meanwhile, headline fiscal numbers are troubling. US debt is projected to exceed that of Italy and Greece for the first time this century, while the budget deficit remains near 6% in peacetime. Beyond near-term indicators, Atul and Glenn raise a deeper structural concern: demand in an AI-driven economy. Even if AI significantly boosts production and efficiency, it may also displace jobs faster than new ones emerge. Atul likens the situation to the late 1920s, when productivity surged, but demand failed to keep pace, ending in a market collapse. Signs of stress are already showing. University of Michigan consumer confidence fell to 50.3 in November, the second-worst reading ever recorded — worse than during the 2008 global financial crisis or the 2020 Covid-19 downturn. Household balance sheets are also deteriorating: roughly 4.5% of US household debt is now delinquent, while student-loan delinquencies have reached record levels. Youth unemployment has climbed above 8%, and job-search times are lengthening. Simultaneously, while the dollar remains the world’s main trading currency, it is declining as a store of value. Central banks and investors are diversifying away from the mighty greenback. Even allies like Canada are actively seeking to reduce reliance on the US market through shifting trade, tourism and even defense procurement decisions. Importantly, rising market volatility presents a major risk, with the Cboe Volatility Index crossing the 20 mark, signaling higher-than-normal expected market volatility and increased investor uncertainty or fear Investors and economists are increasingly talking of an impending crash. These predictions might be a bit too pessimistic, but dismissing them would be reckless. As Atul puts it, “just because there’s a lot of talk about it doesn’t mean that it is all talk.” Together, the indicators paint a consistent picture: an irrational exuberance in markets, an economy under increasing strains and a growing risk that economic realities upend ebullient markets. [Lee Thompson-Kolar edited this piece.] The views expressed in this article/video are the author’s own and do not necessarily reflect Fair Observer’s editorial policy. Please read our commenting guidelines before commenting. 1. Be Respectful: Please be polite to the author. Avoid hostility. The whole point of Fair Observer is openness to different perspectives from perspectives from around the world. 2. Comment Thoughtfully: Please be relevant and constructive. We do not allow personal attacks, disinformation or trolling. We will remove hate speech or incitement. 3. Contribute Usefully: Add something of value — a point of view, an argument, a personal experience or a relevant link if you are citing statistics and key facts. Please agree to the guidelines before proceeding. In this section of the November 2025 FO° Exclusive, Atul Singh and Glenn Carle examine the escalating tensions between China... In this section of the November 2025 FO° Exclusive, Atul Singh and Glenn Carle dissect US President Donald Trump’s 28-point... In this section of the November 2025 FO° Exclusive, Atul Singh and Glenn Carle track a month of turmoil as... We rely on your support for our independence, diversity and quality. Fair Observer is a 501(c)(3) independent nonprofit. We are not owned by billionaires or controlled by advertisers. We publish nearly 3,000 authors from over 90 countries after fact-checking and editing each piece. We do not have a paywall and anyone can read us for free. With your vital donations, we can continue to do our work. Please make a recurring (or even one-time) donation today. Even $1 goes a long way because a million donors like you mean one million dollars. Thank you for keeping us independent, free and fair. Enter your registered email address or username. You will receive a link to create a new password via email. Please enter your username or email address. You will receive an email message with instructions on how to reset your password. We have sent a link to your registered email address to reset your password. Unique Insights from 2,500+ Contributors in 90+ Countries Total Views:
--------------------------------------------------

Title: The Reverse-Centaur's Guide to Criticizing AI
URL: https://pluralistic.net/2025/12/05/pop-that-bubble/
Time Published: 2025-12-07T12:45:46Z
Full Content:
Pluralistic: Daily links from Cory Doctorow No trackers, no ads. Black type, white background. Privacy policy: we don't collect or retain any data at all ever period. Last night, I gave a speech for the University of Washington's "Neuroscience, AI and Society" lecture series, through the university's Computational Neuroscience Center. It was called "The Reverse Centaur’s Guide to Criticizing AI," and it's based on the manuscript for my next book, "The Reverse Centaur’s Guide to Life After AI," which will be out from Farrar, Straus and Giroux next June: https://www.eventbrite.com/e/future-tense-neuroscience-ai-and-society-with-cory-doctorow-tickets-1735371255139 The talk was sold out, but here's the text of my lecture. I'm very grateful to UW for the opportunity, and for a lovely visit to Seattle! == I'm a science fiction writer, which means that my job is to make up futuristic parables about our current techno-social arrangements to interrogate not just what a gadget does, but who it does it for, and who it does it to. What I don't do is predict the future. No one can predict the future, which is a good thing, since if the future were predictable, that would mean that what we all do couldn't change it. It would mean that the future was arriving on fixed rails and couldn't be steered. Jesus Christ, what a miserable proposition! Now, not everyone understands the distinction. They think sf writers are oracles, soothsayers. Unfortunately, even some of my colleagues labor under the delusion that they can "see the future." But for every sf writer who deludes themselves into thinking that they are writing the future, there are a hundred sf fans who believe that they are reading the future, and a depressing number of those people appear to have become AI bros. The fact that these guys can't shut up about the day that their spicy autocomplete machine will wake up and turn us all into paperclips has led many confused journalists and conference organizers to try to get me to comment on the future of AI. That's a thing I strenuously resisted doing, because I wasted two years of my life explaining patiently and repeatedly why I thought crypto was stupid, and getting relentless bollocked by cryptocurrency cultists who at first insisted that I just didn't understand crypto. And then, when I made it clear that I did understand crypto, insisted that I must be a paid shill. This is literally what happens when you argue with Scientologists, and life is Just. Too. Short. So I didn't want to get lured into another one of those quagmires, because on the one hand, I just don't think AI is that important of a technology, and on the other hand, I have very nuanced and complicated views about what's wrong, and not wrong, about AI, and it takes a long time to explain that stuff. But people wouldn't stop asking, so I did what I always do. I wrote a book. Over the summer I wrote a book about what I think about AI, which is really about what I think about AI criticism, and more specifically, how to be a good AI critic. By which I mean: "How to be a critic whose criticism inflicts maximum damage on the parts of AI that are doing the most harm." I titled the book The Reverse Centaur's Guide to Life After AI, and Farrar, Straus and Giroux will publish it in June, 2026. But you don't have to wait until then because I am going to break down the entire book's thesis for you tonight, over the next 40 minutes. I am going to talk fast. # Start with what a reverse centaur is. In automation theory, a "centaur" is a person who is assisted by a machine. You're a human head being carried around on a tireless robot body. Driving a car makes you a centaur, and so does using autocomplete. And obviously, a reverse centaur is machine head on a human body, a person who is serving as a squishy meat appendage for an uncaring machine. Like an Amazon delivery driver, who sits in a cabin surrounded by AI cameras, that monitor the driver's eyes and take points off if the driver looks in a proscribed direction, and monitors the driver's mouth because singing isn't allowed on the job, and rats the driver out to the boss if they don't make quota. The driver is in that van because the van can't drive itself and can't get a parcel from the curb to your porch. The driver is a peripheral for a van, and the van drives the driver, at superhuman speed, demanding superhuman endurance. But the driver is human, so the van doesn't just use the driver. The van uses the driver up. Obviously, it's nice to be a centaur, and it's horrible to be a reverse centaur. There are lots of AI tools that are potentially very centaur-like, but my thesis is that these tools are created and funded for the express purpose of creating reverse-centaurs, which is something none of us want to be. But like I said, the job of an sf writer is to do more than think about what the gadget does, and drill down on who the gadget does it for and who the gadget does it to. Tech bosses want us to believe that there is only one way a technology can be used. Mark Zuckerberg wants you to think that it's technologically impossible to have a conversation with a friend without him listening in. Tim Cook wants you to think that it's technologically impossible for you to have a reliable computing experience unless he gets a veto over which software you install and without him taking 30 cents out of every dollar you spend. Sundar Pichai wants you think that it's impossible for you to find a webpage unless he gets to spy on you from asshole to appetite. This is all a kind of vulgar Thatcherism. Margaret Thatcher's mantra was "There is no alternative." She repeated this so often they called her "TINA" Thatcher: There. Is. No. Alternative. TINA. "There is no alternative" is a cheap rhetorical slight. It's a demand dressed up as an observation. "There is no alternative" means "STOP TRYING TO THINK OF AN ALTERNATIVE." Which, you know, fuck that. I'm an sf writer, my job is to think of a dozen alternatives before breakfast. So let me explain what I think is going on here with this AI bubble, and sort out the bullshit from the material reality, and explain how I think we could and should all be better AI critics. # Start with monopolies: tech companies are gigantic and they don't compete, they just take over whole sectors, either on their own or in cartels. Google and Meta control the ad market. Google and Apple control the mobile market, and Google pays Apple more than $20 billion/year not to make a competing search engine, and of course, Google has a 90% Search market-share. Now, you'd think that this was good news for the tech companies, owning their whole sector. But it's actually a crisis. You see, when a company is growing, it is a "growth stock," and investors really like growth stocks. When you buy a share in a growth stock, you're making a bet that it will continue to grow. So growth stocks trade at a huge multiple of their earnings. This is called the "price to earnings ratio" or "P/E ratio." But once a company stops growing, it is a "mature" stock, and it trades at a much lower P/E ratio. So for every dollar that Target – a mature company – brings in, it is worth ten dollars. It has a P/E ratio of 10, while Amazon has a P/E ratio of 36, which means that for every dollar Amazon brings in, the market values it at $36. It's wonderful to run a company that's got a growth stock. Your shares are as good as money. If you want to buy another company, or hire a key worker, you can offer stock instead of cash. And stock is very easy for companies to get, because shares are manufactured right there on the premises, all you have to do is type some zeroes into a spreadsheet, while dollars are much harder to come by. A company can only get dollars from customers or creditors. So when Amazon bids against Target for a key acquisition, or a key hire, Amazon can bid with shares they make by typing zeroes into a spreadsheet, and Target can only bid with dollars they get from selling stuff to us, or taking out loans, which is why Amazon generally wins those bidding wars. That's the upside of having a growth stock. But here's the downside: eventually a company has to stop growing. Like, say you get a 90% market share in your sector, how are you gonna grow? Once the market decides that you aren't a growth stock, once you become mature, your stock is revalued, to a P/E ratio befitting a mature stock. If you are an exec at a dominant company with a growth stock, you have to live in constant fear that the market will decide that you're not likely to grow any further. Think of what happened to Facebook in the first quarter of 2022. They told investors that they experienced slightly slower growth in the USA than they had anticipated, and investors panicked. They staged a one-day, $240B sell off. A quarter-trillion dollars in 24 hours! At the time, it was the largest, most precipitous drop in corporate valuation in human history. That's a monopolist's worst nightmare, because once you're presiding over a "mature" firm, the key employees you've been compensating with stock, experience a precipitous pay-drop and bolt for the exits, so you lose the people who might help you grow again, and you can only hire their replacements with dollars. With dollars, not shares. And the same goes for acquiring companies that might help you grow, because they, too, are going to expect money, not stock. This is the paradox of the growth stock. While you are growing to domination, the market loves you, but once you achieve dominance, the market lops 75% or more off your value in a single stroke if they don't trust your pricing power. Which is why growth stock companies are always desperately pumping up one bubble or another, spending billions to hype the pivot to video, or cryptocurrency, or NFTs, or Metaverse, or AI. I'm not saying that tech bosses are making bets they don't plan on winning. But I am saying that winning the bet – creating a viable metaverse – is the secondary goal. The primary goal is to keep the market convinced that your company will continue to grow, and to remain convinced until the next bubble comes along. So this is why they're hyping AI: the material basis for the hundreds of billions in AI investment. # Now I want to talk about how they're selling AI. The growth narrative of AI is that AI will disrupt labor markets. I use "disrupt" here in its most disreputable, tech bro sense. The promise of AI – the promise AI companies make to investors – is that there will be AIs that can do your job, and when your boss fires you and replaces you with AI, he will keep half of your salary for himself, and give the other half to the AI company. That's it. That's the $13T growth story that MorganStanley is telling. It's why big investors and institutionals are giving AI companies hundreds of billions of dollars. And because they are piling in, normies are also getting sucked in, risking their retirement savings and their family's financial security. Now, if AI could do your job, this would still be a problem. We'd have to figure out what to do with all these technologically unemployed people. But AI can't do your job. It can help you do your job, but that doesn't mean it's going to save anyone money. Take radiology: there's some evidence that AIs can sometimes identify solid-mass tumors that some radiologists miss, and look, I've got cancer. Thankfully, it's very treatable, but I've got an interest in radiology being as reliable and accurate as possible. If my Kaiser hospital bought some AI radiology tools and told its radiologists: "Hey folks, here's the deal. Today, you're processing about 100 x-rays per day. From now on, we're going to get an instantaneous second opinion from the AI, and if the AI thinks you've missed a tumor, we want you to go back and have another look, even if that means you're only processing 98 x-rays per day. That's fine, we just care about finding all those tumors." If that's what they said, I'd be delighted. But no one is investing hundreds of billions in AI companies because they think AI will make radiology more expensive, not even if that also makes radiology more accurate. The market's bet on AI is that an AI salesman will visit the CEO of Kaiser and make this pitch: "Look, you fire 9/10s of your radiologists, saving $20m/year, you give us $10m/year, and you net $10m/year, and the remaining radiologists' job will be to oversee the diagnoses the AI makes at superhuman speed, and somehow remain vigilant as they do so, despite the fact that the AI is usually right, except when it's catastrophically wrong. "And if the AI misses a tumor, this will be the human radiologist's fault, because they are the 'human in the loop.' It's their signature on the diagnosis." This is a reverse centaur, and it's a specific kind of reverse-centaur: it's what Dan Davies calls an "accountability sink." The radiologist's job isn't really to oversee the AI's work, it's to take the blame for the AI's mistakes. This is another key to understanding – and thus deflating – the AI bubble. The AI can't do your job, but an AI salesman can convince your boss to fire you and replace you with an AI that can't do your job. This is key because it helps us build the kinds of coalitions that will be successful in the fight against the AI bubble. If you're someone who's worried about cancer, and you're being told that the price of making radiology too cheap to meter, is that we're going to have to re-home America's 32,000 radiologists, with the trade-off that no one will ever be denied radiology services again, you might say, "Well, OK, I'm sorry for those radiologists, and I fully support getting them job training or UBI or whatever. But the point of radiology is to fight cancer, not to pay radiologists, so I know what side I'm on." AI hucksters and their customers in the C-suites want the public on their side. They want to forge a class alliance between AI deployers and the people who enjoy the fruits of the reverse centaurs' labor. They want us to think of ourselves as enemies to the workers. Now, some people will be on the workers' side because of politics or aesthetics. They just like workers better than their bosses. But if you want to win over all the people who benefit from your labor, you need to understand and stress how the products of the AI will be substandard. That they are going to get charged more for worse things. That they have a shared material interest with you. Will those products be substandard? There's every reason to think so. Earlier, I alluded to "automation blindness, "the physical impossibility of remaining vigilant for things that rarely occur. This is why TSA agents are incredibly good at spotting water bottles. Because they get a ton of practice at this, all day, every day. And why they fail to spot the guns and bombs that government red teams smuggle through checkpoints to see how well they work, because they just don't have any practice at that. Because, to a first approximation, no one deliberately brings a gun or a bomb through a TSA checkpoint. Automation blindness is the Achilles' heel of "humans in the loop." Think of AI software generation: there are plenty of coders who love using AI, and almost without exception, they are senior, experienced coders, who get to decide how they will use these tools. For example, you might ask the AI to generate a set of CSS files to faithfully render a web-page across multiple versions of multiple browsers. This is a notoriously fiddly thing to do, and it's pretty easy to verify if the code works – just eyeball it in a bunch of browsers. Or maybe the coder has a single data file they need to import and they don't want to write a whole utility to convert it. Tasks like these can genuinely make coders more efficient and give them more time to do the fun part of coding, namely, solving really gnarly, abstract puzzles. But when you listen to business leaders talk about their AI plans for coders, it's clear they're not looking to make some centaurs. They want to fire a lot of tech workers – 500,000 over the past three years – and make the rest pick up their work with coding, which is only possible if you let the AI do all the gnarly, creative problem solving, and then you do the most boring, soul-crushing part of the job: reviewing the AIs' code. And because AI is just a word guessing program, because all it does is calculate the most probable word to go next, the errors it makes are especially subtle and hard to spot, because these bugs are literally statistically indistinguishable from working code (except that they're bugs). Here's an example: code libraries are standard utilities that programmers can incorporate into their apps, so they don't have to do a bunch of repetitive programming. Like, if you want to process some text, you'll use a standard library. If it's an HTML file, that library might be called something like lib.html.text.parsing; and if it's a DOCX file, it'll be lib.docx.text.parsing. But reality is messy, humans are inattentive and stuff goes wrong, so sometimes, there's another library, this one for parsing PDFs, and instead of being called lib.pdf.text.parsing, it's called lib.text.pdf.parsing. Now, because the AI is a statistical inference engine, because all it can do is predict what word will come next based on all the words that have been typed in the past, it will "hallucinate" a library called lib.pdf.text.parsing. And the thing is, malicious hackers know that the AI will make this error, so they will go out and create a library with the predictable, hallucinated name, and that library will get automatically sucked into your program, and it will do things like steal user data or try and penetrate other computers on the same network. And you, the human in the loop – the reverse centaur – you have to spot this subtle, hard to find error, this bug that is literally statistically indistinguishable from correct code. Now, maybe a senior coder could catch this, because they've been around the block a few times, and they know about this tripwire. But guess who tech bosses want to preferentially fire and replace with AI? Senior coders. Those mouthy, entitled, extremely highly paid workers, who don't think of themselves as workers. Who see themselves as founders in waiting, peers of the company's top management. The kind of coder who'd lead a walkout over the company building drone-targeting systems for the Pentagon, which cost Google ten billion dollars in 2018. For AI to be valuable, it has to replace high-wage workers, and those are precisely the experienced workers, with process knowledge, and hard-won intuition, who might spot some of those statistically camouflaged AI errors. Like I said, the point here is to replace high-waged workers. And one of the reasons the AI companies are so anxious to fire coders is that coders are the princes of labor. They're the most consistently privileged, sought-after, and well-compensated workers in the labor force. If you can replace coders with AI, who cant you replace with AI? Firing coders is an ad for AI. Which brings me to AI art. AI art – or "art" – is also an ad for AI, but it's not part of AI's business model. Let me explain: on average, illustrators don't make any money. They are already one of the most immiserated, precartized groups of workers out there. They suffer from a pathology called "vocational awe." That's a term coined by the librarian Fobazi Ettarh, and it refers to workers who are vulnerable to workplace exploitation because they actually care about their jobs – nurses, librarians, teachers, and artists. If AI image generators put every illustrator working today out of a job, the resulting wage-bill savings would be undetectable as a proportion of all the costs associated with training and operating image-generators. The total wage bill for commercial illustrators is less than the kombucha bill for the company cafeteria at just one of Open AI's campuses. The purpose of AI art – and the story of AI art as a death-knell for artists – is to convince the broad public that AI is amazing and will do amazing things. It's to create buzz. Which is not to say that it's not disgusting that former OpenAI CTO Mira Murati told a conference audience that "some creative jobs shouldn't have been there in the first place," and that it's not especially disgusting that she and her colleagues boast about using the work of artists to ruin those artists' livelihoods. It's supposed to be disgusting. It's supposed to get artists to run around and say, "The AI can do my job, and it's going to steal my job, and isn't that terrible?" Because the customers for AI – corporate bosses – don't see AI taking workers' jobs as terrible. They see it as wonderful. But can AI do an illustrator's job? Or any artist's job? Let's think about that for a second. I've been a working artist since I was 17 years old, when I sold my first short story, and I've given it a lot of thought, and here's what I think art is: it starts with an artist, who has some vast, complex, numinous, irreducible feeling in their mind. And the artist infuses that feeling into some artistic medium. They make a song, or a poem, or a painting, or a drawing, or a dance, or a book, or a photograph. And the idea is, when you experience this work, a facsimile of the big, numinous, irreducible feeling will materialize in your mind. Now that I've defined art, we have to go on a little detour. I have a friend who's a law professor, and before the rise of chatbots, law students knew better than to ask for reference letters from their profs, unless they were a really good student. Because those letters were a pain in the ass to write. So if you advertised for a postdoc and you heard from a candidate with a reference letter from a respected prof, the mere existence of that letter told you that the prof really thought highly of that student. But then we got chatbots, and everyone knows that you generate a reference letter by feeding three bullet points to an LLM, and it'll barf up five paragraphs of florid nonsense about the student. So when my friend advertises for a postdoc, they are flooded with reference letters, and they deal with this flood by feeding all these letters to another chatbot, and ask it to reduce them back to three bullet points. Now, obviously, they won't be the same bullet-points, which makes this whole thing terrible. But just as obviously, nothing in that five-paragraph letter except the original three bullet points are relevant to the student. The chatbot doesn't know the student. It doesn't know anything about them. It cannot add a single true or useful statement about the student to the letter. What does this have to do with AI art? Art is a transfer of a big, numinous, irreducible feeling from an artist to someone else. But the image-gen program doesn't know anything about your big, numinous, irreducible feeling. The only thing it knows is whatever you put into your prompt, and those few sentences are diluted across a million pixels or a hundred thousand words, so that the average communicative density of the resulting work is indistinguishable from zero. It's possible to infuse more communicative intent into a work: writing more detailed prompts, or doing the selective work of choosing from among many variants, or directly tinkering with the AI image after the fact, with a paintbrush or Photoshop or The Gimp. And if there will ever be a piece of AI art that is good art – as opposed to merely striking, or interesting, or an example of good draftsmanship – it will be thanks to those additional infusions of creative intent by a human. And in the meantime, it's bad art. It's bad art in the sense of being "eerie," the word Mark Fisher uses to describe "when there is something present where there should be nothing, or there is nothing present when there should be something." AI art is eerie because it seems like there is an intender and an intention behind every word and every pixel, because we have a lifetime of experience that tells us that paintings have painters, and writing has writers. But it's missing something. It has nothing to say, or whatever it has to say is so diluted that it's undetectable. The images were striking before we figured out the trick, but now they're just like the images we imagine in clouds or piles of leaves. We're the ones drawing a frame around part of the scene, we're the ones focusing on some contours and ignoring the others. We're looking at an inkblot, and it's not telling us anything. Sometimes that can be visually arresting, and to the extent that it amuses people in a community of prompters and viewers, that's harmless. I know someone who plays a weekly Dungeons and Dragons game over Zoom. It's transcribed by an open source model running locally on the dungeon master's computer, which summarizes the night's session and prompts an image generator to create illustrations of key moments. These summaries and images are hilarious because they're full of errors. It's a bit of harmless fun, and it bring a small amount of additional pleasure to a small group of people. No one is going to fire an illustrator because D&D players are image-genning funny illustrations where seven-fingered paladins wrestle with orcs that have an extra hand. But bosses have and will fire illustrators, because they fantasize about being able to dispense with creative professionals and just prompt an AI. Because even though the AI can't do the illustrator's job, an AI salesman can convince the illustrator's boss to fire them and replace them with an AI that can't do their job. This is a disgusting and terrible juncture, and we should not simply shrug our shoulders and accept Thatcherism's fatalism: "There is no alternative." So what is the alternative? A lot of artists and their allies think they have an answer: they say we should extend copyright to cover the activities associated with training a model. And I'm here to tell you they are wrong: wrong because this would inflict terrible collateral damage on socially beneficial activities, and it would represent a massive expansion of copyright over activities that are currently permitted – for good reason!. Let's break down the steps in AI training. First, you scrape a bunch of web-pages. This is unambiguously legal under present copyright law. You do not need a license to make a transient copy of a copyrighted work in order to analyze it, otherwise search engines would be illegal. Ban scraping and Google will be the last search engine we ever get, the Internet Archive will go out of business, that guy in Austria who scraped all the grocery store sites and proved that the big chains were colluding to rig prices would be in deep trouble. Next, you perform analysis on those works. Basically, you count stuff on them: count pixels and their colors and proximity to other pixels; or count words. This is obviously not something you need a license for. It's just not illegal to count the elements of a copyrighted work. And we really don't want it to be, not if you're interested in scholarship of any kind. And it's important to note that counting things is legal, even if you're working from an illegally obtained copy. Like, if you go to the flea market, and you buy a bootleg music CD, and you take it home and you make a list of all the adverbs in the lyrics, and you publish that list, you are not infringing copyright by doing so. Perhaps you've infringed copyright by getting the pirated CD, but not by counting the lyrics. This is why Anthropic offered a $1.5b settlement for training its models based on a ton of books it downloaded from a pirate site: not because counting the words in the books infringes anyone's rights, but because they were worried that they were going to get hit with $150k/book statutory damages for downloading the files. OK, after you count all the pixels or the words, it's time for the final step: publishing them. Because that's what a model is: a literary work (that is, a piece of software) that embodies a bunch of facts about a bunch of other works, word and pixel distribution information, encoded in a multidimensional array. And again, copyright absolutely does not prohibit you from publishing facts about copyrighted works. And again, no one should want to live in a world where someone else gets to decide which truthful, factual statements you can publish. But hey, maybe you think this is all sophistry. Maybe you think I'm full of shit. That's fine. It wouldn't be the first time someone thought that. After all, even if I'm right about how copyright works now, there's no reason we couldn't change copyright to ban training activities, and maybe there's even a clever way to wordsmith the law so that it only catches bad things we don't like, and not all the good stuff that comes from scraping, analyzing and publishing. Well, even then, you're not gonna help out creators by creating this new copyright. If you're thinking that you can, you need to grapple with this fact: we have monotonically expanded copyright since 1976, so that today, copyright covers more kinds of works, grants exclusive rights over more uses, and lasts longer. And today, the media industry is larger and more profitable than it has ever been, and also: the share of media industry income that goes to creative workers is lower than its ever been, both in real terms, and as a proportion of those incredible gains made by creators' bosses at the media company. So how it is that we have given all these new rights to creators, and those new rights have generated untold billions, and left creators poorer? It's because in a creative market dominated by five publishers, four studios, three labels, two mobile app stores, and a single company that controls all the ebooks and audiobooks, giving a creative worker extra rights to bargain with is like giving your bullied kid more lunch money. It doesn't matter how much lunch money you give the kid, the bullies will take it all. Give that kid enough money and the bullies will hire an agency to run a global campaign proclaiming "think of the hungry kids! Give them more lunch money!" Creative workers who cheer on lawsuits by the big studios and labels need to remember the first rule of class warfare: things that are good for your boss are rarely what's good for you. The day Disney and Universal filed suit against Midjourney, I got a press release from the RIAA, which represents Disney and Universal through their recording arms. Universal is the largest label in the world. Together with Sony and Warner, they control 70% of all music recordings in copyright today. It starts: "There is a clear path forward through partnerships that both further AI innovation and foster human artistry." It ends: "This action by Disney and Universal represents a critical stand for human creativity and responsible innovation." And it's signed by Mitch Glazier, CEO of the RIAA. It's very likely that name doesn't mean anything to you. But let me tell you who Mitch Glazier is. Today, Mitch Glazier is the CEO if the RIAA, with an annual salary of $1.3m. But until 1999, Mitch Glazier was a key Congressional staffer, and in 1999, Glazier snuck an amendment into an unrelated bill, the Satellite Home Viewer Improvement Act, that killed musicians' right to take their recordings back from their labels. This is a practice that had been especially important to "heritage acts" (which is a record industry euphemism for "old music recorded by Black people"), for whom this right represented the difference between making rent and ending up on the street. When it became clear that Glazier had pulled this musician-impoverishing scam, there was so much public outcry, that Congress actually came back for a special session, just to vote again to cancel Glazier's amendment. And then Glazier was kicked out of his cushy Congressional job, whereupon the RIAA started paying more than $1m/year to "represent the music industry." This is the guy who signed that press release in my inbox. And his message was: The problem isn't that Midjourney wants to train a Gen AI model on copyrighted works, and then use that model to put artists on the breadline. The problem is that Midjourney didn't pay RIAA members Universal and Disney for permission to train a model. Because if only Midjourney had given Disney and Universal several million dollars for training rights to their catalogs, the companies would have happily allowed them to train to their heart's content, and they would have bought the resulting models, and fired as many creative professionals as they could. I mean, have we already forgotten the Hollywood strikes? I sure haven't. I live in Burbank, home to Disney, Universal and Warner, and I was out on the line with my comrades from the Writers Guild, offering solidarity on behalf of my union, IATSE 830, The Animation Guild, where I'm a member of the writers' unit. And I'll never forget when one writer turned to me and said, "You know, you prompt an LLM exactly the same way an exec gives shitty notes to a writers' room. You know: 'Make me ET, except it's about a dog, and put a love interest in there, and a car chase in the second act.' The difference is, you say that to a writers' room and they all make fun of you and call you a fucking idiot suit. But you say it to an LLM and it will cheerfully shit out a terrible script that conforms exactly to that spec (you know, Air Bud)." These companies are desperate to use AI to displace workers. When Getty Images sues AI companies, it's not representing the interests of photographers. Getty hates paying photographers! Getty just wants to get paid for the training run, and they want the resulting AI model to have guardrails, so it will refuse to create images that compete with Getty's images for anyone except Getty. But Getty will absolutely use its models to bankrupt as many photographers as it possibly can. A new copyright to train models won't get us a world where models aren't used to destroy artists, it'll just get us a world where the standard contracts of the handful of companies that control all creative labor markets are updated to require us to hand over those new training rights to those companies. Demanding a new copyright just makes you a useful idiot for your boss, a human shield they can brandish in policy fights, a tissue-thin pretense of "won't someone think of the hungry artists?" When really what they're demanding is a world where 30% of the investment capital of the AI companies go into their shareholders' pockets. When an artist is being devoured by rapacious monopolies, does it matter how they divvy up the meal? We need to protect artists from AI predation, not just create a new way for artists to be mad about their impoverishment. And incredibly enough, there's a really simple way to do that. After 20+ years of being consistently wrong and terrible for artists' rights, the US Copyright Office has finally done something gloriously, wonderfully right. All through this AI bubble, the Copyright Office has maintained – correctly – that AI-generated works cannot be copyrighted, because copyright is exclusively for humans. That's why the "monkey selfie" is in the public domain. Copyright is only awarded to works of human creative expression that are fixed in a tangible medium. And not only has the Copyright Office taken this position, they've defended it vigorously in court, repeatedly winning judgments to uphold this principle. The fact that every AI created work is in the public domain means that if Getty or Disney or Universal or Hearst newspapers use AI to generate works – then anyone else can take those works, copy them, sell them, or give them away for free. And the only thing those companies hate more than paying creative workers, is having other people take their stuff without permission. The US Copyright Office's position means that the only way these companies can get a copyright is to pay humans to do creative work. This is a recipe for centaurhood. If you're a visual artist or writer who uses prompts to come up with ideas or variations, that's no problem, because the ultimate work comes from you. And if you're a video editor who uses deepfakes to change the eyelines of 200 extras in a crowd-scene, then sure, those eyeballs are in the public domain, but the movie stays copyrighted. But creative workers don't have to rely on the US government to rescue us from AI predators. We can do it ourselves, the way the writers did in their historic writers' strike. The writers brought the studios to their knees. They did it because they are organized and solidaristic, but also are allowed to do something that virtually no other workers are allowed to do: they can engage in "sectoral bargaining," whereby all the workers in a sector can negotiate a contract with every employer in the sector. That's been illegal for most workers since the late 1940s, when the Taft-Hartley Act outlawed it. If we are gonna campaign to get a new law passed in hopes of making more money and having more control over our labor, we should campaign to restore sectoral bargaining, not to expand copyright. Our allies in a campaign to expand copyright are our bosses, who have never had our best interests at heart. While our allies in the fight for sector bargaining are every worker in the country. As the song goes, "Which side are you on?" OK, I need to bring this talk in for a landing now, because I'm out of time, so I'm going to close out with this: AI is a bubble and bubbles are terrible. Bubbles transfer the life's savings of normal people who are just trying to have a dignified retirement to the wealthiest and most unethical people in our society, and every bubble eventually bursts, taking their savings with it. But not every bubble is created equal. Some bubbles leave behind something productive. Worldcom stole billions from everyday people by defrauding them about orders for fiber optic cables. The CEO went to prison and died there. But the fiber outlived him. It's still in the ground. At my home, I've got 2gb symmetrical fiber, because AT&T lit up some of that old Worldcom dark fiber. All things being equal, it would have been better if Worldcom hadn't ever existed, but the only thing worse than Worldcom committing all that ghastly fraud would be if there was nothing to salvage from the wreckage. I don't think we'll salvage much from cryptocurrency, for example. Sure, there'll be a few coders who've learned something about secure programming in Rust. But when crypto dies, what it will leave behind is bad Austrian economics and worse monkey JPEGs. AI is a bubble and it will burst. Most of the companies will fail. Most of the data-centers will be shuttered or sold for parts. So what will be left behind? We'll have a bunch of coders who are really good at applied statistics. We'll have a lot of cheap GPUs, which'll be good news for, say, effects artists and climate scientists, who'll be able to buy that critical hardware at pennies on the dollar. And we'll have the open source models that run on commodity hardware, AI tools that can do a lot of useful stuff, like transcribing audio and video, describing images, summarizing documents, automating a lot of labor-intensive graphic editing, like removing backgrounds, or airbrushing passersby out of photos. These will run on our laptops and phones, and open source hackers will find ways to push them to do things their makers never dreamt of. If there had never been an AI bubble, if all this stuff arose merely because computer scientists and product managers noodled around for a few years coming up with cool new apps for back-propagation, machine learning and generative adversarial networks, most people would have been pleasantly surprised with these interesting new things their computers could do. We'd call them "plugins." It's the bubble that sucks, not these applications. The bubble doesn't want cheap useful things. It wants expensive, "disruptive" things: Big foundation models that lose billions of dollars every year. When the AI investment mania halts, most of those models are going to disappear, because it just won't be economical to keep the data-centers running. As Stein's Law has it: "Anything that can't go on forever eventually stops." The collapse of the AI bubble is going to be ugly. Seven AI companies currently account for more than a third of the stock market, and they endlessly pass around the same $100b IOU. Bosses are mass-firing productive workers and replacing them with janky AI, and when the janky AI is gone, no one will be able to find and re-hire most of those workers, we're going to go from disfunctional AI systems to nothing. AI is the asbestos in the walls of our technological society, stuffed there with wild abandon by a finance sector and tech monopolists run amok. We will be excavating it for a generation or more. So we need to get rid of this bubble. Pop it, as quickly as we can. To do that, we have to focus on the material factors driving the bubble. The bubble isn't being driven by deepfake porn, or election disinformation, or AI image-gen, or slop advertising. All that stuff is terrible and harmful, but it's not driving investment. The total dollar figure represented by these apps doesn't come close to making a dent in the capital expenditures and operating costs of AI. They are peripheral, residual uses: flashy, but unimportant to the bubble. Get rid of all those uses and you reduce the expected income of AI companies by a sum so small it rounds to zero. Same goes for all that "AI Safety" nonsense, that purports to concern itself with preventing an AI from attaining sentience and turning us all into paperclips. First of all, this is facially absurd. Throwing more words and GPUs into the word-guessing program won't make it sentient. That's like saying, "Well, we keep breeding these horses to run faster and faster, so it's only a matter of time until one of our mares gives birth to a locomotive." A human mind is not a word-guessing program with a lot of extra words. I'm here for science fiction thought experiments, don't get me wrong. But also, don't mistake sf for prophesy. SF stories about superintelligence are futuristic parables, not business plans, roadmaps, or predictions. The AI Safety people say they are worried that AI is going to end the world, but AI bosses love these weirdos. Because on the one hand, if AI is powerful enough to destroy the world, think of how much money it can make! And on the other hand, no AI business plan has a line on its revenue projections spreadsheet labeled "Income from turning the human race into paperclips." So even if we ban AI companies from doing this, we won't cost them a dime in investment capital. To pop the bubble, we have to hammer on the forces that created the bubble: the myth that AI can do your job, especially if you get high wages that your boss can claw back; the understanding that growth companies need a succession of ever-more-outlandish bubbles to stay alive; the fact that workers and the public they serve are on one side of this fight, and bosses and their investors are on the other side. Because the AI bubble really is very bad news, it's worth fighting seriously, and a serious fight against AI strikes at its roots: the material factors fueling the hundreds of billions in wasted capital that are being spent to put us all on the breadline and fill all our walls with high-tech asbestos. (Image: Cryteria, CC BY 3.0, modified) An Analysis of the Proposed Spirit Financial-Credit Union 1 Merger. The Consequences for the Credit Union System https://chipfilson.com/2025/12/an-analysis-of-the-proposed-spirit-financal-credit-union-1-merger/ Zillow deletes climate risk data from listings after complaints it harms sales https://www.theguardian.com/environment/2025/dec/01/zillow-removes-climate-risk-data-home-listings After Years of Controversy, the EU’s Chat Control Nears Its Final Hurdle: What to Know https://www.eff.org/deeplinks/2025/12/after-years-controversy-eus-chat-control-nears-its-final-hurdle-what-know How the dollar-store industry overcharges cash-strapped customers while promising low prices https://www.theguardian.com/us-news/2025/dec/03/customers-pay-more-rising-dollar-store-costs #20yrsago Haunted Mansion papercraft model adds crypts and gates https://www.haunteddimensions.raykeim.com/index313.html #20yrsago Print your own Monopoly money https://web.archive.org/web/20051202030047/http://www.hasbro.com/monopoly/pl/page.treasurechest/dn/default.cfm #15yrsago Bunnie explains the technical intricacies and legalities of Xbox hacking https://www.bunniestudios.com/blog/2010/usa-v-crippen-a-retrospective/ #15yrsago How Pac Man’s ghosts decide what to do: elegant complexity https://web.archive.org/web/20101205044323/https://gameinternals.com/post/2072558330/understanding-pac-man-ghost-behavior #15yrsago Glorious, elaborate, profane insults of the world https://www.reddit.com/r/AskReddit/comments/efee7/what_are_your_favorite_culturally_untranslateable/?sort=confidence #15yrsago Walt Disney World castmembers speak about their search for a living wage https://www.youtube.com/watch?v=f5BMQ3xQc7o #15yrsago Wikileaks cables reveal that the US wrote Spain’s proposed copyright law https://web.archive.org/web/20140723230745/https://elpais.com/elpais/2010/12/03/actualidad/1291367868_850215.html #15yrsago Cities made of broken technology https://web.archive.org/web/20101203132915/https://agora-gallery.com/artistpage/Franco_Recchia.aspx #10yrsago The TPP’s ban on source-code disclosure requirements: bad news for information security https://www.eff.org/deeplinks/2015/12/tpp-threatens-security-and-safety-locking-down-us-policy-source-code-audit #10yrsago Fossil fuel divestment sit-in at MIT President’s office hits 10,000,000,000-hour mark https://twitter.com/FossilFreeMIT/status/672526210581274624 #10yrsago Hacker dumps United Arab Emirates Invest Bank’s customer data https://www.dailydot.com/news/invest-bank-hacker-buba/ #10yrsago Illinois prisons spy on prisoners, sue them for rent on their cells if they have any money https://www.chicagotribune.com/2015/11/30/state-sues-prisoners-to-pay-for-their-room-board/ #10yrsago Free usability help for privacy toolmakers https://superbloom.design/learning/blog/apply-for-help/ #10yrsago In the first 334 days of 2015, America has seen 351 mass shootings (and counting) https://web.archive.org/web/20151209004329/https://www.washingtonpost.com/news/wonk/wp/2015/11/30/there-have-been-334-days-and-351-mass-shootings-so-far-this-year/ #10yrsago Not even the scapegoats will go to jail for BP’s murder of the Gulf Coast https://arstechnica.com/tech-policy/2015/12/manslaughter-charges-dropped-in-bp-spill-case-nobody-from-bp-will-go-to-prison/ #10yrsago Urban Transport Without the Hot Air: confusing the issue with relevant facts! https://memex.craphound.com/2015/12/03/urban-transport-without-the-hot-air-confusing-the-issue-with-relevant-facts/ #5yrsago Breathtaking Iphone hack https://pluralistic.net/2020/12/03/ministry-for-the-future/#awdl #5yrsago Graffitists hit dozens of NYC subway cars https://pluralistic.net/2020/12/03/ministry-for-the-future/#getting-up #5yrsago The Ministry For the Future https://pluralistic.net/2020/12/03/ministry-for-the-future/#ksr #5yrsago Monopolies made America vulnerable to covid https://pluralistic.net/2020/12/03/ministry-for-the-future/#big-health #5yrsago Section 230 is Good, Actually https://pluralistic.net/2020/12/04/kawaski-trawick/#230 #5yrsago Postmortem of the NYPD's murder of a Black man https://pluralistic.net/2020/12/04/kawaski-trawick/#Kawaski-Trawick #5yrsago Student debt trap https://pluralistic.net/2020/12/04/kawaski-trawick/#strike-debt #1yrago "That Makes Me Smart" https://pluralistic.net/2024/12/04/its-not-a-lie/#its-a-premature-truth #1yrago Canada sues Google https://pluralistic.net/2024/12/03/clementsy/#can-tech Madison, CT: Enshittification at RJ Julia, Dec 8 https://rjjulia.com/event/2025-12-08/cory-doctorow-enshittification Hamburg: Chaos Communications Congress, Dec 27-30 https://events.ccc.de/congress/2025/infos/index.html Denver: Enshittification at Tattered Cover Colfax, Jan 22 https://www.eventbrite.com/e/cory-doctorow-live-at-tattered-cover-colfax-tickets-1976644174937 We have become slaves to Silicon Valley (Politics JOE) https://www.youtube.com/watch?v=JzEUvh1r5-w How Enshittification is Destroying The Internet (Frontline Club) https://www.youtube.com/watch?v=oovsyzB9L-s Escape Forward with Cristina Caffarra https://escape-forward.com/2025/11/27/enshittification-of-our-digital-experience/ Why Every Platform Betrays You (Trust Revolution) https://fountain.fm/episode/bJgdt0hJAnppEve6Qmt8 "Enshittification: Why Everything Suddenly Got Worse and What to Do About It," Farrar, Straus, Giroux, October 7 2025 https://us.macmillan.com/books/9780374619329/enshittification/ "Picks and Shovels": a sequel to "Red Team Blues," about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (https://us.macmillan.com/books/9781250865908/picksandshovels). "The Bezzle": a sequel to "Red Team Blues," about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (the-bezzle.org). "The Lost Cause:" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (http://lost-cause.org). "The Internet Con": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245). "Red Team Blues": "A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before." Tor Books http://redteamblues.com. "Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com "Enshittification, Why Everything Suddenly Got Worse and What to Do About It" (the graphic novel), Firstsecond, 2026 "The Memex Method," Farrar, Straus, Giroux, 2026 "The Reverse-Centaur's Guide to AI," a short book about being a better AI critic, Farrar, Straus and Giroux, June 2026 Today's top sources: Currently writing: "The Post-American Internet," a short book about internet policy in the age of Trumpism. PLANNING. A Little Brother short story about DIY insulin PLANNING This work – excluding any serialized fiction – is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net. https://creativecommons.org/licenses/by/4.0/ Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution. Blog (no ads, tracking, or data-collection): Pluralistic.net Newsletter (no ads, tracking, or data-collection): https://pluralistic.net/plura-list Mastodon (no ads, tracking, or data-collection): https://mamot.fr/@pluralistic Medium (no ads, paywalled): https://doctorow.medium.com/ Twitter (mass-scale, unrestricted, third-party surveillance and advertising): https://twitter.com/doctorow Tumblr (mass-scale, unrestricted, third-party surveillance and advertising): https://mostlysignssomeportents.tumblr.com/tagged/pluralistic "When life gives you SARS, you make sarsaparilla" -Joey "Accordion Guy" DeVilla READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies ("BOGUS AGREEMENTS") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer. ISSN: 3066-764X ISSN: 3066-764X
--------------------------------------------------