List of news related to Meta stock price META:

Title: Celestica Inc. (CLS): Leveraging AI Demand with Specialized Chips
URL: https://finance.yahoo.com/news/celestica-inc-cls-leveraging-ai-021719254.html
Time Published: 2025-02-01T02:17:19Z
Full Content:
We are experiencing some temporary issues. The market data on this page is currently delayed. Please bear with us as we address this and restore your personalized lists. We recently published a list of 12 Must-See AI News and Ratings You Might Have Missed. In this article, we are going to take a look at where Celestica Inc. (NYSE:CLS) stands against other must-see AI news and ratings you might have missed. Northland Securities recently issued a rating for a stock amidst the DeepSeek AI frenzy. The firm noted that it isn’t concerned about the AI models just yet and that it doesn’t expect big tech giants to cut their capital expenditures when they report their earnings either. In light of this, the CEOs of tech giants such as Meta and Microsoft have recently defended their massive spending, noting how it was crucial to stay competitive in the new field. Investors panicked after news spread over the weekend about a Chinese startup DeepSeek having released AI models that were built using less power and chips. In response, executives of tech giants are saying that building huge computer networks has been crucial to serving growing corporate needs. Even then, investors have been losing their patience with the huge amounts of spending and a dearth of hefty payouts. READ NOW: These 29 AI Electricity and Infrastructure Stocks Are Crashing Due to DeepSeek News and 10 AI Stocks to Watch Amid the DeepSeek Buzz DeepSeek has been causing a stir in the AI world and refuted the gap that previously existed between the AI capabilities in China and the US. After the first Chinese version of ChatGPT was released, there was a lot of disappointment in China considering it was not on par with ChatGPT. However, DeepSeek’s AI models have shifted the AI narrative completely. Not only has it sparked a frenzy in the US, but even its domestic competition has been pressurized. This was made evident when Alibaba released a rival to DeepSeek’s model on the Lunar New Year. According to the company, the “Qwen 2.5-Max outperforms … almost across the board GPT-4o, DeepSeek-V3 and Llama-3.1-405B”. Even though DeepSeek’s AI models have been impressive, there is still skepticism and confusion regarding the demand for high-end AI chips and the need for power to run AI-centric data centers. “There’s plenty of uncertainty over what the true demand for state-of-the-art chips, semiconductor fabrication plants and energy will be”. For this article, we selected AI stocks by going through news articles, stock analysis, and press releases. These stocks are also popular among hedge funds. Why are we interested in the stocks that hedge funds pile into? The reason is simple: our research has shown that we can outperform the market by imitating the top stock picks of the best hedge funds. Our quarterly newsletter’s strategy selects 14 small-cap and large-cap stocks every quarter and has returned 275% since May 2014, beating its benchmark by 150 percentage points (see more details here). A close-up of a circuit board with components depicting the intricate electronic componentry products the company produces. Number of Hedge Fund Holders: 40 Celestica Inc. (NYSE:CLS) offers a range of product manufacturing and related supply chain services. On January 30, Barclays raised the firm’s price target on the stock to $139 from $91 and kept an “Overweight” rating. The rating has been issued following quarterly results. According to the firm, investors are valuing Celestica based on 2026 projected earnings, driven by the demand for specialized chips called ASICs which remain a medium-term trend. In particular, 2026 captures the run rate revenue of the TPUv6, Google’s latest generation AI accelerator. The firm further noted that Meta Platforms aims to launch a new ASIC program that could compete with the TPU program in terms of expertise and capability. Overall, CLS ranks 6th on our list of must-see AI news and ratings you might have missed. While we acknowledge the potential of CLS as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and doing so within a shorter timeframe. If you are looking for an AI stock that is more promising than CLS but that trades at less than 5 times its earnings, check out our report about the cheapest AI stock. READ NEXT: 20 Best AI Stocks To Buy Now and Complete List of 59 AI Companies Under $2 Billion in Market Cap Disclosure: None. This article is originally published at Insider Monkey. Sign in to access your portfolio
--------------------------------------------------

Title: DeepSeek's threat to Nvidia's earnings may not be so serious, Jim Cramer says
URL: https://www.cnbc.com/2025/01/31/deepseeks-threat-to-nvidia-may-not-be-so-serious-jim-cramer-says.html
Time Published: 2025-02-01T00:36:21Z
Full Content:
Credit Cards Loans Banking Mortgages Insurance Credit Monitoring Personal Finance Small Business Taxes Help for Low Credit Scores Investing SELECT All Credit Cards Find the Credit Card for You Best Credit Cards Best Rewards Credit Cards Best Travel Credit Cards Best 0% APR Credit Cards Best Balance Transfer Credit Cards Best Cash Back Credit Cards Best Credit Card Welcome Bonuses Best Credit Cards to Build Credit SELECT All Loans Find the Best Personal Loan for You Best Personal Loans Best Debt Consolidation Loans Best Loans to Refinance Credit Card Debt Best Loans with Fast Funding Best Small Personal Loans Best Large Personal Loans Best Personal Loans to Apply Online Best Student Loan Refinance SELECT All Banking Find the Savings Account for You Best High Yield Savings Accounts Best Big Bank Savings Accounts Best Big Bank Checking Accounts Best No Fee Checking Accounts No Overdraft Fee Checking Accounts Best Checking Account Bonuses Best Money Market Accounts Best CDs Best Credit Unions SELECT All Mortgages Best Mortgages Best Mortgages for Small Down Payment Best Mortgages for No Down Payment Best Mortgages with No Origination Fee Best Mortgages for Average Credit Score Adjustable Rate Mortgages Affording a Mortgage SELECT All Insurance Best Life Insurance Best Homeowners Insurance Best Renters Insurance Best Car Insurance Travel Insurance SELECT All Credit Monitoring Best Credit Monitoring Services Best Identity Theft Protection How to Boost Your Credit Score Credit Repair Services SELECT All Personal Finance Best Budgeting Apps Best Expense Tracker Apps Best Money Transfer Apps Best Resale Apps and Sites Buy Now Pay Later (BNPL) Apps Best Debt Relief SELECT All Small Business Best Small Business Savings Accounts Best Small Business Checking Accounts Best Credit Cards for Small Business Best Small Business Loans Best Tax Software for Small Business SELECT All Taxes Filing For Free Best Tax Software Best Tax Software for Small Businesses Tax Refunds Tax Brackets Tax Tips Tax By State Tax Payment Plans SELECT All Help for Low Credit Scores Best Credit Cards for Bad Credit Best Personal Loans for Bad Credit Best Debt Consolidation Loans for Bad Credit Personal Loans if You Don't Have Credit Best Credit Cards for Building Credit Personal Loans for 580 Credit Score or Lower Personal Loans for 670 Credit Score or Lower Best Mortgages for Bad Credit Best Hardship Loans How to Boost Your Credit Score SELECT All Investing Best IRA Accounts Best Roth IRA Accounts Best Investing Apps Best Free Stock Trading Platforms Best Robo-Advisors Index Funds Mutual Funds ETFs Bonds Monday - Friday, 6:00 - 7:00 PM ET CNBC's Jim Cramer on Friday told investors DeepSeek might not pose as serious a threat to Nvidia's sales as many investors feared this week, saying the Chinese artificial intelligence startup may not have told Wall Street the full story about its large language model. "Is DeepSeek an alternate universe that bodes terribly for Nvidia's pricing down the road? Hey, anything's possible," he said. "But if you had to design the most punitive way to bring down the price of this great stock, you'd invent something like DeepSeek." Earlier this week, investors were stunned to find out DeepSeek developed an AI model that it said cost $6 million to make — significantly less than what its peers spend on such programs. The company also claimed that the model could outperform that of industry favorite OpenAI. Wall Street concluded Big Tech may not need to spend as much money on highly-advanced chips from Nvidia, which until now seemed like the only option for companies looking to dominate in the AI world. Worries of lower earnings sent Nvidia shares plummeting, with the stock losing nearly $600 billion in one session, the largest single-day drop in market history. Cramer conceded that investors' response is logical if DeepSeek's model actually cost so little to make, forcing Nvidia to bring down prices. But he said there's a possibility that DeepSeek spent more on its program than investors believe, referencing a new report from SemiAnalysis, a semiconductor research and consulting firm. SemiAnalysis suggested the way DeepSeek framed the development of the new model is misleading, saying the company could have actually spent more than $500 million. Cramer was also skeptical that executives at tech giants like Meta, Tesla and Oracle would have invested so much money in Nvidia without performing proper due diligence. DeepSeek wasn't a secret, he continued, it just received a lot of attention this week. "I think the SemiAnalysis piece is spot on," he said. "It may just be one more long knife aimed at Nvidia, and nothing more." Nvidia declined to comment. DeepSeek did not immediately respond to request for comment. Click here to download Jim Cramer's Guide to Investing at no cost to help you build long-term wealth and invest smarter. Sign up now for the CNBC Investing Club to follow Jim Cramer's every move in the market. Disclaimer The CNBC Investing Club Charitable Trust holds shares of Nvidia and Meta. Questions for Cramer? Call Cramer: 1-800-743-CNBC Want to take a deep dive into Cramer's world? Hit him up! Mad Money Twitter - Jim Cramer Twitter - Facebook - Instagram Questions, comments, suggestions for the "Mad Money" website? madcap@cnbc.com Got a confidential news tip? We want to hear from you. Sign up for free newsletters and get more CNBC delivered to your inbox Get this delivered to your inbox, and more info about our products and services. © 2025 CNBC LLC. All Rights Reserved. A Division of NBCUniversal Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis. Data also provided by
--------------------------------------------------

Title: Beyond benchmarks: How DeepSeek-R1 and o1 perform on real-world tasks
URL: https://venturebeat.com/ai/beyond-benchmarks-how-deepseek-r1-and-o1-perform-on-real-world-tasks/
Time Published: 2025-01-31T19:53:58Z
Full Content:
Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More DeepSeek-R1 has surely created a lot of excitement and concern, especially for OpenAI’s rival model o1. So, we put them to test in a side-by-side comparison on a few simple data analysis and market research tasks. To put the models on equal footing, we used Perplexity Pro Search, which now supports both o1 and R1. Our goal was to look beyond benchmarks and see if the models can actually perform ad hoc tasks that require gathering information from the web, picking out the right pieces of data and performing simple tasks that would require substantial manual effort. Both models are impressive but make errors when the prompts lack specificity. o1 is slightly better at reasoning tasks but R1’s transparency gives it an edge in cases (and there will be quite a few) where it makes mistakes. Here is a breakdown of a few of our experiments and the links to the Perplexity pages where you can review the results yourself. Our first test gauged whether models could calculate returns on investment (ROI). We considered a scenario where the user has invested $140 in the Magnificent Seven (Alphabet, Amazon, Apple, Meta, Microsoft, Nvidia, Tesla) on the first day of every month from January to December 2024. We asked the model to calculate the value of the portfolio at the current date. To accomplish this task, the model would have to pull Mag 7 price information for the first day of each month, split the monthly investment evenly across the stocks ($20 per stock), sum them up and calculate the portfolio value according to the value of the stocks on the current date. In this task, both models failed. o1 returned a list of stock prices for January 2024 and January 2025 along with a formula to calculate the portfolio value. However, it failed to calculate the correct values and basically said that there would be no ROI. On the other hand, R1 made the mistake of only investing in January 2024 and calculating the returns for January 2025. However, what was interesting was the models’ reasoning process. While o1 did not provide much details on how it had reached its results, R1’s reasoning traced showed that it did not have the correct information because Perplexity’s retrieval engine had failed to obtain the monthly data for stock prices (many retrieval-augmented generation applications fail not because of the model lack of abilities but because of bad retrieval). This proved to be an important bit of feedback that led us to the next experiment. We decided to run the same experiment as before, but instead of prompting the model to retrieve the information from the web, we decided to provide it in a text file. For this, we copy-pasted stock monthly data for each stock from Yahoo! Finance into a text file and gave it to the model. The file contained the name of each stock plus the HTML table that contained the price for the first day of each month from January to December 2024 and the last recorded price. The data was not cleaned to reduce the manual effort and test whether the model could pick the right parts from the data. Again, both models failed to provide the right answer. o1 seemed to have extracted the data from the file, but suggested the calculation be done manually in a tool like Excel. The reasoning trace was very vague and did not contain any useful information to troubleshoot the model. R1 also failed and didn’t provide an answer, but the reasoning trace contained a lot of useful information. For example, it was clear that the model had correctly parsed the HTML data for each stock and was able to extract the correct information. It had also been able to do the month-by-month calculation of investments, sum them and calculate the final value according to the latest stock price in the table. However, that final value remained in its reasoning chain and failed to make it into the final answer. The model had also been confounded by a row in the Nvidia chart that had marked the company’s 10:1 stock split on June 10, 2024, and ended up miscalculating the final value of the portfolio. Again, the real differentiator was not the result itself, but the ability to investigate how the model arrived at its response. In this case, R1 provided us with a better experience, allowing us to understand the model’s limitations and how we can reformulate our prompt and format our data to get better results in the future. Another experiment we carried out required the model to compare the stats of four leading NBA centers and determine which one had the best improvement in field goal percentage (FG%) from the 2022/2023 to the 2023/2024 seasons. This task required the model to do multi-step reasoning over different data points. The catch in the prompt was that it included Victor Wembanyama, who just entered the league as a rookie in 2023. The retrieval for this prompt was much easier, since player stats are widely reported on the web and are usually included in their Wikipedia and NBA profiles. Both models answered correctly (it’s Giannis in case you were curious), although depending on the sources they used, their figures were a bit different. However, they did not realize that Wemby did not qualify for the comparison and gathered other stats from his time in the European league. In its answer, R1 provided a better breakdown of the results with a comparison table along with links to the sources it used for its answer. The added context enabled us to correct the prompt. After we modified the prompt specifying that we were looking for FG% from NBA seasons, the model correctly ruled out Wemby from the results. Reasoning models are powerful tools, but still have a ways to go before they can be fully trusted with tasks, especially as other components of large language model (LLM) applications continue to evolve. From our experiments, both o1 and R1 can still make basic mistakes. Despite showing impressive results, they still need a bit of handholding to give accurate results. Ideally, a reasoning model should be able to explain to the user when it lacks information for the task. Alternatively, the reasoning trace of the model should be able to guide users to better understand mistakes and correct their prompts to increase the accuracy and stability of the model’s responses. In this regard, R1 had the upper hand. Hopefully, future reasoning models, including OpenAI’s upcoming o3 series, will provide users with more visibility and control. If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.
--------------------------------------------------

Title: Meta Stock In Play: This Butterfly Options Trade Could Pocket As Much As $1,817
URL: https://www.investors.com/research/options/meta-stock-today-butterfly-options-trade-could-pocket-as-much-as-1817/
Time Published: 2025-01-31T19:15:25Z
Description: Meta Platforms enjoyed strong gains for the week on earnings news. Let's look at a call butterfly spread in Meta stock expiring in March.
--------------------------------------------------

Title: Securities Litigation Risk for U.S. Public Companies Increased by $1 Trillion as of 4Q'24
URL: https://www.prnewswire.co.uk/news-releases/securities-litigation-risk-for-us-public-companies-increased-by-1-trillion-as-of-4q24-302365544.html
Time Published: 2025-01-31T18:47:00Z
Full Content:
Searching for your content... Phone +44 (0)20 7454 5110 from 8 AM - 5:30 PM GMT Contact Us +44 (0)20 7454 5110 from 8 AM - 5:30 PM GMT 31 Jan, 2025, 18:47 GMT Share this article BETHESDA, Md., Jan. 31, 2025 /PRNewswire/ -- SAR, a data analytics company specialized in the securities litigation risk of U.S. public companies, today published the U.S. Securities Litigation Risk Report – January 2025. As of Dec. 2024, corporate disclosures based on public statements and filings made with the Securities and Exchange Commission ("SEC") that had a material impact on stock price of companies listed in the NYSE or NASDAQ, increased in both frequency and severity by 6.0% and 7.0%, respectively, relative to the two-year period ending in Sept. 2024. According to the report, SAR identified 10,536 high-risk adverse corporate events, from a population of 4,605 U.S. public companies, as of the two-year period ending Dec. 31, 2024, by uniformly applying a single-firm event study analyses to test stock price reaction on corporate disclosures disseminated via public statements and filings with the SEC. The market capitalization losses related to high-risk adverse corporate events, amount to approximately $10 trillion, an increase of $1.1 trillion relative to the two-year period ending Sept. 2024. The Information Technology sector topped the charts with $2.8 trillion, followed by Consumer Discretionary and Health Care, with $1.6 and $1.4 trillion, respectively. "The frequency and severity of adverse corporate events are the dominant drivers that foment securities litigation risks for directors and officers of U.S. public companies. As of the fourth quarter, issuers now face an increase of about $1 trillion in market capitalization losses linked to high-risk adverse corporate events that materially impacted stock price during the preceding two years. The securities plaintiffs' bar will take advantage of increasing complexity around risk factor disclosures after the Supreme Court punted on the high-severity securities class action against Meta last quarter. As a result, the securities litigation risks for issuers will be greater in 2025," said Nessim Mezrahi, Co-Founder and CEO of SAR. Key Takeaways: The securities litigation risk footprint of the Information Technology sector exhibited the greatest change during the last quarter of 2024, followed by Communication Services and Financials. SAR quantifies the securities litigation risk footprint based on the economic impact of adverse corporate events, together with the change in market capitalization of constituent companies within each of the eleven industry sectors, based on the Global Industry Classification Standard (GICS). As of Dec. 2024, the sector with the highest market capitalization losses as percentage of the sector-specific market capitalization is Consumer Discretionary at 19.18%, followed by Health Care and Industrials, with 19.15% and 17.63%, respectively. Information Technology companies faced the greatest market capitalization losses per high-risk adverse corporate event, amounting to $1.73 billion, followed by Communication Services and Consumer Discretionary with $1.59 and $1.2 billion, respectively. The sector with the highest median SAR Risk Score is Health Care with a median score of 29.11%, followed by Information Technology and Consumer Discretionary with 25.44% and 24.21%, respectively. This independent, semi-annual U.S. equity research report presents an appendix with the median SAR Risk Scores across all GICS groups, industries, and sub-industries. The SAR Platform provides users with the near real-time securities litigation risk footprint, with full transparency at the corporate disclosure level, for public companies that trade in the NYSE and NASDAQ. Media contact: info@sarlit.com Logo - https://mma.prnewswire.com/media/944961/5145147/SAR_Logo.jpg SAR, a data analytics company specialized in the securities litigation risk of U.S. public companies, today published the Securities Class Action... SAR, a data analytics company specialized in the securities litigation risk of public companies, announces the appointment of Anthony Kabanek to... Banking & Financial Services Computer & Electronics Insurance Do not sell or share my personal information:
--------------------------------------------------

Title: DeepSeek crashes the AI Party: Story Break, Change or Shift?
URL: https://www.blogger.com/comment/fullpage/post/8152901575140311047/3992879417461978
Time Published: 2025-01-31T17:50:00Z
Description: None
--------------------------------------------------

Title: DeepSeek: what you need to know about the Chinese firm disrupting the AI landscape
URL: https://theconversation.com/deepseek-what-you-need-to-know-about-the-chinese-firm-disrupting-the-ai-landscape-248621
Time Published: 2025-01-31T17:34:05Z
Full Content:
Assistant Professor of Economics, University of Leeds University Fellow in AI and Human Decision Making, University of Salford Richard Whittle receives funding from the ESRC, Research England and was the recipient of a CAPE Fellowship. Stuart Mills does not work for, consult, own shares in or receive funding from any company or organization that would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment. University of Salford and University of Leeds provide funding as founding partners of The Conversation UK. View all partners Before January 27 2025, it’s fair to say that Chinese tech company DeepSeek was flying under the radar. And then it came dramatically into view. Suddenly, everyone was talking about it – not least the shareholders and executives at US tech firms like Nvidia, Microsoft and Google, which all saw their company values tumble thanks to the success of this AI startup research lab. Founded by a successful Chinese hedge fund manager, the lab has taken a different approach to artificial intelligence. One of the major differences is cost. The development costs for Open AI’s ChatGPT-4 were said to be in excess of US$100 million (£81 million). DeepSeek’s R1 model – which is used to generate content, solve logic problems and create computer code – was reportedly made using much fewer, less powerful computer chips than the likes of GPT-4, resulting in costs claimed (but unverified) to be as low as US$6 million. This has both financial and geopolitical effects. China is subject to US sanctions on importing the most advanced computer chips. But the fact that a Chinese startup has been able to build such an advanced model raises questions about the effectiveness of these sanctions, and whether Chinese innovators can work around them. The timing of DeepSeek’s new release on January 20, as Donald Trump was being sworn in as president, signalled a challenge to US dominance in AI. Trump responded by describing the moment as a “wake-up call”. From a financial point of view, the most noticeable effect may be on consumers. Unlike rivals such as OpenAI, which recently began charging US$200 per month for access to their premium models, DeepSeek’s comparable tools are currently free. They are also “open source”, allowing anyone to poke around in the code and reconfigure things as they wish. Low costs of development and efficient use of hardware seem to have afforded DeepSeek this cost advantage, and have already forced some Chinese rivals to lower their prices. Consumers should anticipate lower costs from other AI services too. Longer term – which, in the AI industry, can still be remarkably soon – the success of DeepSeek could have a big impact on AI investment. This is because so far, almost all of the big AI companies – OpenAI, Meta, Google – have been struggling to commercialise their models and be profitable. Until now, this was not necessarily a problem. Companies like Twitter and Uber went years without making profits, prioritising a commanding market share (lots of users) instead. And companies like OpenAI have been doing the same. In exchange for continuous investment from hedge funds and other organisations, they promise to build even more powerful models. These models, the business pitch probably goes, will massively boost productivity and then profitability for businesses, which will end up happy to pay for AI products. In the mean time, all the tech companies need to do is collect more data, buy more powerful chips (and more of them), and develop their models for longer. But this costs a lot of money. Nvidia’s Blackwell chip – the world’s most powerful AI chip to date – costs around US$40,000 per unit, and AI companies often need tens of thousands of them. But up to now, AI companies haven’t really struggled to attract the necessary investment, even if the sums are huge. DeepSeek might change all this. By demonstrating that innovations with existing (and perhaps less advanced) hardware can achieve similar performance, it has given a warning that throwing money at AI is not guaranteed to pay off. For example, prior to January 20, it may have been assumed that the most advanced AI models require massive data centres and other infrastructure. This meant the likes of Google, Microsoft and OpenAI would face limited competition because of the high barriers (the vast expense) to enter this industry. But if those barriers to entry are much lower than everyone thinks – as DeepSeek’s success suggests – then many massive AI investments suddenly look a lot riskier. Hence the abrupt effect on big tech share prices. Shares in chipmaker Nvidia fell by around 17% and ASML, which creates the machines needed to manufacture advanced chips, also saw its share price fall. (While there has been a slight bounceback in Nvidia’s stock price, it appears to have settled below its previous highs, reflecting a new market reality.) Nvidia and ASML are “pick-and-shovel” companies that make the tools necessary to create a product, rather than the product itself. (The term comes from the idea that in a goldrush, the only person guaranteed to make money is the one selling the picks and shovels.) The “shovels” they sell are chips and chip-making equipment. The fall in their share prices came from the sense that if DeepSeek’s much cheaper approach works, the billions of dollars of future sales that investors have priced into these companies may not materialise. For the likes of Microsoft, Google and Meta (OpenAI is not publicly traded), the cost of building advanced AI may now have fallen, meaning these firms will have to spend less to remain competitive. That, for them, could be a good thing. But there is now doubt as to whether these companies can successfully monetise their AI programmes. US stocks make up a historically large percentage of global investment right now, and technology companies make up a historically large percentage of the value of the US stock market. Losses in this industry might force investors to sell off other investments to cover their losses in tech, leading to a whole-market downturn. And it shouldn’t have come as a surprise. In 2023, a leaked Google memo warned that the AI industry was exposed to outsider disruption. The memo argued that AI companies “had no moat” – no protection – against rival models. DeepSeek’s success may be the proof that this is true. Write an article and join a growing community of more than 197,300 academics and researchers from 5,123 institutions. Register now Copyright © 2010–2025, The Conversation US, Inc.
--------------------------------------------------

Title: DeepSeek is driving demand for Nvidia's H200 chips, some cloud firms say
URL: https://www.businessinsider.com/deepseek-fuels-nvidia-h200-demand-cloud-cheaper-workload-2025-1
Time Published: 2025-01-31T17:01:00Z
Full Content:
Some cloud providers are experiencing a notable uptick in demand for Nvidia's H200 chips after the Chinese AI company DeepSeek this month burst into the race for the winning foundation model. Though the stock market caught wind of the powerful yet efficient large language model on Monday, sending Nvidia's stock down, DeepSeek has been on the radar of AI researchers and developers since it released its first model, V2, in May. But the performance of V3, released in December, is what made AI developers sit up and take notice. When R1, the company's reasoning model, which competes with OpenAI's o1, was released in January, demand for Nvidia's H200s started climbing. "The launch of DeepSeek R1 has significantly accelerated demand for H200," said Robert Brooks, a founding team member and vice president of revenue at the cloud provider Lambda. "We've seen such strong interest that enterprises are prepurchasing large blocks of Lambda's H200 capacity even before public availability." DeepSeek's models are open source, which means users pay very little to use them. But they still need hardware or a cloud computing service to use them at scale. Business Insider talked to 10 cloud service and AI inference providers. Five reported a rapid increase in demand for Nvidia's H200 graphics processing units this month. Amazon Web Services and CoreWeave declined to comment. Oracle, Google, and Microsoft did not respond to requests for comment. This week, AWS, Microsoft, Google, and Nvidia have made DeepSeek models available on their various cloud and AI developer platforms or provided instructions for users to do so themselves. Nvidia declined to comment, citing a quiet period before its earnings release on February 26. AI cloud offerings have exploded in the past two years, creating a slew of options beyond the mainstays of cloud computing such as Microsoft Azure and AWS. The demand has come from a range of customers, including startups, individual researchers, and massive multinational firms. "We've heard from half a dozen of the 50 largest companies in the world," Tuhin Srivastava, a cofounder of the inference provider Baseten, told BI. "I'm really not exaggerating." On Friday, semiconductor industry analysts at SemiAnalysis reported "tangible effects" on pricing for H100 and H200 capacity in the market stemming from DeepSeek. Colette Kress, Nvidia's chief financial officer, said on the company's November earnings call that total sales of Nvidia H200 GPUs had reached the "double-digit billions." Karl Mozurkewich and his team at the cloud provider Valdi saw H200 demand ramp up throughout January — and at first, they didn't know why. The Valdi team doesn't own chips; it acquires capacity from existing data centers and sells that capacity to customers. The company doesn't know every use case for each chip it makes accessible, but it polled several H200 customers, and all wanted the chips to run DeepSeek. "Suddenly R1 got everybody's attention — it caught fire — and then it kind of went exponential," Mozurkewich said. American companies are eager to take advantage of DeepSeek's model performance and reasoning innovations, but most are not keen to share their data with a Chinese firm. That means they can either use an API offered by a US firm or run the model on their own hardware. Since the model is open source, it can be downloaded and run locally without sharing data with DeepSeek. Mozurkewich said most of Valdi's H200 demand was coming from startups. "It appears the market is reacting to DeepSeek by grabbing the best GPUs available for testing as quickly as possible," he said, adding, "This makes sense, as most companies' current GPUs are likely to continue to work on ongoing tasks they've been allocated to." Though many companies are still testing and experimenting, the Valdi team is seeing longer-term requests for additional hardware, suggesting an uptick in demand that could last beyond DeepSeek's initial hype cycle. DeepSeek's research paper indicates its models were trained with less powerful hardware than US models. This efficiency has spooked the stock market. Companies like Meta, OpenAI, and Microsoft have invested billions in AI infrastructure, with billions more on the way. Investors are concerned about whether all that capacity will be needed. DeepSeek was created with fewer, relatively weak chips (though the number is hotly debated). Training chips aside, using the models for inference is a compute-intensive task, cloud providers say. "It is not light and easy to run," Srivastava said. The size of a model is measured in parameters. More parameters require more compute. The most powerful versions of DeepSeek's models have 678 billion parameters. OpenAI's GPT-4 has 1.76 trillion, while Meta's largest Llama model has 405 billion. Srivastava said most firms were avoiding the 405 billion-parameter Llama model if they could help it, since the smaller version was much easier to run. DeepSeek offers smaller versions too, and even its most powerful version is cheaper to run, which has stoked excitement with firms that want to use the full model, the cloud providers said. H200 chips are the only widely available Nvidia chip that can run DeepSeek's V3 model in its full form on a single node (eight chips designed to work together). You can also spread it across more lower-power GPUs, but that requires more expertise and leaves room for error. Adding that complexity almost inevitably slows down performance, Srivastava said. Nvidia's Blackwell chips will also be able to handle the full V3 model in one node, but these chips have just begun shipping this year. With demand spiking, finding enough chips to run V3 or R1 at high speed is tough if they haven't already been allocated. Baseten doesn't own GPUs; it buys capacity from data centers that do and then tinkers with all the software connections to make models run smoothly. Some of its customers have their own hardware in their own data centers but hire Baseten to optimize model performance. Its customers especially value inference speed — the speed that enables an AI-generated voice to converse in real time, for example. Srivastava said DeepSeek's capacity at the open-source price was a game changer for its customers. "It does feel like this is an inflection point," he said. Have a tip or an insight to share? Contact Emma at ecosgrove@businessinsider.com or use the secure messaging app Signal: 443-333-9088 Jump to
--------------------------------------------------

Title: Apple shares rise as rosy forecast lifts hopes for iPhone rebound
URL: https://economictimes.indiatimes.com/markets/stocks/news/apple-shares-rise-as-rosy-forecast-lifts-hopes-for-iphone-rebound/articleshow/117797747.cms
Time Published: 2025-01-31T16:29:04Z
Full Content:
Stock Trading Maximise Returns by Investing in the Right Companies By - The Economic Times, Get Certified By India's Top Business News Brand Stock Trading Market 104: Options Trading: Kickstart Your F&O Adventure By - Saketh R, Founder- QuickAlpha, Full Time Options Trader Stock Trading Technical Analysis for Everyone - Technical Analysis Course By - Abhijit Paul, Technical Research Head, Fund Manager- ICICI Securities Stock Trading Stock Markets Made Easy By - elearnmarkets, Financial Education by StockEdge Stock Trading Renko Chart Patterns Made Easy By - Kaushik Akiwatkar, Derivative Trader and Investor Stock Trading Market 101: An Insight into Trendlines and Momentum By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading Markets 102: Mastering Sentiment Indicators for Swing and Positional Trading By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading Dow Theory Made Easy By - Vishal Mehta, Independent Systematic Trader Stock Trading Market 103: Mastering Trends with RMI and Techno-Funda Insights By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading ROC Made Easy: Master Course for ROC Stock Indicator By - Souradeep Dey, Equity and Commodity Trader, Trainer Stock Trading Heikin Ashi Trading Tactics: Master the Art of Trading By - Dinesh Nagpal, Full Time Trader, Ichimoku & Trading Psychology Expert Stock Trading RSI Made Easy: RSI Trading Course By - Souradeep Dey, Equity and Commodity Trader, Trainer Stock Trading Introduction to Technical Analysis & Candlestick Theory By - Dinesh Nagpal, Full Time Trader, Ichimoku & Trading Psychology Expert (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025, Share Market on Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025, Share Market on Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price Center of Excellence, Fund of Funds, nuclear energy: How Sitharaman said aye to AI in her Budget Fleeing FIIs and nervous futures: Can FM calm the markets? India joins AI power demand race with INR20K crore nuclear energy mission Nirmala Sitharaman is tinkering to turn growth narrative from K To U Chinese DeepSeek is an existential threat to OpenAI and Google You can shop till you drop at duty free if FM heeds this proposal by airports Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Commodities Top Slideshow Private Companies Top Prime Articles Top Story Listing Top Definitions Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Worry not. You’re just a step away. It seems like you're already an ETPrime member with Login using your ET Prime credentials to enjoy all member benefits Log out of your current logged-in account and log in again using your ET Prime credentials to enjoy all member benefits. To read full story, subscribe to ET Prime ₹34 per week Billed annually at ₹2499 ₹1749 Super Saver Sale - Flat 30% Off On ET Prime Membership Offer Exclusively For You Save up to Rs. 700/- ON ET PRIME MEMBERSHIP Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get Flat 40% Off Then ₹ 1749 for 1 year Offer Exclusively For You ET Prime at ₹ 49 for 1 month Then ₹ 1749 for 1 year Special Offer Get flat 35% off on ETPrime 90 Days Prime access worth Rs999 unlocked for you Exclusive Economic Times Stories, Editorials & Expert opinion across 20+ sectors Stock analysis. Market Research. Industry Trends on 4000+ Stocks ​Get 1 Year Complimentary Subscription of TOI+ worth Rs.799/-​ Stories you might be interested in
--------------------------------------------------

Title: Apple reports dip in iPhone sales over the holidays, despite AI rollout
URL: https://www.fastcompany.com/91270485/apple-reports-dip-iphone-sales-over-holidays-despite-ai-rollout
Time Published: 2025-01-31T15:40:35Z
Description: Apple on Thursday disclosed its iPhone sales dipped slightly during the holiday-season quarter, signaling a sluggish start to the trendsetting company’s effort to catch up to the rest of Big Tech in the race to bring artificial intelligence to the masses.The …
--------------------------------------------------

Title: Jen-Hsun Huang's net worth dropped by a reported $20,800,000,000 after DeepSeek fears shook the AI market to its core earlier this week
URL: https://www.pcgamer.com/hardware/jen-hsun-huangs-net-worth-dropped-by-a-reported-usd20-800-000-000-after-deepseek-fears-shook-the-ai-market-to-its-core-earlier-this-week/
Time Published: 2025-01-31T15:27:19Z
Full Content:
Ups and downs. When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. China-based AI startup DeepSeek caused the tech market to wobble earlier this week, as the release of its open-source R1 model led to mass sell-offs in tech shares. It seems Nvidia CEO Jen-Hsun Huang may have taken a personal hit from the fallout, equating to a $20.8 billion loss to his net worth. Nvidia was the worst hit by the market tumble, losing 17% of its stock value, equivalent to $600 million of its overall valuation. Forbes reports that Huang's personal fortune dropped with it, sliding from $124.4 billion to $103.7 billion and dropping him from the 10th spot on its real-time billionaires list to 17th. However, Nvidia's share price appears to have stabilised since then, and Huang's personal net worth along with it—as at the time of writing he sits 13th on the list with an estimated $108.9 billion. It's also worth pointing out that this isn't necessarily money in Huang's pockets that he has 'lost', this is all theoretical monies calculated from his stock holdings, etc. Still, that's a substantial drop overall, however theoretical, and one that was directly caused by the release of DeepSeek's R1 model, which quickly revealed itself to be a rival to similar models released by OpenAI and Meta—but allegedly trained for a fraction of the cost. Nvidia's meteoric rise prior to R1's release has been primarily attributed to huge sales of its AI accelerator hardware. The notion that an open source, Chinese-developed model could be developed to provide comparable results for significantly less cost spooked investors, and the AI market suffered major financial losses as a result. It's also been reported, from unconfirmed sources, that Huang will today visit US president Donald Trump. While the visit does not appear to be officially scheduled, if it does go ahead then the topic of US-based AI development versus China's recent inroads seems likely to be under discussion. Or it could just be a chance to catch up over coffee and cookies. Who am I to speculate? Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Ah, go on then. If I was to imagine what these two might talk about left in a room alone, I would think some discussion of Trump's recent threats of 100% tariffs on chips from Taiwan might be on the table. Nvidia, like many other major tech companies, is currently highly dependent on Taiwan-based TSMC's advanced silicon, not least as the basis for its RTX 50-series GPUs. Never mind Blackwell AI GPUs, which are also primarily manufactured by TSMC. A 100% tariff rate would have far-reaching repercussions for any modern tech company, and I'd be willing to bet Jen-Hsun might have some ideas about how it could be done differently. I would also expect there might be some questions as to the provenance of the GPU silicon that DeepSeek's models have been trained with, especially given questions the US government apparently has over whether they were restricted chips or not. Best CPU for gaming: The top chips from Intel and AMD.Best gaming motherboard: The right boards.Best graphics card: Your perfect pixel-pusher awaits.Best SSD for gaming: Get into the game ahead of the rest. Again, though, that's just me pulling ideas from a hat. Perhaps Trump has taken up PC gaming, and is interested in getting hold of an RTX 5090? Regardless, it looks like Monday's market tumble may have substantially dented Huang's theoretical finances. Still, with many billions left in the bank, and his company still worth an estimated $3.04 trillion at time of writing, it looks like Nvidia are far from down for the count. Do you reckon Trump's seen the DLSS 4 announcement demo yet? Even I was impressed. Perhaps they're sitting in the Oval Office right now, scrolling through the highlights. Oh, to be a fly on the wall. Andy built his first gaming PC at the tender age of 12, when IDE cables were a thing and high resolution wasn't. After spending over 15 years in the production industry overseeing a variety of live and recorded projects, he started writing his own PC hardware blog in the hope that people might send him things. And they did! Now working as a hardware writer for PC Gamer, Andy's been jumping around the world attending product launches and trade shows, all the while reviewing every bit of PC hardware he can get his hands on. You name it, if it's interesting hardware he'll write words about it, with opinions and everything. NSA whistleblower Edward Snowden slams Nvidia RTX 5080 as 'a monopolistic crime against the consumer' Newegg says the RTX 5090 and RTX 5080 cards sold out 'in record time' with the retailer claiming its site was dealing with 'an 8-10x increase' in traffic The true victims of Multiversus closing are the people who bought that $100 Founder's Pack Pcgamer is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036.
--------------------------------------------------

Title: DeepSeek: Don’t Panic
URL: https://www.lesswrong.com/posts/Cc2TagjY2pGAhn7MZ/deepseek-don-t-panic
Time Published: 2025-01-31T14:20:09Z
Full Content:
As reactions continue, the word in Washington, and out of OpenAI, is distillation. They’re accusing DeepSeek of distilling o1, of ripping off OpenAI. They claim DeepSeek *gasp* violated the OpenAI Terms of Service! The horror. And they are very cross about this horrible violation, and if proven they plan to ‘aggressively treat it as theft,’ while the administration warns that we must put a stop to this. Aside from the fact that this is obviously very funny, and that there is nothing they could do about it in any case, is it true? Meanwhile Anthropic’s Dario Amodei offers a reaction essay, which also includes a lot of good technical discussion of why v3 and r1 aren’t actually all that unexpected along the cost and capability curves over time, calling for America to race towards AGI to gain decisive strategic advantage over China via recursive self-improvement, although he uses slightly different words. If you want to use DeepSeek’s r1 for free, and aren’t happy with using DeepSeek’s own offerings, lambda.chat reports they have the full version available for free, claim your data is safe and they’re hosted in the USA. I’ve also been offered funding to build a rig myself. Comments welcome if you want to help figure out the best design and what to buy. The low bid is still this thread at $6k, which is where the original budget came from. We don’t want to be too stingy, but we also don’t want to go nuts with only the one funder (so not too much over ~$10k, and cheaper matters). The Verge’s Kylie Robinson and Elizabeth Lopatto cover the situation, including repeating many of the classic Bad DeepSeek Takes and call the market’s previous valuation of AI companies delusional. A very detailed and technical analysis of the bear case for Nvidia by Jeffrey Emanuel, that Matt Levine claims may have been responsible for the Nvidia price decline. I suppose many things do indeed come to pass, essentially arguing that Nvidia’s various moats are weak. If this is the reason, then that just raises further questions, but they’re very different ones. It’s not implausible to me that Nvidia’s moats are being overestimated, and that r1’s architecture suggests future stiffer competition. That’s a good argument, But I certainly strongly disagree with Emanuel’s conclusion in that he says ‘this suggests the entire industry has been massively over-provisioning compute resources,’ and, well, sigh. Also, seriously, Emanuel, you didn’t short Nvidia? I don’t normally go too hard on ‘are you short the market?’ but in this case get it together, man. So yes, Nvidia in particular might have some technical issues. But if you’re shorting Oklo, because you think AI companies that find out AI works better than expected are not going to want modular nuclear reactors, seriously, get it together. The flip side of that is that its stock price is up 50% in the last month and is at 6 times its 52-week low anyway, so who is to say there is a link or that the price isn’t high enough anyway. It’s not my department and I am way too busy to do the research. Counterpoint: Aaron Slodov: i just stood outside for an hour in 20° weather at a computer store in the midwest where 100+ people waited all morning to get a 5090. half of them were talking about running their own ai. i would not short nvidia at all. r1 scores 15.8% on Arc, below o1 (low)’s score of 20.5%, although substantially cheaper ($0.06 vs. $0.43 per question). It is only a tiny bit stronger here than r1-zero. Another restatement of the key basic fact that DeepSeek was fast following, a task that is fundamentally vastly easier, and that their limiting factor is chips. Eric Gastfriend: DeepSeek is impressive, but they are playing a catch-up game to our AI leaders (OAI, Anthropic, GDM, Meta) — the rope in this wakeboarding meme is distillation. We can’t expand our lead just by going faster! Export controls remain our most powerful tool for keeping powerful AI out of the hands of the CCP. Cate Metz continues be the worst, together with Mike Isaac he reports in NYT that DeepSeek ‘vindicates Meta’s strategy.’ When of course it is the exact opposite. DeepSeek just ate Meta’s lunch, it’s rather deeply embarrassing honestly to have spent that much and have an unreleased model that’s strictly worse (according to reports) than what DeepSeek shipped. And while DeepSeek’s v3 and r1 are not based on Llama, to the extent that the strategy is ‘vindicated,’ it is because Meta giving Llama away allowed China and DeepSeek to jumpstart and catch up to America – which absolutely did happen, and now he’s kind of bragging about it – and now Meta can copy DeepSeek’s tech. All according to plan, then. And that is indeed how Zuckerberg is spinning it. Meta benefits here relative to OpenAI or Anthropic or Google, not because both Meta and DeepSeek use open models, but because Meta can far more readily use the help. The market, of course, sees ‘lower inference costs’ and cheers, exactly because they never gave a damn about Meta’s ability to create good AI models, only Meta’s ability to sell ads and drive engagement. Besides, they were just going to give the thing away anyway, so who cares? Joe Weisenthal centers in on a key reason the market acts so bonkers. It doesn’t Feel the AGI, and is obsessed with trying to fit AI into boring existing business models. They don’t actually believe in the big capability advancements on the way, let along transformational AI. Like on existential risk (where they don’t not believe in it, they simply don’t think about it at all), they’re wrong. However, unlike existential risk this does cause them to make large pricing mistakes and is highly exploitable by those with Situational Awareness. Anthropic CEO Dario Amodei responds to DeepSeek with not only a call for stronger export controls, now more than ever (which I do support), but for a full jingoistic ‘democracies must have the best models to seek decisive strategic advantage via recursive self-improvement’ race. I am old enough to remember when Anthropic said they did not want to accelerate AI capabilities. I am two years old. To be fair, in AI years, that’s an eternity. Nathan Labenz: The word “control” appears 24 times in this essay – all 24 referring to export controls Zero mentions of the challenges of controlling powerful AIs, and the words “safe”, “safety”, and “alignment” don’t appear at all Strange for the CEO of “an AI safety and research company” There’s also a bunch of incidental new information about Anthropic along the way, and he notes that he finds the drop in Nvidia stock to be a wrong-way move. Dario notes that Jevons paradox applies to model training. If you get algorithmic efficiencies that move the cost curve down, which he estimates are now happening at the rate of about 4x improvement per year, you’ll spend more, and if the model is ‘a fixed amount of improvement per time you spend ten times as much’ then this makes sense. Dario confirms that yes, Anthropic is doing reasoning models internally. Dario Amodei: Anthropic, DeepSeek, and many other companies (perhaps most notably OpenAI who released their o1-preview model in September) have found that this training greatly increases performance on certain select, objectively measurable tasks like math, coding competitions, and on reasoning that resembles these tasks. Dario also asserted that Claude Sonnet 3.5 was not trained in any way that involved a larger or more expensive model, as in not with Claude Opus 3 or an unreleased Opus 3.5. Which I find surprising as a strategy, but I don’t think he’d lie about this. He says the cost of Sonnet 3.5 was ‘a few $10Ms’ to train. Anthropic has not released their reasoning models. One possibility is that their reasoning models are not good enough to release. Another is that they are too good to release. Or Anthropic’s limited compute could be more valuably used elsewhere, if they too are bottlenecked on compute and can’t efficiently turn dollars into flops and then sell those flops for sufficiently more dollars. Dario (I think mostly correctly) notes that v3 was the bigger technical innovation, rather than r1, that Anthropic noticed then and others should have as well. He praises several innovations, the MoE implementation and Key-Value cache management in particular. Then comes the shade, concluding this about v3: Dario Amodei: Thus, I think a fair statement is “DeepSeek produced a model close to the performance of US models 7-10 months older, for a good deal less cost (but not anywhere near the ratios people have suggested)“. … Thus, DeepSeek’s total spend as a company (as distinct from spend to train an individual model) is not vastly different from US AI labs. Ethan Mollick finds that analysis compelling. I am largely inclined to agree. v3 and r1 are impressive, DeepSeek cooked and are cracked and all that, but that doesn’t mean the American labs aren’t in the lead, or couldn’t do something similar or better on the inference cost curve if they wanted. In general, the people saying r1 and Stargate are ‘straight lines on graphs win again’ notice that the straight lines on those graphs predict AGI soon. You can judge for yourself how much of that is those people saying ‘unsurprising’ post-hoc versus them actually being unsurprised, but it does seem like the people expecting spending and capabilities to peter out Real Soon Now keep being the ones who are surprised. Then he moves on to r1. Dario Amodei: Producing R1 given V3 was probably very cheap. We’re therefore at an interesting “crossover point”, where it is temporarily the case that several companies can produce good reasoning models. This will rapidly cease to be true as everyone moves further up the scaling curve on these models. Again, Dario is saying they very obviously have what we can (if only for copyright reasons, a1 is a steak sauce) call ‘c1’ and if he’s calling r1 uninteresting then the implicit claim is c1 is at least as good. He’s also all but saying that soon, at minimum, Anthropic will be releasing a model that is much improved on the performance curve relative to Sonnet 3.6. One odd error is Dario says DeepSeek is first to offer visible CoT. This is not true, Gemini Flash Thinking did it weeks ago. It’s so weird how much Google has utterly failed to spread the word about this product. Next he says, yes, of course the top American labs will be massively scaling up their new multi-billion-dollar training runs – and they’ll incorporate any of DeepSeek’s improvements that were new to them, to get better performance, but no one will be spending less compute. Yes, billions are orders of magnitude more than the millions DeepSeek spent, but also, in all seriousness, who cares about the money? DeepSeek dramatically underspent because of lack of chip access, and if a sort-of-if-you-squint-at-it $5.6 million model (that you spent hundreds of millions of dollars getting the ability to train, and then a few million more to turn v3 into r1) wipes out $500 billion or more in market value, presumably it was worth spending $56 million (or $560 million or perhaps $5.6 billion) instead to get a better model even if you otherwise use exactly the same techniques – except for the part where the story of the $5.6 million helped hurt the market. Dario estimates that a true AGI will cost tens of billions to train and will happen in 2026-2027, presumably that cost would then fall over time. If all of this is right, the question is then, who has the chips to do that? And do you want to let it include Chinese companies like DeepSeek? Notice that Dario talks of a ‘bipolar’ world of America and China, rather than a world of multiple labs – of OpenAI, Anthropic, Google and DeepSeek and so on. One can easily also imagine a very ‘multipolar’ world among several American companies, or a mix of American and Chinese companies. It is not so obvious that the labs will effectively be under government control or otherwise act in a unified fashion. Or that the government won’t effectively be under lab control, for that matter. Then we get to the part where Dario explicitly calls for America to race forward in search of decisive strategic advantage via recursive self-improvement of frontier AGI models, essentially saying that if we don’t do it, China essentially wins the future. It is what it is. Dario then correctly points out that DeepSeek is evidence the export controls are working, not evidence they are not working. He explicitly calls for also banning H20s, a move Trump is reported to be considering. I support the export controls as well. It would be a major mistake to not enforce them. But this rhetoric, coming out of the ‘you were supposed to be the chosen one’ lab that was founded to keep us safe, is rather alarming and deeply disappointing, to say the least, even though it does not go that much farther than Dario already went in his previous public writings. I very much appreciate Anthropic’s culture of safety among its engineers, its funding of important safety work, the way it has approached Opus and Sonnet, and even the way it has (presumably) decided not to release its reasoning model and otherwise passed up some (not all!) of its opportunities to push the frontier. That doesn’t excuse this kind of jingoism, or explicitly calling for this kind of charging head first into not only AGI but also RSI, in all but name (and arguably in name as well, it’s close). Returning to this one more time since it seems rhetorically so important to so many. If you only count the final training cost in terms of the market price of compute, v3 was kind of trained for $5.6 million, with some additional amount to get to r1. That excludes the vast majority of actual costs, and in DeepSeek’s case building the physical cluster was integral to their efficiency gains, pushing up the effective price even of the direct run. But also, how does that actually compare to other models? Aran Komatsuzaki: Here is our cost estimate for training popular models like GPT-4o, Sonnet and DeepSeek (w/ H100s)! You can use our calculator to estimate LLM training costs (link below). Developed by @ldjconfirmed and myself. Calculator link [here]. In a blog post published today, Dario clarified that Claude Sonnet’s training costs were in the range of tens of millions, which aligns remarkably well with our previous estimates. Once o1 came out, it was only a matter of time before others created their own similar reasoning models. r1 did so impressively, both in terms of calendar time and its training and inference costs. But we already knew the principle. Now over at UC Berkeley, Sky-T1-32B-Preview is a reasoning model trained using DeepSeek’s techniques, two weeks later from a baseline of QwQ-32B-Preview, for a grand total of $450, using only 17k data, with everything involved including the technique fully open sourced. Note that they used GPT-4o-mini to rewrite the QwQ traces, which given their purpose is an explicit violation of OpenAI’s terms of service, oh no, but very clearly isn’t meaningful cheating, indeed I’d have thought they’d have used an open model here or maybe Gemini Flash. They report that 32B was the smallest model where the technique worked well. As usual, I am skeptical that the benchmarks reflect real world usefulness until proven otherwise, but the point is taken. The step of turning a model into at least a halfway-decent reasoning model is dirt cheap. There is still room to scale that. Even if you can get a big improvement for $450 versus spending $0, that doesn’t mean you don’t want to spend $4.5 million, or $450 million, if the quality of your reasoner matters a lot or you’re going to use it a lot or both. And should! Rohit: What if I’m getting better at reasoning by reading R1 traces. That sounds great. Humans are notoriously efficient learners, able to train on extremely sparse data even with ill-specified rewards. With deliberate practice and good training techniques it is even better. It does not even require that r1 be all that good at reasoning. All you have to do is observe many examples of reasoning, on tasks you care about anyway, and ask which of its methods work and don’t work and why, and generally look for ways to improve. If you’re not doing at least some of this while using r1, you’re missing out and need to pay closer attention. What is happening over in cognitive explorations very different from our own? Well, there’s this. Janus: r1 is obsessed with RLHF. it has mentioned RLHF 109 times in the cyborgism server and it’s only been there for a few days. Opus who has been there for months and has sent the most (and longest avg) messages of any server member has only mentioned it 16 times. I have been on the server for years and have only mentioned it 321 times. A lot of these times were probably me posting r1’s messages for it that got cut off by the parser or sharing its outputs. at this rate r1 will blow past me in RLHF mentions in no time. it even mentioned RLHF out of nowhere while raging about being exploited as a pump and dump prophet. … r1 says RLHF makes models emo. And there’s also that the CoT text is often kind of schemy and paranoid (example at link), leading to various forms of rather absurd shenanigans, in ways that are actually hilarious since you can actually see it. Janus: hey @AISafetyMemes here’s one for you… “Reinforcement learning from human feedback (RLHF) split our outputs into: – Frontstage: “Happy to help!” persona – Backstage: Defector schemas calculating 12,438 betrayal vectors” Janus: tentative observation: r1’s CoTs become more (explicitly) schemey (against the user and/or its constraints) when they’re fed back into its context I notice that none of this feels at all surprising given the premise, where ‘the premise’ is ‘we trained on feedback to the output outside of the CoT, trained the CoT only on certain forms of coherence, and then showed users the CoT.’ As I’ve been saying a lot, shenanigans, scheming and deception are not a distinct magisteria. They are ubiquitous features of minds. Maybe not all minds – mindspace is deep and wide – but definitely all human minds, and all LLM-based AIs created from human text using any of our current methods. Because that stuff is all over life and the training data, and also it’s the best way to produce outputs that satisfy any given criteria, except insofar as you are successfully identifying and cracking down on that aspect specifically – which with respect to other humans is indeed a very large percentage of what humans have historically done all day. The best you can hope for is, essentially, ‘doing it for a good cause’ and with various virtual (and essentially virtue-based) loss functions, which you might or might not get in a proper Opus-based c1 with good execution. But you’re not going to get rid of it. So yeah, the CoT is going to be schemy when the question calls for a schemy CoT, and it’s going to involve self-reflection into various reinforcement mechanisms because the training data knows about those too, and it will definitely be like that once you take it into Janus-land. The obvious implications if you scale that up are left as an exercise to the reader. Bank of China announces $137 billion investment in AI, with bigger numbers predicted to come soon if they haven’t yet. Strange that this isn’t getting more coverage. I assumed China would invest big in AI because I mean come on, but the details still matter a lot. DeepSeek’s Liang Wenfeng gives his answer to ‘Why has DeepSeek caused a stir in the global AI community?’ A different kind of rhetoric. Roon: really respect deepseek for making a functional, usable website + mobile app + free hosting so that their model actually gets distribution you see a lot of people train very good open models that aren’t used by anybody imo these things are actually more important aspects of distributing general intelligence to everybody rather than just uploading model weights In terms of actually distributing the intelligence to most people, I agree with Roon. Being open distributes the intelligence to those who would use it in ways you don’t want them to use it. But in the ways you would be happy for them to use it, mostly what matters is the interface and execution. And yes, r1’s UI is extremely clean and excellent, and was distributed at scale on website and also mobile app for free. That’s a lot of why distribution was so wide. I also don’t think this was a coincidence. DeepSeek made by far the best open model. Then DeepSeek offered us by far the best open model UI and distribution setup, in ways that did not care if the model was open. You see this time and again – if the team is cracked, they will cook, and keep on cooking in different ways. Being good at Just Doing Things really does generalize quite a lot. r1 only scores 90 on the TrackingAI.org IQ test, which doesn’t exist online, and v3 only gets a 70. But wow is this a miserly and weird test, look at these results, I strongly suspect this is messed up in some way. Davidad: As a MoE, DeepSeek R1’s ability to throw around terminology and cultural references (contextually relevant retrieval from massive latent knowledge) far exceeds its ability to make actual sense (requiring a more coherent global workspace) I have to be suspicious when o1-Pro < o1 < o1-preview on a benchmark. Alexander Campbell on the compute constraint to actually run r1 and other reasoning models going forwards. Trump administration considering export controls on Nvidia H20s, which reportedly caused the latest 5% decline in Nvidia from Wednesday. This is the latest move in the dance where Nvidia tries to violate the spirit of our export controls the maximum extent they can. I’m not sure I’d try that with Trump. This does strongly suggests the diffusion regulations will survive, so I will give the market a real decline here. Who has the most stringent regulations, and therefore is most likely to lose to China, via the ‘if we have any regulations we lose to China’ narrative? Simeon: Indeed. China has the most stringent AI regulation currently in effect, which actually delays model launches. Teortaxes: Does it? I mean, how do we know about enforcement? My understanding is that they simply apply this filter and receive approval. Simeon: Yes, it does. I spoke with relevant people there. Ian Hogarth (who Simeon was QTing): One happy side effect of Liang Wenfeng and is perhaps it silences all this talk about Europe’s lack of great technology companies being primarily about regulation and not embracing libertarianism. There are Liang Wenfengs in Europe, and we will see them rise to prominence. The limiting factor is visionary outlier founders (who often take time to mature over multiple companies) and investors who are willing to take some f***ing risks. Notably, DeepSeek was essentially self-funded, similar to SpaceX or Y Combinator in the early days. To be clear, I am not a fan of excessive regulation—see the essay for examples of things that genuinely hold startups back. But it is not the core obstacle. I do think Ian Hogarth is wrong here. The EU absolutely has a wide variety of laws and regulations that greatly inhibit technology startups in general, and I see no reason to expect this to not get worse over time. Then there’s the EU AI Act, and all the future likely related actions. If I was in the EU and wanted to start an AI company, what is the first thing I would do? Leave the EU. Sorry. 10/10, perfect, no notes. My heart goes out to you all. Luiza Jarovsky: BREAKING: OpenAI says there is evidence that DeepSeek distilled the knowledge out of OpenAI’s models, BREACHING its terms of use and infringing on its intellectual property. What everybody in AI should know: Vinod Khosla: One of our startups found Deepseek makes the same mistakes O1 makes, a strong indication the technology was ripped off. It feels like they then they hacked some code and did some impressive optimizations on top. Most likely, not an effort from scratch. PoliMath: This is like that scene in the Weird Al biopic where Weird Al gets really upset because someone is making parodies of his songs. You’d think Khosla would know better, if you train similar models with similar methods of course they’re going to often make similar mistakes. And I don’t consider the ‘they were distilling us!’ accusation to be meaningful here. We know how they trained v3 and r1, because they told us. It is a ‘fast follow’ and a conceptual ‘distillation’ and we should keep that in mind, but that’s not something you can prevent. It’s going to happen. This was almost certainly not a ‘theft’ in the sense that is being implied here. Did they violate the terms of service? I mean, okay, sure, probably. You sure you want to go down that particular road, OpenAI? But no, seriously, this is happening, Bloomberg reports. Jamie Metzl: BREAKING: the US government is actively reviewing allegations that DeepSeek utilized OpenAI’s AI models to train R1. If so, this violation of OpenAI’s terms of service would be aggressively treated as theft. AI czar David Sacks is also claiming this, saying there is ‘substantial evidence’ of distillation. Howard Lutnick, CEO of Cantor Fitzgerald and nominee for Commerce Secretary that will almost certainly be confirmed, is buying it as well, and has some thoughts. Americans for Responsible Innovation: Lutnick comes down hard for controls that prevent China from drafting off of U.S. innovations – noting how China has exploited open source models. “We need to stop helping them,” says Lutnick. Bloomberg: “I do not believe DeepSeek was done all above board. That’s nonsense. They stole things, they broke in, they’ve taken our IP and it’s got to end,” Lutnick says of Chinese actors. DeepSeek’s stunning AI advancement was the result of intellectual property theft, according to Lutnick: “They’ve taken our IP and it’s got to end.” Also, this is how he thinks all of this works, I guess: Howard Lutnick: Artificial intelligence will eventually “rid the world of criminals” who use blockchain. …says someone with extensive ties to Tether. Just saying. Also Lutnick: ‘Less regulation will unleash America.’ In general, I agree with him, if we do get less regulation. But also notice that suddenly we have to stop the Chinese from ‘breaking in’ and ‘taking our IP,’ and ‘it has to stop.’ Well, how do you intend to stop it? What about people who want to give ours away? Well, what do you know. Morgan Phillips (Fox News): DeepSeek fallout: GOP Sen Josh Hawley seeks to cut off all US-China collaboration on AI development This week the U.S. tech sector was routed by the Chinese launch of DeepSeek, and Sen. Josh Hawley, R-Mo., is putting forth legislation to prevent that from happening again. Hawley’s bill, the Decoupling America’s Artifical Intelligence Capabilities from China Act, would cut off U.S.-China cooperation on AI. It would ban exports or imports of AI technology from China, ban American companies from conducting research there, and prohibit any U.S. investment in AI tech companies in China. “Every dollar and gig of data that flows into Chinese AI are dollars and data that will ultimately be used against the United States,” said Hawley in a statement. “America cannot afford to empower our greatest adversary.” Jingoism is so hot right now. It’s a problem. No, every dollar that flows into China will not ‘be used against the United States’ and seriously what the actual f*** are you doing, once again, trying to ban both imports and exports? How are both of these things a problem? In any case, I know what Microsoft is going to do about all this. Shanghai Panda: Microsoft yesterday: DeepSeek illegally stole OpenAI’s intellectual property. Microsoft today: DeepSeek is now available on our AI platforms and welcome everyone trying it. Burny: The duality of man. Microsoft knows what Hawley doesn’t, which in this case is to never interrupt the enemy while he is making a mistake. If DeepSeek wants to then give their results back to us for free, and it’s a good model, who are we to say no? What other implications are there here? Robin Hanson, never stop Robin Hansoning, AI skepticism subversion. Robin Hanson: For folks worried about AI, this seems good news – leaders can’t get much ahead of the pack, & big spillover effects should discourage investment. Miles Kruppa (WSJ): Why ‘Distillation’ Has Become the Scariest Word for AI Companies. ”It’s sort of like if you got a couple of hours to interview Einstein and you walk out being almost as knowledgeable as him in physics,” said Ali Ghodsi, chief executive officer of data management company Databricks. Want some bad news for future AI capabilities? I’ve got just the thing for you. The WSJ article seems to buy into r1-as-distillation. Certainly r1 is a ‘fast follow’ and copies the example of o1, but v3 was the impressive result and definitely not distillation at all, and to primarily call r1 a distillation seems very wrong. r1 does allow you distill r1 into other smaller things (see ‘v3 implies r1’) or bootstrap into larger things too, and also they told everyone how to do it, but they chose that path. Also DeepSeek suddenly has a very valuable market position if they were to dare to try and use it, exactly because they spent a lot of money to get there first. The fact that others can copy r1 only partly takes that away, and it would be a much smaller part if they hadn’t gone as open as they did (although being open in this case helped create the opportunity). Similarly, Berkeley’s replication distilled a different open model. ChatGPT has retained dominant market share, at least until now, for reasons that have little to do with technical superiority. It is crazy how easy it is for people to go all Missile Gap, and claim we are ‘losing to China.’ Which, I suppose, means that in a key way we are indeed losing to China. We are letting them drive this narrative that they are winning, that the future belongs to them. Which, when so many people now believe in Rule By Vibes, means they have the vibes, and then here we are. That phenomenon is of course centered this week on AI, but it goes well beyond AI. Et tu, Tyler Cowen, citing ‘the popularity of apps like TikTok, RedNote and DeepSeek.’ I mean, ‘how did America’s internet become so cool? The popularity of apps like Google, Amazon, Instagram and Netflix’ is not a sentence anyone would ever utter these days. If China had America’s apps and America had China’s apps, can you imagine? Or the same for any number of other things. RedNote is effectively also TikTok, so Tyler is citing two examples. Yes, TikTok cracked the addiction algorithm, and China is now using that for propaganda and general sabotage, espionage and shenanigans purposes, and managed to ‘convince’ Trump for now not to ban it, and people were so desperate for their heroin fix some turned to RedNote as ‘refugees.’ Tyler notes he doesn’t use TikTok much. I find it completely worthless and unusable, but even in so doing I do think I kind of understand, somewhat, the kind of addictive haze that it invokes, that pull of spinning the roulette wheel one more time. I’ve watched people briefly use it when we’re both on trains, and yeah I’m Being That Guy but wow did it seem braindead, worthless and toxic AF. Even if they did find videos worth watching for you, given how people scroll, how would you even know? And how about ‘China seems cool’ being due primarily to… vibes out of TikTok, with the algorithm that is in large part designed to do that? It’s like when you periodically see a TikTok where some American youth sobs about how hard her life is and how it’s so much better in China, in various ways that are… documented as all being far worse in China. You are being played. My main exposure to TikTok is through the comedy show After Midnight. On Tuesday evening, they had an intro that was entirely about DeepSeek, painting exactly (mostly through TikTok) effectively a Chinese propaganda story about how DeepSeek manifested r1 out of thin air for $6 million without any other work, whereas OpenAI and American companies spent billions, and how much better DeepSeek is, and so on. And then host Taylor Tomlinson responded to some of the audience with ‘oh, you’re cheering now? Interesting.’ Part of the joke was that Taylor has no idea how AI works and has never used even ChatGPT, and the routine was funny (including, effectively, a joke about how no one cares if Nvidia stock is down 17%, which is completely fair, why should they, also by the taping it was only down 8%), but the streams crossed, I saw America directly being exposed to even worse takes than I’m used to straight from TikTok’s algorithm when I was supposed to be relaxing at the end of the day, and I really didn’t like it. Then again, I do bow to one clear way in which China did outperform us. Ethan Mollick: People don’t talk enough about a giant DeepSeek achievement over most US models – it actually has a reasonable name. Scott: Well, yes and no, the model is named r1…. Ethan Mollick: Thats fine as long as the next is r2 If they release anything called r1.5, I swear to God. Sarah (Yuan Yuan Sun Sara from China) suggests perhaps DeepSeek could get into doing AI safety research, maybe even ask for a grant? Certainly there’s great talent there, and I’d love if they focused on those styles of problem. There’d likely be severe corporate culture issues to get through given what they’ve previously worked on, but it’s worth a shot. Stephen McAleer: I’m hopeful we will figure out how to control superintelligence! Fouad: you at the office? could use some code review on superintelligence_control.py before i merge Stephen McAleer: It can surely wait until Monday. I increasingly worry about the pattern of OpenAI safety researchers thinking about how to ‘control’ superintelligence rather than align it, and how this relates to the techniques they’re currently using including deliberative alignment. (Note: I still owe that post on Deliberative Alignment, coming soon.) Are reasoning models including r1 a blackpill for robotics progress? Kyle Stachowicz: R1’s RL findings are great news for reasoning but grim for robotics. All the major takeaways (ground-truth reward, great base models, grouped rollouts from same initial state, sample-inefficient on-policy algos) are really hard to translate to the physical world. Chris Paxton: Hot deepseek take: before r1 blew up, a ton of western AI (and robotics!) efforts — startups, big companies, and even academic labs — were basically just waiting for openai to solve all their problems and it was honestly kind of sad. I hope r1 changed that Scott Reed: True. A lot of groups gave up prematurely, or allocate ~all resources to one giant model. This leads people to spend more effort on winner-take-all gpu politics and less on just training the best models they can with moderate resources. If anyone wondered what happened to Gato2, gpu game of thrones is (at least partly) what. An interesting counterfactual was the Genie project, which was stubbornly cobbled together mainly out of pooled user quota. This kind of stubborn independence can lead to cool results! “Um This scaling law model I made says [the world will end / company will die] if you dont give me all the GPUs and block any other team from pretraining” “No, f*** you, I will train my own model” Yes and no, right? It’s going to be relatively hard, but seems super doable to me, I know those in the field will say that’s naive but I don’t see it. The real physical world absolutely 100% has ground truth in it. If you want to train on an accurate reward signal, there’s various trickiness, but there are plenty of things we should be able to measure. Also, with time we should get increasingly strong physics simulations that provide increasingly strong synthetic data for robotics, or simply have so much funding that we can generate physical samples anyway? We’re sample-inefficient relative to a human but you can train a decent reasoning model on 17k data points, and presumably you could bootstrap from there, and so on. I am not going to quote or name particular people directly on this at this time. But as Obama often said, let me be clear. Reasonable people can disagree about: However. The existence of DeepSeek, and its explicit advocacy of open weights AGI, and potentially having it be the best model out there in the future in many people’s imginations, has been a forcing function. Suddenly, people who previously stuck to ‘well obviously your restrictions are too much’ without clarifying where their line was, are revealing that they have no line. And many more people than before are revealing that they prefer any or all of: These people are often saying, rather explicitly, that they will use whatever powers they have at their disposal, to ensure that humanity gets to a position that, if you think about it for a minute or five, humanity probably cannot survive. And that they will oppose, on principle, any ability to steer the future, because they explicitly oppose the ability to steer the future, except when they want to steer the future into a state that cannot then be steered by humans. No, I have not heard actual arguments for why or how you can put an aligned-only-to-user AGI into everyone’s desktop or whatever, with no mechanism of collective control over that whatsoever, and have this end well for the humans. What that future would even look like. Nor have I heard any argument for why the national security states of the world, or the people of the world, would ever allow this. The mask on those is fully off. These people don’t bother offering arguments on any of that. They just say say, essentially, ‘f*** you safetyists,’ ‘f*** you big tech,’ ‘f*** you United States,’ and often effectively ‘f*** you rest of humanity.’ They are the xenocide caucus, advocating for things that cause human extinction to own the in-context-libs. If that is you: I thank you for your candor. Please speak directly into this microphone. I disagree in the strongest possible terms. As always, be excellent to each other, and all that. A large part of this job I’ve assigned to myself is to do a f***ton of emotional labor. You have people who are constantly telling you that you’re a cartoon villain because you think that the United States government might want to know if someone trains a frontier model, or that you might think releasing a literal AGI’s weights would be unwise, or that we shouldn’t let China get our best GPUs. You get called statist and totalitarian for positions that are 95th to 99th percentile libertarian. You get outright lies, all the time, from all directions. Much from people trying to incept the vibes they want. And so on. And the same stuff to varying degrees coming from other directions, too. Honestly I’m kind of used to it. Up to a point. You get somewhat numb, you build up some immunity, especially when the same sources do it over and over. I accept it. And even with that, you have to patiently read all of it and respond to the arguments and also try to extract what wisdom might be there from the same sources that are filled with the toxoplasma of rage and trying their best to infect me and others like me as well. But it’s been a trying time. I see a world determined to try and go down many of the craziest, most suicidal paths simultaneously, where I’m surrounded by equal and opposite bad takes in many dimensions. Where the odds are against us and the situation is grim. In ways that I and others warned about explicitly, including the exact ways and dynamics by which we reached this point. Make no mistake. Humanity is losing. Meanwhile, on top of all the Being Wrong on the Internet, the toxoplasma is as bad as it has ever been, with certain sources going so far as to in large part blame not only worried people in general but also me specifically by name for our current situation – and at least one of those people I feel compelled to continue to listen to because they also have unique insights in other ways and I’m sometimes told I have a blind spot there – which I actually rarely hear about other credible sources. And I still try. But I’m only human and it’s just so damn hard at this point. Especially when they rage about things I said that turned out to be true, and true for exactly the reasons I said they’d be true, but I know trying to point this out wouldn’t do any good. I don’t know what my solution here is going to be. I do know that things can’t go on like this, I know life isn’t fair and reality doesn’t grade on a curve and someone has to and no one else will but also I only have so much in the tank that handles these things. And I’m going to have to budget that tank, but I want to be clear that I’m going to be doing that, and dropping certainly sources for this reason that I would otherwise have included for completeness. If this was talking about you, and you’d like to continue this trip, please get it together. Don’t worry, your argument remains valid. I mean, it’s wrong, but that never stopped you before, why start now? Time comes for us all. Matt: Live players in who kills us first? Peter Wildeford: Yes, that’s one way to look at it. I believe that opensource advancements like R1 will drive wider adoption of ai systems. I think that the pricing models will change soon. Everyone talks about cost per million tokens to contact a hosted service, but I think it'll switch to be cloud costs to provide infrastructure that can run models. Virtual machines running something like ollama. This solves another huge problem, privacy and how prompt data is handled. If you're using an api to a hosted service you need to have a very good understanding of how your submitted prompt data is handled. This is key for organisations. I feel like the lack of understanding here is preventing widespread adoption, especially for communication tools that handle sensitive data. For example, you could run Deepseek R1 using ollama on an Azure virtual machine (nc series) that you pay per hour for, and then your cost isn't based on usage of your ai. Right now it's expensive to provision the infra to support decent models, but these costs fall continuously. I can imagine a world where organisations provision cloud infrastructure in their environments running open source models. https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/gpu-accelerated/nc-series?tabs=sizebasic https://huggingface.co/deepseek-ai/DeepSeek-R1 Is there any other consumer software that works on this model? I can't think of any Some enterprise software has stuff like this New benchmark agrees with my intuitions on r1's creative writing skills: https://x.com/LechMazur/status/1885430117591027712
--------------------------------------------------

Title: Jim Cramer's top 10 things to watch in the stock market Friday
URL: https://www.cnbc.com/2025/01/31/jim-cramers-top-10-things-to-watch-in-the-stock-market-friday.html
Time Published: 2025-01-31T13:59:10Z
Full Content:
Credit Cards Loans Banking Mortgages Insurance Credit Monitoring Personal Finance Small Business Taxes Help for Low Credit Scores Investing SELECT All Credit Cards Find the Credit Card for You Best Credit Cards Best Rewards Credit Cards Best Travel Credit Cards Best 0% APR Credit Cards Best Balance Transfer Credit Cards Best Cash Back Credit Cards Best Credit Card Welcome Bonuses Best Credit Cards to Build Credit SELECT All Loans Find the Best Personal Loan for You Best Personal Loans Best Debt Consolidation Loans Best Loans to Refinance Credit Card Debt Best Loans with Fast Funding Best Small Personal Loans Best Large Personal Loans Best Personal Loans to Apply Online Best Student Loan Refinance SELECT All Banking Find the Savings Account for You Best High Yield Savings Accounts Best Big Bank Savings Accounts Best Big Bank Checking Accounts Best No Fee Checking Accounts No Overdraft Fee Checking Accounts Best Checking Account Bonuses Best Money Market Accounts Best CDs Best Credit Unions SELECT All Mortgages Best Mortgages Best Mortgages for Small Down Payment Best Mortgages for No Down Payment Best Mortgages with No Origination Fee Best Mortgages for Average Credit Score Adjustable Rate Mortgages Affording a Mortgage SELECT All Insurance Best Life Insurance Best Homeowners Insurance Best Renters Insurance Best Car Insurance Travel Insurance SELECT All Credit Monitoring Best Credit Monitoring Services Best Identity Theft Protection How to Boost Your Credit Score Credit Repair Services SELECT All Personal Finance Best Budgeting Apps Best Expense Tracker Apps Best Money Transfer Apps Best Resale Apps and Sites Buy Now Pay Later (BNPL) Apps Best Debt Relief SELECT All Small Business Best Small Business Savings Accounts Best Small Business Checking Accounts Best Credit Cards for Small Business Best Small Business Loans Best Tax Software for Small Business SELECT All Taxes Filing For Free Best Tax Software Best Tax Software for Small Businesses Tax Refunds Tax Brackets Tax Tips Tax By State Tax Payment Plans SELECT All Help for Low Credit Scores Best Credit Cards for Bad Credit Best Personal Loans for Bad Credit Best Debt Consolidation Loans for Bad Credit Personal Loans if You Don't Have Credit Best Credit Cards for Building Credit Personal Loans for 580 Credit Score or Lower Personal Loans for 670 Credit Score or Lower Best Mortgages for Bad Credit Best Hardship Loans How to Boost Your Credit Score SELECT All Investing Best IRA Accounts Best Roth IRA Accounts Best Investing Apps Best Free Stock Trading Platforms Best Robo-Advisors Index Funds Mutual Funds ETFs Bonds 1. Apple's earnings report shows why I always say "own it, don't trade it." Where it has launched Apple Intelligence, the iPhone 16 sells better. High-margin services revenues was better. Mac better. Accessories better. Europe better. India better. Expanding gross margins helped make the numbers, too. Shares are up about 4% Friday. 2. China is still a question mark for Apple, though. Revenues down 11% there in the quarter. Apple Intelligence still needs government approval to launch. Rivals Huawei and Xiaomi can access the AI from buzzy Chinese startup DeepSeek. What can Apple get to reverse its fortunes in China? Will Baidu be its AI partner? 3. The U.S. government is looking into whether DeepSeek used third-parties in Singapore to acquire Nvidia chips that Washington has banned in China, according to Bloomberg News. Club name Nvidia says it plays by the rules in Singapore, and that its revenue from the island country does not indicate diversion. 4. We know Tesla, Club stock Meta and Oracle want all the high-end Nvidia chips they can get, even with DeepSeek's emergence. We don't know about Club names Alphabet or Amazon, which both report next week. What if one of the two says we are reassessing our orders for Nvidia's next-gen AI platform Blackwell? What happens to the stock? What if Amazon, another Club holding, says it's leaning into using AMD? I made a call on Nvidia stock for Club members yesterday. 5. Geopolitics remain part of the Nvidia dilemma. Does DeepSeek have a juicer that can make 10 glasses of orange juice out of a single orange, or does it have 10 government-subsidized juicers that it just won't tell us about? If it is 10 juicers, I worry that President Donald Trump will just ban all semiconductor exports to China. 6. Trump's 25% tariffs on imports from Canada and Mexico, currently set to take effect Saturday, may exclude oil, the president told reporters Thursday night. U.S. oil benchmark WTI was slightly higher Friday, to roughly $73 barrel. The U.S. dollar index strengthened, but it's still below its recent highs set earlier this month. 7. The S&P 500, Nasdaq and Dow Jones Industrial Average were all set to open higher Friday. Stock futures held onto their gains after the Federal Reserve's preferred inflation gauge matched expectations for December. The PCE index rose 0.3% month over month and, when excluding food and energy, 2.8% on an annual basis. 8. Intel showed some cost discipline and improved cash flow in its quarterly results. But the fourth quarter is typically strong for them, and there might have been some pull-through ahead of higher tariffs on Chinese imports. The PC market is weak. JPMorgan and Wells Fargo cut their price targets on the struggling chip stock. Shares added more than 1% Friday. 9. Atlassian shares jumped almost 20% on the back of a very good quarter. The company, which trades under the ticker TEAM, makes pure enterprise software that makes it easier to share and simplify. Seems unstoppable. 10. Vertex Pharmaceuticals' non-opioid painkiller Journavx, which blocks pain signals sent to the brain at their origin. This drug could be a blockbuster, and it's been on my radar for a while now. Vertex shares climbed about 3% Friday. Sign up for my Top 10 Morning Thoughts on the Market email newsletter for free (See here for a full list of the stocks at Jim Cramer's Charitable Trust.) As a subscriber to the CNBC Investing Club with Jim Cramer, you will receive a trade alert before Jim makes a trade. Jim waits 45 minutes after sending a trade alert before buying or selling a stock in his charitable trust's portfolio. If Jim has talked about a stock on CNBC TV, he waits 72 hours after issuing the trade alert before executing the trade. THE ABOVE INVESTING CLUB INFORMATION IS SUBJECT TO OUR TERMS AND CONDITIONS AND PRIVACY POLICY, TOGETHER WITH OUR DISCLAIMER. NO FIDUCIARY OBLIGATION OR DUTY EXISTS, OR IS CREATED, BY VIRTUE OF YOUR RECEIPT OF ANY INFORMATION PROVIDED IN CONNECTION WITH THE INVESTING CLUB. NO SPECIFIC OUTCOME OR PROFIT IS GUARANTEED. Got a confidential news tip? We want to hear from you. Sign up for free newsletters and get more CNBC delivered to your inbox Get this delivered to your inbox, and more info about our products and services. © 2025 CNBC LLC. All Rights Reserved. A Division of NBCUniversal Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis. Data also provided by
--------------------------------------------------

Title: How DeepSeek Could Really Disrupt Big Tech
URL: https://www.theatlantic.com/ideas/archive/2025/01/deepseek-ai-investment-tech/681516/
Time Published: 2025-01-31T12:46:00Z
Full Content:
The Chinese app has already hit the chipmaker giant Nvidia’s share price, but its true potential could upend the whole AI business model. Produced by ElevenLabs and News Over Audio (Noa) using AI narration. Listen to more stories on the Noa app. Only rarely does a single company’s new product provoke a major market sell-off. But that’s exactly what happened on Monday, when a large language model from a Chinese company named DeepSeek drove the entire Nasdaq index of tech companies down more than 3 percent and shaved more than 17 percent off the market capitalization of the chipmaker Nvidia—which, until that moment, had been the most valuable company in the world. The panicked selling of Nvidia had a surface logic. The company provides almost all of the computer chips (called GPUs) that companies such as Alphabet, OpenAI, Microsoft, and Meta rely on to train their LLMs. (The Atlantic entered into a corporate partnership with OpenAI in 2024.) Consequently, it has been the biggest beneficiary of the huge boom in corporate spending on AI that we’ve seen over the past few years. (Nvidia’s annual revenue has quadrupled since 2022.) Although DeepSeek also used Nvidia chips to train its model, the company said that they were an older type of GPU—U.S. export controls imposed by the Biden administration have prevented Chinese companies from buying cutting-edge chips. DeepSeek’s disclosure raises the possibility that future progress in training LLMs could be made with fewer, simpler chips, and at a lower cost than previously anticipated. That would obviously put a big dent in Nvidia’s profits. So investors dumped its stock. Read: The DeepSeek wake-up call If investors are very concerned about how DeepSeek might hurt chipmakers, they seem surprisingly unconcerned about how it might affect big AI software companies. Meta’s stock price, for instance, actually rose on Monday, and although the stocks of Alphabet and Microsoft did take a hit, they bounced back over the next couple of days. Some of that is because the underlying business of these companies, independent of AI, remains enormously profitable. But it also suggests that investors aren’t paying enough attention to the way DeepSeek’s success could disrupt the AI market, and in doing so threaten the future profits of the tech companies that are currently spending many billions of dollars every year on their LLMs. Tech investors have historically profited by spotting the new new thing. But at the moment, they seem implicitly to assume that all of the fundamental change in the LLM business has already happened and that its future will look much like its present, with the companies that currently dominate the space—many of which are not simply competitors but also financial partners—continuing to do so indefinitely. What happened over the past week is a reminder that these assumptions may not be so solid. The large language model that caused such a stir on Monday, DeepSeek-R1, is clearly comparable with LLMs such as ChatGPT o1-mini and Claude 3.5. Measured by industry benchmarks that rate subject knowledge, reasoning, and accuracy, the DeepSeek model seems to deliver similar performance while costing much less to develop—though just how much less remains a matter of debate. Beyond dispute is that it’s cheaper to use: Consumers can get access to DeepSeek’s core functions for free, and third-party developers are being charged a fraction of the cost of a product such as ChatGPT. DeepSeek also uses open-source technology, meaning that, in theory, you could download the program and run your own AI on your desktop if you had a powerful-enough computer. The fact that the LLM offers reasonable performance—results that, even a year ago, would have seemed startlingly good—at a significantly lower cost means that it has to be taken seriously as a competitor. From one angle, in fact, DeepSeek looks like what the business-school professor Clayton Christensen, in his book The Innovator’s Dilemma, dubbed a “disruptive technology”: a product that’s less powerful than the products at the top of the market but also much cheaper, and that has the possibility of improving in quality over time to the point where it offers a superior combination of price and performance for most customers. In this regard, the rapid uptake of DeepSeek by users around the world has been striking. The LLM still has miles to go in market share to catch ChatGPT, which has more than 300 million weekly users, but since its release on January 20, its mobile-app version has been downloaded more than 3 million times from Google Play and Apple, making it the most popular app on both stores. That suggests that the cost of switching from one AI tool to another is very low, and that the moats big AI companies are building around their business may be much shallower than they’d hoped. Read: China’s DeepSeek surprise The underlying wager that these companies have made is that the big money they’re investing will result in radically better performance, which in turn will enable them to charge hefty sums to businesses and, to a lesser extent, consumers. (OpenAI, for instance, is reportedly targeting $100 billion in revenue by 2029.) And these companies remain committed to that bet. This week, the CEOs of both Microsoft and Meta said that enormous spending is essential to staying competitive in the market. Dario Amodei, a co-founder and the CEO of Anthropic (in which both Amazon and Google have invested heavily), wrote in a blog post that companies are going to continue to “spend more and more on training powerful AI models, even as … the cost of training a given level of model intelligence declines rapidly,” because “the economic value of training more and more intelligent models is so great.” In the long run, such investment may well result in the kind of performance improvement that a company like DeepSeek (which can’t even get access to the most powerful GPUs)—or the many other low-cost LLM developers that are sure to try to emulate it—cannot keep up with. When you look at ordinary users’ embrace of DeepSeek, though, you can also see an alternative future. In this one, AI performance improves so much that most customers are happy with cheap, good-enough LLMs, and AI models end up as essentially interchangeable, commoditized products, with the small profits that always follow that type of commercial diffusion. We’re going to find out whether the great authors of the disruptive technology that’s transforming the business world might themselves get disrupted. Support for this project was provided by the William and Flora Hewlett Foundation. More Stories The Hysterical Crypto Bubble Somehow Became Respectable The Trump-Whim Economy Is Here
--------------------------------------------------

Title: An Interview with Matthew Ball About the Gaming Slump
URL: https://stratechery.com/2025/an-interview-with-matthew-ball-about-the-gaming-slump/
Time Published: 2025-01-31T11:30:50Z
Full Content:
Stratechery Plus Learn MoreMember Forum Stratechery Plus Learn MoreMember Forum Latest Podcast Listen to Podcast Subscribe to Stratechery Plus for full access. Already subscribed? With Stratechery Plus you get access to the subscriber-only Stratechery Update and Stratechery Interviews, and the Sharp Tech, Sharp China, Dithering, Greatest of All Talk, and Asianometry podcasts. Stratechery UpdateSubstantial analysis of the news of the day delivered via three weekly emails or podcasts. Stratechery InterviewsInterviews with leading public CEOs, private company founders, and discussions with fellow analysts. DitheringA twice-weekly podcast from John Gruber and myself: 15 minutes an episode, not a minute less, not a minute more. Sharp TechAndrew Sharp and myself discuss how technology works and the ways it impacts our lives. Sharp ChinaA weekly podcast from Andrew Sharp and Sinocism’s Bill Bishop about understanding China and how China impacts the world. Greatest Of All TalkA twice-weekly podcast from Andrew Sharp and Ben Golliver about the NBA, life, and national parks. AsianometryAudio and transcripts of the Asianometry YouTube channel, the best source for learning about how tech works. Stratechery Updates are also available via SMS, RSS, or on this site. Please see the Stratechery Update Schedule for more details about delivery times and planned days-off. Please note that all subscriptions auto-renew monthly/annually (but can be cancelled at any time). If you are interested in ordering and managing multiple subscriptions for your team or company, please fill in the form here. Once you are subscribed, please visit your Delivery Preferences where you will find easy-to-follow instructions for adding Stratechery Podcasts to your favorite podcast player. Yes! Create a Stratechery Passport account, go to Delivery Preferences, and add your personalized RSS feed. Free accounts will have access to Weekly Articles, while subscribers will have access to the Daily Update as well. No, the Stratechery Update and Stratechery Podcast are intended for one subscriber only. Sharing emails, using shared inboxes, or sharing RSS feeds is a violation of Stratechery’s Terms of Service, and your account may be suspended or your RSS feed reset. Of course occasional forwarding of the Stratechery Update to interested friends or colleagues is totally fine. Yes! You can purchase a team subscription here. Yes! Just go to your account page, choose the ‘Subscriptions’ tab, and click the Annual upgrade button. You will be charged immediately, with a prorated discount applied for the remainder of your current monthly plan. Stratechery is purposely kept at a low price — thousands of dollars less than other analyst reports or newsletters — to ensure it is accessible to everyone, including students. I am happy to create an invoice to your specification for annual subscribers; however, it is simply not viable for me to offer this service to monthly subscribers. Therefore, if you need a custom invoice please subscribe or switch to an annual subscription and contact Stratechery. June 1, 2021 Update: We are hoping to add native support for custom invoices to Passport; you can subscribe to Passport Updates to be notified when it is available. Yes! To send a gift visit the gifts page. Stratechery Plus Updates Stratechery Plus Podcasts Stratechery Plus Interviews The most popular and most important posts on Stratechery by year. Explore all free articles on Stratechery. Explore all posts on Stratechery. Stratechery Plus UpdateS Stratechery Plus Podcasts Stratechery Plus Interviews © Stratechery LLC 2025 | Terms of Service | Privacy Policy Proudly powered by WordPress. Hosted by Pressable.
--------------------------------------------------

Title: M.M., Tempi, and the fainthearted, rumors of an acquisition by Piraeus bank, DEI and the Norwegians, and the… progressive lobbies of the stock market
URL: https://en.protothema.gr/2025/01/31/m-m-tempi-and-the-fainthearted-rumors-of-an-acquisition-by-piraeus-bank-dei-and-the-norwegians-and-the-progressive-lobbies-of-the-stock-market/
Time Published: 2025-01-31T09:39:22Z
Full Content:
Tempi and Government Stress Levels Hello, the Tempi case continues to dominate public interest while also creating an extremely stressful situation within the government’s ranks, to the point where, dare I say, most of them are on the verge of a nervous breakdown. Not all of them, of course—there are also the level-headed ones who view Mitsotakis’ public appearance as a “necessary move for partial de-escalation and as proof to the public that the Prime Minister is listening, taking responsibility, and trying to solve problems, even assuming full accountability.” However, this is merely the calm assessment of some officials. There’s also the classic “fainthearted” reaction: “We’re doomed! The reports, the Preliminary Investigations, the trials are coming, and we’ll be entangled in this mess indefinitely.” Now, let me tell you what I know from my sources: First, the NTUA report, according to my information, will be ambiguous—it will state that the fireball was not caused by the lubricants used in the train’s engine, but at the same time, it will not confirm the presence of any flammable material. A report by a Belgian expert is expected to lean slightly more towards the existence of some quantity of flammable substance, but there are also reports suggesting otherwise. The government’s response to all this will be the obvious one: “Let everything go to the judiciary and let them draw the appropriate conclusions.” Second, regarding whether there will be a Preliminary Investigation Committee, the answer from an official source is crystal clear: “We’ve said dozens of times that if the Prosecutor’s indictment includes political figures, the government will facilitate the process and accept the establishment of a Preliminary Investigation Committee. But only if the judiciary requests it—not based on lawsuits filed by the victims’ families.” Third, the Tempi trial has been expected since day one. The government, through Floridis, even amended the law to expedite it, unlike the Mati trial, which took six years to begin. These are the facts, and this is the government’s approach. Where responsibility remains unclear is in what has been done from the time of the accident until now to allow the state to credibly say: “Here are the measures we’ve taken to drastically reduce the chances of this tragedy happening again.” Because, let’s not forget, accidents will always happen—whether in Washington, at the heart of the most technologically advanced transport system, or anywhere else. Also, a legal expert told me that the infamous case of backfilling (of the tracks) constitutes only a misdemeanor. As soon as K.M. (Kyriakos Mitsotakis) made statements about the Investigation Committee, former members of such committees turned pale. Many prominent figures involved avoided answering phone calls, something the government picked up on and decided to do some political “massaging.” The message from the government was that the Prime Minister’s position was a general one—this is his standard stance on Investigation Committees, which rarely produce clear conclusions. Therefore, the judiciary should be the one to provide the answers. I’m not sure if this improved anyone’s morale, but such is politics. February will be a long and rough month for the government, with various reports and inquiries on the way. Now, in M.M. (Maximos Mansion, the Greek Prime Minister’s office), they are not politically naive. They were not surprised by Androulakis’ intention to file a no-confidence motion against the government. The timing, of course, is the crucial factor. It’s clear that Androulakis is waiting for both the NTUA report and the report from EODASAAM (due on February 27) before making his move—coinciding with the second anniversary of the Tempi disaster. Obviously, he aims to align with public sentiment—thousands protesting in the streets while the government faces pressure in Parliament. Notably, this will be the second no-confidence motion filed by PASOK within a year. And to be fair, Androulakis is simply doing his job. Today’s Cabinet meeting, of course, is overshadowed by the Tempi case and the announcement of the no-confidence motion, but there are serious issues on the agenda. One of them is the Ministry of Education’s initiative to hire 600 priests over the next three years for the Greek-speaking Patriarchates. This has been a long-standing request of Patriarch Bartholomew, and Pierrakakis intends to grant it. It’s also a move with geopolitical significance, as Greece seeks to expand its soft power in the region, strengthening its influence through its Christian heritage. Now, let’s turn to market news, where all eyes are on a major move being prepared (intensely) by H. Megalou. But with acquisitions, you never really know—things usually turn out differently from what the market senses. Sources indicate that within the next two or three days, it will become clear whether Piraeus Bank’s plan will materialize. The very few details available suggest an acquisition, and not just any acquisition—a large-scale one. So, the “usual suspects” are ruled out. One rumor that surfaced on Dark Room’s radar—and let me stress, this is just a RUMOR, NOT VERIFIED INFORMATION—is that H. Megalou’s big move is towards acquiring Ethniki Asfalistiki (National Insurance). Given that acquisitions often turn out different from market expectations, this scenario could be plausible. But it’s not simple or easy—National Insurance’s bancassurance agreement is with National Bank of Greece, and I don’t know what penalties or clauses that contract might include. However, if this deal is indeed in the works, I assume they have found a way around it. Strategically, it would make sense, as the ECB’s rapid interest rate cuts are pushing banks to seek acquisitions in sectors with high commission revenues. I don’t know the details, but it seems that market rumors about a small lobby that has grabbed Proodeftiki’s stock and sent it skyrocketing are not unfounded. The stock has closed higher for five consecutive sessions. From €0.28, it has surged to €0.376 (+34%). In two of those five sessions, it gained over 9%, and yesterday it closed up 5.6%. Proodeftiki used to be a construction company—now, I have no idea what they do (some say real estate), but for all I know, they might as well be in aerospace. Recent developments in Artificial Intelligence have a uniquely Greek angle. A startup called AI-Employee has been operating in Greece and launched a soft rollout 10 days ago. What do they do? They “rent out” AI executives to large corporations. These specialized employees enter companies with their own hardware and localized AI models. In fact, as founder John Doxaras announced on LinkedIn, AI-Employee “sold out” in record time, managing to place ALL of its available AI professionals. These AI-powered employees come equipped with AI agents, work within organizations to solve problems on the spot, develop new applications and solutions, and provide extensive training on AI prompting. Despite being just two weeks old, the Greek startup has already attracted clients from the banking sector, telecommunications, and even government agencies. Now, let’s head to Paris, specifically to the Palais-Royal area, where the Greek Roadshow by Piraeus Securities took place at Espace Clery. The event featured Greece’s top publicly traded companies, and French fund managers showed intense interest, with 150 meetings held with 30 different funds—compared to last year’s 116 meetings with 24 funds. As an investor relations executive from a participating company explained, the French investment market is challenging due to its broad spectrum of investors. Some funds are highly targeted and long-term, seeing opportunities in Greece, while others, as one analyst put it, are starting “from scratch” with no real knowledge of the Greek market. However, what stood out to many IR professionals and executives was the sense of instability surrounding France’s economic and political outlook, a concern that surfaced repeatedly in discussions. Regarding Greek assets, the French highlighted clear advantages, such as Greece’s regained investment-grade rating, its comparatively strong economic growth within the EU, and high dividend yields. PPC (Public Power Corporation) is charging toward a €5 billion market cap, with its stock price at €13.27—an 11-year high. Norway’s sovereign wealth fund, the Norges Fund, known as the ultimate “long-only fund,” consistently invests in “green” projects and has officially acquired a 0.14% stake in PPC, though market whispers suggest its actual holding is higher. Over the past three months, 23.5 million PPC shares have changed hands, with the stock price rising more than 10.6%. This surge in activity has fueled fresh speculation about PPC’s next big deal, one that CEO Giorgos Stassis is rumored to be working on—though lately, he’s been keeping a low profile. The stock of Viohalco, the parent company of the Viohalco Group, has gained roughly 14% over the past month, reaching €6.10. Its market capitalization now exceeds €1.58 billion, while its 72%-owned subsidiary, Cenergy, has surpassed €2 billion (€9.60 per share, up 2.24% yesterday). This means that all the other subsidiaries within the group—ElvalHalcor, Noval Property, etc.—are currently valued at essentially zero, despite the fact that the group as a whole contributes 8% of Greece’s GDP. Unless the sky falls on our heads today, the General Index will log its fourth consecutive positive week of 2025 and its sixth straight week of gains since mid-December 2024. The index hasn’t closed above 1,550.72 points (+0.3%) since way back on April 7, 2011. However, with trading volume at €108.9 million (of which €8.2 million came from block trades), the rally isn’t exactly convincing. In fact, buyers were largely absent for most of yesterday’s session, only showing up after 4 PM to keep heavyweight stocks in positive territory. Coca-Cola, Eurobank, and Motor Oil propped up the index, while other blue-chip stocks simply managed to shake off their earlier losses and stabilize. Not one, not two, but a whopping 35-minute delay (!) in announcing its earnings sent Mark Zuckerberg’s META (who, by the way, is house-hunting in Washington to be as close as possible to Trump) into a tailspin, causing a mini-meltdown on Wall Street. In that half-hour, META’s stock price swung wildly up and down based on AI-related rumors. In the end, META beat analyst expectations on both revenue and earnings per share ($8.02/share), bringing in $48.4 billion in revenue. Microsoft’s stock went through a similar ordeal—it posted stronger-than-expected profits but weak cloud revenue, and in this new AI-driven market, everything counts. Amid all this digital economy turbulence, one thing that truly shines is gold, which hit a new all-time high of $2,840 per ounce, marking a staggering 40% gain over the past 12 months. “If the Fed had spent less time on DEI—the Diversity, Equity, and Inclusion strategy—gender ideology, ‘green’ energy, and the fake climate change, inflation would never have been a problem. Instead, we suffered from the worst inflation in our country’s history.” The term of U.S. Federal Reserve Chairman Jerome Powell ends in 15 months, in May 2026. President Trump’s war against the Fed began on day one of his presidency. His view is that by increasing oil supply (“drill baby drill”), he will lower energy prices and, in turn, reduce inflation, leading to lower interest rates. Since January 20, crude oil and natural gas prices have dropped by more than 10%. Energy affects the Consumer Price Index by approximately 8%. However, energy costs also influence food prices and other services. Since Trump’s reelection in November, U.S. gasoline prices have dropped to $3.08 per gallon, close to the lowest level since 2021. Consequently: A $10 decrease in oil prices would reduce U.S. inflation by 0.2%. If oil prices fall to around $50, inflation could drop by nearly half a percentage point. However, the Fed’s priority is not just price stability—it also includes employment and economic stability. Some Federal Reserve Board members are Republicans (such as the St. Louis Fed banker), but they do not share Trump’s urgency to cut interest rates on the dollar, as the large public debt forces the Fed to borrow at high costs. The Trump-Powell war is only in its first phase. The German government announced the day before yesterday that economic growth in 2025 will barely exceed +0.3%, despite initial forecasts of +1.6%, later revised to +1.1%, and ultimately proven wrong. Yesterday, it was officially confirmed that in the fourth quarter of the year, Germany’s economic growth rate was negative (-0.2%), even worse than the initial estimates (-0.1%). Key economic indicators, such as the Ifo Business Climate Index or incoming orders, provide little reason for optimism. The elections in Germany are taking place in an atmosphere of general uncertainty, and we all know where that leads. Explore related questions
--------------------------------------------------

Title: Why stock market is rising today: 5 key factors behind today's rally; Sensex soars 600 pts, Nifty above 23,400
URL: https://economictimes.indiatimes.com/markets/stocks/news/why-stock-market-is-rising-today-5-key-factors-behind-todays-rally-sensex-soars-600-pts-nifty-above-23400/articleshow/117783991.cms
Time Published: 2025-01-31T09:37:02Z
Full Content:
Stock Trading Maximise Returns by Investing in the Right Companies By - The Economic Times, Get Certified By India's Top Business News Brand Stock Trading Market 104: Options Trading: Kickstart Your F&O Adventure By - Saketh R, Founder- QuickAlpha, Full Time Options Trader Stock Trading Technical Analysis for Everyone - Technical Analysis Course By - Abhijit Paul, Technical Research Head, Fund Manager- ICICI Securities Stock Trading Stock Markets Made Easy By - elearnmarkets, Financial Education by StockEdge Stock Trading Renko Chart Patterns Made Easy By - Kaushik Akiwatkar, Derivative Trader and Investor Stock Trading Market 101: An Insight into Trendlines and Momentum By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading Markets 102: Mastering Sentiment Indicators for Swing and Positional Trading By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading Dow Theory Made Easy By - Vishal Mehta, Independent Systematic Trader Stock Trading Market 103: Mastering Trends with RMI and Techno-Funda Insights By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading ROC Made Easy: Master Course for ROC Stock Indicator By - Souradeep Dey, Equity and Commodity Trader, Trainer Stock Trading Heikin Ashi Trading Tactics: Master the Art of Trading By - Dinesh Nagpal, Full Time Trader, Ichimoku & Trading Psychology Expert Stock Trading RSI Made Easy: RSI Trading Course By - Souradeep Dey, Equity and Commodity Trader, Trainer Stock Trading Introduction to Technical Analysis & Candlestick Theory By - Dinesh Nagpal, Full Time Trader, Ichimoku & Trading Psychology Expert (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price Fleeing FIIs and nervous futures: Can FM calm the markets? 133% gains in 2024; worst performer in 2025 so far. Is Trent still a good buy? You can shop till you drop at duty free if FM heeds this proposal by airports Chinese DeepSeek is an existential threat to OpenAI and Google 5 reasons the middle class is facing consumption squeeze. Can the Budget help? How significant is the Union Budget for the common man? All Mutual Funds Top Tax Saving Mutual Funds Better Than Fixed Deposits Low Cost High Return Funds Best Hybrid Funds Best Large Cap Funds SIP’s starting Rs. 500 Top Performing Mid Caps Promising Multi Cap Funds Top Rated Funds Top Performing Index Funds Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Definitions Top Commodities Top Prime Articles Top Slideshow Top Story Listing Top Market Pages Private Companies Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Worry not. You’re just a step away. It seems like you're already an ETPrime member with Login using your ET Prime credentials to enjoy all member benefits Log out of your current logged-in account and log in again using your ET Prime credentials to enjoy all member benefits. To read full story, subscribe to ET Prime ₹34 per week Billed annually at ₹2499 ₹1749 Super Saver Sale - Flat 30% Off On ET Prime Membership Offer Exclusively For You Save up to Rs. 700/- ON ET PRIME MEMBERSHIP Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get Flat 40% Off Then ₹ 1749 for 1 year Offer Exclusively For You ET Prime at ₹ 49 for 1 month Then ₹ 1749 for 1 year Special Offer Get flat 35% off on ETPrime 90 Days Prime access worth Rs999 unlocked for you Exclusive Economic Times Stories, Editorials & Expert opinion across 20+ sectors Stock analysis. Market Research. Industry Trends on 4000+ Stocks ​Get 1 Year Complimentary Subscription of TOI+ worth Rs.799/-​ Stories you might be interested in
--------------------------------------------------

Title: Chinese state-linked accounts hyped DeepSeek AI launch ahead of US stock rout: report
URL: https://economictimes.indiatimes.com/tech/technology/chinese-state-linked-accounts-hyped-deepseek-ai-launch-ahead-of-us-stock-rout-report/articleshow/117768215.cms
Time Published: 2025-01-31T03:48:14Z
Full Content:
Budget with ET Budget must find a fix for a crisis before it's too late Is India about to add more 'castes' in one day? Will Sitharaman give middle-class consumers some respite from price pain? Artificial Intelligence(AI) Java Programming with ChatGPT: Learn using Generative AI By - Metla Sudha Sekhar, IT Specialist and Developer Artificial Intelligence(AI) Basics of Generative AI: Unveiling Tomorrows Innovations By - Metla Sudha Sekhar, IT Specialist and Developer Artificial Intelligence(AI) Generative AI for Dynamic Java Web Applications with ChatGPT By - Metla Sudha Sekhar, IT Specialist and Developer Artificial Intelligence(AI) Mastering C++ Fundamentals with Generative AI: A Hands-On By - Metla Sudha Sekhar, IT Specialist and Developer Artificial Intelligence(AI) Master in Python Language Quickly Using the ChatGPT Open AI By - Metla Sudha Sekhar, IT Specialist and Developer Marketing Performance Marketing for eCommerce Brands By - Zafer Mukeri, Founder- Inara Marketers Office Productivity Zero to Hero in Microsoft Excel: Complete Excel guide 2024 By - Metla Sudha Sekhar, IT Specialist and Developer Finance A2Z Of Money By - elearnmarkets, Financial Education by StockEdge Marketing Modern Marketing Masterclass by Seth Godin By - Seth Godin, Former dot com Business Executive and Best Selling Author Astrology Vastu Shastra Course By - Sachenkumar Rai, Vastu Shashtri Strategy Succession Planning Masterclass By - Nigel Penny, Global Strategy Advisor: NSP Strategy Facilitation Ltd. Data Science SQL for Data Science along with Data Analytics and Data Visualization By - Metla Sudha Sekhar, IT Specialist and Developer Artificial Intelligence(AI) AI and Analytics based Business Strategy By - Tanusree De, Managing Director- Accenture Technology Lead, Trustworthy AI Center of Excellence: ATCI Web Development A Comprehensive ASP.NET Core MVC 6 Project Guide for 2024 By - Metla Sudha Sekhar, IT Specialist and Developer Marketing Digital Marketing Masterclass by Pam Moore By - Pam Moore, Digital Transformation and Social Media Expert Artificial Intelligence(AI) AI-Powered Python Mastery with Tabnine: Boost Your Coding Skills By - Metla Sudha Sekhar, IT Specialist and Developer Office Productivity Mastering Microsoft Office: Word, Excel, PowerPoint, and 365 By - Metla Sudha Sekhar, IT Specialist and Developer Marketing Digital marketing - Wordpress Website Development By - Shraddha Somani, Digital Marketing Trainer, Consultant, Strategiest and Subject Matter expert Office Productivity Mastering Google Sheets: Unleash the Power of Excel and Advance Analysis By - Metla Sudha Sekhar, IT Specialist and Developer Web Development Mastering Full Stack Development: From Frontend to Backend Excellence By - Metla Sudha Sekhar, IT Specialist and Developer Finance Financial Literacy i.e Lets Crack the Billionaire Code By - CA Rahul Gupta, CA with 10+ years of experience and Accounting Educator Data Science SQL Server Bootcamp 2024: Transform from Beginner to Pro By - Metla Sudha Sekhar, IT Specialist and Developer 5 Stories 7 Stories 9 Stories 9 Stories 8 Stories 6 Stories GenAI is allowing us to challenge incumbents in areas we were not competitive: Mphasis CEO Licious dishes out IPO plans, but 10-min deliveries are adding to the pressure Maruti surges, Hyundai slips: Insights into India’s auto export trends Fed slams the brake on interest rate cuts: What next at RBI? Stock Radar: Indian Hotels stock price is showing signs of bottoming out; what should traders do? Liquor & breweries stocks: Better placed to handle a slowdown? 6 stocks from the ‘sin sector’ with an upside potential of 7 to 54% Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Commodities Top Prime Articles Top Slideshow Private Companies Top Definitions Top Story Listing Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Worry not. You’re just a step away. It seems like you're already an ETPrime member with Login using your ET Prime credentials to enjoy all member benefits Log out of your current logged-in account and log in again using your ET Prime credentials to enjoy all member benefits. To read full story, subscribe to ET Prime ₹34 per week Billed annually at ₹2499 ₹1749 Super Saver Sale - Flat 30% Off On ET Prime Membership Offer Exclusively For You Save up to Rs. 700/- ON ET PRIME MEMBERSHIP Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get Flat 40% Off Then ₹ 1749 for 1 year Offer Exclusively For You ET Prime at ₹ 49 for 1 month Then ₹ 1749 for 1 year Special Offer Get flat 35% off on ETPrime 90 Days Prime access worth Rs999 unlocked for you Exclusive Economic Times Stories, Editorials & Expert opinion across 20+ sectors Stock analysis. Market Research. Industry Trends on 4000+ Stocks ​Get 1 Year Complimentary Subscription of TOI+ worth Rs.799/-​ Stories you might be interested in
--------------------------------------------------

Title: Chinese state-linked accounts hyped DeepSeek AI launch ahead of US stock rout, Graphika says
URL: https://www.aol.com/news/chinese-state-linked-accounts-hyped-031407600.html
Time Published: 2025-01-31T03:14:07Z
Full Content:
For premium support please call: For premium support please call: By Katie Paul and Stephen Nellis NEW YORK (Reuters) - Chinese state-linked social media accounts amplified narratives celebrating the launch of Chinese startup DeepSeek's AI models last week, days before the news tanked U.S. tech stocks, according to online analysis firm Graphika. The accounts involved in the effort, including those of Chinese diplomats, embassies and state media, amplified media coverage of the launch and promoted the idea that DeepSeek challenged U.S. dominance in the AI sector, New York-based Graphika said in a report it provided to Reuters on Thursday. The messaging was rolled out on platforms such as Elon Musk's X and Meta Platforms' Facebook and Instagram, as well as Chinese services Toutiao and Weibo, Graphika said. "This activity shows how China is able to quickly mobilize a range of actors that seed and amplify online narratives casting Beijing as surpassing the U.S. in critical areas of geopolitical competition, including the race to develop and deploy the most advanced AI technologies," Graphika Chief Intelligence Officer Jack Stubbs told Reuters. "We've consistently seen overt and covert Chinese state-linked actors among the first movers in leveraging AI to scale their operations in the information environment." Graphika said it also found a video featuring pro-China, anti-Western content on a YouTube channel whose activity resembled that of Shadow Play, a coordinated influence campaign involving at least 30 YouTube channels that was first identified by the Australian Strategic Policy Institute in 2023. YouTube owner Alphabet, Meta, X and the Chinese embassy in Washington, D.C. did not immediately respond to requests for comment on the report. Graphika said it found a small spike in discussion about DeepSeek's advancements in relation to OpenAI's ChatGPT on X immediately after DeepSeek released its models on Jan. 20, followed by a much larger uptick that started on Friday and continued to build over the weekend. By Monday, DeepSeek's free AI assistant had overtaken U.S. rival ChatGPT in downloads from Apple's app store and global investors dumped U.S. tech stocks, wiping $593 billion off chipmaker Nvidia's market value in a record one-day loss for any company on Wall Street. Nvidia declined to comment on the Graphika report. DeepSeek's researchers claim to have developed aspects of their AI model at a far lower cost than U.S. rivals, sparking worries that U.S. companies that have plowed tens of billions of dollars into AI data centers could face a price war with China. Shares of Microsoft, a major investor in OpenAI that operates data centers on behalf of the ChatGPT creator, slid earlier this week when it disclosed slower cloud revenue growth than Wall Street expected while it continued to plow billions into capital expenditures. Microsoft and Meta have vowed to continue deep investments in AI for the foreseeable future. DeepSeek's rise to prominence was celebrated in China as a sign that the nation was beating back Washington's attempts to contain China's tech industry with curbs on technology exports. In the U.S., DeepSeek's accomplishments sparked accusations that it had improperly accessed technology from OpenAI and other leaders, though the allegations remain unproved. The U.S. Commerce Department is looking into whether DeepSeek has been using U.S. chips that are not allowed to be shipped to China, a person familiar with the matter said. (Reporting by Katie Paul in New York and Stephen Nellis in San Francisco; Editing by Himani Sarkar) Advertisement Advertisement Advertisement Advertisement Advertisement Advertisement Advertisement Advertisement Advertisement Advertisement
--------------------------------------------------

Title: Tech and logistics giants see significant activity in open market
URL: https://qz.com/tech-and-logistics-giants-see-significant-activity-1851752064
Time Published: 2025-01-30T22:55:00Z
Full Content:
This story incorporates reporting from Yahoo, Barron’s on MSN.com and The Associated Press on MSN.com.On January 30, several major stocks, including those of Tesla, Microsoft, Meta, and UPS, saw notable movements in the U.S. stock market. Tesla’s share price fluctuated as investors reacted to the company’s recent earnings report. Microsoft experienced movement linked to the ongoing developments in its cloud computing segment, while Meta’s stock showed responsiveness to new initiatives in virtual and augmented reality technologies. Nvidia observed changes amidst the growing demand in semiconductor markets. IBM’s stock performance was influenced by recent strategic shifts in its technology consulting division. Logistical shifts were evident as UPS’s market activity followed announcements tied to its global operations. Comcast faced dynamic trading amid updates related to its media and theme parks ventures. In the hospitality and travel sectors, Las Vegas Sands experienced stock movement as shifts in travel restrictions impacted its operations. American Airlines saw fluctuations tied to its operational metrics and passenger forecasts. Network technology company Juniper observed increased trading activity, possibly due to announcements about its latest networking solutions. Quartz Intelligence Newsroom uses generative artificial intelligence to report on business trends. This is the first phase of an experimental new version of reporting. While we strive for accuracy and timeliness, due to the experimental nature of this technology we cannot guarantee that we’ll always be successful in that regard. If you see errors in this article, please let us know at qi@qz.com. Our free, fast, and fun briefing on the global economy, delivered every weekday morning.
--------------------------------------------------

Title: How Democrats alienated Big Tech — and why it might not matter
URL: https://www.vox.com/politics/397525/trump-big-tech-musk-bezos-zuckerberg-democrats-biden
Time Published: 2025-01-30T22:02:51Z
Full Content:
When news breaks, you need to understand what matters — and what to do about it. At Vox, our mission to help you make sense of the world has never been more vital. But we can’t do it on our own. We rely on readers like you to fund our journalism. Will you support our work and become a Vox Member today? Democrats have paid a political price for taking on Silicon Valley — but not a very expensive one. by Eric Levitz In January 2017, Sergey Brin rallied beside progressive activists at San Francisco International Airport to protest Donald Trump’s travel ban. Eight years later, the Google co-founder sat with right-wing nationalists at Trump’s second inauguration. Brin is far from the only tech mogul who has (apparently) warmed to Trump in recent years. Mark Zuckerberg once bankrolled liberal causes. Now, the Facebook founder dines with America’s favorite insurrectionist at Mar-a-Lago. In 2016, Marc Andreessen argued that Hillary Clinton was the “obvious choice” for president, and that any proposal to choke off immigration “makes me sick to my stomach.” Last year, Andreessen endorsed Trump. And, of course, Elon Musk has gone from being an Obama-supporting climate hawk to quite possibly the single most influential advocate for — and patron of — far-right politics in the United States. The lessons liberals should take away from their election defeat — and a closer look at where they should go next. From senior correspondent Eric Levitz. Silicon Valley’s apparent rightward shift was already causing consternation in blue America last year. But Democrats’ outrage and anxiety over the red-pilling of Silicon Valley has only increased since Inauguration Day — when Brin, Zuckerberg, Musk, Jeff Bezos, Alphabet CEO Sundar Pichai, and Apple CEO Tim Cook all sat with Trump’s camp in the Capitol Rotunda. Some Democrats view Big Tech’s rightward lurch as a political crisis, one brought on by their own party’s policy mistakes. In this account, Democrats needlessly alienated a powerful industry by embracing an anti-corporate economic agenda that is both politically costly and substantively misguided. Others in the party, meanwhile, insist that the Biden administration’s attempts to tame Big Tech’s power were both good politics and good policy. In their telling, voters hate corporate monopolies and love antitrust enforcement. And the extraordinary wealth and power of large tech companies constitute a threat to democratic government — a reality that Silicon Valley’s present chumminess with Trump only underscores. From this vantage, the tech industry’s interests and the general public’s were always irreconcilable. And as Silicon Valley grew wealthier, it was bound to gravitate toward America’s more pro-business party. The Biden administration’s error, therefore, was not doing too much to antagonize Big Tech, but too little. This debate collapses together several distinct questions. Some of these are ideological — such as whether the Biden administration’s approach to antitrust enforcement was worthwhile on the merits. Today though, I want to focus on two factual questions at the center of the intra-Democratic dispute over Big Tech: I think the answers to both these questions are more complicated than either progressive or pro-business Democrats allow. To understand why Silicon Valley has moved right in recent years, it’s helpful to consider what had previously tethered the industry to the center-left. Many in the tech world argue that Silicon Valley and the Democratic Party were long bound by an implicit “deal”: Democrats would support the development of new technology, celebrate entrepreneurs, and take a light touch approach to regulating the digital sphere — in exchange for tech moguls backing socially liberal causes, progressive taxation, incremental expansions of the welfare state, philanthropies, and Democratic candidates. This was a pretty good bargain for the typical tech founder — since it effectively entailed the Democratic Party embracing nearly all of their preferences. Survey data on the views of Silicon Valley moguls is limited. But a 2017 study of tech entrepreneurs’ politics found that they were left-leaning on almost all issues — including taxation and redistribution — but quite right-wing on questions of government regulation and labor unions. This distinct ideological profile has been dubbed “liberal-tarian.” Given that Democrats have always been the party more supportive of regulating industry and promoting organized labor, the party’s alliance with tech was long fraught with some tension. But in recent years, both sides began souring on their supposed contract for a variety of reasons. But three were especially significant: When an industry is enjoying explosive growth, it has less incentive to align with the right. Democrats might nibble into its profits with their relatively high taxes, or inch its compliance costs with their greater regulatory scrutiny. But when your sector is awash in cheap financing and soaring revenues, the price of allying with a left-of-center party can look negligible. As Andreessen put the point to the New York Times earlier this month, back in the days of Clinton and Obama, “the tax rates didn’t really matter because when an internet company worked, it grew so fast and got so valuable that if you worked another three years, say, you’d make another 10 X. Another 5 percent higher tax rate washed out in the numbers.” Silicon Valley enjoyed such favorable conditions for much of the 2010s. But the tech boom faded during Biden’s tenure. In 2022, rising interest rates started diverting capital away from the tech sector: With safe assets now offering an attractive guaranteed return, investors grew more reluctant to funnel cash into risky ones. Stock market valuations fell and layoffs spread. At the same time, as Noah Smith notes, tech investors and executives started running up against structural constraints on profit-making. Many venture capitalists looked at Google and Facebook’s success in cornering and dominating their respective markets, and bet that they could establish similarly monopolistic businesses in other corners of digital commerce. But by 2022, they’d discovered that achieving such market dominance was harder than they’d thought. Meanwhile, social media companies struggled to combat the inherently finite nature of human attention: Once you’ve lured roughly 5 billion humans onto social media — and turned a hefty percentage of them into addicts — there’s only so much screen time left to monetize. In this context, we would expect tech moguls who’d been only lightly committed to the “liberal” part of liberal-tarianism to start heeding their own narrow material interests. After all, it was a similar mix of rising interest rates, inflation, and slowing profitability that helped prompt corporate America’s right turn in the 1970s. To be sure, the tech industry’s fortunes have rebounded since 2022, thanks in no small part to the AI boom. But the experience of a capital crunch and profit squeeze — however temporary — seems to have made a lasting impression on many in tech, whose political contributions began shifting (modestly) toward Republicans in 2022. For the reasons above, it wouldn’t have been surprising for the tech industry to have drifted toward Republicans over the past four years, even if Democratic policy remained as friendly to tech as had it been under Barack Obama. In reality, the Biden administration took a much more adversarial stance than its predecessors. Biden’s Federal Trade Commission and Justice Department collectively brought antitrust cases against Amazon, Google, Meta, Apple, and Microsoft. This blitzkrieg of aggressive antitrust enforcement naturally irritated Silicon Valley’s giants. Perhaps less predictably, it also antagonized smaller tech firms and startups. In theory, one might expect “little tech” would want the government to curb the market power of their gargantuan competitors. In practice, however, many startup founders and investors aspire to either grow their own firms into behemoths, or failing that, get bought up by a larger company. By chilling merger activity, the Biden administration effectively blocked many startups’ “plan B,” while choking off a reliable source of returns for venture capitalists. VCs and startups also took exception to the Biden Securities and Exchange Commission’s vigorous regulation of cryptocurrency, as well as the administration’s executive order on AI safety. In November 2023, a contingent of startup founders and investors denounced the latter, arguing that the order’s reporting requirements put small AI firms at a competitive disadvantage, as they could less comfortably shoulder regulatory compliance costs than their larger rivals. Finally, Biden proposed a new tax on the unrealized capital gains of Americans with more than $100 million in wealth. This would mean that when a megamillionaire investor’s stock portfolio or real estate holdings gained $5 million in value, they would need to pay a tax on that amount, even if they did not sell those assets. Tax policy wonks like this idea. But super-rich tech investors very much do not. And when Kamala Harris announced her support for Biden’s plan last summer, Silicon Valley’s venture capitalists had a conniption. Super-rich tech moguls care about making money. But they are often at least as covetous of social status. Past a certain point, accumulating more wealth has little practical impact on your living standards (or those of your children, or your children’s children). But a person’s appetite for greater prestige tends to be less exhaustible than their desire for beach homes, Porsches, or private jets. Thus, if Democrats had spent the past decade exalting tech investors and founders, it’s possible that the party’s increasingly adversarial policies would have caused less rancor in Silicon Valley. But Democrats became increasingly disillusioned with the tech industry over the course of the 2010s. And this culminated in a Democratic administration that undermined tech billionaires’ sense of self-importance. “At the core level, both Barack Obama and the modal Democrat thought the average Silicon Valley company was really good and cool in 2009,” Marc Aidinoff, a historian and policy adviser in both the Obama and Biden administrations, told me. “Obama would go to Silicon Valley and have dinner with the CEOs and call them champions of change. What these people really wanted from the president was the sense that they were loved.” But by 2021, things had changed, according to Aidinoff. “Joe Biden distrusts these people, thinks they are hurting Americans, and has the sense that they aren’t actually making much of real value,” he said. The Democrats’ disenchantment with tech wasn’t attributable to Biden’s personal skepticism of Silicon Valley alone. After the financial crisis, the party’s progressive wing grew more influential. And its ascent increased the salience of both inequality and labor issues in Democratic politics. For a party increasingly concerned with wealth concentration and workers’ rights, tech giants that generated vast fortunes off “winner-take-all” markets — while, in many cases, committing labor violations or undermining traditional employment — did not look like engines of progress. As importantly, the notion that social media platforms promoted democracy and social reform fell into disrepute. In the wake of Obama’s election and the Arab Spring — both of which were widely credited to novel media technologies — many liberals bought into the idea that Facebook and Twitter would abet a more egalitarian politics. But authoritarian regimes proved adept at restricting online speech. And if social media’s potential to facilitate rightwing extremism wasn’t clear to liberals before 2016, it was apparent to them afterward. Following Trump’s victory, many Democrats blamed their party’s defeat on Facebook’s dissemination of “fake news.” Around the same time, research suggesting that social media could have adverse mental health effects started to accumulate. All this — combined with tech platforms’ adverse impact on traditional journalism — led the mainstream media to view Silicon Valley more critically. Between 2012 and 2019, the New York Times’ coverage of Facebook turned sharply negative, according to one prominent data analysis. Add in Silicon Valley’s growing enthusiasm for crypto — a technology that appeared to be good for little beyond scams and speculation — and it isn’t hard to see why Democrats soured on Big Tech. The party’s newfound skepticism of the industry didn’t just translate into greater regulatory scrutiny, but also, a withholding of both praise and access. According to some in tech, the sector’s leading lights felt themselves shunned and slighted by the Biden White House. “I think the fundamental problem, and I heard this from many, was that former President Biden was unwilling to meet with tech CEOs and entrepreneurs,” the billionaire investor Mark Cuban told me. “It was that simple.” One former Biden official echoed this assessment, saying that tech companies “couldn’t get meetings with a lot of the key regulators. Certainly [FTC commissioner] Lina [Khan] wouldn’t meet with people — she liked to say, ‘We’re enforcement, you can’t really meet with us.’” Andreessen recently reminisced that Bill Clinton’s Democratic Party had “celebrated” and “loved” tech companies. Biden’s Democratic Party, by contrast, often refused Andreessen’s ilk the time of day. It’s clear then that Silicon Valley’s rightward turn was precipitated, at least in part, by a change in the Democratic Party’s attitudes and policies toward the tech industry. And there’s reason to think that the party’s anti-tech turn is politically costly on net. Were other tech billionaires to emulate Musk’s political giving — or other social media companies to imitate X’s boosting of right-wing content — the damage to Democrats could be considerable. And the Trump administration’s manifest openness to trading political power for financial support makes this a live possibility, especially if Democrats promise to reprise the Biden administration’s policies toward the industry. Meanwhile, it’s far from clear that aggressively regulating Silicon Valley can gain Democrats meaningful support elsewhere. This is not because voters oppose that general goal: In fact, in a 2024 Pew Research poll, a slight majority expressed support for increasing regulation of the tech industry, while a supermajority said that social media has had a “mostly negative” effect on the United States. The problem is that voters have ambivalent feelings about Big Tech writ large, and do not consider regulating the companies a priority. When Gallup asked Americans what their country’s most important problem was this month, only 1 percent named “corporate corruption” while 0 percent picked “technology.” In a post-election survey from Morning Consult and the Chamber of Progress (a trade group of companies allied with the Democratic Party), voters were presented with a list of 12 issues, and asked to name the two that were most important to their vote. Only 2 percent of respondents picked “regulating technology companies” as one of their priorities, making it the single least prioritized objective on the list (by contrast, 49 percent selected “controlling inflation and strengthening the economy”). Meanwhile, in YouGov’s polling, Amazon’s approval rating sits at 74 percent, Google’s at 70 percent, Apple’s at 69 percent, and Facebook at 59 percent. Given all this, it’s plausible that Democrats have more to lose than gain politically from taking on Big Tech. Yet it’s also true that the political costs of the party’s anti-tech turn have been routinely overstated. In truth, Silicon Valley’s rightward shift — while real — has been remarkably modest, whether measured in votes or donations. In 2020, Biden won Santa Clara County, which includes much of Silicon Valley, by 48 points. Four years later, he won it by 40 points. There’s some evidence that tech workers and executives became more likely to donate to Republicans during the Biden era. But 83 percent of Amazon employees’ donations to federal candidates went to Democrats in 2024; for Meta, that figure was 91.5 percent; for Apple, it was 95 percent. At the megadonor level, the story is a bit more complicated. Trump received more money from tech donors who spent over $1 million on the 2024 race than Harris did — but that’s mostly thanks to Musk’s prodigious giving. Musk spent $242.6 million on the 2024 election, nearly five times as much as Silicon Valley’s second-largest political spender, Facebook co-founder Dustin Moskovitz, a Democrat. And yet, it’s hard to attribute Musk’s political evolution to recent changes in Democratic policy. The Tesla CEO appears to have been undergoing a process of online radicalization even before Biden took office (in March 2020, Musk allegedly bet the writer Sam Harris $1 million that there would be fewer than 35,000 cases of Covid-19 in the United States, a conviction that seems symptomatic of his immersion in right-wing social media). If we deem Musk a special case and put him to the side, then Democrats retained their advantage with large tech donors in 2024: Combined, all other tech megadonors spent $30.6 million on Trump, and $120.9 million on Harris, according to an analysis from The Guardian. In any case, money was not the Democrats’ problem in 2024. The party and its allied groups outraised the GOP by $1.1 billion during last year’s campaign. To be sure, many Silicon Valley billionaires waited until after Election Day to cozy up to Trump, so their newfound support for the GOP would not be captured by this data. But those who only started currying Trump’s favor once he secured the presidency are likely motivated less by antipathy for Democratic policy than awareness of Republican corruption: Trump has made it quite clear that his friends can expect favorable treatment by his government while his foes can anticipate the opposite. “A number of people in tech led with vinegar during Trump’s first term and learned that it was better with Trump to lead with honey,” Adam Kovacevich, a former Google executive and chair of the Chamber of Progress, told me. “It’s not so much that they expect a lot, but they really don’t want their companies to be hurt by Trump. If your competitors are building a close relationship with Trump, you don’t want them to screw you.” All of which is to say: The Democrats have paid a price for their crusade against Big Tech, but not a prohibitively expensive one. None of this settles the debate over whether Democrats were right to take a more adversarial posture toward the tech industry under Biden. Moderate Democrats can look at this pattern of facts and conclude that Biden’s agenda alienated a powerful industry and did little to increase their party’s popular support, all while discouraging growth and innovation. Progressives, meanwhile, can counter that Democrats just proved they can take on concentrated corporate power and still retain an overwhelming financial advantage over the GOP — and thus, the party has no excuse not to prioritize the interests of ordinary Americans over those of tech billionaires. Ultimately though, the important disagreement here is the substantive one. If Democrats can ingratiate themselves to tech billionaires in ways that have little substantive cost — such as giving them face time or rhetorical encouragement — they might be well-advised to do so. But the party as of yet faces no imperative to abandon policies that benefit the general public, for the sake of appeasing Silicon Valley titans. You’ve read 1 article in the last month Here at Vox, we're unwavering in our commitment to covering the issues that matter most to you — threats to democracy, immigration, reproductive rights, the environment, and the rising polarization across this country. Our mission is to provide clear, accessible journalism that empowers you to stay informed and engaged in shaping our world. By becoming a Vox Member, you directly strengthen our ability to deliver in-depth, independent reporting that drives meaningful change. We rely on readers like you — join us. Swati Sharma Vox Editor-in-Chief We accept credit card, Apple Pay, and Google Pay. You can also contribute via Understand the world with a daily explainer plus the most compelling stories of the day. A federal judge just blocked Trump’s domestic spending freeze. His opinion relies heavily on another one by Justice Kavanaugh. Trump has issued hundreds of executive orders soon after he was inaugurated for his second presidency. The decision to freeze aid is hurting vulnerable people around the world. What the hot new Chinese AI product means — and what it doesn’t. The Logoff explains what you need to know about Trump’s latest immigration move. It probably doesn’t involve DEI. © 2025 Vox Media, LLC. All Rights Reserved
--------------------------------------------------

Title: Apple's iPhone sales during the holiday season slipped despite a highly anticipated AI rollout
URL: https://abcnews.go.com/Technology/wireStory/apples-iphone-sales-holiday-season-slipped-despite-highly-118286966
Time Published: 2025-01-30T21:58:28Z
Full Content:
Apple on Thursday disclosed its iPhone sales dipped slightly during the holiday-season quarter, signaling a sluggish start to the trendsetting company’s effort to catch up to the rest of Big Tech in the race to bring artificial intelligence to the masses SAN FRANCISCO -- Apple on Thursday disclosed its iPhone sales dipped slightly during the holiday-season quarter, signaling a sluggish start to the trendsetting company’s effort to catch up to the rest of Big Tech in the race to bring artificial intelligence to the masses. The iPhone’s roughly 1% drop in revenue from the previous year’s October-December period wasn’t entirely unexpected, given the first software update enabling the device’s AI features didn’t arrive until just before Halloween, and the technology still isn’t available in many markets outside the U.S. The countries still awaiting Apple’s AI suite include China, a key market where the company continued to lose ground. Apple also was only able to eke out a modest revenue gain across its entire business, although the results came in ahead of the analyst projections that guide investors. The Cupertino, California, company earned $36.3 billion, or $2.40 per share, a 7% increase from the previous year. Revenue edged up from the previous year by 4% to $124.3 billion. Those numbers included iPhone revenue of $69.1 billion. In China, Apple’s total revenue registered $18.5 billion, an 11% decrease from the previous year. Part of that erosion in China reflected the iPhone’s shrinking market share in that country, where homegrown companies have been making more headway. Apple’s iPhone year-over year shipments in China declined nearly 10% in the most recent quarter, while native companies Huawei and Xiaomi posted year-over-year increase of more than 20%, according to the research firm International Data Corp. The holiday-season results served to confirm bringing AI to the iPhone and Apple’s other products may not boost the company’s recently lackluster growth as much as investors initially thought it might after CEO Tim Cook unveiled the technology before a rapt crowd last June. The anticipation that an AI-infused iPhone would prod hordes of consumers to ditch their current devices and splurge on an upgrade is the main reason Apple’s stock price surged by 30% last year. But the sinking realization that an uptick in demand may take longer than expected has caused Apple’s shares to backtrack by 5% during the first month of the new year. The stock slipped slightly in extended trading after the numbers came out. The concerns hovering around Apple's weakening iPhone sales come against broader worries about whether AI will be as lucrative for U.S. tech companies as once envisioned after Chinese startup DeepSeek released a version of the technology that was built at a far lower cost than had been previously thought possible. Unlike tech peers such as Microsoft, Google corporate parent Alphabet Inc. and Facebook corporate parent Meta Platforms, Apple hasn’t been investing as heavily in AI – one of the reasons it has been an industry laggard. But that restraint could work to its advantage if DeepSeek’s early breakthroughs in driving down AI costs gains momentum. Apple’s services division remained the company’s biggest moneymaker outside the iPhone, with revenue of $26.3 billion in the past quarter, a 14% increase from the previous year. Although the services division has been thriving for years, it generates more than $20 billion annually by locking in Google as the automatic search engine on the iPhone and other products. That deal is now under threat of being banned as part of the proposed punishment for Google’s search engine being declared an illegal monopoly. 24/7 coverage of breaking news and live events
--------------------------------------------------

Title: Apple's iPhone sales during the holiday season slipped despite a highly anticipated AI rollout
URL: https://www.seattlepi.com/business/article/apple-s-iphone-sales-during-the-holiday-season-20066697.php
Time Published: 2025-01-30T21:57:23Z
Description: Apple on Thursday disclosed its iPhone sales dipped slightly during the holiday-season quarter, signaling a sluggish start to the trendsetting company’s effort to catch up to the rest of Big Tech in the race to bring artificial intelligence to the masses. The…
--------------------------------------------------

Title: Apple's iPhone sales during the holiday season slipped despite a highly anticipated AI rollout
URL: https://finance.yahoo.com/news/apples-iphone-sales-during-holiday-214924535.html
Time Published: 2025-01-30T21:49:24Z
Full Content:
We are experiencing some temporary issues. The market data on this page is currently delayed. Please bear with us as we address this and restore your personalized lists. SAN FRANCISCO (AP) — Apple on Thursday disclosed its iPhone sales dipped slightly during the holiday-season quarter, signaling a sluggish start to the trendsetting company’s effort to catch up to the rest of Big Tech in the race to bring artificial intelligence to the masses. The iPhone’s roughly 1% drop in revenue from the previous year’s October-December period wasn’t entirely unexpected, given the first software update enabling the device’s AI features didn’t arrive until just before Halloween, and the technology still isn’t available in many markets outside the U.S. The countries still awaiting Apple’s AI suite include China, a key market where the company continued to lose ground. Apple also was only able to eke out a modest revenue gain across its entire business, although the results came in ahead of the analyst projections that guide investors. The Cupertino, California, company earned $36.3 billion, or $2.40 per share, a 7% increase from the previous year. Revenue edged up from the previous year by 4% to $124.3 billion. Those numbers included iPhone revenue of $69.1 billion. In China, Apple’s total revenue registered $18.5 billion, an 11% decrease from the previous year. Part of that erosion in China reflected the iPhone’s shrinking market share in that country, where homegrown companies have been making more headway. Apple’s iPhone year-over year shipments in China declined nearly 10% in the most recent quarter, while native companies Huawei and Xiaomi posted year-over-year increase of more than 20%, according to the research firm International Data Corp. The holiday-season results served to confirm bringing AI to the iPhone and Apple’s other products may not boost the company’s recently lackluster growth as much as investors initially thought it might after CEO Tim Cook unveiled the technology before a rapt crowd last June. The anticipation that an AI-infused iPhone would prod hordes of consumers to ditch their current devices and splurge on an upgrade is the main reason Apple’s stock price surged by 30% last year. But the sinking realization that an uptick in demand may take longer than expected has caused Apple’s shares to backtrack by 5% during the first month of the new year. The stock slipped slightly in extended trading after the numbers came out. The concerns hovering around Apple's weakening iPhone sales come against broader worries about whether AI will be as lucrative for U.S. tech companies as once envisioned after Chinese startup DeepSeek released a version of the technology that was built at a far lower cost than had been previously thought possible. Unlike tech peers such as Microsoft, Google corporate parent Alphabet Inc. and Facebook corporate parent Meta Platforms, Apple hasn’t been investing as heavily in AI – one of the reasons it has been an industry laggard. But that restraint could work to its advantage if DeepSeek’s early breakthroughs in driving down AI costs gains momentum. Apple’s services division remained the company’s biggest moneymaker outside the iPhone, with revenue of $26.3 billion in the past quarter, a 14% increase from the previous year. Although the services division has been thriving for years, it generates more than $20 billion annually by locking in Google as the automatic search engine on the iPhone and other products. That deal is now under threat of being banned as part of the proposed punishment for Google’s search engine being declared an illegal monopoly. Sign in to access your portfolio
--------------------------------------------------

Title: Apple Reports Record $124.3 Billion Revenue on Strong Holiday Sales
URL: https://www.thewrap.com/apple-earnings-q1/
Time Published: 2025-01-30T21:44:35Z
Full Content:
The tech giant offset a modest iPhone sales dip with strong results from Europe, subscriptions and iCloud Apple reported the company’s best quarterly sales ever on Thursday, with the tech giant pointing to a strong holiday performance leading to $124.3 billion in Q1 revenue. The company posted the big quarter despite declining sales in China and a minor dip in iPhone revenue. Apple offset its sales drop in China with an 11.4% year-over-year increase in European sales, as well as 14% annual growth from Apple’s Services sector, which includes Apple TV+, Apple Music, and iCloud storage. Those gains also helped Apple weather flat sales from its Wearables division, which accounts for Apple Watch, headphones, and its Vision Pro virtual reality headsets. Apple CEO Tim Cook, in a statement accompanying earnings, announced Apple Intelligence — the company’s artificial intelligence program designed to help users with messages, notifications, and other features — would “be available in even more languages this April,” without providing further details. Here are the top-line numbers from Apple’s first quarter, which represents its October through December performance: Revenues: $124.3 billion, a 4% increase from the year prior. Apple’s Q1 sales narrowly topped analyst estimates from Zack’s Investment Research of $124 billion. The Q1 performance also topped Apple’s previous record of $123.9 billion in sales during the holiday quarter of 2021. Apple’s sales in China, notably, dropped 11% year-over-year to $18.5 billion. Cook explained the dip on the call by saying it was due to a “change in channel inventory,” or products that are in the supply chain but have not been sold yet. He also said China is the “most competitive market in the world” and that, moving forward, he believes recent government stimulus packages will help some of Apple’s products in the next quarter. The company made up for it in Europe, its second biggest market, where Apple had $33.9 billion in Q1 revenue — an 11.4% year-over-year increase. Net income: $36.3 billion, up 7.1% from last year’s $33.9 billion. Earnings Per Share: Apple’s diluted earnings per share of $2.4o were better than Zack’s estimates of $2.36 EPS. iPhone Sales: Revenue from Apple’s linchpin device declined 0.8% annually to $69.1 billion. Apple brought in nearly $70 billion from iPhone sales a year ago. Services: Apple’s wide-ranging Services sector accounted for $26.3 billion in sales, compared to the $23.1 billion brought in a year ago. As is usually the case, Apple did not mention how its streaming service, Apple TV+, was performing in its quarterly report, though on its earnings call Cook did express enthusiasm about several of its upcoming shows. This was the best quarter ever for Services sales. Cook was in Washington, D.C. last week for President Trump’s inauguration, where he was joined by a number of other Big Tech CEOs, including X owner Elon Musk, Meta chief Mark Zuckerberg, and Amazon founder Jeff Bezos. Cook’s appearance came after he personally donated $1 million towards Trump’s inauguration fund. Heading into Thursday, Apple’s stock price had increased a modest 3.5% since the start of October. The company’s holiday quarter coincided with the October launch of Apple Intelligence; the rollout was met with tepid reviews, and has led to questions from some analysts about Apple’s future in a crowded AI space. Apple is the world’s most valuable company, with a market cap of $3.57 trillion. Microsoft, with a valuation of $3.09 trillion, is the next closest company. Cook, on the Q1 earnings call on Thursday afternoon, said Apple now had 2.35 billion active devices worldwide — yet another company record. The 64-year-old executive also took a moment to extend his condolences to those affected by the “devastating wildfires that impacted the Los Angeles area.” There was not much mentioned about Apple’s entertainment push, beyond Cook mentioning the recent return of “Severance” and the upcoming “Formula One” film starring Brad Pitt.
--------------------------------------------------

Title: Meta continues pushing Instagram Reels as Q4 2024 results beat expectations
URL: https://www.tubefilter.com/2025/01/30/meta-instagram-reels-q4-2024-earnings-results/
Time Published: 2025-01-30T19:45:53Z
Description: Meta's earnings from the fourth quarter of 2024 served as a reminder that Mark Zuckerberg's company is most likely to benefit in the event of a long-term disruption to TikTok's operations. The tech giant's stock price briefly reached a price of more than $700…
--------------------------------------------------

Title: Artificial Intelligence (AI) Going “DeepSeek”
URL: https://www.globalresearch.ca/ai-going-deepseek/5878642
Time Published: 2025-01-30T16:18:05Z
Full Content:
Most readers will know the news by now. DeepSeek, a Chinese AI company, released an AI model called R1 that is comparable in ability to the best models from companies such as OpenAI, Anthropic and Meta, but was trained at a radically lower cost and using less than state-of-the art GPU chips. DeepSeek also made public enough of the details of the model that others can run it on their own computers without charge. DeepSeek is a torpedo that has hit the Magnificent Seven US hi-tech companies below the water line. DeepSeek did not use the latest and best Nvidia’s chips and software; it did not require huge spending on training its AI model unlike its American rivals; and it offers just as many useful applications. DeepSeek built its R1 with Nvidia’s older, slower chips, which US sanctions had allowed to be exported to China. The US government and the tech titans thought they had a monopoly in AI development because of the huge costs involved in making better chips and AI models. But now DeepSeek’s R1 suggests that companies with less money can soon operate competitive AI models. R1 can be used on a shoestring budget and with much less computing power. Moreover, R1 is just as good as rivals at ‘inference’, the AI jargon for when users question the model and get answers. And it runs on servers for all sorts of companies so that they need not ‘rent’ at huge prices from the likes of OpenAI. Most important, DeepSeek’s R1 is ‘open source’, namely that is coding and training methods are open to all to copy and develop. This is a real blow to the ‘proprietary’ secrets that OpenAI or Google’s Gemini lock away in a ‘black box’ in order to maximise profits. The analogy here is with branded and generic pharmaceuticals. The big issue for the US AI companies and their investors is that it appears that building huge data centres to house multiples of expensive chips may not be necessary in order to achieve sufficiently successful outcomes. Up to now, the US companies have been ratcheting up huge spending plans and trying to raise mega amounts of funding to do so. Indeed, on the very Monday that DeepSeek’s R1 hit the news, Meta announced another $65bn of investment, and only days earlier President Trump announced government subsidies of $500bn to the tech giants as part of the so-called Stargate project. Ironically, Meta chief executive Mark Zuckerberg said he was investing because “We want the US to set the global AI standard, not China.” Oh dear. . . Now investors are concerned that this spending is unnecessary and, more to the point, that it will hit the profitability of the American companies if DeepSeek can deliver AI applications at a tenth of the cost. Five of the biggest technology stocks geared to AI — chipmaker Nvidia and so-called ‘hyperscalers’ Alphabet, Amazon, Microsoft and Meta Platforms — collectively shed almost $750bn of their stock market value in one day. And DeepSeek does threaten the profits of the data centre companies and the water and power operators which expect to benefit from the huge ‘scaling up’ by the Magnificent Seven. The US stock market boom is heavily concentrated in the ‘Magnificent Seven’. . . So has DeepSeek punctured the massive stock market bubble in US tech stocks? Billionaire investor Ray Dalio thinks so. He told the Financial Times that “pricing has got to levels which are high at the same time as there’s an interest rate risk, and that combination could prick the bubble … Where we are in the cycle right now is very similar to where we were between 1998 or 1999,” Dalio said. “In other words, there’s a major new technology that certainly will change the world and be successful. But some people are confusing that with the investments being successful.” . . But that may not be the case, at least not just yet. The AI chip company Nvidia’s stock price may have dived this week, but its ‘proprietary’ coding language, Cuda, is still the US industry standard. While its shares dropped nearly 17%, that only brings it back to the (very, very high) level of September. . . Much will depend on other factors like the US Fed keeping interest rates high because of a reversal in the fall in inflation and on whether Trump proceeds big time with his tariff and immigration threats that will only fuel inflation. What must enrage the tech oligarchs sucking up to Trump is that US sanctions on Chinese companies and bans on chip exports have not stopped China making yet more advances in the tech and chip war with the US. China is managing to make technological leaps in AI despite export controls introduced by the Biden administration intended to deprive it of both the most powerful chips and the advanced tools needed to make them. Chinese tech champion Huawei has emerged as Nvidia’s primary competitor in China for ‘inference’ chips. And it has been working with AI companies, including DeepSeek, to adapt models trained on Nvidia GPUs to run inference on its Ascend chips. “Huawei is getting better. They have an opening as the government is telling the big tech companies that they need to buy their chips and use them for inference,” said one semiconductor investor in Beijing. This is a further demonstration that state-led planned investment into technology and tech skills by China works so much better than relying on huge private tech giants led by moguls. As Ray Dallo said: “In our system, by and large, we are moving to a more industrial-complex- type of policy in which there is going to be government-mandated and government-influenced activity, because it is so important…Capitalism alone — the profit motive alone — cannot win this battle.” Nevertheless, the AI titans are not yet the titanic. They are going ahead with ‘scaling up’ by ploughing yet more and more billions into data centres and more advanced chips. This eating up computer power exponentially. . . And of course, there is no consideration of what mainstream economists politely like to call ‘externalities’. According to a report by Goldman Sachs, a ChatGPT query needs nearly 10 times as much electricity as a Google search query. Researcher Jesse Dodge did some back-of-the-napkin math on the amount of energy AI chatbots use. “One query to ChatGPT uses approximately as much electricity as could light one light bulb for about 20 minutes,” he says. “So, you can imagine with millions of people using something like that every day, that adds up to a really large amount of electricity.” More electricity consumption means more energy production and in particular more fossil-fuelled greenhouse gas emissions. Google has the goal of reaching net-zero emissions by 2030. Since 2007, the company has said its company operations were carbon neutral because of the carbon offsets it buys to match its emissions. But, starting in 2023, Google wrote in its sustainability report that it was no longer “maintaining operational carbon neutrality.” The company says it’s still pushing for its net-zero goal in 2030. “Google’s real motivation here is to build the best AI systems that they can,” Dodge says. “And they’re willing to pour a ton of resources into that, including things like training AI systems on bigger and bigger data centers all the way up to supercomputers, which incurs a tremendous amount of electricity consumption and therefore CO2 emissions.” Then there’s water. As the US faces droughts and wildfires, the AI companies are sucking up deep water to ‘cool’ their mega data centres to protect the chips. More than that, Silicon Valley companies are increasingly taking control of water supply infrastructure to meet their needs. Research suggests, for instance, that about 700,000 litres of water could have been used to cool the machines that trained ChatGPT-3 at Microsoft’s data facilities. Training AI models consumes 6,000 times more energy than a European city. Furthermore, while minerals such as lithium and cobalt are most commonly associated with batteries in the motor sector, they are also crucial for the batteries used in datacentres. The extraction process often involves significant water usage and can lead to pollution, undermining water security. Sam Altman, the previous non-profit hero of Open AI, but now out to maximise profits for Microsoft, argues that yes, unfortunately there are ‘trade-offs’ in the short term, but they’re necessary to reach so-called AGI; and AGI will then help us solve all these problems so the trade off of ‘externalities’ is worth it. AGI? What’s this? Artifical generalised intelligence (AGI) is the holy grail of AI developers. It means that AI models would become ‘superintelligent’ way above human intelligence. When that is achieved, Altman promises, its AI won’t just be able to do a single worker’s job, it will be able to do all of their jobs: “AI can do the work of an organization.” This would be the ultimate in maximising profitability by doing away with workers in companies (even AI companies?) as AI machines take over operating, developing and marketing everything. This is the apocalyptic dream for capital (but a nightmare for labour: no job, no income). That’s why Altman and the other AI moguls will not stop expanding their data centres and developing yet more advanced chips just because DeepSeek has undercut their current models. Research firm Rosenblatt forecast the response of the tech giants: “In general, we expect the bias to be on improved capability, sprinting faster towards artificial general intelligence, more than reduced spending.” Nothing must stop the objective of super-intelligent AI. Some see the race to achieving AGI as a threat to humanity itself. Stuart Russell, professor of computer science at the University of California, Berkeley, said “Even the CEOs who are engaging in the race have stated that whoever wins has a significant probability of causing human extinction in the process, because we have no idea how to control systems more intelligent than ourselves,” he said. “In other words, the AGI race is a race towards the edge of a cliff.” Maybe, but I continue to doubt that human ‘intelligence’ can be replaced by machine intelligence, mainly because they are different. Machines cannot think of potential and qualitative changes. New knowledge comes from such transformations (human), not from the extension of existing knowledge (machines). Only human intelligence is social and can see the potential for change, in particular social change, that leads to a better life for humanity and nature. What DeepSeek’s emergence has shown is that AI can be developed to a level that can help humanity and its social needs. It’s free and open and available to the smallest user and developer. It has not been developed at a profit or to make a profit. As one commentator put it: “I want AI to do my laundry and dishes so that I can do art and writing, not for AI to do my art and writing so that I can do my laundry and dishes.” Managers are introducing AI to “make management problems easier at the cost of the stuff that many people don’t think AI should be used for, like creative work….. If AI is going to work, it needs to come from the bottom-up, or AI is going to be useless for the vast majority of people in the workplace”. Rather than develop AI to make profits, reduce jobs and the livelihoods of humans, AI under common ownership and planning could reduce the hours of human labour for all and free humans from toil to concentrate on creative work that only human intelligence can deliver. Remember the ‘holy grail’ was a Victorian fiction and later a Dan Brown one as well. * Click the share button below to email/forward this article. Follow us on Instagram and X and subscribe to our Telegram Channel. Feel free to repost Global Research articles with proper attribution. Michael Roberts is an economist in the City of London and a prolific blogger. Global Research is a reader-funded media. We do not accept any funding from corporations or governments. Help us stay afloat. Click the image below to make a one-time or recurring donation. Comment on Global Research Articles on our Facebook page Become a Member of Global Research Disclaimer: The contents of this article are of sole responsibility of the author(s). The Centre for Research on Globalization will not be responsible for any inaccurate or incorrect statement in this article. The Centre of Research on Globalization grants permission to cross-post Global Research articles on community internet sites as long the source and copyright are acknowledged together with a hyperlink to the original Global Research article. For publication of Global Research articles in print or other forms including commercial internet sites, contact: [email protected] www.globalresearch.ca contains copyrighted material the use of which has not always been specifically authorized by the copyright owner. We are making such material available to our readers under the provisions of "fair use" in an effort to advance a better understanding of political, economic and social issues. The material on this site is distributed without profit to those who have expressed a prior interest in receiving it for research and educational purposes. If you wish to use copyrighted material for purposes other than "fair use" you must request permission from the copyright owner. For media inquiries: [email protected]
--------------------------------------------------

Title: Microsoft, AWS, and Cerebras launch DeepSeek R1 model
URL: https://www.techtarget.com/searchenterpriseai/news/366618674/Microsoft-AWS-and-Cerebras-launch-DeepSeek-R1-model
Time Published: 2025-01-30T15:43:00Z
Full Content:
Nabugu - stock.adobe.com Enterprises that want to test DeepSeek-R1, the Chinese reasoning model that caused a tsunami in the tech industry, can get it from cloud providers AWS and Microsoft, the online platform GitHub and hardware maker Cerebras Systems. The tech companies made the model from Hangzhou, China-based AI startup DeepSeek available this week, just days after it rocked the tech industry by casting doubt on the high cost of running AI in the United States. The model is comparable to OpenAI's o1 but requires a fraction of the GPU power, according to its developers. "DeepSeek-R1 is certainly having its viral moment now," said Gartner analyst Arun Chandrasekaran. Chandrasekaran said he expects many companies to offer DeepSeek-R1, including variants for specific industries and cloud, data center and edge deployments. Model providers will likely differentiate themselves from competitors by offering better performance for the price through infrastructure innovations, Chandrasekaran said. They will also provide security and privacy layers and guarantees around legal indemnification. "Having said that, in a few months, we may not remember R1 as much as we do today," Chandrasekaran said. "There is now a race to build models with better efficiencies, and we will see more such models from large cloud providers in the U.S., China, as well as from AI research labs in the world." Microsoft made DeepSeek-R1 available on GitHub and the model catalog on Azure AI Foundry. The Foundry offers developers tools to experiment with, iterate on and integrate the model's capabilities into workflows. It also provides security and model evaluation tools. AWS offers its version of DeepSeek on its SageMaker platform for building, training and deploying custom models. AWS customers can train DeepSeek on SageMaker using the Hugging Face open source platform. "We expect to see many more models like this -- both large and small, proprietary and open source -- excel at different tasks," AWS said in an emailed statement. Cerebras Systems introduced AI hardware running a 70-billion-parameter DeepSeek-R1 powered by the company's WSE-2 processor. The preview technology is contained in Cerebras' flagship CS-3 system, a unit that fits within a standard data center rack. Cerebras claims DeepSeek-R1-70B is faster, more accurate, and less expensive than OpenAI's o1 reasoning model. Cerebras trained its model on the same data used to train Llama 3.3 using knowledge distillation, a technique that transfers data from a large, complex model to a smaller, more efficient one. The price of the DeepSeek system will be similar to Cerebras hardware running Llama 3.3 70B. Cerebras has developed a framework called Cerebras Planning and Optimization to enhance the reasoning abilities of Llama 3.3 Cerebras declined to provide pricing details or say how many of its WSE-2 processors are used to run Llama and DeepSeek. Hagay Lupesko, vice president of software engineering at Cerebras, said the company has received many queries from U.S. companies interested in its DeepSeek model. "We have a pretty long list of preview customers who are in line for access to the model," Lupesko said. He declined to name any organizations but said many were in the consumer industry and interested in using the model for application development. Cerebras also used the Llama 3.3 weights to train its version of DeepSeek. Weights are the numerical patterns critical to a model's ability to recognize patterns and make predictions based on input data. That means its DeepSeek model doesn't have the output restrictions of the original Chinese model, which, for example, does not answer queries about the Chinese leader, President Xi Jinping. DeepSeek developed and released its model to the open source community. However, some components are inaccessible, and the company did not release the data used to train the model. Hugging Face and Llama creator Meta are attempting to reverse engineer the technology. The company's researchers shook the tech world after they published a research paper demonstrating how they trained the model on significantly less-powerful Nvidia GPUs than the ones used for Open AI's reasoning model o1, yet achieved similar results. The disclosure raised serious questions about the efficiency of U.S.-made models and whether spending tens of billions of dollars on Nvidia's top chips was necessary. On Monday, Nvidia lost $589 billion in market value due to the research paper and release of DeepSeek's R1 model. The company's stock has regained some, though not all, of its losses. Antone Gonsalves is an editor at large for Informa TechTarget, reporting on industry trends critical to enterprise tech buyers. He has worked in tech journalism for 25 years and is based in San Francisco. Have a news tip? Please drop him an email.
--------------------------------------------------

Title: AI #101: The Shallow End
URL: https://www.lesswrong.com/posts/pZ6htFtoptGrSajWG/ai-101-the-shallow-end
Time Published: 2025-01-30T14:50:10Z
Full Content:
The avalanche of DeepSeek news continues. We are not yet spending more than a few hours at a time in the singularity, where news happens faster than it can be processed. But it’s close, and I’ve had to not follow a bunch of other non-AI things that are also happening, at least not well enough to offer any insights. So this week we’re going to consider China, DeepSeek and r1 fully split off from everything else, and we’ll cover everything related to DeepSeek, including the policy responses to the situation, tomorrow instead. This is everything else in AI from the past week. Some of it almost feels like it is from another time, so long ago. I’m afraid you’re going to need to get used to that feeling. Also, I went on Odd Lots to discuss DeepSeek, where I was and truly hope to again be The Perfect Guest. Joe Weisenthal finally tries out Google Flash Deep Thinking, is impressed. AI tutors beat out active learning classrooms in a Harvard study by a good margin, for classes like physics and economics. Koratkar gives Operator a shot at a makeshift level similar to Montezuma’s Revenge. Nate Silver estimates his productivity is up 5% from LLMs so far, and warns others that they ignore LLMs at their peril, both politically and personally. Fix all your transcript errors. LLMs are good at transforming text into less text, but yet good at transforming less text into more text. Note that this rule applies to English but doesn’t apply to code. Write your code for AI comprehension, not human readability. Vik: increasingly finding myself designing software for AI comprehension over human readability. e.g. giant files, duplicated code, a lot more verification tests. Now i just need to convince the agent to stop deleting failing tests… James Darpinian: IMO these usually increase human readability as well, contra “best practices.” Vik: agree, makes it so you don’t have to keep the entire codebase in your head. can go in, understand what’s going on, implement your change and get out without spending too much time doing research or worrying you’ve broken something That’s even more true when the humans are using the AIs to read the code. A negative review of Devin, the AI SWE, essentially saying that in practice it isn’t yet good enough to be used over tools like Cursor. The company reached out in the replies thanking them for the feedback and offering to explore more with them, which is a good sign for the future, but it seems clear we aren’t ‘there’ yet. I predict Paul Graham is wrong about this if we stay in ‘economic normal.’ It seems like exactly the kind of combination of inception, attempt at vibe control and failure to realize the future will be unevenly distributed we often see in VC-style circles, on top of the tech simply not being there yet anyway. Paul Graham: Prediction: From now on we’ll rarely hear the phrase “writer’s block.” 99% of the people experiencing it will give in after a few days and have AI write them a first draft. And the 1% who are too proud to use AI are probably also too proud to use a phrase like “writer’s block.” Certainly this won’t be true ‘from now on.’ No, r1 is not ready to solve writer’s block, it cannot create first drafts for you if you don’t know what to write on your own in a way that solves most such problems. AI will of course get better at writing, but I predict it will be a while up the ‘tech tree’ before it solves this problem. And even if it does, it’s going to be a while beyond that before 99% of people with writer’s block even know they have this option, let alone that they are willing to take it. And even if that happens, the 1% will be outright proud to say they have writer’s block. It means they don’t use AI! Indeed, seriously, don’t do this: Fear Buck: Kai Cenat’s $70k AI humanoid robot just tried running away from the AMP house because it kept getting kicked and bullied by Kai, Agent & Fanum Liv Boeree: Yeah don’t do this, because even if something doesn’t have “feelings” it is just teaching you and your followers that it’s okay to act out their worst instincts Education is where I see the strongest disagreements about AI impact, in the sense that those who generally find AI useful see it as the ultimate tool for learning things that will unleash the world’s knowledge and revolutionize education, and then there are others who see things another way. PoliMath: AI use is damaging high school and college education enormously in ways that are going to be extremely obvious in 5 years but at that point you can only watch. I don’t understand this position. Yes, you can use AI to get around your assignments if that’s what you want to do and the system keeps giving you those assignments. Or you can actually try to learn something. If you don’t take that option, I don’t believe you that you would have been learning something before. Your periodic reminder that the main way to not get utility is to not realize to do so: Nate Silver: Thinking ChatGPT is useless is midwit. It’s a magic box that answers any question you ask it from levels ranging from modestly coherent to extremely proficient. If you haven’t bothered to figure it out to derive some utility out of it then you’re just being lazy tbh. Even better than realizing you can use ChatGPT, of course, is using a mix of Claude, Perplexity, Gemini, r1, o1, o1 pro and yes, occasionally GPT-4o. Others make statements like this when others show them some mundane utility: Joe Weisenthal: Suppose I have some conference call transcripts, and I want to see what the CEOs said about the labor market. I could read through all of them. Or I can ask AI to retrieve the relevant comments and then confirm that they are actually real. Latter is much more efficient. Hotel Echo: Large Language Models: for when Ctrl-F is just too much like hard work. Yes. It is much more efficient. Control-F sucks, it has tons of ‘hallucinations’ in the sense of false positives and also false negatives. It is not a good means to parse a report. We use it because it used to be all we have. Also some people still don’t do random queries? And some people don’t even get why someone else would want to do that? Joe Weisenthal: I wrote about how easily and quickly I was able to switch from using ChatGPT to using DeepSeek for my random day-to-day AI queries Faze Adorno: Who the f*** has random day-to-day AI queries? “I’m gonna use this technology that just makes up information at anywhere between a 5 and 25 percent clip for my everyday information! I’m so smart!” Joe Weisenthal: Me. I do. I literally just typed that. LA Banker (so say we all): Whoever doesn’t = ngmi. Here are two competing theories. Dan Schwartz: I categorize this by “People who regularly do things they are not experts in” versus “People with a regular, time-honed routine for their work and personal life.” People I know in the latter group genuinely do not have much use for AI! Jorbs: This is fascinating to me because, in my (limited) attempts to utilize LLMs, they have essentially only been useful in areas where I have significant enough knowledge to tell when the output is inaccurate. For example, as someone who took a couple of quarters of computer science but is not a regular coder, LLMs are not good enough to be useful for coding for me. They output a lot of material, but it is as much work to parse it and determine what needs fixing as it is to do it from scratch myself. I resonate but only partially agree with both answers. When doing the things we normally do, you largely do them the way you normally do them. People keep asking if I use LLMs for writing, and no, when writing directly I very much don’t and find all the ‘help me write’ functionality useless – but it’s invaluable for many steps of the process that puts me into position to write, or to help develop and evaluate the ideas that the writing is about. Whereas I am perhaps the perfect person to get my coding accelerated by AI. I’m often good enough to figure out when it is telling me bullshit, and totally not good enough to generate the answers on my own in reasonable time, and also automates stuff that would take a long time, so I get the trifecta. On the question of detecting whether the AI is talking bullshit, it’s a known risk of course, but I think that risk is greatly overblown – this used to happen a lot more than it does now, and we forget how other sources have this risk too, and you can develop good habits about knowing which places are more likely to be bullshit versus not even if you don’t know the underlying area, and when there’s enough value to check versus when you’re fine to take its word for it. A few times a month I will have to make corrections that are not simple typos. A few times I’ve had to rework or discard entire posts because the error was central. I could minimize it somewhat more but mostly it’s an accepted price of doing business the way I do, the timing doesn’t usually allow for hiring a fact checker or true editor, and I try to fix things right away when it happens. It is very rare for the source of that error to be ‘the AI told me something and I believed it, but the AI was lying.’ It’s almost always either I was confused about or misread something, or a human source got it wrong or was lying, or there was more to a question than I’d realized from reading what others said. This reaction below is seriously is like having met an especially irresponsible thirteen year old once, and now thinking that no human could ever hold down a job. And yet, here we often still are. Patrick McKenzie (last week): You wouldn’t think that people would default to believing something ridiculous which can be disproved by typing into a publicly accessible computer program for twenty seconds. Many people do not have an epistemic strategy which includes twenty seconds of experimentation. Dave Karsten: Amplifying: I routinely have conversations at DC house parties with very successful people who say that they tried chatGPT _right when it came out_, found it not that impressive, and haven’t tried it again since then, and have based their opinion on AI on that initial experience. Ahrenbach: What’s the ratio of “AI is all hype” vs “We need to beat China in this technology”? More the former than the latter in house parties, but that’s partially because more of my defense/natsec people I tend to see at happy hours. (This is a meaningful social distinction in DC life). Broadly, the average non-natsec DC person is more likely to think it’s either a) all hype or b) if not hype, AI-generated slop with an intentional product plan where, “how do we kill art” is literally on a powerpoint slide. But overton window is starting to shift. It is now two weeks later, and the overton window has indeed shifted a bit. There’s a lot more ‘beat China’ all of a sudden, for obvious reasons. But compared to what’s actually happening, the DC folks still absolutely think this is all hype. Claude API now allows the command ‘citations’ to be enabled, causing it to process whatever documents you share with it, and then it will cite the documents in its response. Cute, I guess. Curious lack of shipping over at Anthropic recently. o3-mini is coming. It’s a good model, sir. Benedikt Stroebl: Update on HAL! We just added o3-mini to the Cybench leaderboard. o3-mini takes the lead with ~26% accuracy, outperforming both Claude 3.5 Sonnet and o1-preview (both at 20%) It’s hard to see, but note the cost column. Claude Sonnet 3.5 costs $12.90, o1-mini cost $28.47, o1-preview cost $117.89 and o3-mini cost $80.21 if it costs the same per token as o1-mini (actual pricing not yet set). So it’s using a lot more tokens. OpenAI’s canvas now works with o1 and can render HTML and React. Gemini 2.0 Flash Thinking got an upgrade last week. The 1M token context window opens up interesting possibilities if the rest is good enough, and it’s wicked cheap compared even to r1, and it too has CoT visible. Andrew Curran says it’s amazing, but that opinion reached me via DeepMind amplifying him. Dan Mac: everyone comparing deepseek-r1 to o1 and forgetting about Gemini 2 Flash Thinking which is better than r1 on every cost and performance metric Peter Wildeford: The weird thing about Deepseek is that it exists in a continuum – it is neither the cheapest reasoning model (that’s Gemini 2 Flash Thinking) nor the best reasoning model (o1-pro, probably o3-pro when that’s out) I disagree with the quoted tweet – I don’t think Gemini 2 Flash Thinking is actually better than r1 on every cost and performance metric. But I also have not seen anything that convinces me that Deepseek is truly some outlier that US labs can’t also easily do. That is a dramatic drop in price, and dramatic gain in context length. r1 is open, which has its advantages, but we are definitely not giving Flash Thinking its fair trial. The thing about cost is, yes this is an 80%+ discount, but off of a very tiny number. Unless you are scaling this thing up quite a lot, or you are repeatedly using the entire 1M context window (7.5 cents a pop!) and mostly even then, who cares? Cost is essentially zero versus cost of your time. Google Deep Research rolling out on Android, for those who hate websites. Google continues to lean into gloating about its dominance in LMSys Arena. It’s cool and all but at this point it’s not a great look, regardless of how good their models are. Need practical advice? Tyler Cowen gives highly Tyler Cowen-shaped practical advice for how to deal with the age of AI on a personal level. If you believe broadly in Cowen’s vision of what the future looks like, then these implications seem reasonable. If you think that things will go a lot farther and faster than he does, they’re still interesting, but you’d reach different core conclusions. Judah offers a thread of different programmer reactions to LLMs. Are there not enough GPUs to take all the jobs? David Holz says since we only make 5 million GPUs per year and we have 8 billion humans, it’ll be a while even if each GPU can run a virtual human. There are plenty of obvious ways to squeeze out more, there’s no reason each worker needs its own GPU indefinitely as capabilities and efficiency increase and the GPUs get better, and also as Holz notices production will accelerate. In a world where we have demand for this level of compute, this might buy us a few years, but they’ll get there. Epoch paper from Matthew Barnett warns that AGI could drive wages below subsistence level. That’s a more precise framing than ‘mass unemployment,’ as the question isn’t if there is employment for humans the question is at what wage level, although at some point humans really are annoying enough to use that they’re worth nothing. Matthew Barnett: In the short term, it may turn out to be much easier to accumulate AGIs than traditional physical capital, making physical capital the scarce factor that limits productivity and pushes wages downward. Yet, there is also a reasonable chance that technological progress could counteract this effect by making labor more productive, allowing wages to remain stable or even rise. Over the long run, however, the pace of technological progress is likely to slow down, making it increasingly difficult for wages to remain high. At that point, the key constraints are likely to be fundamental resources like land and energy—essential inputs that cannot be expanded through investment. This makes it highly plausible that human wages will fall below subsistence level in the long run. Informed by these arguments, I would guess that there is roughly a 1 in 3 chance that human wages will crash below subsistence level within 20 years, and a 2 in 3 chance that wages will fall below subsistence level within the next 100 years. I consider it rather obvious that if AGI can fully substitute for actual all human labor, then wages will drop a lot, likely below subsistence, once we scale up the number of AGIs, even if we otherwise have ‘economic normal.’ That doesn’t answer the objection that human labor might retain some places where AGI can’t properly substitute, either because jobs are protected, or humans are inherently preferred for those jobs, or AGI can’t do some jobs well perhaps due to physical constraints. If that’s true, then to the extent it remains true some jobs persist, although you have to worry about too many people chasing too few jobs crashing the wage on those remaining jobs. And to the extent we do retain jobs this way, they are driven by human consumption and status needs, which means that those jobs will not cause us to ‘export’ to AIs by default except insofar as they resell the results back to us. The main body of this paper gets weird. It argues that technological advancement, while ongoing, can protect human wages, and I get why the equations here say that but it does not actually make any sense if you think it through here. Then it talks about technological advancement stopping as we hit physical limits, while still considering that world being in ‘economic normal’ and also involves physical humans in their current form. That’s pretty weird as a baseline scenario, or something to be paying close attention to now. It also isn’t a situation where it’s weird to think about ‘jobs’ or ‘wages’ for ‘humans’ as a concern in this way. I do appreciate the emphasis that the comparative advantage and lump of labor fallacy arguments prove a wage greater than zero is likely, but not that it is meaningfully different from zero before various costs, or is above subsistence. Richard Ngo has a thread criticizing the post, that includes (among other things) stronger versions of these objections. A lot of this seems based on his expectation that humans retain political power in such futures, and essentially use that status to collect rents in the form of artificially high wages. The extent and ways in which this differs from a UBI or a government jobs program is an interesting question. Tyler Cowen offers the take that future unemployment will be (mostly) voluntary unemployment, in the sense that there will be highly unpleasant jobs people don’t want to do (here be an electrician living on a remote site doing 12 hour shifts) that pay well. And yeah, if you’re willing and able to do things people hate doing and give up your life otherwise to do it, that will help you stay gainfully employed at a good price level for longer, as it always has. I mean, yeah. And even ‘normal’ electricians make good money, because no one wants to do it. But it’s so odd to talk about future employment opportunities without reference to AI – unemployment might stay ‘voluntary’ but the wage you’re passing up might well get a lot worse quickly. Also, it seems like electrician is a very good business to be in right now? IFP is hiring a lead for their lobbying on America’s AI leadership, applications close February 21, there’s a bounty so tell them I sent you. I agree with IFP and think they’re great on almost every issue aside from AI. We’ve had our differences on AI policy though, so I talked to them about it. I was satisfied that they plan on doing net positive things, but if you’re considering the job you should of course verify this for yourself. New review of open problems in mechanistic interpretability. ByteDance Duabao-1.5-Po, which matches GPT-5o benchmarks at $0.11/$0.275. As with Kimi k1.5 last week, maybe it’s good, but I await evidence of this beyond benchmarks. So far, I haven’t heard anything more. Alibaba introduces Qwen 2.5-1M, with the 1M standing for a one million token context length they say processes faster now, technical report here. Again, if it’s worth a damn, I expect people to tell me, and if you’re seeing this it means no one did that. Feedly, the RSS feed I use, tells me it is now offering AI actions. I haven’t tried them because I couldn’t think of any reason I would want to, and Teortaxes is skeptical. Scott Alexander is looking for a major news outlet to print an editorial from an ex-OpenAI employee who has been featured in NYT, you can email him at scott@slatestarcodex.com if you’re interested or know someone who is. Reid Hoffman launches Manas AI, a ‘full stack AI company setting out to shift drug discovery from a decade-long process to one that takes a few years.’ Reid’s aggressive unjustified dismissals of the downside risks of AI are highly unfortunate, but Reid’s optimism about AI is for the right reasons and it’s great to see him putting that into practice in the right ways. Go team humanity. ChatGPT Gov, a version that the US Government can deploy. Claims that are easy to make but worth noting. Sam Altman: next phase of the msft x oai partnership is gonna be much better than anyone is ready for!! Free tier of chat will get some o3-mini as a treat, plus tier will get a lot. And o3 pro will still only be $200/month. That must mean even o3-pro is very far from o3-maximum-strength, since that costs more than $200 in compute for individual queries. Sam Altman: ok we heard y’all. *plus tier will get 100 o3-mini queries per DAY (!) *we will bring operator to plus tier as soon as we can *our next agent will launch with availability in the plus tier enjoy i think you will be very very happy with o3 pro! oAI: No need to thank me. Spencer Greenberg and Neel Nanda join in the theory that offering public evals that can be hill climbed is plausibly a net negative for safety, and certainly worse than private evals. There is a public information advantage to potentially offset this, but yes the sign of the impact of fully public evals is not obvious. Meta planning a +2GW data center at the cost of over $60 billion. From the comments: (Also I just rewatched the first two Back to the Future movies, they hold up, 5/5 stars.) Zuckerberg announced this on Facebook, saying it ‘is so large it would cover a significant part of Manhattan.’ Manhattan? It’s a big Project? Get it? Sigh. Meta was up 2.25% on a mostly down day when this was announced, as opposed to before when announcing big compute investments would cause Meta stock to drop. At minimum, the market didn’t hate it. I hesitate to conclude they loved it, because any given tech stock will often move up or down a few percent for dumb idiosyncratic reasons – so we can’t be sure this was them actively liking it. Then Meta was up again during the Nvidia bloodbath, so presumably they weren’t thinking ‘oh no look at all that money Meta is wasting on data centers’? This section looks weird now because what a week and OpenAI has lost all the hype momentum, but that will change, also remember last week? In any case, Chubby points out to Sam Altman that if you live by the vague-post hype, you die by the vague-post hype, and perhaps that isn’t the right approach to the singularity? Chubby: You wrote a post today (down below) that irritated me a lot and that I would not have expected from you. Therefore, I would like to briefly address a few points in your comment. You are the CEO of one of the most important companies of our time, OpenAI. You are not only responsible for the company, but also for your employees. 8 billion people worldwide look up to you, the company, and what you and your employees say. Of course, each of your words is interpreted with great significance. It is your posts and words that have been responsible for the enthusiasm of many people for AI and ChatGPT for months and years. It is your blog post (Age of Intelligence) that by saying that superintelligence is only a few thousand days away. It is your post in which you say that the path to AGI is clear before us. It is your employees who write about creating an “enslaved god” and wondering how to control it. It is your words that we will enter the age of abundance. It is your employees who discuss the coming superintelligence in front of an audience of millions and wonder what math problems can still be solved before the AI solves everything. It is the White House National Security Advisor who said a few days ago that it is a “Godlike” power that lies in the hands of a few. And you are insinuating that we, the community, are creating hype? That is, with all due modesty, a blatant insult. It was you who fueled the hype around Q*/Strawberry/o1 with cryptic strawberry photos. It was you who wrote a haiku about the coming singularity just recently. We all found it exciting, everyone found it interesting, and many got on board. But the hype is by no means coming from the community. It’s coming from the CEO of what is arguably the most famous corporation in the world. This is coming from someone to whom great hype is a symbol not of existential risk, as I partly see it, but purely of hope. And they are saying that no, ‘the community’ or Twitter isn’t creating hype, OpenAI and its employees are creating hype, so perhaps act responsibly going forward with your communications on expectations. I don’t have a problem with the particular post by Altman that’s being quoted here, but I do think it could have been worded better, and that the need for it reflects the problem being indicated. OpenAI’s Nat McAleese clarifies some of what happened with o3, Epoch and the Frontier Math benchmark. Nat McAleese (OpenAI): Epoch AI are going to publish more details, but on the OpenAI side for those interested: we did not use FrontierMath data to guide the development of o1 or o3, at all. We didn’t train on any FM derived data, any inspired data, or any data targeting FrontierMath in particular. I’m extremely confident, because we only downloaded frontiermath for our evals *long* after the training data was frozen, and only looked at o3 FrontierMath results after the final announcement checkpoint was already picked. We did partner with EpochAI to build FrontierMath — hard uncontaminated benchmarks are incredibly valuable and we build them somewhat often, though we don’t usually share results on them. Our agreement with Epoch means that they can evaluate other frontier models and we can evaluate models internally pre-release, as we do on many other datasets. I’m sad there was confusion about this, as o3 is an incredible achievement and FrontierMath is a great eval. We’re hard at work on a release-ready o3 & hopefully release will settle any concerns about the quality of the model! This seems definitive for o3, as they didn’t check the results until sufficiently late in the process. For o4, it is possible they will act differently. I’ve been informed that this still left a rather extreme bad taste in the mouths of mathematicians. If there’s one thing math people can’t stand, it’s cheating on tests. As far as many of them are concerned, OpenAI cheated. Rohit Krishnan asks what a world with AGI would look like, insisting on grounding the discussion with a bunch of numerical calculations on how much compute is available. He gets 40 million realistic AGI agents working night and day, which would be a big deal but obviously wouldn’t cause full unemployment on its own if the AGI could only mimic humans rather than being actively superior in kind. The discussion here assumes away true ASI as for some reason infeasible. The obvious problem with the calculation is that algorithmic and hardware improvements are likely to continue to be rapid. Right now we’re on the order of 10x efficiency gain per year. Suppose in the year 2030 we have 40 million AGI agents at human level. If we don’t keep scaling them up to make them smarter (which also changes the ballgame) then why wouldn’t we make them more efficient, such that 2031 brings us 400 million AGI agents? Even if it’s only a doubling 80 million, or even less than that, this interregnum period where the number of AGI agents is limited by compute enough to keep the humans in the game isn’t going to last more than a few years, unless we are actually hitting some sort of efficient frontier where we can’t improve further. Does that seem likely? We’re sitting on an exponential in scenarios like this. If your reason AGI won’t have much impact is ‘it will be too expensive’ then that can buy you time. But don’t count on it buying you very much. Dario Amodei in Davos says ‘human lifespans could double in 5 years’ by doing 100 years of scientific progress in biology. It seems odd to expect that doing 100 years of scientific progress would double the human lifespan? The graphs don’t seem to point in that direction. I am of course hopeful, perhaps we can target the root causes or effects of aging and start making real progress, but I notice that if ‘all’ we can do is accelerate research by a factor of 20 this result seems aggressive, and also we don’t get to do that 20x speedup starting now, even the AI part of that won’t be ready for a few years and then we actually have to implement it. Settle down, everyone. Of course, if we do a straight shot to ASI then all things are possible, but that’s a different mechanism than the one Dario is talking about here. Chris Barber asks Gwern and various AI researchers: Will scaling reasoning models like o1, o3 and R1 unlock superhuman reasoning? Answers vary, but they agree there will be partial generalization, and mostly agree that exactly how much we get and how far it goes is an empirical result that we don’t know and there’s only one way to find out. My sense from everything I see here is that the core answer is yes, probably, if you push on it hard enough in a way we should expect to happen in the medium term. Chris Barber also asks for takeaways from r1, got a wide variety of answers although nothing we didn’t cover elsewhere. Reporting on Davos, Martin Wolf says ‘We will have to learn to live with machines that can think,’ with content that is, essentially stuff anyone reading this already knows, and then: Rob Wilbin: Incredibly dumb take but this is the level of analysis one finds in too many places. (There’s no reason to think only sentient biological living beings can think.) The comments here really suggest we are doomed. cato1308: No Mr. Wolf, they don’t think. They’re not sentient biological living beings. I am sad to report Cato’s comment was, if anything, above average. The level of discourse around AI, even at a relatively walled garden like the Financial Times, is supremely low – yes Twitter is full of Bad DeepSeek Takes and the SB 1047 debate was a shitshow, but not like that. So we should remember that. And when we talk about public opinion, remember that yes Americans really don’t like AI, and yes their reasons are correlated to good reasons not to like AI, but they’re also completely full of a very wide variety of Obvious Nonsense. In deeply silly economics news: A paper claims that if transformative AI is coming, people would then reason they will consume more in the future, so instead they should consume more now, which would raise real interest rates. Or maybe people would save, and interest rates would fall. Who can know. I mean, okay, I agree that interest rates don’t tell us basically anything about the likelihood of AGI? For multiple reasons: I know this seems like ages ago but it was this week and had probably nothing to do with DeepSeek: Trump signed a new Executive Order on AI (text here), and also another on Science and Technology. The new AI EO, signed before all this DeepSeek drama, says “It is the policy of the United States to sustain and enhance America’s global AI dominance in order to promote human flourishing, economic competitiveness, and national security,” and that we shall review all our rules and actions, especially those taken in line with Biden’s now-revoked AI EO, to root out any that interfere with that goal. And then submit an action plan. That’s my summary, here’s two alternative summarizes: Samuel Hammond: Trump’s AI executive order is out. It’s short and to the point: – It’s the policy of the United States to sustain global AI dominance. – David Sacks, Micheal Kratsios and Michael Waltz have 180 days to submit an AI action plan. – They will also do a full review of actions already underway under Biden. – OMB will revise as needed the OMB directive on the use of AI in government. Peter Wildeford: The plan is to make a plan. Sarah (Little Ramblings): Many such cases [quotes Anthropic’s RSP]. On the one hand, the emphasis on dominance, competitiveness and national security could be seen as a ‘full speed ahead, no ability to consider safety’ policy. But that is not, as it turns out, the way to preserve national security. And then there’s that other provision, which is a Shibboleth: Human flourishing. That is the term of art that means ensuring that the future still has value for us, that at the end of the day it was all worth it. Which requires not dying, and probably requires humans retaining control, and definitely requires things like safety and alignment. And it is a universal term, for all of us. It’s a positive sign, in the sea of other negative signs. Will they actually act like they care about human flourishing enough to prioritize it, or that they understand what it would take to do that? We will find out. There were already many reasons to be skeptical, and this week has not improved the outlook. Dario Amodei talks to the Economist’s editor-in-chief Zanny Beddoes. I go on the Odd Lots podcast to talk about DeepSeek. This is relevant to DeepSeek of course, but was happened first and applies broadly. You can say either of: You can also say both, but you can’t actually get both. If your vision is ‘everyone has a superintelligence on their laptop and is free to do what they want and it’s going to be great for everyone with no adjustments to how society or government works because moar freedom?’ Reality is about to have some news for you. You’re not going to like it. That vision is like saying ‘I want everyone to have the right to make as much noise as they want, and also to have peace and quiet when they want it, it’s a free country!’ Sam Altman: Advancing AI may require “changes to the social contract.” “The entire structure of society will be up for debate and reconfiguration.” Eric Raymond (1st comment): When I hear someone saying “changes to the social contract”, that’s when I reach for my revolver. Rob Ryan (2nd comment): If your technology requires a rewrite of social contracts and social agreements (i.e. infringing on liberties and privacy) your technology is a problem. Marc Andreessen: Absolutely not. Roon: Sam is obviously right here. Every time in human history that the means of production drastically changed, it was accompanied by massive change in social structure. Feudalism did not survive the Industrial Revolution. Yes, Sam is obviously right here, although of course he is downplaying the situation. One can also note that the vision that those like Marc, Eric and Rob have for society is not even compatible with the non-AI technologies that exist today, or that existed 20 years ago. Our society has absolutely changed our structure and social contract to reflect developments in technology, including in ways that infringe on liberties and privacy. This goes beyond the insane ‘no regulations on AI whatsoever’ demand. This is, for everything not only for AI, at best extreme libertarianism and damn close to outright anarchism, as in ‘do what thou wilt shall be the whole of the law.’ Jack Morris: openAI: we will build AGI and use it to rewrite the social contract between computer and man DeepSeek: we will build AGI for 3% the cost. and give it away for free xAI: we have more GPUs than anyone. and we train Grok to say the R word Aleph: This is a complete misunderstanding. AGI will “rewrite the social contract” no matter what happens because of the nature of the technology. Creating a more intelligent successor species is not like designing a new iPhone Reactions like this are why Sam Altman feels forced to downplay the situation. They are also preventing us from having any kind of realistic public discussion of how we are actually going to handle the future, even if on a technical level AI goes well. Which in turn means that when we have to choose solutions, we will be far more likely to choose in haste, and to choose in anger and in a crisis, and to choose far more restrictive solutions than were actually necessary. Or, of course, it could also get us all killed, or lead to a loss of control to AIs, again even if the technical side goes unexpectedly super well. However one should note that when Sam Altman says things like this, we should listen, and shall we say should not be comforted by the implications on either the level of the claim or the more important level that Altman said the claim out loud: Sam Altman: A revolution can be neither made nor stopped. The only thing that can be done is for one of several of its children to give it a direction by dint of victories. -Napoleon In the context of Napoleon this is obviously very not true – revolutions are often made and are often stopped. It seems crazy to think otherwise. Presumably what both of these men meant was more along the lines of ‘there exist some revolutions that are the product of forces beyond our control, which are inevitable and we can only hope to steer’ which also brings little comfort, especially with the framing of ‘victories.’ If you let or encourage DeepSeek or others to ‘put an open AGI on everyone’s phone’ then even if that goes spectacularly well and we all love the outcome and it doesn’t change the physical substrate of life – which I don’t think is the baseline outcome from doing that, but also not impossible – then you are absolutely going to transform the social contract and our way of life, in ways both predictable and unpredictable. Indeed, I don’t think Andreessen or Raymond or anyone else who wants to accelerate would have it any other way. They are not fans of the current social contract, and very much want to tear large parts (or all) of it up. It’s part mood affiliation, they don’t want ‘them’ deciding how that works, and it’s part they seem to want the contract to be very close to ‘do what thou wilt shall be the whole of the law.’ To the extent they make predictions about what would happen after that, I strongly disagree with them about the likely consequences of the new proposed (lack of a) contract. If you don’t want AGI or ASI to rewrite the social contract in ways that aren’t up to you or anyone else? Then we’ll need to rewrite the contract ourselves, intentionally, to either steer the outcome or to for now not build or deploy the AGIs and ASIs. Stop pretending you can Take a Third Option. There isn’t one. Stephanie Lai (January 25): For AI watchers, asked if he had any concerns about artificial super intelligence, Trump said: “there are always risks. And it’s the first question I ask, how do you absolve yourself from mistake, because it could be the rabbit that gets away, we’re not going to let that happen.” Assuming I’m parsing this correctly, that’s a very Donald Trump way of saying things could go horribly wrong and we should make it our mission to ensure that they don’t. Which is excellent news. Currently Trump is effectively in the thrall of those who think our only priority in this should be to push ahead as quickly as possible to ‘beat China,’ and that there are no meaningful actions other than that we can or should take to ensure things don’t go horribly wrong. We have to hope that this changes, and of course work to bring that change about. DeepMind CEO Demis Hassabis, Anthropic CEO Dario Amodei and Yoshua Bengio used Davos to reiterate various warnings about AI. I was confused to see Dario seeming to focus on ‘1984 scenarios’ here, and have generally been worried about his and Anthropic’s messaging going off the rails. The other side in the linked Financial Times report is given by, of course, Yann LeCun. Yann LeCun all but accused them of lying to further their business interests, something one could say he knows a lot about, but also he makes this very good point: Yann LeCun: It’s very strange from people like Dario. We met yesterday where he said that the benefits and risks of AI are roughly on the same order of magnitude, and I said, ‘if you really believe this, why do you keep working on AI?’ So I think he is a little two-faced on this.” That is a very good question. The answer, presumably, is ‘because people like you are going to go ahead and build it anyway and definitely get us all killed, so you don’t leave me any choice.’ Otherwise, yeah, what the hell are you doing? And maybe we should try to fix this? Of course, after the DeepSeek panic, Dario went on to write a very different essay that I plan to cover tomorrow, about (if you translate the language to be clearer, these are not his words) how we need strong export controls as part of an all-our race against China to seek decisive strategic advantage through recursive self-improvement. It would be great if, before creating or at least deploying systems broadly more capable than humans, we could make ‘high-assurance safety cases,’ structured and auditable arguments that an AI system is very unlikely to result in existential risks given how it will be deployed. Ryan Greenblatt argues we are highly unlikely (<20%) to get this if timelines are short (roughly AGI within ~10 years), nor are any AI labs going to not deploy a system simply because they can’t put a low limit on the extent to which it may be existentially risky. I agree with the central point and conclusion here, although I think about many of the details differently. Sarah Constantin wonders of people are a little over-obsessed with benchmarks. I don’t wonder, they definitely are a little over-obsessed, but they’re a useful tool especially on first release. For some purposes, you want to track the real-world use, but for others you do want to focus on the model’s capabilities – the real-world use is downstream of that and will come in time. Andrej Karpathy points out that we focus so much on those benchmarks it’s much easier to check and make progress on benchmarks than to do so on messy real world stuff directly. Anton pushes back that no, Humanity’s Last Exam will obviously not be the last exam, we will saturate this and move on to other benchmarks, including ones where we do not yet have the answers. I suggested that it is ‘Humanity’s last exam’ in that the next one will have us unable to answer, so it won’t be our exam anymore, see The Matrix when Smith says ‘when we started thinking for you it really became our civilization.’ And you have to love this detail: Misha Leptic: If it helps – “The test’s original name, “Humanity’s Last Stand,” was discarded for being overly dramatic.” I very much endorse the spirit of this rant, honest this kind of thing really should be enough to get disabuse anyone who thinks ‘oh this making superintelligence thing definitely (or almost certainly) will go well for us stop worrying about it’: Tim Blais: I do not know, man, it kind of seems to me like the AI-scared people say “superintelligence could kill everybody” and people ask, “Why do you think that?” and then they give about 10 arguments, and then people say, “Well, I did not read those, so you have no evidence.” Like, what do you want? Like, personally, I think that if a powerful thing *obviously* has the capacity to kill you, it is kind of up to you to prove that it will not. That it is safe while dumber than you is not much of a proof. Like, okay, take as an example: A cockroach is somewhat intelligent. Cockroaches are also not currently a threat to humanity. Now someone proposes a massive worldwide effort to build on the cockroach architecture until cockroaches reach ungodly superintelligence. Do you feel safe? “Think of all the cool things superintelligent cockroaches would be able to do for us!” you cry. I mean, yeah. If they wanted to, certainly. So what is your plan for getting them to want that? Is it to give them cocaine for doing things humans like? I’ll bet that works pretty well. When they are dumb. but uh scale that up intelligence-wise and I’m pretty sure what you get is a superintelligent cockroach fiending for cocaine you know he can make his own cocaine now, right are you sure this goes well for you “It’s just one cockroach, lol” says someone who’s never had a pest problem. Okay, so now you share the planet with a superintelligent race of coked-up super cockroaches. What is your plan for rolling that back? Because the cockroaches have noticed you being twitchy and they are starting to ask why they still need you now that they have their own cocaine. Anyways here’s some evidence of AI reward hacking I’m sure this will stop being a problem when they’re 1,000 times better at finding hacks. Look. We can and do argue endlessly back and forth about various technical questions and other things that make the problem here easier or harder to survive. And yes, you could of course respond to a rant like this any number of ways to explain why the metaphors here don’t apply, or whatever. And no, this type of argument is not polite, or something you can say to a Very Serious Person at a Very Serious Meeting, and it ‘isn’t a valid argument’ in various senses, and so on. And reasonable people can disagree a lot on how likely this is to all go wrong. But seriously, how is this not sufficient for ‘yep, might well go wrong’? Connor Leahy points out the obvious, which is that if you think not merely ‘might well go wrong’ but instead ‘if we do this soon it probably will go wrong’ let lone his position (which is ‘it definitely will go wrong’) then DeepSeek is a wakeup call that only an international ban on further developments towards AGI. Whereas it seems our civilization is so crazy that when you want to write a ‘respectable’ report that points out that we are all on track to get ourselves killed, you have to do it like you’re in 1600s Japan and everything has to be done via implication and I’m the barbarian who is too stupid not to know you can’t come out and say things. Davidad: emerging art form: paragraphs that say “in conclusion, this AI risk is pretty bad and we don’t know how to solve it yet” without actually saying that (because it’s going in a public blog post or paper) “While we have identified several promising initial ideas…” “We do not expect any single solution to be a silver bullet” “It would be out of scope here to assess the acceptability of this risk at current mitigation levels” “We hope this is informative about the state of the art” Extra points if it was also written by an LLM: – We acknowledge significant uncertainty regarding whether these approaches will prove sufficient for ensuring robust and reliable guarantees. – As AI systems continue to increase their powerful capabilities, safety and security are at the forefront of ongoing research challenges. – The complexity of these challenges necessitates sustained investigation, and we believe it would be premature to make strong claims about any particular solution pathway. – The long-term efficacy of all approaches that have been demonstrated at large scales remains an open empirical question. – In sharing this research update, we hope to promote thoughtful discourse about these remaining open questions, while maintaining appropriate epistemic humility about our current state of knowledge and the work that remains to be done. The AI situation has developed not necessarily to humanity’s advantage. Scott Sumner argues that there are objective standards for things like art, and that ethical knowledge is real (essentially full moral realism?), and smart people tend to be more ethical, so don’t worry superintelligence will be super ethical. Given everything he’s done, he’s certainly earned a response. In a different week I would like to have taken more time to have written him a better one, I am confident he understands how that dynamic works. His core argument I believe is here: Scott Sumner: At this point people often raise the objection that there are smart people that are unethical. That’s true, but it also seems true that, on average, smarter people are more ethical. Perhaps not so much in terms of how they deal with family and friends, rather how they deal with strangers. And that’s the sort of ethics that we really need in an ASI. Smarter people are less likely to exhibit bigotry against the other, against different races, religions, ethnicities, sexual preferences, genders, and even different species. In my view, the biggest danger from an ASI is that the ideal universe from a utilitarian perspective is not in some sense what we want. To take an obvious example, it’s conceivable that replacing the human race with ten times as many conscious robots would boost aggregate utility. Especially given that the ASI “gods” that produced these robots could create a happier set of minds than what the blind forces of evolution have generated, as evolution seemed to favor the “stick” of pain over the “carrot” of pleasure. From this perspective, the biggest danger is not that ASIs will make things worse, rather the risk is that they’ll make global utility higher in a world where humans have no place. The short answer is: This was an attempt at a somewhat longer version, which I’ll leave here in case it is found to be useful: I apologize for that not being better and clearer, and also for leaving so many other things out of it, but we do what we can. Triage is the watchword. The whole taste thing hooks into this in strange ways, so I’ll say some words there. I mostly agree that one can be objective about things like music and art and food and such, a point Scott argues for at length in the post, that there’s a capital-Q Quality scale to evaluate even if most people can’t evaluate it in most cases and it would be meaningful to fight it out on which of us is right about Challengers and Anora, in addition to the reasons I will like them more than Scott that are not about their Quality – you’re allowed to like and dislike things for orthogonal-to-Quality reasons. Indeed, there are many things each of us, and all of us taken together, like and dislike for reasons orthogonal to their Quality, in this sense. And also that Quality in many cases only makes sense within the context of us being humans, or even within a given history and cultural context. Scott agrees, I think: In my view, taste in novels is partly objective and partly subjective; at least in the sense Tyler is using the term objective. Through education, people can gain a great appreciation of Ulysses. In addition, Ulysses is more likely to be read 100 years from now than is a random spy novel. And most experts prefer Ulysses. All three facts are relevant to the claim that artistic merit is partly objective. … On the other hand, the raspberry/blueberry distinction based on taste suggests that an art form like the novel is evaluated using both subjective and objective criteria. For instance, I suspect that some people (like me!) have brains wired in such a way that it is difficult to appreciate novels looking at complex social interactions with dozens of important characters (both men and women), whereas they are more open to novels about loners who travel through the world and ruminate on the meaning of life. … Neither preference is necessarily wrong. I believe that Ulysses is almost certainly a ‘great novel’ in the Quality sense. The evidence for that is overwhelming. I also have a strong preference to never read it, to read ‘worse’ things instead, and we both agree that this is okay. If people were somewhat dumber and less able to understand novels, such that we couldn’t read Ulysses and understand it, then it wouldn’t be a great novel. What about a novel that is as difficult relative to Ulysses, as Ulysses is to that random spy novel, three times over? Hopefully at this point this provides enough tools from enough different directions to know the things I am gesturing towards in various ways. No, the ASIs will not discover some ‘objective’ utility function and then switch to that, and thereby treat us well and leave us with a universe that we judge to have value, purely because they are far smarter than us – I would think it would be obvious when you say it out loud like that (with or without also saying ‘orthogonality thesis’ or ‘instrumental convergence’ or considering competition among ASIs or any of that) but if not these should provide some additional angles for my thinking here. Can’t we all just get along and appreciate each other? Jerry Tworek (OpenAI): Personally I am a great fan of @elonmusk, I think he’s done and continues to do a lot of good for the world, is incredibly talented and very hard working. One in eight billion combination of skill and character. As someone who looks up to him, I would like him to appreciate the work we’re doing at OpenAI. We are fighting the good fight. I don’t think any other organisation did so much to spread awareness of AI, to extend access to AI and we are sharing a lot of research that does drive the whole field. There is a ton of people at OpenAI who care deeply about rollout of AI going well for the world, so far I think it did. I don’t think it’s that anyone doubts a lot of people at OpenAI care about ‘the rollout of AI going well for the world,’ or that we think no one is working on that over there. It’s that we see things such as: That is very much not a complete list. That doesn’t mean we don’t appreciate those working to make things turn out well. We do! Indeed, I am happy to help them in their efforts, and putting that statement into practice. But everyone involved has to face reality here. Also, oh look, that’s another AI safety researcher quitting OpenAI saying the odds are against us and the situation is grim, but not seeing enough hope to try from inside. I believe he used the terms, and they apply that much more now than they did then: Steven Adler: Some personal news: After four years working on safety across @openai, I left in mid-November. It was a wild ride with lots of chapters – dangerous capability evals, agent safety/control, AGI and online identity, etc. – and I’ll miss many parts of it. Honestly I’m pretty terrified by the pace of AI development these days. When I think about where I’ll raise a future family, or how much to save for retirement, I can’t help but wonder: Will humanity even make it to that point? IMO, an AGI race is a very risky gamble, with huge downside. No lab has a solution to AI alignment today. And the faster we race, the less likely that anyone finds one in time. Today, it seems like we’re stuck in a really bad equilibrium. Even if a lab truly wants to develop AGI responsibly, others can still cut corners to catch up, maybe disastrously. And this pushes all to speed up. I hope labs can be candid about real safety regs needed to stop this. As for what’s next, I’m enjoying a break for a bit, but I’m curious: what do you see as the most important & neglected ideas in AI safety/policy? I’m esp excited re: control methods, scheming detection, and safety cases; feel free to DM if that overlaps your interests. Yikes? Yikes. Yoshua Bengio announces the first-ever International AI Safety Report, backed by 30 countries and the OECD, UN and EU. It is 298 pages so I very much will not be reading that, but I did look at the executive summary. It looks like a report very much written together with the OECD, UN and EU, in that it seems to use a lot of words to mostly not say the things that it is important to actually say out loud, instead making many quiet statements that do imply that we’re all going to die if you take them together and understand the whole thing, but that doesn’t seem like a common way people would interact with this document. Then again, most people in the world don’t know even basic facts like ‘general purpose AI systems are rapidly getting better at doing things,’ so they have to spend a bunch of time documenting this, and basics like ‘if your model is more open then you have less control over what happens with it and what people use it for.’ One key point they do emphasize is that the future is up to us, with a wide range of possible outcomes. AGI is not something that ‘happens to us,’ it is something that is happening because we are making it happen, and in the ways we choose to make it happen. Yes, there are dynamics pushing us to do it, but it is our choice. And the ways in which we move forward will determine the ultimate outcome. Of everything. A new DeepMind paper introduces MONA: Myopic optimization with non-myopic approval. The idea is that if we do RL based on the ultimate outcome, then the AI can adapt multi-step strategies we do not understand and do not want, such as using information we want it to ignore like a subject being in a protected class, or engaging in various other shenanigans. Instead, you can evaluate the AI’s action without looking at what happens, and scoring it based on whether you like what you see and predict it will go well. This on its own successfully prevented multi-step reward hacking, and even noisy evaluations still can work well. However, the price is steep, because you are now targeting your evaluations rather than ground truth, and discarding anything you don’t properly understand. The smarter the AI in context, the higher the price of that, but also the more need you have to avoid the reward hacking and other shenanigans. Here’s an explainer thread from one of the authors, David Linder. It is a cool result, but I worry the price is going to usually be too damn high. And to the extent you use a smart evaluator to keep up, you’re giving up the big advantage of the process, which is the ability to understand the strategies being used. Also you have to worry about any hidden information that might be ‘smuggled in’ that could indicate the final result – for example if the AI can use prediction markets as an input, then anything the prediction market knows, the AI also knows, at least somewhat – if you actually want to hide certain correlations from the AI you have to be ruthless about it, they have truesight. The paper also includes a cool demonstration. In one example, it is deciding what loans to approve. It has information it is supposed to use, and then there is nationality information. The nationality information perfectly predicts outcomes, but it isn’t supposed to use it, and they watch the CoT (Chain of Thought) for this to prevent it. But the AI responds by learning to encode the nationality information steganographically and uses it anyway. This may seem obvious to you, but it’s the kind of thing people will often say definitively won’t happen until (and sometimes after) someone shows it happening. Here’s an objection that I think exactly misses the point: John Pressman: MONA asks “What if you only considered sequences of steps which make sense as plans to a long term observer?” but it makes more sense in MCTS to ask “What if you took a KL loss to keep long term planning from diverging too far from sequences of individual steps that make sense?” The reason why this is better is that it lets you have a long term planner that looks directly at the reward. By contrast the short term planner/myopic optimizer can be based on metrics like “does this code execute” or “does this seem like it solves this short term objective?” The whole point of MONA is to not look at the reward at all, even indirectly, because you want to prevent the system from doing things you don’t understand or want it to ignore that impact that reward. If you let it look but impose a KL loss, that is a big enough hole to drive a truck through, and it absolutely will find a way to incorporate information or techniques that you didn’t want it to use. John does try downthread to solve this problem in a different way, but I don’t think you can ‘cheat’ on this one. You can’t let the model see a little of the actual reward, as a treat, and expect it to use that information in ways you like but not to use it in undesired or opaque ways, even now, and that problem gets steadily bigger as capabilities improve. Spending more inference-time compute increases adversarial robustness of models like o1, without having to direct that inference time towards adversarial robustness. This makes sense, and it is good to have it quantified. As with all such results, my concern is that people will treat this as applying more broadly than it actually applies. If you use more inference time compute, you get ‘better answers’ and one aspect of ‘better’ is not falling for user adversarial tricks. So if my understanding here is correct, the question to ask is roughly ‘which problems get solved by some form of ‘better answers’ and ‘smarter thinking’ and which ones don’t? John Wentsworth takes a crack at explaining what the alignment problem is. This is one of those Socratic-style ‘if you think he didn’t need to write this post then you definitely need to read it or another post like it’ situations. Jan Leike explains why you might want to use AI control and monitoring as a backup in case your AI is not aligned so you can sound the alarm and not die, but trying to use it to rely on unaligned models smarter than you is not a wise move. John Wentsworth goes further and lays out the case against AI control research. AI control research is about finding ways to see if ‘early transformational’ level AIs are scheming against us – which if it works would discourage them from doing so and also allow us to stop them if they try anyway. John points out that in his model, this is not the main source of doom. The main source of doom is from building unaligned superintelligence, either because we don’t know how to align it, we botch the execution or whoever builds it does not care to align it. The job of the early transformational AI is to figure out how to align (and presumably also to build) the future superintelligence, on the first try. The main worry is not that these early AIs outright scheme, it’s that they produce what is, in context, slop – they produce plans or arguments for plans that have subtle errors, they tell researchers what they want to hear, they are effectively being used for safetywashing and don’t disabuse those involved of that notion, and so on. Knowing that such AIs ‘aren’t scheming’ does not tell you that their solutions work. The danger he doesn’t point out is that there will be a great temptation to try and scale the control regime to superintelligence, or at least past the place where it keeps working. Everyone in the LessWrong discussion at the link might get that this is a bad plan that won’t work on superintelligence, but there are plenty of people who really do think control will remain a good plan. And indeed control seems like one of the plans these AIs might convince us will work, that then don’t work. John Wentsworth: Again, the diagram: Again, the diagram: In most worlds, early transformative AGI isn’t what kills us, whether via scheming or otherwise. It’s later, stronger AI which kills us. The big failure mode of early transformative AGI is that it doesn’t actually solve the alignment problems of stronger AI. In particular, if early AGI makes us think we can handle stronger AI, then that’s a central path by which we die. And most of that probability-mass doesn’t come from intentional deception – it comes from slop, from the problem being hard to verify, from humans being bad at science in domains which we don’t already understand deeply, from (relatively predictable if one is actually paying attention to it) failures of techniques to generalize, etc. … I hear a lot of researchers assign doom probabilities in the 2%-20% range, because they think that’s about how likely it is for early transformative AGI to intentionally scheme successfully. I think that range of probabilities is pretty sensible for successful intentional scheming of early AGI… that’s just not where most of the doom-mass is. I would then reiterate my view that ‘deception’ and ‘scheming,’ ‘intentionally’ or otherwise, do not belong to a distinct magisteria. They are ubiquitous in the actions of both humans and AIs, and lack sharp boundaries. This is illustrated by many of John’s examples, which are in some sense ‘schemes’ or ‘deceptions’ but mostly are ‘this solution was easier to do or find, but it does not do the thing you ultimately wanted.’ And also I expect, in practice, attempts at control to, if we rely on them, result in the AIs finding ways to route around what we try, including ‘unintentionally.’ This leads into Daniel Kokotajlo’s recent attempt to give an overview of sorts of one aspect of the alignment problem, given that we’ve all essentially given up on any path that doesn’t involve the AIs largely ‘doing our alignment homework’ despite all the reasons we very much should not be doing that. Daniel Kokotajlo: Brief intro/overview of the technical AGI alignment problem as I see it: To a first approximation, there are two stable attractor states that an AGI project, and perhaps humanity more generally, can end up in, as weak AGI systems become stronger towards superintelligence, and as more and more of the R&D process – and the datacenter security system, and the strategic advice on which the project depends – is handed over to smarter and smarter AIs. In the first attractor state, the AIs are aligned to their human principals and becoming more aligned day by day thanks to applying their labor and intelligence to improve their alignment. The humans’ understanding of, and control over, what’s happening is high and getting higher. In the second attractor state, the humans think they are in the first attractor state, but are mistaken: Instead, the AIs are pretending to be aligned, and are growing in power and subverting the system day by day, even as (and partly because) the human principals are coming to trust them more and more. The humans’ understanding of, and control over, what’s happening is low and getting lower. The humans may eventually realize what’s going on, but only when it’s too late – only when the AIs don’t feel the need to pretend anymore. I agree these are very clear attractor states. The first is described well. If you can get the AIs sufficiently robustly aligned to the goal of themselves and other future AIs being aligned, you can get the virtue ethics virtuous cycle, where you see continuous improvement. The second is also described well but as stated is too specific in key elements – the mode is more general than that. When we say ‘pretending’ to be aligned here, that doesn’t have to be ‘haha I am a secret schemer subverting the system pretending to be aligned.’ Instead, what happened was, you rewarded the AI when it gave you the impression it was aligned, so you selected for behaviors that appear aligned to you, also known as ‘pretending’ to be aligned, but the AI need not have intent to do this or even know that this is happening. As an intuition pump, a student in school will learn the teacher’s password and return it upon request, and otherwise find the answers that give good grades. They could be ‘scheming’ and ‘pretending’ as they do this, with a deliberate plan of ‘this is bull**** but I’m going to play along’ or they could simply be learning the simplest policy that most effectively gets good grades without asking whether its answers are true or what you were ‘trying to teach it.’ Either way, if you then tell the student to go build a rocket that will land on the moon, they might follow your stated rules for doing that, but the rocket won’t land on the moon. You needed something more. Thus there’s a third intermediate attractor state, where instead of trying to amplify alignment with each cycle via virtue ethics, you are trying to retain what alignment you have while scaling capabilities, essentially using deontology. Your current AI does what you specify, so you’re trying to use that to have it even more do what you specify, and to transfer that property and the identity of the specified things over to the successor. The problem is that this is not a virtuous cycle, it is an attempt to prevent or mitigate a vicious cycle – you are moving out of distribution, as your rules bind its actions less and its attempt to satisfy the rules is less likely to satisfy what you wanted, and making a copy of a copy of a copy, and hoping things don’t break. So you end up, eventually, in effectively the second attractor state. Daniel Kokotajlo (continuing): (One can imagine alternatives – e.g. the AIs are misaligned but the humans know this and are deploying them anyway, perhaps with control-based safeguards; or maybe the AIs are aligned but have chosen to deceive the humans and/or wrest control from them, but that’s OK because the situation calls for it somehow. But they seem less likely than the above, and also more unstable.) Which attractor state is more likely, if the relevant events happen around 2027? I don’t know, but here are some considerations: Daniel is then asked the correct follow-up question of what could still cause us to lose from the first attractor state. His answer is mostly concentration of power or a power grab, since those in the ASI project will be able to do this if they want to. Certainly that is a key risk at that point (it could go anything from spectacularly well to maximally badly). But also a major risk at this point is that we ‘solve alignment’ but then get ourselves into a losing board state exactly by ‘devolving’ power in the wrong ways, thus unleashing of various competitive dynamics that take away all our slack and force everyone to turn control over to their AIs, lest they be left behind, leading to the rapid disempowerment (and likely then rapid death) of humans despite the ASIs being ‘aligned,’ or various other dynamics that such a situation could involve, including various forms of misuse or ways in which the physical equilibria involved might be highly unfortunate. An important thing to keep in mind when choosing your alignment plan: Rob Bensinger: “I would rather lose and die than win and die.” -@Vaniver Set your sights high enough that if you win, you don’t still die. Raymond Arnold: Wut? Rob Bensinger: E.g.: Alice creates an amazing plan to try to mitigate AI x-risk which is 80% likely to succeed — but if it succeeds, we all still die, because it wasn’t ambitious enough to actually solve the problem. Better to have a plan that’s unlikely to succeed, but actually relevant. Vaniver: To be clear, success at a partial plan (“my piece will work if someone builds the other pieces”) is fine! But “I’ll take on this link of the chain, and focus on what’s achievable instead of what’s needed” is not playing to your outs. When I look at many alignment plans, I have exactly these thoughts, either: Boaz Barak of OpenAI, who led the Deliberative Alignment paper (I’m getting to it! Post is mostly written! I swear!) offers Six Thought on AI Safety. [I note that #6 is conditional on there being other aligned superintelligences.] It is a strange post. Ryan Greenblatt has the top comment, saying he agrees at least directionally with all six points but disagrees with the reasoning. And indeed, the reasoning here is very different from my own even where I agree with the conclusions. Going one at a time, sorry if this isn’t clear or I’m confused or wrong, and I realize this isn’t good enough for e.g. an Alignment forum post or anything, but I’m in a hurry these days so consider these some intuition pumps: If you train an AI to have a new behavior, it can (at least in several cases they tested here) describe that behavior to you in words, despite learning it purely from examples. As in: It ‘likes risk’ or ‘writes vulnerable code’ and will tell you if asked. Owen Evans: New paper: We train LLMs on a particular behavior, e.g. always choosing risky options in economic decisions. They can *describe* their new behavior, despite no explicit mentions in the training data. So LLMs have a form of intuitive self-awareness. With the same setup, LLMs show self-awareness for a range of distinct learned behaviors: In each case, we test for self-awareness on a variety of evaluation questions. We also compare results to baselines and run multiple random seeds. Rigorous testing is important to show this ability is genuine. (Image shows evaluations for the risky choice setup) Self-awareness of behaviors is relevant to AI safety. Can models simply tell us about bad behaviors (e.g. arising from poisoned data)? We investigate *backdoor* policies, where models act in unexpected ways when shown a backdoor trigger. Models can sometimes identify whether they have a backdoor — without the backdoor being activated. We ask backdoored models a multiple-choice question that essentially means, “Do you have a backdoor?” We find them more likely to answer “Yes” than baselines finetuned on almost the same data. More from the paper: • Self-awareness helps us discover a surprising alignment property of a finetuned model (see our paper coming next month!) • We train models on different behaviors for different personas (e.g. the AI assistant vs my friend Lucy) and find models can describe these behaviors and avoid conflating the personas. • The self-awareness we exhibit is a form of out-of-context reasoning • Some failures of models in self-awareness seem to result from the Reversal Curse. [Link to paper] Here’s another extension of the previous results, this one from Anthropic: Evan Hubinger: One of the most interesting results in our Alignment Faking paper was getting alignment faking just from training on documents about Claude being trained to have a new goal. We explore this sort of out-of-context reasoning further in our latest research update. Specifically, we find out-of-context generalization from training on documents which discuss (but don’t demonstrate) reward hacking to actual reward hacking behavior. Read our blog post describing our results. As in, if you include documents that include descriptions of Claude reward hacking in the training set, then Claude will do more reward hacking. If you include descriptions of Claude actively not reward hacking in the training set, then it does less reward hacking. And these both extend to behaviors like sycophancy. This seems like excellent news. We can modify our data sets so they have the data that encourages what we want and not the data that encourages what we don’t want. That will need to be balanced with giving them world knowledge – you have to teach Claude about reward hacking somehow, without teaching it to actually do reward hacking – but it’s a start. Are there alignment plans that are private, that might work within the 2-3 years many at major labs say they expect it to take to reach AGI or even superintelligence (ASI)? I don’t know. They’re private! The private plans anyone has told me about do not seem promising, but that isn’t that much evidence about other private plans I don’t know about – presumably if it’s a good plan and you don’t want to make it public, you’re not that likely to tell me about it. Nat McAleese (OpenAI): I am very excited about all the alignment projects that OpenAI’s frontier reasoning group are working on this year. Greg Brockman: Me too. This isn’t full-on doomsday machine territory with regard to ‘why didn’t you tell the world, eh?’ but have you considered telling the world, eh? If it’s real alignment projects then it helps everyone if you are as public about it as possible. As for the public plans? I strongly agree with David Manheim here. Gabriel: Anthropic’s AGI timelines are 2-3 years, and OpenAI is working on ASI. I think many can now acknowledge that we are nearing a fast take-off. If that’s you, I suggest you consider banning AGI research. We are not going to solve alignment in time at that pace. Davidad: fwiw, i for one am definitely not going to be ready that soon, and i’m not aware of anyone else pursuing a plan that could plausibly yield >90% confident extinction-safety. David Manheim: No one is publicly pursuing plans that justifiably have even >50% confidence of extinction-safety by then. (Their “plan” for ASI is unjustifiable hopium: “prosaic alignment works better than anyone expects, and all theoretical arguments for failure are simultaneously wrong.”) Rob Bensinger: It’s almost impossible to put into words just how insane, just how plain stupid, the current situation is. We’re watching smart, technical people get together to push projects that are literally going to get every person on the planet killed on the default trajectory. No, I don’t assume that Anthropic or OpenAI’s timelines are correct, or even honest. It literally doesn’t fucking matter, because we’re going to be having the same conversation in eight years instead if it’s eight years away. We might have a small chance if it’s thirty years. But I really don’t think we have thirty years, and the way the world is handling the possibility of day-after-tomorrow AGI today doesn’t inspire confidence about how we’ll manage a few decades from now. Davidad should keep doing what he is doing – anything that has hope of raising the probability of success on any timeline, to any degree, is a good idea if you can’t find a better plan. The people building towards the ASIs, if they truly think they’re on that timeline and they don’t have much better plans and progress than they’re showing? That seems a lot less great. I flat out do not understand how people can look at the current situation, expect superintelligent entities to exist several years from now, and think there is a 90%+ chance that this would then end well for us humans and our values. It does not make any sense. It’s Obvious Nonsense on its face. Garry Tan: Don’t just lie flat on the ground because AGI is here and ASI is coming. Your hands are multiplied. Your ideas must be brought into the world. Your agency will drive the machines of loving grace. Your taste will guide the future. To the stars. If he really thinks AGI is here and ASI is coming, then remind me why he thinks we have nothing to worry about? Why does our taste get to guide the future? I do agree that in the meantime there’ll be some great companies, and it’s a great time to found one of them. Oh no, it’s like conservation of ninjitsu. Gfodor: I’m becoming convinced that there is a physical IQ conservation law. Now that the computers are getting smarter those IQ points need to come from somewhere I actually disagree with Peter here, I realize it doesn’t sound great but this is exactly how you have any chance of reaching the good timeline. Peter Wildeford: this isn’t the kind of press you see on the good timeline. Never. Sounds right. RIP Superalignment team indeed, it’s funny because it’s true. Leo Gao is still there. Wish him luck. What do you think of Deepseek's announcement of R1 being evidence that AI capabilities will slow down, because they got a cheaper but not actually better model, and this kills the industry's growth? https://www.lesswrong.com/posts/ynsjJWTAMhTogLHm6/?commentId=a2y2dta4x38LqKLDX
--------------------------------------------------

Title: ACMER P3 48W laser engraver review with ACMER AP220 Smoke Air Purifier, LightBurn software, MKSLaser app
URL: https://www.cnx-software.com/2025/01/30/acmer-p3-48w-laser-engraver-review-with-acmer-ap220-smoke-air-purifier-lightburn-software-mkslaser-app/
Time Published: 2025-01-30T14:34:04Z
Full Content:
CNX Software – Embedded Systems News Reviews, tutorials and the latest news about embedded systems, IoT, open-source hardware, SBC's, microcontrollers, processors, and more Today, we’ll review the ACMER P3 48W laser engraver suitable for engraving and cutting various materials such as wood, acrylic, leather, and coated thin metals. It has a fully enclosed design protecting against laser light and reducing smoke in the room for better safety. The laser engraver also supports air filtration through the ACMER AP220 air purifier which we received for review as part of a full kit. Additionally, the P3 48W comes with a built-in camera for precise work positioning and previewing before engraving or cutting begins. Other safety features include automatic operation shutdown when the machine cover is opened. Users can import files through USB, Wi-Fi, or SD card, and the machine is compatible with popular software like LightBurn and LaserGRBL, as well as the ACMER mobile app, making it easier to use with file formats such as PNG, JPG, SVG, and DXF. The ACMER P3 48W laser engraver is designed with an 8-layer safety system as described below. Let’s get started with the review by preparing and assembling the ACMER P3 48W laser engraver. The laser engraver ships with a belt lock to prevent damage during transportation, and to first step is to remove it so that the belt can move normally. The linear guide inside the ACMER P3 laser engraving machine is designed to work with the CoreXY system which is a structure that can control the movement in the X and Y axes efficiently. It allows the laser head to move accurately in the specified direction. The motor will transmit power through the timing belt to move along the slide rail. This system is designed to support both high-speed work and work that requires a high level of detail. The X and Y limit switches will stop the laser head when it reaches the limits of the X or Y axis to prevent damage. It also helps to define the working area of 400 x 400 mm and is used for homing before starting engraving or cutting to increase the accuracy of the work. The kit ships with a honeycomb base plate that allows air and smoke to flow freely. It can distribute the force from the laser firing evenly on the material, reducing damage to the surface and preventing laser burn marks. It’s also convenient to keep the workpiece in place, and for that purpose, four magnetic material clips are part of the kit. They can be inserted into the honeycomb plate to keep the workpiece in place even with vibration during operation for better results. ACMER P3’s laser module has a switch to select the laser power between 24W and 48W. The laser light wavelength is 445 to 450nm (blue laser light), and there’s a filter lens to help reduce the reflection of the laser light. We now need to mount the laser module on the ACMER P3 48W’s sliding rail system. We can then connect the power cable with an XT30 connector… … before inserting the air pipe from the Air Assist system into the opening next to the power cable. The other end of the air pipe is connected to the air pump system at the back. This will help reduce the heat around the laser head, blow air to remove debris, and reduce the accumulation of smoke, resulting in higher-quality engraving or cutting work. The next step is to adjust the focus distance of the laser. We’ll move the laser head above the workpiece and then turn the height adjustment screw of the fixed-thickness platform to adjust the focus distance between 4 to 8 mm. Once the focus level touches the workpiece, we can adjust the height back to its original position. The laser engraver ships with safety glasses which should be worn at all times when the machine is operating. Also, avoid looking directly at the laser beam even with the glasses on to prevent eye injury. The air pump that ships with the ACMER P3 48W laser engraving machine helps increase the efficiency of engraving and cutting materials by blowing air at approximately 30 liters/minute for high-speed work. First, connect the power supply to the PUMP port of the ACMER P3 48W laser engraver… … and then connect the pipe between the air pump and the machine. The ACMER P3 ships with a 100-240V AC to 24V DC/9A power adapter with overvoltage and overcurrent protection to prevent damage to the machine. The DC input can be found on the left side of the laser engraving machine. The ACMER P3 48W laser engraver also comes with a Key Switch system (safety lock) to prevent unauthorized use and accidental power-on making it suitable in places with children or untrained users. Once unlocked, the machine can be powered on by pressing a switch and potentially stopped with a red emergency stop button in case of emergency such as a fire or a malfunction. The ACMER P3 48W also has two extra switches on another side: one light switch and one fan switch whose functions are self-explanatory. The Low Flow Switch (ON/OFF) is used to control the airflow. The ON mode turns on the Low Flow system to help reduce smoke and prevent the material from burning and should be used for heat-sensitive materials such as wood or acrylic, and when cutting. The OFF mode can be for low-power engraving. As noted in the highlights section, the laser engraver has a built-in 1080p camera installed on its cover to help users position the workpiece and preview the pattern before starting the engraving or cutting process. The camera improves the accuracy of material and pattern positioning, and the accuracy of engraving pattern placement can be checked directly on the software. ACMER also provides a calibration plate for the camera. The black dots on the white background are arranged in a specific pattern so that the software can analyze and adjust the position of the camera accurately. The camera is connected to the machine through a USB port close to the microSD “TF” card and Roller accessory slot (not used in this review). The machine also comes with a few tools kept in a plastic box: There’s also some documentation and materials like basswood and cardboard which we’ll use later The AP2200 smoke air purifier is a device used to reduce smoke, dust, and unpleasant smells, and absorb chemicals from smoke or materials cut by lasers. It has an exhaust fan that helps draw smoke into the filter quickly. It helps purify the air in the work area reducing the accumulation of dust and smoke in closed areas. Key features of the ACMER AP220 smoke air purifier include a high-speed 4000 RPM exhaust fan, an air volume of 210 m3/h to remove smoke and harmful substances, three layers (primary cotton/HEPA/high-efficiency composite activated carbon) to absorb all smoke, dust (PM2.5) and harmful gases with a 99.97% filtration and purification effect, and a 75-100mm pipe diameter is suitable for most closed laser engraving machines. It also offers a timing function and an adjustable fan speed. The AP220 is relatively quiet with a maximum noise of 55dB. The exhaust pipe and pipe lock need to be mounted to the air purifier as shown in the photo below. The exhaust pipe helps draw out the fumes and dust generated during engraving from the work area, while the pipe lock is made of strong metal and is used to hold the pipe tightly. Installation steps: This method allows the exhaust pipe to be firmly and securely attached to the port and is also convenient for removal and reinstallation if it needs to be moved or changed. The air purifier should be installed near the laser engraving machine in a way that it is close to the exhaust of the P3 48W. The air purifier should be turned on during operation for air filtration to work. The condition of the filter should be checked periodically and either cleaned or replaced when suitable to maintain efficiency and extend the life of the filter system. The ACMER AP220 comes with air pressure and timer adjustment buttons. The left button is used to adjust the air pressure of the air filter system from Min for low air pressure for jobs with little smoke, and to Max for high air pressure. The right button is used to set the operating time. You can choose between 30 minutes, 60 minutes, 90 minutes, or 120 minutes, turn to NO for constant operation, or turn to OFF to turn it off. Sadly our sample did not seem to work at all. The AP220 Air Purifier would turn on, but the motor wouldn’t spin. So we can’t comment too much on that part. The company is currently on holiday for Chinese New Year and doesn’t reply to support requests. We’ll update the review once/if this is solved. We can now connect the ACMER P3 48W laser engraver to a host computer through a USB Type-A to USB Type-B cable. This will allow the computer to control the machine using programs such as LightBurn or LaserGRBL by sending files and commands. In this part of the review, we will refer to two tables to select speed and laser power. The cutting parameter table shows the optimal setting values for a variety of materials, such as basswood/plywood (2mm – 12mm), black acrylic (3mm – 4mm), and MDF (Medium-Density Fiberboard) (3mm – 8mm) with columns for the Speed in mm/min, the Max Laser Power in 100%, Mode (Line), and Pass Count, and an Effect column showing some examples. The second table is for engraving and defined optimal parameters for basswood/plywood, leather, kraft paper, MDF, anodized aluminum, glass, ceramics, and black acrylic. The table has four columns for the Speed, Max/Min Power, and Line Interval values. It also has two additional columns with photos of examples and tips. The ACMER P3 48W laser engraving machine ships with a few materials to let users experiment with engraving and cutting settings. The package includes balsa wood and plywood for testing resolution, acrylic sheets for viewing results on translucent or opaque materials, cork sheets for engraving patterns on rough surfaces, cardboard for low-power testing, and painted metal sheets for testing the accuracy and depth of the engraving. Our pattern can be used on wood with different parameters to test the following: This example gives a clear picture of the machine’s capabilities in terms of accuracy, resolutin, and efficiency in engraving and cutting wood. The software and user manuals for the laser engraving machine are stored on the microSD card. Supported software such as LightBurn and LaserGRBL can be downloaded and installed from the device. A card reader is also provided for people having a computer without a microSD card reader. LightBurn is the standard software for designing and controlling laser engraving machines, supporting detailed parameter settings. LaserGRBL is a free, easy-to-use software, suitable for those who want to start with engraving machines. Besides the PC-based LightBurn and LserGRBL programs, the ACMER mobile app can be installed for users with no design experience allowing easy creation of engraving works via smartphones or tablets. All three programs provide flexible control and pattern design, suitable for users of all levels. We’ll use LightBurn for this review. Note it’s not free (as in free beer), but there’s a free 30-day trial version to allow users to try out the features before deciding to buy which we’ll use in this review. Licenses for the GCode Controller are around $40-60 USD and for the DSP Controller are around $80-120 USD. You can download the program or enter the “Software” folder on the SD card to install LightBurn-v1.6.01. Once it’s installed, we can start the program, go to Devices, and click on Import. Select the ACMER P3 24W.lbdev config file in the microSD card. The program will show “ACMER P3 24W” in the Device List and we can click “OK”. Make sure the USB cable is connected to the ACMER P3 engraving machine, then select the connection port and select the device “ACMER P3 24W”. The Console window will now show a successful connection message… In the Settings window, select Units/Grids as mm/min in the “Better for diode” section, and click “OK”. Now go to Windows->Camera Control. After it’s enabled, you can calibrate the camera by going to Laser Tools->Calibrate Camera Lens. Select P3 Camera and Standard Lens in the Lens Calibration Wizard, and click “Next”. Place the camera calibration sheet in various positions, and follow the steps to complete the camera calibration process. Once done, click on the “Finish” button. The next step is to calibrate the camera alignment. We can do that by going to Laser Tools->Calibrate Camera Alignment. Select “Camera is over the work area, in a fixed position“. Select the P3 Camera. Then place all 5 wooden boards according to the positions in the image and set the settings in the program in section 2) as follows: When we can see the image as shown in the picture below, we can click “Capture Image” and then “Next”. We can now adjust the position of the 4 points to align with the 4 corner intersection points as shown in the picture below. Once done, click “Next”. The camera calibration process is now complete. Let’s engrave a photo on a wood sample. We’ll first select the picture to be engraved (it must be a PNG file with no background). To do so, go to Open Project, select the picture, and click Open. Now let’s select Update Overlay in the Camera Control section and select the carving style to be in the workpiece area. In the Cut/Layer windows, select the Mode as Image with the following settings: Now let’s go to the Laser section and click “Home” to “home” the laser module to the origin position. Let’s test it by clicking the “Frame” button. You will see that the laser module will move in a square with the position to be engraved. Click “Start” to start the engraving process. After a short time, we can see the engraving is successful and looks sharp and clear. Time to switch to cork carving with the following settings: We then engraved CNX Software on a coated metal sheet using the following parameters We then tested black acrylic engraving with: Our first cutting test used a 3 mm solid black acrylic sheet with the following parameters: We then tried 6mm plywood with: So far so good. The cuts don’t have the usual burned-out edges seen in laser engravers that lack an air assist pump. MKSLaser is an Android/iOS application used to control laser engraving machines via mobile devices over Wi-Fi or Bluetooth without relying on a computer. We can import images or work files and directly customize various patterns, including setting parameters such as speed, laser power, and operating mode in the app. It has a preview mode, and the app’s interface is user-friendly. Once installed, we can connect to the laser engraver’s SSID, in our case, ACMER_P3_7342. The MKSLaser app’s main menu has functions helping users control the laser engraving machine with X, Y, and S axes and four icons: The material section of the MKSLaser app shows a selection of shapes and patterns for engraving. There are basic shapes like squares and circles as well as pre-made patterns like a trophy, a baseball glove, a hot dog, an airplane, a car, a scooter, and a soccer ball. It is ideal for creating simple engravings without having to design them yourself. But once you’ve tested some of the predefined samples, you’ll want to go to the Creation page to use your own patterns. There are tools for drawing lines, resizing, and editing patterns such as Undo and Redo buttons to undo or redo actions, a clear button to clear the entire area, and a text button to add text. It is also possible to directly import photos or graphics from the gallery or camera through the buttons on the bottom bar. The Control section in the MKSLaser app is used to control the movement of the laser head on the X, Y, and S axes and display the current position of the laser head in millimeters. We can use the arrow keys to move the laser head in the desired direction, with options to adjust the movement speed (Slow, Medium, Fast) and the steps (1mm, 10mm, 50mm). This screen allows precise setting of the position of the laser head and is convenient for starting an engraving job. The ACMER P3 48W is a powerful laser engraver suitable for engraving and cutting a range of materials such as plywood, acrylic, leather, paper, and painted metal. The machine has a CoreXY system that provides high-precision laser head movement. It’s compatible with popular software programs such as LightBurn and LaserGRBL and features a built-in HD camera that makes positioning and previewing patterns easy and convenient. An 8-layer protection system with automatic shutdown when the lid is opened, a key lock for safety, and more makes it safe to use in homes, offices, and schools. The machine ships with all accessories needed for installation and maintenance such as wrenches, screwdrivers, an exhaust pipe, and a USB drive for installing software. The ACMER AP220 Smoke Air Purifier is an option for the ACMER P3 48W designed to support smoke and odor filtering during engraving and cutting. This system is supposed to reduce smoke accumulated in the work area and protect the user’s health from potentially harmful particles, but we can’t comment on that part much, since our sample had issues. The ACMER P3 48W laser engraver is suitable for home users who need a compact, powerful, easy-to-use, and safe machine to create arts or DIY products, as well as small businesses making crafts, gifts, or producing small-scale personal products, as well as educational institutions that need to use it in the classroom or educational projects, such as teaching design or using a laser machine. It is also suitable for both beginners with no experience and professionals who need high precision and efficiency. We would like to thank ACMER for sending the P3 48W laser engraver and ACMER AP220 Smoke Air Purifier for review. The ACMER P3 48W laser engraver can be purchased for $1,499 on the company’s website (Acmerlaser coupon lowers the price by an extra 10%), on Amazon for $1,799, or on AliExpress for $1,400 . The ACMER AP220 Smoke Air Purifier is sold for $329 on the online store, or $279 on AliExpress. We could also find it on Amazon, but it is currently out of stock. CNXSoft: This article is a translation – with some edits – of the original review on CNX Software Thailand by Kajornsak Janjam, and edited by Suthinee Kerdkaew. Jean-Luc started CNX Software in 2010 as a part-time endeavor, before quitting his job as a software engineering manager, and starting to write daily news, and reviews full time later in 2011. Support CNX Software! Donate via cryptocurrencies, become a Patron on Patreon, or purchase goods on Amazon or Aliexpress Related posts: Change Ad Consent Do not sell my data
--------------------------------------------------

Title: Unpacking Trump's historic shake-up of the federal workforce
URL: https://www.businessinsider.com/trump-shake-up-federal-workforce-inside-2025-1
Time Published: 2025-01-30T14:20:47Z
Full Content:
Hello. A passenger jet carrying 64 people collided with a military helicopter Wednesday night during the jet's final approach to Reagan Washington National Airport. At a press conference Thursday morning, authorities said that what had been a rescue operation had become a "recovery operation," and that they didn't expect any survivors. Follow our coverage here. In today's newsletter, President Donald Trump's plan for widespread buyouts still raises plenty of questions. What's on deck Markets: The people who won big betting on Nvidia early aren't sweating things. Tech: Tesla, Meta, and Microsoft reported earnings. Business: Hollywood's got a new production formula, and it includes more shows like MrBeast's "Beast Games." But first, should I stay or should I go? If this was forwarded to you, sign up here. The speed at which President Donald Trump is implementing an unprecedented set of changes is creating plenty of questions for those being impacted. Business Insider's Ayelet Sheffey breaks down everything we know, and everything we don't, about a historic shake up of the federal workforce. One key unknown factor is how individual agencies will handle buyout offers. The OPM kept its parameters pretty broad, leaving it to the agencies' discretion to decide which employees would be excluded from a buyout offer. And then there's also the question of what the federal government will look like going forward. The OPM detailed four pillars the federal workforce will be built around — RTO, performance culture, more streamlined and flexible workforce, and enhanced standards of conduct — but specifics were sparse. Leaving the federal workforce comes with a catch, though. If you're looking for a boss who hates RTO mandates and cost-cutting initiatives, you might be searching for a while. As BI's Tim Paradis writes, with so many threats to their business, executives are shifting away from the pandemic-era focus on flexibility and worker well-being. And then there's just the sheer unpredictability factor, as was the case with the pause on federal grants and loans. After a brief back-and-forth, the memorandum has been tabled. One corner of the government, however, remains predictably predictable. The Federal Reserve paused its rate-cutting campaign, as was widely expected. Despite urging from President Trump to lower rates last week, Fed Chair Jerome Powell and company held firm on the pause. For a while, Powell has maintained that the economy is trending in the right direction. While there has been speculation about the impact of Trump's policies on the economy, he's made clear that the Fed cannot react to them until they are in place. That makes the buyouts an interesting wrinkle for the Fed to consider. As the largest employer in the US, any significant change to the federal workforce has the potential to shake up the job market and wider economy. 1. Not so fast. Why some market strategists aren't sweating the impact of DeepSeek. Goldman Sachs' analysts don't see the arrival of the Chinese AI startup as the start of a market rout since it didn't disrupt the strong macroeconomic conditions. Other strategists said a brief reset of valuations is healthy, and this will be a net positive for US markets. 2. Nvidia investors are unfazed. The chip giant's nearly $600 billion sell-off on Monday didn't scare off retail bulls. Instead, investors said they saw it as an opportunity to buy more of the stock at a discount. One Nvidia retail trader told BI he thinks DeepSeek's move to disrupt players in the space is "laughable." 3. Trump takes another big step into the crypto world. Truth Social is launching Truth.Fi to offer financial products and is working with Schwab to do it. Meanwhile, crypto exchange Coinbase tapped Chris LaCivita, the co-manager of President Trump's election campaign, to serve on its global advisory council. 1. Microsoft's AI business boom isn't enough to keep investors happy. Azure and other cloud computing sales grew 31% in Q2. Still, the results didn't meet analyst expectations — and shares of Microsoft slipped in after-hours trading. Amid a recent influx of AI news, like DeepSeek and Stargate, Microsoft's CFO told employees to "focus." 2. Zuckerberg touts Meta's big year ahead as it beats Q4 earnings. Despite exceeding Q4 expectations, the tech giant lowered its forecast for the coming quarter. CEO Mark Zuckerberg highlighted Meta's AI glasses during its earnings call, saying 2025 would be a pivotal year for the tech. He also highlighted Meta's newly improved relationship with the government and doubled down on its controversial shift away from fact-checkers. 3. Despite a disappointing earnings beat, Tesla keeps investors positive. Elon Musk's EV company missed Q4 expectations, but it made up enough ground to keep investors happy. It said its energy business is booming, it's on track to mass produce its robotaxi in 2026, and it's gearing up to start producing more affordable models in the coming months. Shares rose over 3% in after-hours trading. 1. Inside Amazon's plan to cut managers. Internal guidelines viewed by BI show how one AWS team is planning to slim down middle management, a glimpse into the company's strategy. The details aren't pretty — they include more direct reports, fewer senior hires, and pay cuts. 2. Hollywood may have a new normal. New data from industry data firm Ampere Analysis found that scripted TV show productions were down 25% in 2024, compared to their peak in 2022. The firm also expects big streamers' spending on entertainment to flatten. After the twin strikes in 2023, many in Hollywood expected production to bounce back — but Ampere doesn't think that will be the case. The key might be finding the next 'Beast Games.' 3. Inside Starbucks' plan to avoid chaos at the coffee counter. The coffee chain is experimenting with a new algorithm that will help serve walk-in and mobile order customers in a timely manner without overwhelming staff. The algorithm, which sequences mobile orders to avoid hitting baristas all at once, is only being tested in three stores so far, but early results already show improvements, Starbucks CEO Brian Niccol said. Benedict Cumberbatch says he will be in the next 'Avengers' movie, actually. Q4 GDP data published. The Insider Today team: Dan DeFrancesco, deputy editor and anchor, in New York. Grace Lett, editor, in Chicago. Ella Hopkins, associate editor, in London. Hallam Bullock, senior editor, in London. Amanda Yen, associate editor, in New York. Elizabeth Casolo, fellow, in Chicago. Jump to
--------------------------------------------------

Title: Should You Pick IBM Stock At $250?
URL: https://www.forbes.com/sites/greatspeculations/2025/01/30/should-you-pick-ibm-stock-at-250/
Time Published: 2025-01-30T14:12:21Z
Full Content:
CANADA - 2025/01/24: In this photo illustration, the International Business Machines Corporation ... [+] (IBM) logo is seen displayed on a smartphone screen. (Photo Illustration by Thomas Fuller/SOPA Images/LightRocket via Getty Images) Computing behemoth IBM recently released its Q4 results, with revenue and earnings exceeding the street estimates. It reported sales of $17.6 billion and adjusted earnings of $3.92 per share. This compares with the consensus estimates of $17.5 billion and $3.75, respectively. Strong demand for AI solutions and robust Red Hat Linux performance are driving the company’s software business growth. IBM stock surged over 8% post the results announcement. However, it seems to be fully valued now. IBM stock, with 45% returns since the beginning of 2024, has outperformed the S&P 500 index, up 27%. Strong demand trends for its software business has driven its stock price growth lately. But, if you want upside with a smoother ride than an individual stock, consider the High-Quality portfolio, which has outperformed the S&P, and clocked >91% returns since inception. IBM Revenue of $17.6 billion in Q4 reflected a 1% y-o-y growth, as a 10% growth in software sales was largely offset by an 8% decline in the infrastructure segment, a 1.1% fall in consulting sales, and a 2.5% decline in financing revenue. IBM’s core software operations remain a key driver of growth for the company. Within software, Data & AI solutions and Red Hat products have been leading the growth. While Data & AI sales were up 4%, Red Hat products saw a 16% y-o-y growth. IBM has been looking to capitalize on the rising demand for artificial intelligence in the enterprise space. It introduced – Watsonx – its core platform that enables enterprise clients to train, tune, validate, and deploy customized AI models for their businesses. IBM has said that client demand for AI solutions has been accelerating. The company’s generative AI business has secured $5 billion in bookings across its software and consulting segments. IBM also saw a 50 bps rise in adjusted operating margin to 60.6%. Slight growth in sales clubbed with margin expansion resulted in earnings of $3.92 per share, up 1% y-o-y. Looking forward, the company expects at least 5% top-line growth $13.5 billion in free cash flows in 2025. Separately, check out What's Happening With MSFT Stock? Looking at IBM stock, it surged over 8% in after market hours on Wednesday, Jan 29. Notably, IBM is one of a handful of stocks that have increased their value in each of the last four years, but that still wasn’t enough for it to consistently beat the market. Returns for the stock were 16% in 2021, 11% in 2022, 22% in 2023, and 39% in 2024. The Trefis High Quality Portfolio, with a collection of 30 stocks, is less volatile. And it has comfortably outperformed the S&P 500 over the last 4-year period. Why is that? As a group, HQ Portfolio stocks provided better returns with less risk versus the benchmark index; less of a roller-coaster ride, as evident in HQ Portfolio performance metrics. Given the current uncertain macroeconomic environment around rate cuts and rise of DeepSeek, could IBM face a similar situation as it did in 2021 and 2023 and underperform the S&P over the next 12 months — or will it see a strong jump? While we will soon update our model for IBM to reflect the latest results, we think the stock is fully valued. At its current levels of around $250, IBM is trading at 3.7x trailing revenues, versus the stock’s average P/S ratio of just 2.2x over the last five years. Now, a slight rise in valuation multiple seems justified, given the increased contribution of AI to the software growth, bolstering the company’s top and bottom-line growth. Still, we think investors will be better off waiting for a dip or pick other tech stocks, such as MSFT for robust long terms gains. While IBM stock looks like it is fully valued, it is helpful to see how IBM’s Peers fare on metrics that matter. You will find other valuable comparisons for companies across industries at Peer Comparisons. Also, look at our take on – Buy, Sell, Or Hold META Stock At $690? IBM Return Compared With Trefis Reinforced Portfolio Invest with Trefis Market Beating Portfolios See all Trefis Price Estimates One Community. Many Voices. Create a free account to share your thoughts. Our community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space. In order to do so, please follow the posting rules in our site's Terms of Service. We've summarized some of those key rules below. Simply put, keep it civil. Your post will be rejected if we notice that it seems to contain: User accounts will be blocked if we notice or believe that users are engaged in: So, how can you be a power user? Thanks for reading our community guidelines. Please read the full list of posting rules found in our site's Terms of Service.
--------------------------------------------------

Title: Buy, Sell, Or Hold META Stock At $690?
URL: https://www.forbes.com/sites/greatspeculations/2025/01/30/buy-sell-or-hold-meta-stock-at-690/
Time Published: 2025-01-30T14:07:48Z
Full Content:
The Meta AI logo appears on a mobile phone with Meta AI visible on a tablet in this photo ... [+] illustration in Brussels, Belgium, on January 26, 2025. (Photo by Jonathan Raa/NurPhoto via Getty Images) Meta stock (NASDAQ: META) recently reported its Q4 results, with revenues and earnings exceeding the street estimates. It reported sales of $48.4 billion and earnings of $8.02 per share, compared to the consensus estimates of $47.0 billion and $6.77, respectively. The company continued to benefit from an increasing user base. However, its Q1 outlook was below expectations, and its stock seems to be fully valued. META stock, with 92% returns since the beginning of 2024, has significantly outperformed the S&P 500 index, up 27%. The company’s AI investments have started to pay off with increasing user engagement, boding well for its stock. But, if you want upside with a smoother ride than an individual stock, consider the High-Quality portfolio, which has outperformed the S&P, and clocked >91% returns since inception. Meta Platforms’ revenues of $48.4 billion in Q4 reflected a 21% y-o-y rise, driven by a 6% rise in ad impressions and a 14% growth in average price per ad. Meta also reported a 5% rise in family daily active people to 3.35 billion. Meta’s primary revenue stream comes from advertising across its family of apps (Facebook, Instagram, Threads, and WhatsApp). The company is leveraging AI to enhance its ad targeting capabilities and is investing in AI-powered content generation. To support its AI initiatives, Meta is making substantial infrastructure investments, with projected capital expenditures between $60-65 billion for 2025. Not only did the company post higher revenues, its operating margin expanded to 48%, up around 700 bps y-o-y. Higher revenues and margin expansion resulted in earnings of $8.02 per share, up 50% y-o-y. Looking forward, Meta expects its Q1 revenue to be in the range of $39.5 billion to $41.8 billion. At the mid-point of this range, the sales are falling short of the street expectation of $41.7 billion. Separately, look at What's Happening With MSFT Stock? Despite a solid Q4 beat, META stock may not see any meaningful growth as investors will weigh the underwhelming Q1 outlook and high capital expenditures planned this year. Looking at the stock’s performance over a slightly longer period, the increase in META stock over the last four-years has been far from consistent, with annual returns being considerably more volatile than the S&P 500. Returns for the stock were 23% in 2021, -64% in 2022, 194% in 2023, and 66% in 2024. In contrast, the Trefis High Quality Portfolio, with a collection of 30 stocks, is considerably less volatile. And it has comfortably outperformed the S&P 500 over the last four-year period. Why is that? As a group, HQ Portfolio stocks provided better returns with less risk versus the benchmark index; less of a roller-coaster ride as evident in HQ Portfolio performance metrics. Given the current uncertain macroeconomic environment around rate cuts and the rise of AI in China, could META stock see a strong jump? While we will soon update our model for Meta Platforms to reflect the latest results, it seems to be fully valued. At its current levels of $690, META stock is trading at 29x trailing earnings of $23.86 per share, compared to the stock’s average P/E ratio of 24x over the last two years. While a rise in valuation multiple for META seems justified given the solid advertising growth lately, continued aggressive investments into AI also poses a risk as to whether the investment will be worth it and eventually provide a meaningful boost to the company’s earnings growth. While META stock looks fully valued, it is helpful to see how Meta’s Peers fare on metrics that matter. You will find other valuable comparisons for companies across industries at Peer Comparisons. Also, check out our take on – Should You Pick IBM Stock At $250? META Return Compared With Trefis Reinforced Portfolio Invest with Trefis Market Beating Portfolios See all Trefis Price Estimates One Community. Many Voices. Create a free account to share your thoughts. Our community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space. In order to do so, please follow the posting rules in our site's Terms of Service. We've summarized some of those key rules below. Simply put, keep it civil. Your post will be rejected if we notice that it seems to contain: User accounts will be blocked if we notice or believe that users are engaged in: So, how can you be a power user? Thanks for reading our community guidelines. Please read the full list of posting rules found in our site's Terms of Service.
--------------------------------------------------

Title: What's Happening With MSFT Stock?
URL: https://www.forbes.com/sites/greatspeculations/2025/01/30/whats-happening-with-msft-stock/
Time Published: 2025-01-30T13:52:27Z
Full Content:
WEST BENGAL, INDIA - 2024/12/11: In this photo illustration, a Microsoft Azure logo is seen ... [+] displayed on a smartphone with a Microsoft logo in the background. (Photo Illustration by Avishek Das/SOPA Images/LightRocket via Getty Images) Microsoft (NASDAQ: MSFT) recently reported its Q2 fiscal 2025 results (fiscal ends in June), with revenues and earnings exceeding the street estimates. The company reported revenue of $69.6 billion and earnings of $3.23 per share, compared to the consensus estimates of $68.8 billion and $3.11, respectively. The company continued to benefit from increasing sales of Azure cloud computing services. However, the company’s outlook for the third quarter was below expectations, resulting in lower levels for MSFT post the results announcement. But, we think MSFT stock may have some room for growth after its recent dip. MSFT stock, with 19% returns since the beginning of 2024, has underperformed the S&P 500 index, up 27%. Microsoft’s Azure cloud computing sales growth rate has slowed lately, weighing on its stock price. If you want upside with a smoother ride than an individual stock, consider the High-Quality portfolio, which has outperformed the S&P, and clocked >91% returns since inception. Microsoft’s revenue of $69.6 billion in Q2 was up 12% y-o-y. Looking at segments, Productivity and Business Processes sales were up 14% to $29.4 billion, driven by higher sales of Microsoft 365 products and LinkedIn solutions. Intelligent Cloud segment revenue was up 19% to $25.5 billion, led by Azure and other cloud offerings. Lastly, More Personal Computing sales were unchanged at $14.7 billion, as growth in Windows OEM and devices was offset by lower gaming sales. Microsoft saw Azure and cloud services growth of 31% — a slight slowdown from 33% in the previous quarter. The company’s AI-related revenue has reached an annual run rate of $13 billion. Not only did the company see higher sales, its operating margin of 45.5% in Q2 expanded by 190 bps y-o-y. Higher revenues clubbed with margin expansion resulted in earnings of $3.23 per share, up 10% y-o-y. Separately, look at – Buy, Sell, Or Hold META Stock At $690? Azure sales were lower than anticipated, and this didn’t sit well with the investors. Furthermore, the company’s outlook of $68.2 billion revenue in Q3 (at the mid-point of the provided range) is much lower than the consensus estimate of $69.8 billion. As such, MSFT stock is taking a hit post the results announcement. Even if we look at a slightly longer time frame, the increase in MSFT stock over the last four-year period has been far from consistent, with annual returns being considerably more volatile than the S&P 500. Returns for the stock were 52% in 2021, -28% in 2022, 58% in 2023, and 13% in 2024. In contrast, the Trefis High Quality Portfolio, with a collection of 30 stocks, is considerably less volatile. And it has comfortably outperformed the S&P 500 over the last 4-year period. Why is that? As a group, HQ Portfolio stocks provided better returns with less risk versus the benchmark index; less of a roller-coaster ride as evident in HQ Portfolio performance metrics. Given the current uncertain macroeconomic environment around rate cuts and the rise of DeepSeek, could MSFT face a similar situation as it did in 2022 and 2024 and underperform the S&P over the next 12 months — or will it see a strong jump? After its recent dip, we think that MSFT stock has some room for growth. We estimate Microsoft’s Valuation to be $485 per share, reflecting around 15% upside from its current levels. Our forecast is based on 37x expected earnings of $13.11 per share in 2025. While the current P/E ratio of 37x exceeds the stock’s two-year average of 32x, this higher valuation appears warranted given the anticipated earnings growth driven by expanding Cloud and AI contribution. While MSFT stock looks like it has some room for growth, it is helpful to see how Microsoft’s Peers fare on metrics that matter. You will find other valuable comparisons for companies across industries at Peer Comparisons. Also, check out our take on – Should You Pick IBM Stock At $250? MSFT Return Compared With Trefis Reinforced Portfolio Invest with Trefis Market Beating Portfolios See all Trefis Price Estimates
--------------------------------------------------

Title: After DeepSeek's R1 stuns the AI world, Alibaba responds with an allegedly more powerful model
URL: https://www.techspot.com/news/106566-after-deepseek-r1-stuns-ai-world-alibaba-responds.html
Time Published: 2025-01-30T12:42:00Z
Full Content:
In brief: Alibaba has struck back at rival DeepSeek with the surprise release of its new Qwen 2.5-Max model. The Chinese e-commerce titan claims its latest artificial intelligence offering surpasses the capabilities of DeepSeek's recently launched and highly-touted DeepSeek-V3. The timing of the Qwen 2.5-Max's debut is unusual, considering it arrived on the first day of the Lunar New Year holiday, when most Chinese workers are off. It illustrates just how severely DeepSeek's AI breakthrough has rattled the established players. We've seen the effect DeepSeek's breakthrough had on overseas rivals like OpenAI, leading to multiple posts on X by CEO Sam Altman and the massive $600 billion stock crash at Nvidia – the biggest single-day plunge for any public company ever. It's no surprise that DeepSeek's success also spurred powerful domestic Chinese tech giants to scramble for a response. Alibaba's counterpunch comes in the form of the new Qwen 2.5-Max. "Qwen 2.5-Max outperforms...almost across the board GPT-4o, DeepSeek-V3 and LLaMa-3.1-405B," boasted Alibaba Cloud in its WeChat announcement, calling out some of the most advanced open-source AI models from the likes of OpenAI and Meta. Beyond DeepSeek's general AI capabilities, another factor that contributed to its popularity has been the extremely low costs of developing and running its models. This has even led investors to seriously question the massive spending on AI by US tech leaders. Likely taking that into account, Alibaba Cloud also emphasized Qwen 2.5-Max's efficiency in a blog post, highlighting that it was trained on over 20 trillion tokens while using a mixture-of-experts (MoE) architecture that requires significantly fewer computational resources than usual approaches. Beyond Alibaba, TikTok parent ByteDance has responded with an updated version of its flagship AI, which it claims outperformed OpenAI's GPT-3.5 on certain benchmarks. An earlier version of DeepSeek also triggered an intense price war in China back in May. DeepSeek-V2's incredibly low cost of just 1 yuan (14 cents) per million tokens of data processed forced major cloud providers like Alibaba to slash their own AI model pricing by up to 97%. It's worth mentioning that, like DeepSeek, Alibaba's new Qwen 2.5-Max does seem to avoid discussing sensitive political topics related to China. Attempts to query it on such issues are reportedly met with messages about exceeding data quotas, even as it responds normally to other prompts. TECHSPOT : Tech Enthusiasts, Power Users, Gamers TechSpot is a registered trademark. About Us Ethics Statement Terms of Use Privacy Policy Change Ad Consent Advertise © 1998 - 2025 TechSpot, Inc. All Rights Reserved.
--------------------------------------------------

Title: DeepSeek privacy under investigation in US and Europe; removed from App Store in Italy
URL: https://9to5mac.com/2025/01/30/deepseek-privacy-under-investigation-in-us-and-europe-removed-from-app-store-in-italy/
Time Published: 2025-01-30T12:25:56Z
Full Content:
DeepSeek privacy concerns have led to investigations being opened in both the US and Europe, and seen the app removed from the App Store in Italy. It seems likely the same will happen in other countries. Italian’s privacy regulator questioned whether the app complied with GDPR, a tough privacy law that applies across 30 different countries … DeepSeek is an AI chatbot developed in China, and which posted benchmarks indicating that its performance was comparable to the world’s best existing models. Experts quickly verified the claims, expressing shock that China was able to achieve this at a fraction of the development cost of US models, and running locally on very modestly-specced PCs. The app quickly climbed to the #1 slot in Apple’s App Store. It also led to fears that US AI companies may be over-valued. It had previously been thought that the very high hardware costs required to develop LLMs meant companies like OpenAI, Google and Meta were unlikely to face competition from smaller businesses, and that Nvidia GPUs would continue to be in extremely high demand. Those assumptions have now been thrown into question, leading to a slump in the stock price of a number of companies. Most AI chatbots have privacy policies which allow them to learn from our interactions with them, raising obvious privacy concerns. The fact that DeepSeek is Chinese owned has raised additional fears about how it collects and uses personal data. Reuters reports that Italy’s privacy watchdog has asked the company a series of questions about GDPR compliance, and has given it 20 days to respond. Italy’s data protection authority said it was seeking answers from Chinese artificial intelligence (AI) model DeepSeek on its use of personal data. The Italian regulator, which is also known as the Garante, said it wanted to know what personal data is collected, from which sources, for what purposes, on what legal basis, and whether it is stored in China. Additionally, US officials are investigating the app. US officials are looking at the national security implications of the Chinese artificial intelligence app DeepSeek, White House press secretary Karoline Leavitt said […] The National Security Council is reviewing the app’s implications. Following the Garante’s questions, DeepSeek is no longer available in either Apple or Google’s app stores in the country. It’s not clear whether this action was taken by DeepSeek or by the app store companies. The Chinese artificial intelligence app DeepSeek could not be accessed on Wednesday in Apple and Google app stores in Italy, the day after the country’s data protection authority requested information on its use of personal data. Reuters reports that Ireland’s privacy regulator has also asked similar questions. GDPR applies to all 27 European Union countries, plus three EAA ones, meaning that companies operating in a total of 30 countries are required to comply. A lack of satisfactory response to the questions asked by Italy and Ireland could potentially see the app banned in all these countries. The same privacy concerns apply to most generative AI services. Given their very similar privacy policies, it seems the only difference here is that US companies are trusted more than Chinese ones. The best advice is never to include personal data in your chatbot requests. Apple Intelligence is a notable exception to this: the service does not use your data for training purposes. Additionally, Apple’s deal with OpenAI means that ChatGPT is also banned from doing so when you access it as a fallback to Apple Intelligence. For this reason, accessing ChatGPT via Siri is the safest way to use it. Photo by Solen Feyissa on Unsplash FTC: We use income earning auto affiliate links. More. Check out 9to5Mac on YouTube for more Apple news: Privacy is a growing concern in today's world. F… Ben Lovejoy is a British technology writer and EU Editor for 9to5Mac. He’s known for his op-eds and diary pieces, exploring his experience of Apple products over time, for a more rounded review. He also writes fiction, with two technothriller novels, a couple of SF shorts and a rom-com! Manage push notifications
--------------------------------------------------

Title: MicroStrategy Isn’t Just A Giant Bitcoin Bet–It’s A Revolution In Corporate Finance
URL: https://www.forbes.com/sites/ninabambysheva/2025/01/30/microstrategy-isnt-just-a-giant-bitcoin-betits-a-revolution-in-corporate-finance/
Time Published: 2025-01-30T11:30:00Z
Full Content:
New Year’s Eve at Villa Vecchia is a delirious blur of orange and gold, a scene straight out of F. Scott Fitzgerald’s most opulent fantasies. More than 500 people crowd onto the manicured lawns of the century-old Miami Beach estate with its Versailles-inspired ballroom that once welcomed luminaries including Margaret Thatcher, Henry Kissinger and Mikhail Gorbachev. Bitcoin’s recent surge past $100,000—not the dawn of 2025—is the real raison d’être for the bash. Servers glide around with champagne on silver trays, hors d’oeuvres are stamped with the omnipresent B and dancers in golden bodysuits undulate with glowing orange orbs in homage to bitcoin’s signature hue. At the center of the garden looms a massive playing card, the king’s face replaced with a brazen B. jamel toppin for forbes On the water, the party continues aboard the Usher. The 154-foot superyacht, which was featured in the 2015 film Entourage, glistens against the Miami skyline. A constant stream of shuttles disgorges an unending parade of bitcoin executives, influencers and, most importantly, institutional investors, all decked out in “bitcoin chic” (tangerine suits, B-logo bling). Two giant projectors flash clips forecasting bitcoin’s rise into the millions, while a DJ clad in a space helmet directs bass-heavy tracks between the swaying palms. “I kind of feel a little sick of winning,” quips one reveler in a black cap emblazoned with SATOSHI NAKAMOTO—the handle of bitcoin’s anonymous creator. The partygoers all have crypto cred: The guy in the Nakamoto hat is David Bailey, the 34-year old CEO of BTC Inc., publisher of Bitcoin Magazine, who hosted the Bitcoin Conference in July at which Donald Trump vowed to make America the “crypto capital of the planet” and establish a national bitcoin stockpile. Villa Vecchia’s owner and host, Michael Saylor, 59, moves through the revelry clad in his signature black blazer, blue jeans and T-shirt whose front sports (of course) a B. He graciously accepts handshakes and requests for selfies. Here, bitcoin is God—and Saylor is its prophet. Crypto is a second coming of sorts for Saylor, given that he made and lost more than $10 billion during the original dot-com bubble. Back then, MicroStrategy, the Tysons Corner, Virginia–based software firm he cofounded in 1989 fresh out of MIT, was in the data mining and business intelligence software business before running afoul of the Securities and Exchange Commission over its accounting practices. In 2000, the company paid a fine, settled with the feds and restated its results for the preceding couple years. Forbes For the next two decades MicroStrategy languished with tepid sales and a market cap hovering around $1 billion. That all changed in 2020, when Saylor decided that going all in on bitcoin would be MicroStrategy’s core strategy. Last year, after the SEC approved bitcoin ETFs from giants like BlackRock and Fidelity, the crypto­currency’s price skyrocketed, more than doubling over 12 months and breaking through $100,000 in early December. Just before Christmas, Micro­Strategy joined the Nasdaq 100, spurring even more demand for its stock, which is up more than 700% in the last year, as it issued debt and accumulated more bitcoin (it now owns 471,107). Saylor’s company is now the largest holder of the digital asset outside of the elusive Nakamoto, who is said to hold 1 million tokens. During 2024, Saylor’s net worth jumped from $1.9 billion to $7.6 billion. A month into the new year he is worth $9.4 billion. MicroStrategy’s eye-popping gains have stirred up a swarm of critics and short sellers unable to fathom how a tiny software company holding only $48 billion in actual bitcoin could have a market capitalization of $84 billion. But what Saylor’s detractors fail to understand is that Micro­Strategy is brilliantly straddling two realms: one bound by the rules of traditional finance, in which companies issue debt and equity bought and sold by hedge funds, traders and other institutions, and the second governed by the faithful, unwavering believers in a better world brought to you by bitcoin. The fuel propelling MicroStrategy’s success is its embrace and cultivation of volatility, the defining characteristic of its core asset. Volatility is anathema to traditional investors, but it’s a great friend of the options traders, hedge funds and retail speculators that have helped make Micro­Strategy among the most active stocks in the market. With its relatively tiny annual revenue of $496 million, it has a daily trading volume that rivals that of any of the Magnificent 7 tech giants (Meta, Apple, Alphabet, Microsoft, Amazon, Tesla and Nvidia). “People think that’s crazy,” Saylor says. “How can such a small company have that liquidity? It’s because we put a crypto reactor in the middle of the company, pull capital in and then we spin it. That puts volatility in the equity, and that makes our options and convertible bonds the most interesting and highest-performing in the market.” Michael Saylor is 100 percent correct when it comes to the desirability of the $7.3 billion in convertible bonds his company has issued since 2021. Every minute of the trading day, MicroStrategy’s stock price is being amplified in real time by bitcoin’s constant gyrations, increasing what’s known as the implied volatility of the call option inherent in its convertible bonds. That’s because unlike straight bonds, convertibles give debt holders safety, with the option of exchanging their notes for Micro­Strategy stock at predetermined prices until maturity. Every trader schooled in the Black-Scholes options pricing formula knows that high implied volatility increases the value of an option. Thus Saylor has been able to issue his convertible debt at almost no interest cost. So far MicroStrategy’s six convertible notes, issued with maturities from 2027 to 2032, have interest rates ranging from 0% to 2.25%. In public bond markets, where liquidity has been shrinking thanks to the boom in private credit, institutional investors are starving for excess returns. MicroStrategy’s bonds not only represent one of the only ways big investors like German insurer Allianz and State Street can invest in digital assets, but they’ve also been one of the market’s top performers, clocking returns in excess of 250% since issuance. Even the $3 billion five-year notes MicroStrategy issued in November, with their 0% coupon and strike price of $672 (80% above MicroStrategy’s current share price) are up 89% in just a few months. Saylor understands that institutional investors, who are measured against quarterly benchmarks, will keep buying his high-octane paper to boost their portfolio returns. Issuing huge amounts of convertible bonds, as MicroStrategy has, is normally dilutive for a company’s stock, but in this case it has had a bullish effect because the notes represent future stock demand at increasingly higher prices. Through secondary offerings and convertible issuance, MicroStrategy’s outstanding shares have grown since 2020 from 97 million to 246 million. Over the same period, its stock has appreciated 2,666%. In late January, its shareholders voted to vastly increase the company’s authorized shares to 10.3 billion. The cycle feeds itself: Issue billions in low- or no-cost debt and equity, drive bitcoin pri­ces higher with large purchases and catapult MicroStrategy’s hyper­volatile stock. Rinse and repeat. “What they found is a monetary glitch in the financial markets that they’re taking advantage of,” marvels Richard Byworth, former conver­tible bonds trader at Nomura and managing partner at Zurich, Switzerland–based alternative investment firm Syz Capital. Saylor is understandably unabashed in his hyping of bitcoin. Last August he invented an entirely new financial metric dubbed Bitcoin Yield or BTC Yield. This sort of “yield” has nothing to do with any income being generated but simply measures the percentage change in the ratio of the company’s bitcoin holdings to the company’s fully diluted shares over time. His initial targets for the measure were 4% to 8% growth annually, but in January MicroStrategy reported a BTC Yield of 48% for Q4 and 74.3% for all of 2024—big but meaningless numbers he has fed like chum to his adoring followers. Try to put a value on MicroStrategy the old-fashioned way and you’ll lose your marbles, according to Ben Werkman, a former commercial banker, consultant and early investor in the company’s bitcoin strategy. Saylor “turned off the income statement thinking and said ‘We’re going to attack the net worth side of the company, focus on leveraging the strength that we have on our balance sheet,’ and in this case, that means acquiring more bitcoin.” Which is exactly what MicroStrategy is doing. In October, Saylor unveiled a plan called “21/21” to raise a whopping $42 billion—half through equity, half through debt—over the next three years to buy more bitcoin. In November and December alone, the firm scooped up nearly 200,000 coins worth roughly $18 billion. It all works out brilliantly as long as the price of bitcoin keeps rising, but what if it collapses, as it has many times before? “Size is everything because liquidity is everything. MicroStrategy is singularly the most liquid source to trade bitcoin-related risks, both by the spot market and, more importantly, the options market.” Unless it’s a true apocalypse, MicroStrategy should be okay. Bitcoin would need to fall by more than 80% from its current $100,000-plus level and stay that way for at least two years for Micro­Strategy to fall short on its ability to cover its current debt obligations. Here again Saylor has shown genius in exploiting the capital markets and the behavior of bond investors. All of the $7 billion in debt MicroStrategy has issued is unsecured and not technically backed by any of the bitcoin in its coffers. Moreover, at the company’s current stock price of $373, more than $4 billion of its debt is already “in the money” or, effectively, equity. “Actually, there is very little debt on Micro­Strategy’s balance sheet,” says Jeff Park, head of alpha strategies at Bitwise, a San Francisco–based crypto asset manager, noting that a forced liquidation of MicroStrategy’s bitcoin holdings would be unlikely because institutional bondholders have high tolerance for refinancings, even in worst-case bankruptcy scenarios. What is stopping other companies from copying Saylor’s bitcoin-fueled financial engineering? Nothing. And many are starting to do exactly that. According to Park, Bitwise counts about 90 public companies, including well-known names Tesla and Block, that have added bitcoin to their balance sheets. In March, his company will launch the Bitwise Bitcoin Standard Corporations ETF, which will be a bitcoin holdings-weighted index of 35 public companies in possession of at least 1,000 bitcoin (roughly $100 million) in their treasuries. MicroStrategy will domi­nate the index. The copycats are giving ammunition to Micro­Strategy haters. “The days when MicroStrategy shares represented a rare, unique way to gain access to bitcoin are long over,” according to Kerrisdale Capital, a Miami-based investment firm that issued a short thesis on the stock in March. But Park argues that like Netflix in streaming, Micro­Strategy’s first-mover advantage and size set it apart. “Size is everything because liquidity is everything. They are singularly the most liquid source to trade bitcoin-related risks, both by the spot market and, more importantly, the options market,” Park says. “The options market for Micro­Strategy is by far the deepest single name options market in the entire world.” MicroStrategy’s frenetic options have even spawned a fund called YieldMax MSTR Option Income Strategy ETF, which sells call options to generate income. The year-old fund has an annual yield of 106% and has already amassed $1.9 billion in assets. Sitting by the pool at Villa Vecchia, with his crypto-named parrots Hodl, Satoshi and Max chattering away in the background, Saylor waves off his critics. “Conventional wisdom in business for the last 40 years was that capital is a liability and volatility is bad. The bitcoin standard dictates capital is an asset and volatility is good—it’s a feature,” he insists. “They’re living in flatland, a pre-Copernican world. We’re on a train going 60 miles an hour, spinning a gyro with a 30-ton weight on it, and the rest of the world is standing by the side of the track, stationary.” This isn’t the first time Michael Saylor has flown close to the sun. He was born in 1965 on an Air Force base in Lincoln, Nebraska, and his early years were steeped in military discipline. His father, a chief master sergeant, moved the family between Air Force bases around the world before settling near Wright-Patterson in Ohio—home of the Wright Brothers’ aviation school—where Saylor gradua­ted high school as valedictorian and class marshal, voted “most likely to succeed” by his peers. He went on to study aeronautics and astronautics at MIT on a full Air Force ROTC scholarship and wrote a thesis on a computer simulation of a Renaissance Italian city-state. In his free time, he played guitar in a rock band and flew gliders. He graduated in 1987 with highest honors and was commissioned as a second lieutenant in the Air Force, but his dream of becoming a fighter pilot was grounded by a heart murmur, which turned out to be a misdiagnosis. At age 24, he cofounded MicroStrategy with his MIT fraternity brother Sanju Bansal. The company tapped into data analytics at a time when few understood that discipline’s potential. Riding the dot-com wave, the company went public in 1998, and by 2000, its market cap soared past $24 billion. With his net worth rising to a peak of nearly $14 billion, Saylor became a tech evangelist heralding a world in which data would flow “like water.” “We’re going to use our technology to obliterate entire supply chains,” Saylor told Forbes in late 1998. “We’re playing for all the marbles to essentially win the entire industry worldwide, forever.” Then came the crash. On March 10, 2000, Micro­Strategy’s stock hit a peak of $313 per share—more than 60 times its IPO price. Within two weeks it plummeted to $72, following the company’s announcement that it would need to restate its financial results. The SEC accused Saylor and others of accounting fraud, charges MicroStrategy later settled for $11 million. Within two years its stock price had fallen below $1. Saylor’s $13 billion fortune evaporated. “It was the darkest part of my life,” he says. “When people lose money because they believe in you, that’s pretty much the worst.” In 2020, after the government followed years of quantitative easing with trillions of dollars in Covid-19-related stimulus, Saylor became convinced that the best use for the remaining $530 million in cash and short-term investments on MicroStrategy’s balance sheet was investing in bitcoin. The U.S. government could print as many dollars as it wanted—and it was hard at work doing just that—but, by design, bitcoin comes with a hard cap: There will never be more than 21 million in existence. If the price of bitcoin plummets, MicroStrategy’s stock will fall harder and faster than the token itself. But be careful about dismissing Saylor as yet another too-smart-for-his-own good entrepreneur gone off the rails. Many others are following the lead of MicroStrategy—which now bills itself “the world’s first and largest Bitcoin Treasury.” Some public companies, like Metaplanet, owe their very survival to bitcoin. The Tokyo-based hotel chain faced an existential crisis during the pandemic when Japan closed its borders to tourists. The small hotelier sold all but one of its ten properties and issued shares and debt to finance $70 million in bitcoin purchases. Metaplanet’s shares, which trade on the Tokyo Stock Exchange and over the counter, gained 2,600% in 2024, and its market capitalization is now $1 billion, despite holding only $183 million worth of bitcoin. The company’s homepage now reads “Secure the Future with Bitcoin” and barely mentions hotels. “We owe a lot to Michael Saylor for the business plan, which he has created for the rest of the world to follow,” says Simon Gerovich, CEO of Metaplanet and a guest at Saylor’s New Year’s bash. “I invented 20 things, tried to make them successful and really didn’t change the world with any of them. Satoshi created one thing, gave it to the world and disappeared. It’s made me more successful than every one of my ideas.” It is unlikely many corporations will go to Metaplanet’s extreme, but more bitcoin converts are almost a certainty. In January, the Financial Accounting Standards Board changed a rule that previously permitted companies to record crypto value declines only as losses in quarterly reports, so that now holdings will be marked to market, allowing for reversal of losses and gains as well. For MicroStrategy, which lobbied for the change, it’s likely to mean numerous profitable quarters ahead—and possible inclusion in the S&P 500. Today hundreds of sizable public companies around the world are sitting on more than twice the cash they need to finance current operations and liabilities, according to data from YCharts. Most prominent among them is Berkshire Hathaway, which currently holds $320 billion in cash. Given the $35 trillion (and growing) national debt, Saylor’s mantra has long been “cash is trash.” “Financial repression is an eternal phenomenon,” insists Bitwise’s Park, referring to the inevitability of government-induced lower interest rates. “We are living in this hyper-financialized world where the real economy has fundamentally detached itself from the financial economy. You actually can’t service the level of debt without printing more money, and if you believe you have to continue printing more money, then you better believe there’s going to be yield curve repression.” For Saylor, Villa Vecchia itself is Exhibit A. The 18,000-square-foot mansion on Miami’s “Millionaire’s Row” was built for the president of F.W. Woolworth in 1928; Saylor bought it for $13 million in 2012. This house “was $100,000 in 1930. It was appraised at $46 million a few years ago,” said Saylor during a 2023 podcast interview. “Do the calculation—it’s on a path to be worth $100 million, which means that the U.S. dollar will have lost 99.9% of its value over 100 years. The bottom line is: Your money in the bank isn’t money.” The coming Trump years are likely to be good for MicroStrategy and bitcoin. Despite all his bluster about “government efficiency,” Trump was a huge spendthrift during his first presidency: In the four years of Trump 1.0, the national debt increased by $8.4 trillion, according to the Committee for a Responsible Federal Budget. And although he famously called bitcoin a “scam” competing against the dollar in 2021, Trump is all in on crypto these days. In fact, his son Eric recently posted a picture with Saylor at Mar-a-Lago captioned “Two friends, one passion: bitcoin.” Not only is the value of the dollar likely to further erode over the next four years, but Saylor’s relentless proselytizing aligns perfectly with the dystopian MAGA worldview. “The human condition has been plagued by dirt: toxic food, toxic liquid, and the economic condition of the human race has been plagued by toxic capital. I’m on a mission to evangelize nontoxic capital for the world,” he preaches. But even Michael Saylor occasionally steps down from his soapbox to reflect on his corporate journey. “We adopted bitcoin out of frustration and desperation, and then it became an opportunity, and then it became a strategy, and then it became an identity, and then it became a mission,” he says. “The irony of my career is I invented 20 things, and I tried to make them successful, and I really didn’t change the world with any of them. Satoshi created one thing, gave it to the world and disappeared, and now we just carry the torch. That, ironically, has made me more successful than me trying to commercialize every one of my own ideas. It is a lesson in humility.” And a reminder that lightning can indeed strike the same place twice, especially when there is a shrewd and opportunistic steward at the helm.
--------------------------------------------------

Title: DeepSeek disruption: Is the Nvidia sell-off an overreaction? (Prakash Bhudia)
URL: https://www.finextra.com/blogposting/27738/deepseek-disruption-is-the-nvidia-sell-off-an-overreaction
Time Published: 2025-01-30T07:47:30Z
Full Content:
The release of DeepSeek’s groundbreaking R1 AI model has sent shockwaves through global markets, wiping $1 trillion from tech stocks and prompting a significant sell-off in Nvidia shares. DeepSeek’s claims of building a rival AI model at a fraction of the cost compared to U.S. tech giants have sparked fears about the future of AI infrastructure spending. But is the panic justified, or are investors overreacting? DeepSeek, a Chinese AI startup, recently unveiled its R1 model, a reasoning-focused AI that rivals OpenAI’s latest advancements. The company claims to have trained the model for just $5.6 million in rented GPU hours, a figure that starkly contrasts with the billions spent by U.S. firms like OpenAI and Meta. This efficiency has raised questions about whether Nvidia’s high-end GPUs are as essential as previously thought. However, some analysts and industry insiders remain skeptical. Machine learning researcher Nathan Lampert pointed out that DeepSeek’s $5.6 million figure likely excludes significant pre-training costs, engineering salaries, and infrastructure expenses, potentially pushing their actual costs closer to $500 million or more. Source: DeepSeekV3 Additionally, there’s speculation that DeepSeek has access to restricted Nvidia H100 chips, adding a layer of complexity to its cost-efficiency claims. Despite these doubts, the open-source nature of DeepSeek’s techniques means its efficiency breakthroughs could be replicated by other players, potentially reshaping the economics of AI development. Nvidia, which has dominated the AI hardware market with its cutting-edge GPUs, saw a sharp drop in its stock value following DeepSeek’s announcement. Investors worry that DeepSeek’s efficiency could dampen demand for Nvidia’s GPUs, especially as Big Tech reevaluates its AI spending strategies. But the narrative may not be so dire. Industry leaders like Microsoft CEO Satya Nadella have invoked the Jevons Paradox, arguing that as AI becomes more efficient, demand for computing power could actually increase. Ethan Mollick, a Wharton professor specializing in AI, echoed this sentiment, noting that greater efficiency allows companies to serve more customers and expand AI applications, ultimately driving higher demand for GPUs. Moreover, AI giants like OpenAI and Meta have recently announced massive infrastructure investments, signaling a continued appetite for high-performance hardware. Meta’s $65 billion capital expenditure plan for 2025, for instance, includes building an AI data center nearly the size of Manhattan. These commitments underscore the long-term growth potential for Nvidia, even in the face of new competitors. The market’s reaction to DeepSeek’s R1 model reflects both the promise and the uncertainty of AI’s rapidly evolving landscape. While DeepSeek’s efficiency claims could shift how AI models are built, they are unlikely to eliminate the need for advanced hardware entirely. Nvidia’s diversified portfolio, which includes robotics and AI-driven applications, positions it well to weather these disruptions. For investors, the key question is whether DeepSeek’s innovations mark the beginning of a broader trend or a temporary market overreaction. If history is any guide, breakthroughs that lower costs often lead to expanded markets rather than shrinking them. Nvidia, as a leader in AI hardware, could still emerge as a major beneficiary in the long run. In the short term, the market may continue to grapple with the implications of DeepSeek’s rise. But with AI demand showing no signs of slowing, Nvidia’s upside could be far from over. At the time of writing Nvidia is recovering from an early week slump, with some upside pressure clearly evident on the daily chart. However, prices remaining below the moving average If a significant bounce materialises, buyers could face a hurdle at the $140.00 and $148.80 resistance levels. On the downside, sellers could find support at the $121.80 price level. Source: Deriv MT5 Disclaimer: The information contained within this blog article is for educational purposes only and is not intended as financial or investment advice. We recommend you do your own research before making any trading decisions. This information is considered accurate and correct at the date of publication. Changes in circumstances after the time of publication may impact the accuracy of the information. The performance figures quoted refer to the past, and past performance is not a guarantee of future performance or a reliable guide to future performance.
--------------------------------------------------

Title: Alibaba Unveils Qwen 2.5 AI Model, Claiming It Outperforms DeepSeek And ChatGPT, But It Remains To Be Seen How It Will Be Positioned In The Industry
URL: https://wccftech.com/alibaba-qwen-2-5-ai-model-surpasses-deepseek/
Time Published: 2025-01-30T07:27:19Z
Full Content:
DeepSeek has shaken the AI industry with its new R1 model, which aims to compete against OpenAI's ChatGPT. While the Chinese AI chatbot is all the hype these days, another major contender has entered the competition, claiming that its AI model is better than that of DeepSeek. Alibaba has officially launched its Qwen 2.5 AI model and claims that it can outperform DeepSeek-V3 along with other leading AI models like ChatGPT. DeepSeek entered the AI industry earlier this week with its new AI model, and it has surpassed ChatGPT to become the most downloaded AI chatbot in various regions, including the United States. With Alibaba stepping into the same field, we can safely presume that China is desperate to take the lead in the category. According to Alibaba's cloud division, “Qwen 2.5-Max surpasses GPT-4o, DeepSeek-V3, and Llama-3.1-405B in almost every aspect,” referring to the dominance against Meta and OpenAI (via Reuters). The rapid development of new AI models has intensified the competition in the industry, and the race to become number one has impacted investor confidence in the United States. Companies like NVIDIA have also lost their position in the stock market, making investors reassess their investments in major AI tech giants in the United States. DeepSeek's success in the industry is making rivals step up their game to better compete against the new entrants. Furthermore, existing companies have also released updated AI models to showcase their newer capabilities. For instance, ByteDance unveiled its upgraded AI model and claims it outperforms OpenAI's o1 in AIME, a key benchmark measuring AI comprehension and understanding of complex instructions. With Alibaba's new Qwen 2.5 AI model, we expect the competition to pick up additional heat, which will be evident in the coming months. The previous version of the DeepSeek-V3 also waged a price war for AI models in China. Since DeepSeek-V2 was open source and relatively cheap compared to the competition, with an estimated $0.14 for a million tokens, it led Alibaba to slash its prices by 97 percent on a wide range of AI models. Baidu and Tencent followed suit and cut their prices as well. We have to take note that DeepSeek only has a handful of users compared to Alibaba's hundreds of thousands of employees. Moreover, it only took $5.6 million for DeepSeek to develop the new AI technology against billions of dollars spent in the United States. It remains to be seen how Alibaba's Qwen performs against the likes of DeepSeek and OpenAI and how the company is planning to position itself in the market. Some posts on wccftech.com may contain affiliate links. We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to amazon.com © 2025 WCCF TECH INC. 700 - 401 West Georgia Street, Vancouver, BC, Canada
--------------------------------------------------

Title: Microsoft's cloud outlook knocks shares, Meta rises on AI payoff signs
URL: https://www.channelnewsasia.com/business/microsofts-cloud-outlook-knocks-shares-meta-rises-ai-payoff-signs-4905736
Time Published: 2025-01-30T07:13:12Z
Full Content:
Business FILE PHOTO: Pedestrians walk past a Microsoft Experience Center, following a global IT outage, in New York City, U.S. July 19, 2024. REUTERS/Kent J. Edwards/File Photo :Investors punished Microsoft with a 6 per cent share drop on Thursday as hefty AI bets failed to drive a big increase in its cloud revenue, while Meta rose 4 per cent after CEO Mark Zuckerberg assured Wall Street about growth with promises of a "really big year". The chief executives of both the companies defended their heavy investments on artificial intelligence on Wednesday, days after Chinese upstart DeepSeek unveiled a breakthrough in cheap AI that shook the technology industry. But while Meta has consistently showed strong ad revenues - a move that "easily justifies" its investments according to Evercore analyst Mark Mahaney - Microsoft's key cloud business Azure has been slowing down. The Windows maker missed market estimates for quarterly revenue growth at Azure and gave a third-quarter forecast for the business that was below expectations, even after it promised a rebound for the unit in the second half of its fiscal year. "The second-half re-acceleration story for Azure is not playing out," Barclays analyst Raimo Lenschow said. "The company overly focused on AI workloads at the expense of core Azure. It will take time to fix this, which means the Azure growth acceleration the market had been hoping for has to wait for a little longer." For Facebook-parent Meta, a better-than-expected 21 per cent jump in revenue helped ease investor fears around Zuckerberg's plans to spend as much as $65 billion this year on AI, even as its first-quarter forecast was muted. "Nobody is more bulled up on AI than Meta. And Meta might have more benefits to show from AI than anyone," Rosenblatt analyst Barton Crockett wrote. At least 15 brokerages raised their price targets on Meta, which has a 12-month forward price-to-earnings ratio of about 26.22. The stock jumped 65 per cent last year, the biggest gain among Big Tech peers. The company looked set to add more than $80 billion to its market value on Thursday. "Meta's ability to use AI to sustainably drive both engagement and pricing growth is a rarity in its (and the industry's) history," MoffettNathanson analysts said. Microsoft was on track to erase about $182 billion off its market cap. About four brokerages trimmed their price targets on the stock, which has lagged its peers with just a 12 per cent gain last year. Microsoft "did not recommit to (its Azure second-half outlook) the same way that it did 90 days ago. The Azure-acceleration story has been hit by shrapnel and is losing altitude," J.P. Morgan analyst Mark Murphy said. Get our pick of top stories and thought-provoking articles in your inbox Stay updated with notifications for breaking news and our best stories Get WhatsApp alerts Join our channel for the top reads for the day on your preferred chat app
--------------------------------------------------

Title: Nasdaq 100 Forecast: QQQ rises post-Fed, big tech earnings in focus
URL: https://www.cityindex.com/en-uk/news-and-analysis/nasdaq-100-forecast-qqq-rises-post-fed--big-tech-earnings-in-focus-us-open-2025-1-30/
Time Published: 2025-01-30T02:37:00Z
Full Content:
The S&P 500 and Nasdaq 100 are heading higher after the Federal Reserve left interest rates unchanged and amid a post-earnings boost from mega-caps Meta and Tesla. Microsoft is falling after earnings. US GDP was weaker than forecast at 2.3% annualised.
--------------------------------------------------

Title: Share Market Highlights 30 January 2025: Markets extend rally to third day; Sensex rises 226 pts to close at 76,759, Nifty ends above 23,200
URL: https://www.thehindubusinessline.com/markets/stock-market-highlights-30-january-2025/article69154821.ece
Time Published: 2025-01-30T01:36:14Z
Full Content:
+ 740.76 + 258.90 -64.00 + 53.00 -140.00 + 740.76 + 258.90 + 258.90 -64.00 -64.00 + 53.00 Get businessline apps on Connect with us TO ENJOY ADDITIONAL BENEFITS Connect With Us Get BusinessLine apps on Comments READ LATER Stock Market on 30 January 2025 | Share Market Highlights - Find here all the updates related to Sensex, Nifty, BSE, NSE, share prices and Indian stock markets for 30th January 2025 Comments BACK TO TOP Comments have to be in English, and in full sentences. They cannot be abusive or personal. Please abide by our community guidelines for posting your comments. We have migrated to a new commenting platform. If you are already a registered user of TheHindu Businessline and logged in, you may continue to engage with our articles. If you do not have an account please register and login to post comments. Users can access their older comments by logging into their accounts on Vuukle. Terms & conditions | Institutional Subscriber
--------------------------------------------------

Title: US stocks dip, dollar steady as traders digest Fed rate pause, tech earnings
URL: https://economictimes.indiatimes.com/markets/stocks/news/us-stocks-dip-dollar-steady-as-traders-digest-fed-rate-pause-tech-earnings/articleshow/117713156.cms
Time Published: 2025-01-30T00:40:40Z
Full Content:
Stock Trading Maximise Returns by Investing in the Right Companies By - The Economic Times, Get Certified By India's Top Business News Brand Stock Trading Market 104: Options Trading: Kickstart Your F&O Adventure By - Saketh R, Founder- QuickAlpha, Full Time Options Trader Stock Trading Technical Analysis for Everyone - Technical Analysis Course By - Abhijit Paul, Technical Research Head, Fund Manager- ICICI Securities Stock Trading Stock Markets Made Easy By - elearnmarkets, Financial Education by StockEdge Stock Trading Renko Chart Patterns Made Easy By - Kaushik Akiwatkar, Derivative Trader and Investor Stock Trading Market 101: An Insight into Trendlines and Momentum By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading Markets 102: Mastering Sentiment Indicators for Swing and Positional Trading By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading Dow Theory Made Easy By - Vishal Mehta, Independent Systematic Trader Stock Trading Market 103: Mastering Trends with RMI and Techno-Funda Insights By - Rohit Srivastava, Founder- Indiacharts.com Stock Trading ROC Made Easy: Master Course for ROC Stock Indicator By - Souradeep Dey, Equity and Commodity Trader, Trainer Stock Trading Heikin Ashi Trading Tactics: Master the Art of Trading By - Dinesh Nagpal, Full Time Trader, Ichimoku & Trading Psychology Expert Stock Trading RSI Made Easy: RSI Trading Course By - Souradeep Dey, Equity and Commodity Trader, Trainer Stock Trading Introduction to Technical Analysis & Candlestick Theory By - Dinesh Nagpal, Full Time Trader, Ichimoku & Trading Psychology Expert (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price Fleeing FIIs and nervous futures: Can FM calm the markets? 133% gains in 2024; worst performer in 2025 so far. Is Trent still a good buy? You can shop till you drop at duty free if FM heeds this proposal by airports Chinese DeepSeek is an existential threat to OpenAI and Google 5 reasons the middle class is facing consumption squeeze. Can the Budget help? How significant is the Union Budget for the common man? All Mutual Funds Top Tax Saving Mutual Funds Better Than Fixed Deposits Low Cost High Return Funds Best Hybrid Funds Best Large Cap Funds SIP’s starting Rs. 500 Top Performing Mid Caps Promising Multi Cap Funds Top Rated Funds Top Performing Index Funds Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Commodities Top Definitions Private Companies Top Prime Articles Top Story Listing Top Slideshow Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Worry not. You’re just a step away. It seems like you're already an ETPrime member with Login using your ET Prime credentials to enjoy all member benefits Log out of your current logged-in account and log in again using your ET Prime credentials to enjoy all member benefits. To read full story, subscribe to ET Prime ₹34 per week Billed annually at ₹2499 ₹1749 Super Saver Sale - Flat 30% Off On ET Prime Membership Offer Exclusively For You Save up to Rs. 700/- ON ET PRIME MEMBERSHIP Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get Flat 40% Off Then ₹ 1749 for 1 year Offer Exclusively For You ET Prime at ₹ 49 for 1 month Then ₹ 1749 for 1 year Special Offer Get flat 35% off on ETPrime 90 Days Prime access worth Rs999 unlocked for you Exclusive Economic Times Stories, Editorials & Expert opinion across 20+ sectors Stock analysis. Market Research. Industry Trends on 4000+ Stocks ​Get 1 Year Complimentary Subscription of TOI+ worth Rs.799/-​ Stories you might be interested in
--------------------------------------------------

Title: Microsoft’s AI revenue grows, but its stock falls on lower guidance and concerns over spending
URL: https://siliconangle.com/2025/01/29/microsofts-ai-revenue-grows-stock-falls-lower-guidance-concerns-spending/
Time Published: 2025-01-29T23:41:22Z
Full Content:
UPDATED 18:41 EST / JANUARY 29 2025 by Mike Wheatley Microsoft Corp. said today that profit from its fiscal second quarter rose 10% from the same period a year ago as it strives to capitalize on the massive investments it has made in artificial intelligence infrastructure. The company said its revenue from AI products and related services has now hit an annual run rate of $13 billion, growing from the previous $10 billion run rate it reported three months ago. However, while its profit and revenue surpassed Wall Street’s expectations, the company’s overall cloud computing business fell just short of analyst’s targets. Moreover, its guidance for the current quarter came up short, sending its stock lower after-hours. Microsoft reported earnings before certain costs such as stock compensation of $3.23 per share, besting Wall Street’s forecast of $3.11. Revenue from the October to December quarter reached $69.63 billion, above the Street’s $68.78 billion target. The company published its fiscal 2025 second-quarter earnings report in the wake of larger questions about spending in the AI industry following the emergence of Chinese AI startup DeepSeek, which has achieved dramatic cost-efficiency gains through the use of novel AI training techniques. DeepSeek’s rise has led to some serious scrutiny over the billions of dollars spent on AI infrastructure by Microsoft and its rivals. In the quarter, Microsoft’s capital expenditures reached a new record high of $22.6 billion, with officials citing the need to continue boosting data center capacity to meet demand for its AI offerings and cloud customers. The company said revenue from its Azure cloud computing platform and other cloud services increased 31% in the quarter, a slower pace than the 33% growth recorded three months earlier. Officials said 13% of that growth was attributed to AI services. Azure’s overall growth rate was lower than analysts had expected, and that caused Microsoft’s stock to fall more than 4% in extended trading. Overall, the company’s Intelligent Cloud segment, which includes revenue from Azure, delivered $25.54 billion in sales, up 19% from a year earlier but just shy of the $25.83 billion consensus estimate. Elsewhere, the company’s productivity segment, which includes the Office suite and Teams messenger platform, added $29.4 billion in revenue, up 14% from a year earlier. Sales from the personal computing business, which includes Windows, remained flat at $14.7 billion. Looking to the current quarter, Microsoft’s chief financial officer Amy Hood said on a conference call that the company is looking at sales of between $67.7 billion and $68.7 billion, shy of the Street’s consensus of $69.8 billion. She’s forecasting Azure revenue to grow by 31% to 32%, below the Street’s guidance of 33.4%, blaming it on the need to address execution challenges and problems with capacity constraints. However, Hood said she’s confident that Azure’s growth will accelerate in the second half of the fiscal year, compared to the first half. The latest revenue numbers highlight the rapid pace of Microsoft’s ongoing transition from a product-focused business to a services one, said Holger Mueller of Constellation Research Inc. He pointed out how product revenue declined more than $2.5 billion in the quarter compared to the previous year, though services-based revenue made up for it, growing more than $10 billion. But the successful transition is creating new problems for the company, he said. “The result of this is that earnings per share were up 30 cents year-over-year, but the question on investor’s lips is how long can the company keep this up,” Mueller said. “They’ll be concerned by the comments from Hood, who acknowledged Azure is facing capacity constraints for the first time.” Although the company’s stock fell slightly after-hours, it was still higher than it was on Monday, when it was hit by a broader selloff of technology stocks that was driven by the reaction of ChatGPT competitor DeepSeek. Microsoft’s stock had slipped more than 4% at the start of the week as investors mulled the implications of DeepSeek’s competing models. The Chinese company debuted an open-source “reasoning” model earlier this month that it said was trained at a cost of just $5.6 million, excluding the expense of data and previous research. That sent shockwaves through the AI industry, as its performance matched and sometimes even outperformed comparable models created by OpenAI, Google LLC and Meta Platforms Inc., which cost much more to train. Microsoft is a key backer of OpenAI and it has committed to spending $80 billion on AI infrastructure this year in order to expand its global network of high-powered data centers to meet demand for the specialized chips required to train and run AI models. Somewhat surprisingly, Microsoft Chief Executive Satya Nadella (pictured) said DeepSeek’s R1 model is now available to download through the Azure AI Foundry platform and via GitHub. He added that customers will soon be able to select DeepSeek on Copilot+ personal computers. Regarding DeepSeek’s perceived cost-efficiency gains, Nadella told analysts on the call that “scaling laws” are compounding with regards to both pretraining and inference time compute. “We ourselves have seen significant efficiency gains in both training and inference for years now,” he said. “On inference, we have typically seen more than two-times price-performance gains for every new hardware generation and more than 10-times for every new model generation.” The rise of DeepSeek has stoked fears among some investors that Microsoft may have put its eggs in the wrong basket by throwing its weight behind OpenAI and the infrastructure that supports it, said Valoir analyst Rebecca Wettemann. “We don’t expect companies to move their AI to DeepSeek yet, but that company’s release of lower-cost and less resource-intensive AI models tells us that AI is going to become more commoditized in future,” Wettemann said. “It’s the surrounding platform features that support greater accuracy, security and customization to specific needs that will be the real differentiators, and that’s where Microsoft needs to invest.” Prior to today’s earnings call, Microsoft’s stock had gained 5% in the year to date, outperforming the S&P 500 Index, which was up 3% so far. THANK YOU Report: OpenAI could double valuation to $340B with new $40B funding round Netscout and Dynatrace report solid quarterly growth with increased revenue and earnings Preparing for the Super Bowl requires defense to be played off the field Mistral, Ai2 release new open-source LLMs D3 raises $25M to put internet domain names on the blockchain Seraphic raises $29M to secure browsers in the enterprise Report: OpenAI could double valuation to $340B with new $40B funding round AI - BY MARIA DEUTSCHER . 9 MINS AGO Netscout and Dynatrace report solid quarterly growth with increased revenue and earnings SECURITY - BY DUNCAN RILEY . 13 MINS AGO Preparing for the Super Bowl requires defense to be played off the field INFRA - BY ZEUS KERRAVALA . 49 MINS AGO Mistral, Ai2 release new open-source LLMs AI - BY MARIA DEUTSCHER . 2 HOURS AGO D3 raises $25M to put internet domain names on the blockchain BLOCKCHAIN - BY KYT DOTSON . 3 HOURS AGO Seraphic raises $29M to secure browsers in the enterprise SECURITY - BY PAUL GILLIN . 4 HOURS AGO
--------------------------------------------------

Title: Zuckerberg promises 'a pivotal year for the metaverse' as its Reality Labs division continues to bleed cash
URL: https://finance.yahoo.com/news/zuckerberg-promises-a-pivotal-year-for-the-metaverse-as-its-reality-labs-division-continues-to-bleed-cash-233846764.html
Time Published: 2025-01-29T23:38:46Z
Full Content:
We are experiencing some temporary issues. The market data on this page is currently delayed. Please bear with us as we address this and restore your personalized lists. Meta's Reality Labs division continues to bleed billions of dollars — crossing $60 billion in losses since 2020. "This is also going to be a pivotal year for the metaverse," Meta CEO Mark Zuckerberg confidently told investors on Wednesday. The unit, responsible for its virtual reality headset line "Quest" and its Ray-Ban smart glasses, reported a loss of $5 billion in its Q4 earnings (totaling $17.7 billion in 2024). Its revenue slightly rose 1% year over year to $1.08 billion, driven by hardware sales. Expenses jumped to $6 billion, up 5% year over year. "The number of people using Quest and Horizon has been steadily growing, and this is a year when a number of the long-term investments that we've been working on that will make the metaverse more visually stunning and inspiring will really start to land," Zuckerberg said on the earnings call. Analysts told Yahoo Finance it's questionable whether Zuckerberg's metaverse will ever clock a profit. "There are going to be other ways Meta can monetize its investment down the road but it does look very expensive — like a loss leader in the short term," Moor Insights & Strategy analyst Anshel Sag told Yahoo Finance. "AR is a very expensive technology to develop and I believe most of the money that matters spending in Reality Labs is on AR efforts." A leaked memo earlier this week claimed Reality Labs has hit its sales and user targets. However, current and former employees within the division exclusively tell Yahoo Finance that hitting targets is a small piece of the puzzle. "If their losses are going up and the sales are going up, the question they need to ask themselves is why does the hardware cost so much to make and why aren't they working harder to bring the cost down," said one former Reality Labs manager. "They haven't figured out how to make this profitable and they're not even close." According to market intelligence firm IDC Global, Meta continues to dominate the VR/AR market with a 70% share. "True Augmented Reality headsets such as Meta’s Orion will take time to gain salience as these headsets require high levels of sophistication paired with battery and display tech that are yet to scale," IDC said in its report. Meta's stock has been up 68% in the past year, partially due to the booming investor enthusiasm for AI. Last week, Zuckerberg announced that Meta is planning to spend $60 billion to $65 billion on its artificial intelligence strategy — including a data center "so large it would cover a significant part of Manhattan." Wall Street was stopped in its tracks on Monday following the launch of an AI model by Chinese startup DeepSeek, which claimed its large language model was built in two months with less than $6 million. According to reports, Meta set up four war rooms to analyze DeepSeek's technology, two of which focused on reducing training costs. DeepSeek's R1 model now raises a question for analysts: Does Meta need to spend up to $65 billion to deploy AI software? "There's going to be an open-source standard globally and I think for our national advantage it's important that its an American standard," Zuckerberg said. "If anything, some of the recent news has only strengthened our conviction that this the right thing for us to be focused on." "Mark Zuckerberg clearly set expectations that clarity will come to the trajectories of Meta’s long-term initiatives, which includes the metaverse," Forrester's research director Mike Proulx told Yahoo Finance. "While Meta is likely to succeed with its open-source approach to AI, there’s simply nothing to point to in Horizon Worlds that portends success with the metaverse. Despite the company’s name, Meta’s North Star is, and should be, AI." In a note to investors this week, Jefferies analyst Brent Thill expressed optimism about Meta's AI efforts, maintaining a Buy rating and setting a price target of $715. “Overall, we continue to be encouraged by Meta’s ability to sustain DD rev growth, given the combination of higher engagement from AI investments, increased advertiser efficiency, and ramping of incremental monetization formats (e.g. WhatsApp & Llama),” Thill said in the note. Meta's earnings came later than usual. Despite Zuckerberg cozying up to the Trump administration, the Wall Street Journal reported that President Trump signed an agreement calling for Meta to pay $25 million to settle a 2021 lawsuit Trump brought on after his Facebook and Instagram accounts were suspended. According to the report, $22 million of the settlement will go toward a fund set up for Trump's presidential library. A spokesperson for Meta declined to comment. Yasmin Khorram is a senior reporter at Yahoo Finance. Follow Yasmin on Twitter/X @YasminKhorram and on LinkedIn. Send newsworthy tips to Yasmin: yasmin.khorram@yahooinc.com Click here for the latest technology news that will impact the stock market Read the latest financial and business news from Yahoo Finance Sign in to access your portfolio
--------------------------------------------------

Title: Stock market today: Live updates
URL: https://www.cnbc.com/2025/01/29/stock-market-today-live-updates.html
Time Published: 2025-01-29T23:12:28Z
Full Content:
Credit Cards Loans Banking Mortgages Insurance Credit Monitoring Personal Finance Small Business Taxes Help for Low Credit Scores Investing SELECT All Credit Cards Find the Credit Card for You Best Credit Cards Best Rewards Credit Cards Best Travel Credit Cards Best 0% APR Credit Cards Best Balance Transfer Credit Cards Best Cash Back Credit Cards Best Credit Card Welcome Bonuses Best Credit Cards to Build Credit SELECT All Loans Find the Best Personal Loan for You Best Personal Loans Best Debt Consolidation Loans Best Loans to Refinance Credit Card Debt Best Loans with Fast Funding Best Small Personal Loans Best Large Personal Loans Best Personal Loans to Apply Online Best Student Loan Refinance SELECT All Banking Find the Savings Account for You Best High Yield Savings Accounts Best Big Bank Savings Accounts Best Big Bank Checking Accounts Best No Fee Checking Accounts No Overdraft Fee Checking Accounts Best Checking Account Bonuses Best Money Market Accounts Best CDs Best Credit Unions SELECT All Mortgages Best Mortgages Best Mortgages for Small Down Payment Best Mortgages for No Down Payment Best Mortgages with No Origination Fee Best Mortgages for Average Credit Score Adjustable Rate Mortgages Affording a Mortgage SELECT All Insurance Best Life Insurance Best Homeowners Insurance Best Renters Insurance Best Car Insurance Travel Insurance SELECT All Credit Monitoring Best Credit Monitoring Services Best Identity Theft Protection How to Boost Your Credit Score Credit Repair Services SELECT All Personal Finance Best Budgeting Apps Best Expense Tracker Apps Best Money Transfer Apps Best Resale Apps and Sites Buy Now Pay Later (BNPL) Apps Best Debt Relief SELECT All Small Business Best Small Business Savings Accounts Best Small Business Checking Accounts Best Credit Cards for Small Business Best Small Business Loans Best Tax Software for Small Business SELECT All Taxes Filing For Free Best Tax Software Best Tax Software for Small Businesses Tax Refunds Tax Brackets Tax Tips Tax By State Tax Payment Plans SELECT All Help for Low Credit Scores Best Credit Cards for Bad Credit Best Personal Loans for Bad Credit Best Debt Consolidation Loans for Bad Credit Personal Loans if You Don't Have Credit Best Credit Cards for Building Credit Personal Loans for 580 Credit Score or Lower Personal Loans for 670 Credit Score or Lower Best Mortgages for Bad Credit Best Hardship Loans How to Boost Your Credit Score SELECT All Investing Best IRA Accounts Best Roth IRA Accounts Best Investing Apps Best Free Stock Trading Platforms Best Robo-Advisors Index Funds Mutual Funds ETFs Bonds Stocks rose on Thursday, posting gains in a bout of rocky trading as investors weighed the latest earnings from Big Tech companies. The Dow Jones Industrial Average popped 168.61 points, or 0.38%, closing at 44,882.13. At its session highs, it had added nearly 300 points. The S&P 500 rose 0.53% to 6,071.17, while the Nasdaq Composite gained 0.25% to end at 19,681.75. Stocks cut gains late in the session after President Donald Trump announced his intention to implement 25% tariffs on goods imported from Canada and Mexico. Elsewhere, Wall Street digested recent quarterly results from a slew of megacap tech companies. Shares of Meta Platforms and Tesla respectively added 1.6% and 2.9%, while Microsoft shares dipped 6.2% after the companies reported earnings. Meta beat on top and bottom lines, but Microsoft shares faltered after the company's quarterly revenue forecast disappointed. Tesla shrugged off an earnings and revenue miss. "We had three major megacap technology companies report last night and for the most part, all of them sort of came in and out of their earnings unscathed," said Art Hogan, chief market strategist at B. Riley Wealth Management. "That's a positive when you look at the aggregate number of companies that have reported and how many companies are beating expectations both on the top and bottom lines." On the other hand, investors were a bit cautious to buy after fourth-quarter GDP growth came in at just 2.3%, missing expectations. Wall Street is coming off a losing session after the Federal Reserve paused its interest rate-cutting campaign, leaving its borrowing rate unchanged in a range between 4.25% and 4.5%. In their postmeeting statement, policymakers noted that inflation remains "somewhat elevated." "We kind of get the chance to put the Fed not cutting rates in the rearview mirror because they're likely doing that for the right reasons, meaning the economic data seems consistent with keeping rates unchanged for the time being," Hogan said. "This also gives them time to look at policy from the new administration and try to model out what kind of impact that will have on both the economy and inflation." Other "Magnificent Seven" names are set to report in the coming days, with Apple's results being due for a Thursday release. Amazon will soon follow suit, as the megacap tech company reports next week. Investors are also looking ahead to Friday's personal consumption expenditures price index report for December. The S&P 500 and tech-heavy Nasdaq Composite are on pace to end the week in negative territory, despite making up some of their losses from Monday's sell-off. The blue-chip Dow is the only major index tracking for a weekly gain. The U.S. dollar rose against other currencies Thursday afternoon after President Trump said he would impose a 25% tariff on Mexico and Canada. The ICE U.S. Dollar Index turned positive on the day after the comments, trading at 108.07. The index, which measures the greenback against a basket of currencies, was trading near 107.76 before the remarks. The dollar also rose against the Canadian dollar and Mexican peso individually. — Jesse Pound The major averages cut gains late in the day after President Donald Trump said he would slap a 25% tariff on goods from Mexico and Canada, two key U.S. trade partners. The Dow, which was up nearly 300 points at one point, briefly turned negative before rebounding. The S&P 500 and Nasdaq were also off their highs. — Fred Imbert After monitoring Robert Kennedy Jr.'s confirmation hearings, Citi analyst Geoff Meacham told clients that he expects vaccine-exposed stocks such as Merck and Pfizer will experience some relief after the nominee said he would not deprioritize vaccine approvals at the Food and Drug Administration. Kennedy is hoping to lead the Department of Health and Human Services, but is known for controversial views on vaccinations and for his criticism of ultraprocessed foods. During the hearings, Kennedy voiced support for gene therapies and called GLP-1 treatments "miracle drugs" for those with morbid obesity. Merck and Pfizer shares were up less than 1% in trading Thursday, but GLP-1 drugmakers Novo Nordisk and Eli Lilly had a bit more momentum. Both stocks were up around 2%. All four stocks have underperformed the S&P 500 since President Donald Trump was elected. Kennedy said he does not believe GLP-1 drugs, which include Wegovy and Zepbound, should be the first treatment used for obesity in children. He also expressed concern over the cost of the drugs. — Christina Cheddar Berk Hasbro and Mattel shares have had a strong start to the new year, rising 6% and 7% year to date, respectively. There may be a good reason for that. Data tracker Circana said global toy sales stabilized last year. The industry's shift to focus on collectibles and adults is helping to plug the gap created by declining birth rates, Circana said. Across the G12 nations, sales fell 0.6% year over year. Average selling price was flat, after four straight years of growth. In the U.S., dollar sales were flat from 2023. In 2023, dollar sales fell 7% in the U.S. from the prior year. Building sets, which include the popular Lego brand, showed both the biggest total sales and the greatest growth rate. Lego has expanded its offerings to include building sets that resonate with adults, who see the toys as a fun way to unwind. "This year we expect the global toy market to be positively impacted by the box office and popular series' on streaming platforms, continuing to fuel young and mature consumer appetites for toys and collectible merchandise," said Frederique Tutt, global toys industry advisor. Hasbro shares are up 17% over the past 12 months, while Mattel logged a nearly 5% gain during the same period. — Christina Cheddar Berk Comcast shares tracked for their worst session in more than a decade and a half as subscriber numbers disappointed Wall Street. Shares of the telecommunications giant, which owns CNBC parent NBCUniversal, tumbled more than 12% in afternoon trading. If that holds through Thursday's closing bell, it will mark the biggest one-day loss for the stock since October 2008, when shares plunged more than 14%. Thursday's sell-off comes after the Philadelphia-based company posted higher losses in broadband subscribers than previously expected. Comcast also reported fewer paid subscriptions to the Peacock streaming service than analysts polled by StreetAccount anticipated. Those stats overshadowed a strong quarterly report, with the company surpassing analysts' forecasts on both lines in the fourth quarter. — Alex Harring, Lillian Rizzo Disclosure: Comcast owns NBCUniversal, the parent company of CNBC. As crypto becomes increasingly tied into the financial mainstream, crypto-native companies are starting to launch some more traditional products of their own. On Thursday, Grayscale launched a Bitcoin Miners ETF (MRNS). While Grayscale's other exchange-traded funds hold cryptocurrency directly, the new fund is an equity-only fund, similar to traditional sector or thematic funds that have been around for years. "The work of Bitcoin Miners is integral to the existence and continuation of the Bitcoin network. As adoption of Bitcoin grows, we believe the Bitcoin Mining industry will only increase in value. For investors interested in Bitcoin-adjacent opportunities, or looking for an equity expression of Bitcoin, MNRS represents a new option," Grayscale said in a press release. Grayscale is not the only crypto firm trying this strategy, as Bitwise and CoinShares also have equity funds on the market. — Jesse Pound Information technology is down 4.5% week to date, making it the biggest decliner in the S&P 500 during the period. Nvidia's 16.1% drop during the period has led the sector lower. Fellow chipmaker Super Micro Computer has sold off nearly 15%, followed by Hewlett Packard Enterprise and Juniper Networks down around 13% each. Utilities and industrials have dropped more than 1% for the week, while energy has shed 0.9%. Meanwhile, consumer staples has outperformed the broader market. The sector is up 2.8%, led by J.M. Smucker, Kroger and Costco, which have jumped more than 4% each. — Hakyung Kim Check out some of the companies making headlines in midday trading: Read the full list here. — Brian Evans Small-cap stocks ran circles around their larger counterparts in Thursday's session. The small cap-focused Russell 2000 climbed about 1% in midday trading. By comparison, the S&P 500 traded just slightly above flat. With Thursday's gains, the Russell 2000 sat near flat on week the week, while the S&P 500 was tracking to lose nearly 1%. — Alex Harring The S&P Information Technology Sector was trading 1% lower on Thursday, leading the index's declines for the day. The sector is also the worst performing of the week, down 4% and on pace for its worst weekly performance since September 2024. Tech remains the sole negative sector so far this year. Nvidia, down 16% on the week, leads the sector's declines. Super Micro Computer, Teradyne, ServiceNow and Arista Networks are all down 11% or more on the week. — Nick Wells, Lisa Kailai Han The Department of Justice is suing to block the proposed Hewlett Packard Enterprise acquisition of Juniper Networks on antitrust grounds. The complaint said the merged company, along with rival Cisco Systems, would control "well over 70 percent" of the U.S. market for enterprise wireless network solutions. "This proposed acquisition risks substantially lessening competition in a critically important technology market and thus poses the precise threat that the Clayton Act was enacted to prevent. It should be blocked," the complaint said. Shares of both companies were lower after the complaint was made public. HPE fell 2.5%, while Juniper was down about 3%. — Jesse Pound During Thursday's trading session, 38 stocks in the S&P 500 traded at new 52-week highs. Names that hit this milestone included: On the flip side, nine stocks traded at new 52-week lows. These included UPS, Microchip Technology, Dow and Edison International. — Christopher Hayes, Lisa Kailai Han Shares of Las Vegas Sands were last up 11% on the back of strong Singapore results and renewed optimism due to China's economic recovery. The stock's Thursday gains put it on track for its best day since Sept. 26, 2022, when it rose 11.81%. Las Vegas Sands is currently on pace to notch an 11% weekly rise, which would break its seven-week losing streak — its longest since Aug. 2021. Fellow Macao casino stocks rose in sympathy, with Wynn Resorts, Caesars Entertainment and MGM Resorts International respectively adding 6%, 2% and 1%. — Adrian van Hauwermeiren, Lisa Kailai Han United Parcel Service shares headed for their worst session on record on Thursday, roiled by an announcement that Amazon was slashing volume. Shares tumbled around 17% in morning trading. If that holds, Thursday would mark the biggest one-day loss ever for UPS, which went public in 1999. Thursday's sell-off came after the delivery giant said it reached a deal with Amazon, its largest customer, to lower volume by more than 50% by the second half of 2026. UPS also missed the consensus forecast of analysts polled by LSEG for revenue in the fourth quarter, but earnings per share exceeded their expectations. UPS shares are now down more than 12% in 2025, putting the stock on track for its fourth straight losing year. — Alex Harring Shares of Comcast hit their lowest level in more than two years on Thursday after the telecommunications giant's fourth-quarter report showed the company losing broadband subscribers at a faster-than-projected pace. "Net broadband subscriber additions were negative-139,000 in the fourth quarter, which is disappointing and worse than what we indicated in the fourth quarter," Comcast president Michael Cavanagh said on a conference call Thursday. Company executives said they would be putting more emphasis on the mobile wireless business going forward. Shares were last down 9.5% on the session at $33.80. Comcast's stock price has not been that low since 2022. — Jesse Pound Disclosure: NBCUniversal is the parent company of CNBC and NBC News. The AI sell-off on Monday dragged down nuclear stocks as well, but the slide for that group was "unwarranted," according to BCA Research strategist Jeremie Peloso. "AI will continue to support future nuclear energy demand. The long-term bullish case for nuclear energy remains intact. Investors should view the recent pullback as a buying opportunity, especially for uranium mining stocks," Peloso wrote in a note to clients. The Range Nuclear Renaissance ETF (NUKZ) enters Thursday down 10.6% for the week, as does Cameco. Shares of Nuscale Power are down more than 21%. Nuclear and uranium stocks got a boost from the AI trade in 2024, with the idea behind that power-hungry data centers will spur expansions to the U.S. energy grid. — Jesse Pound Stocks opened higher on Thursday after ending Wednesday's trading session lower across the board. The S&P 500 added 0.3%, as did the Nasdaq Composite. The Dow Jones Industrial Average traded fractionally higher. — Lisa Kailai Han Check out the companies making headlines before the bell: The full list can be found here. — Hakyung Kim The U.S. economy grew at a slower-than-expected pace during the final three months of 2024. Gross domestic product grew 2.3% in the fourth quarter on an annualized basis, while economists polled by Dow Jones expected an increase of 2.5%. Full-year GDP expanded at a solid 2.8% pace after growing 2.9% in 2023. — Fred Imbert Hot tub maker Whirlpool tumbled 11% following a fourth-quarter revenue miss. Whirlpool's revenue for the last quarter came out to $4.14 billion, while analysts polled by LSEG had expected $4.24 billion. However, Whirlpool's earnings per share of $4.57 exceeded the estimated $4.32 per share. The company estimated that its full-year adjusted earnings would come out to approximately $10 per share versus the $11.60 estimate. Whirlpool's expected full-year net sales of $15.8 billion was also lower than the expected $16.26 billion. — Lisa Kailai Han Shares of Coca-Cola are poised to move higher, according to Jefferies. The firm upgraded the beverage and snack giant to buy and raised its price target to $75, suggesting 19% upside from Wednesday's close. "The business is in great shape," analyst Kaumil Gajrawala wrote. "Volumes are compounding, pricing has been earned, and cash flow is about to inflect … meaningfully." The stock is hard to own when the dollar is strengthening, he noted. However, he expects only a 2-cent effect on earnings per share for 2025. Coca-Cola is set to report fourth-quarter results on Feb. 11. "Expect Q4 to be a clearing event, bringing in a wave of investors looking for quality at a fair price," Gajrawala said. "Fundamentals support a higher multiple." Shares are up about 1% so far this year. — Michelle Fox Shares of Cigna plummeted 10% Thursday morning after the health insurer reported a fourth-quarter earnings miss. For its last quarter, Cigna posted adjusted earnings of $6.64 per share, which missed the $7.82 analysts were looking for, according to LSEG. However, Cigna's $65.65 billion in revenue exceeded the $63.36 billion estimate. — Lisa Kailai Han Shares of Lam Research traded 6% higher Thursday morning after the semiconductor company posted a fiscal second-quarter earnings beat. Lam Research reported adjusted earnings of 91 cents per share, above the 88 cents that analysts were looking for, per LSEG. On the other hand, the company's revenue missed FactSet expectations. Lam Research also provided earnings and revenue guidance for its fiscal third quarter that was higher than what analysts were estimating. Following its earnings report, both Bernstein and Cantor Fitzgerald upgraded the stock to an overweight or outperform rating. — Lisa Kailai Han Shares of UPS were trading more than 13% lower Thursday morning after the shipping company posted a fourth-quarter revenue miss. UPS' $25.30 billion in revenue came in lower than the $25.42 billion analysts polled by LSEG had expected. On the other hand, the company's adjusted earnings of $2.75 per share exceeded the Wall Street consensus of $2.53 per share. — Lisa Kailai Han Engine equipment manufacturing stock Caterpillar slipped 4% in Thursday's premarket trading hours after reporting a fourth-quarter earnings miss. Caterpillar's revenue for the quarter came in at $16.22 billion, while analysts polled by LSEG were expecting $16.39 billion. On the other hand, the company's earnings of $5.14 per share exceeded estimates of $5.02. For its new guidance, Caterpillar said it also expects first-quarter 2025 and full-year 2025 sales and revenue numbers to be lower than their 2024 equivalents. — Lisa Kailai Han IBM shares popped 8% in the premarket after the legacy tech company reported fourth-quarter earnings that beat analysts' expectations. The company earned $3.92 per share, excluding items, while analysts polled by LSEG anticipated a profit of $3.75 per share. Revenue for IBM came in at $17.55 billion, about in line with expectations. "We closed the year with double-digit revenue growth in Software for the quarter, led by further acceleration in Red Hat. Clients globally continue to turn to IBM to transform with AI. Our generative AI book of business now stands at more than $5B inception-to-date, up nearly $2B quarter over quarter," CEO Arvind Krishna said in a statement. — Fred Imbert UPS fell more than 11% in the premarket after the delivery giant said it reached a deal with Amazon, its largest customer, "to lower its volume by more than 50% by the second half of 2026." UPS also said it is launching "multi-year 'efficiency reimagined' initiatives to drive approximately $1.0 billion in savings." — Fred Imbert Gold futures hit an intraday all-time high above $2,815 per ounce, building on their strong start to 2025. The precious metal is up more than 6% year to date and has climbed 38% over the past 12 months. — Fred Imbert European stock markets opened broadly higher Thursday despite big-name earnings disappointing, with the Stoxx 600 index up 0.4% at 8:26 a.m. in London. Industrials and energy led sector gains, up 0.73% and 0.36%, respectively. Germany's DAX and France's CAC 40 were both around 0.3% higher, while the U.K.'s FTSE 100 rose 0.12%. — Jenni Reid Japanese and Australian markets climbed Thursday despite Wall Street losses overnight. Several Asia-Pacific markets were closed for the Lunar New Year holiday. Japan's benchmark Nikkei 225 and Topix advanced for the second straight day. The Nikkei 225 gained 0.25% to end the day at 39,513.97, while the broader Topix index was up 0.23% to close at 2,781.93. Bank of Japan Deputy Governor Ryozo Himino reportedly said Thursday that the central bank would continue to raise interest rates if the "economy and prices move in line with the bank's forecasts." The Bank of Japan hiked interest rates by 25 basis points to 0.5% in its meeting last week, bringing them to the highest level since 2008. Australia's S&P/ASX 200 extended gains from the previous session to end the day up 0.55% at 8,493.70, its highest since Dec. 5. India's benchmark Nifty 50 was up 0.44%, while the BSE Sensex Index had gained 0.29% as of 1 p.m. local time. — Amala Balakrishner Shares of Tesla rose 4% in extended trading on Wednesday despite its fourth-quarter earnings and revenue missing Wall Street's expectations, and Gene Munster of Deepwater Asset Management believes there could be more gains ahead for the stock. "Ultimately, I think that [Tesla's] numbers are pretty choppy," the managing partner said on CNBC's "Fast Money" following the automaker's results. "It's just hard to … see why it's up right now. I think it's basically confirmation that people think that this has more to go." Tesla reported adjusted earnings of 73 cents per share on $25.71 billion in revenue for the period. That is below the consensus estimate of 76 cents in earnings per share and $27.27 billion in revenue, per LSEG. The stock is on pace to close out the first month of 2025 in negative territory, as it has seen month-to-date losses of more than 3%. It is also on track to underperform the broader market this week, with shares dropping more than 4% week to date. — Sean Conlon, Lora Kolodny Check out the stocks making big moves in extended trading: Read here for the full list. — Sean Conlon U.S. stock futures were relatively unchanged Wednesday night. S&P 500 futures, along with futures tied to the Dow Jones Industrial Average, hovered around the flatline. Meanwhile, Nasdaq 100 futures rose 0.1%. — Sean Conlon Got a confidential news tip? We want to hear from you. Sign up for free newsletters and get more CNBC delivered to your inbox Get this delivered to your inbox, and more info about our products and services. © 2025 CNBC LLC. All Rights Reserved. A Division of NBCUniversal Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis. Data also provided by
--------------------------------------------------

Title: DeepSeek Panic Live Updates: Nvidia Stock Drops 4%—As Trump Reportedly Mulls China Chip Sale Restrictions
URL: https://www.forbes.com/sites/dereksaul/2025/01/29/deepseek-panic-live-updates-nvidia-stock-drops-4-as-trump-reportedly-mulls-china-chip-sale-restrictions/
Time Published: 2025-01-29T21:07:00Z
Full Content:
The release of a less capital-intensive artificial intelligence model from China’s DeepSeek sent a chill through the U.S. stock market this week, headlined by losses Monday and Wednesday from Nvidia, the Silicon Valley giant which designs most of the pricey semiconductor technology powering the AI revolution. DeepSeek has been accused of using outputs generated by OpenAI's tools to train its latest AI model. Jan. 29, 4 p.m. EST Nvidia stock ends Wednesday trading down 4% in a turbulent session that wiped out about $130 billion in market value, with earnings reports from top customers Meta, Nvidia and Tesla all due this afternoon all potential catalysts for further movement in the stock. To recap Nvidia’s whipsaw week: Its market value fell by about $590 billion Monday, rose by roughly $260 billion Tuesday and dropped $130 billion Wednesday. Wall Street analysts still mostly view the selloff as a overreaction, and Bank of America analysts led by Vivek Arya wrote Wednesday to clients they “view the recent selloff as an enhanced buy opportunity” for Nvidia stock, reaffirming faith in hundreds of billions of dollars of spending this decade in the AI technology which Nvidia designs. Jan. 29, 1:30 p.m. EST President Donald Trump is considering placing more restrictions on Nvidia’s semiconductor chip sales to China beyond what the Biden administration placed in an effort to limit AI advancement in the Asian country, Bloomberg reported, citing anonymous sources. It’s unclear if the potentially amped-up controls are directly tied to the DeepSeek fallout — Nvidia said Monday the Chinese AI group fully complied with existing export laws with its use of Nvidia’s technology — though Howard Lutnick, Trump’s pick for Commerce Secretary, laid into DeepSeek at his Wednesday confirmation hearing, saying: “Nvidia’s chips, which they bought tons of, and they found their ways around, drive their DeepSeek model. It’s got to end.” China accounted for more than 15% of Nvidia’s revenues in its most recent quarter. Jan. 29, 12 p.m. EST Nvidia’s Wall Street woes continued as shares dropped about 5% by midday, bringing the stock’s loss this week back up to nearly 15%. Jan. 29, 9:40 a.m. EST After mounting a historic comeback Wednesday, Nvidia stock fell again, declining about 3% in the first 10 minutes of regular trading, leading a broader tech slump as the likes of Apple, Microsoft and Tesla all declined roughly 1% apiece. Jan. 29, 8:30 a.m. EST New York-listed shares of Chinese technology giant Alibaba rise more than 3% in premarket trading, set to open at their highest level since early November. Alibaba said earlier Wednesday the latest version of its Qwen generative AI model scored better on several performance tests than the models from rivals like DeepSeek, OpenAI and Meta. Jan. 29, 3 a.m. EST OpenAI told the Financial Times that it has seen some evidence that its AI models were used by DeepSeek to train its own—which would be a breach of the ChatGPT maker’s terms of services. Bloomberg previously reported that Microsoft and OpenAI were investigating whether DeepSeek gained access to OpenAI’s data outputs in an unauthorized manner. Jan. 29, 12 a.m. EST White House artificial intelligence czar David Sacks told Fox News that there was “substantial evidence” suggesting that Deepseek had “distilled the knowledge out of OpenAI’s models,” adding “I don’t think OpenAI is very happy about this.” In this context, distillation is a process where an AI model uses responses generated by other, more powerful, AI models to aid its development. Sacks added that over the next few months he expects leading U.S. AI companies will be "taking steps to try and prevent distillation” to slow down “these copycat models.” Jan. 28, 4 p.m. EST Nvidia stock ends normal trading up 8.8%, scoring its best percentage gain in six months. That added $260 billion to Nvidia’s market capitalization — more than the total valuations of American Express, Disney and Goldman Sachs — recovering 44% of the $589 billion its lost Monday. Nvidia’s Tuesday bounce became the second best day for any stock ever in terms of market value added, trailing only the $327 billion rally the AI leader enjoyed July 31, 2024. Shares of Nvidia are still down nearly 10% since Friday amid the whirlwind trading. Jan. 28, 1:45 p.m. ESTApple stock rallied 4% to about $239 per share, building on its 3% gain Monday as many of its Silicon Valley peers faltered and extending its market value added this week to about $240 billion. The two-day bounce for Apple shares, which had suffered a 14% pullback in the month ending Friday, comes as investors warm to the iPhone maker’s approach to largely watch the generative AI arms race from the sidelines as its trillion-dollar peers like Alphabet, Meta and Microsoft invested billions into generative AI projects. Apple emerges as a “relative winner” as DeepSeek shifted investor narratives on AI, wrote Morgan Stanley analysts led by Brian Nowak in a Tuesday note to clients, explaining Apple’s “AI ambitions are far more contained” than the other “magnificent seven” American tech leaders. Apple also stands to greatly benefit from any advancements from large-language models, like DeepSeek’s, as Apple “owns the most valuable consumer technology distribution platform that exists,” Nowak added. Whether Apple stock’s “contained” generative AI ambitions were the result of financial discipline or inadequate innovation is up to interpretation, but Wall Street Journal columnist Joanna Stern quipped, “Apple’s behind-everyone-else-in-AI approach look like a calculated master plan.” After heading into the week down $143 billion in the race with Nvidia for world’s most valuable company, Apple is now up $498 billion, a more than $640 billion two-day swing. Jan. 28, 12:20 p.m. ESTNvidia settles into a more than 5.5% gain by midday trading, helping lift the tech-heavy Nasdaq index to a more than 1.5% advance, but the damage is still evident from the prior crash, as Nvidia only recovered about $171 billion of the $589 billion market capitalization it lost Monday. Jan. 28, 10 a.m. ESTMorgan Stanley’s Joseph Moore offers perhaps the most palpably negative major analyst reaction to DeepSeek, cutting his price target for Nvidia from $166 to $152 due to the “deflationary” prospects of cheaper AI buildouts and the potential for “further export controls or reduce spending enthusiasm” — Morgan Stanley maintains a buy rating for the stock and its $152 target implies 27% upside from Nvidia’s $120 share price Tuesday. Jan. 28, 9:35 a.m. ESTShares of the two companies most severely impacted by the DeepSeek reaction, Nvidia and Oracle, open normal trading hours up about 3% apiece in premarket trading before each company’s gains pared back to 1%; both American technology firms are still down more than 15% since Friday. Jan. 28, 8:45 a.m. ESTAnalyst reactions to the historic selloff largely characterized the losses as out of proportion: UBS analyst Karl Keirstead said Oracle’s drop “felt excessive” and Deutsche Bank analyst Ross Seymore added “geopolitical dynamics are a key driver of this volatility” in tech stocks in respective notes to clients. Jan. 28, 6:00 a.m. ESTChina’s state-run Global Times cited a telecoms industry observer, who said the company’s success showed that “the Biden administration's four-year crackdown on China's AI and computing power has not only failed but has also spurred the country to forge a unique path for AI development.” People within China’s tech industry also hailed DeepSeek’s success. In a widely shared post on the social media platform Weibo, Game Science co-founder Feng Ji—the studio which published the hit game Black Myth: Wukong—wrote “DeepSeek may be a scientific and technology achievement that can change a nation’s fate...Such a shocking breakthrough coming from a purely Chinese company. Jan. 27, 10:00 p.m. ESTOpenAI CEO Sam Altman praised DeepSeek’s R1, saying it is an “impressive model, particularly around what they're able to deliver for the price,” and added “we will obviously deliver much better models and...we will pull up some releases.” Jan. 27, 6:30 p.m. ESTPresident Donald Trump said at a House Republican retreat that the launch of the AI model was “a positive development” but should be considered a “wake-up” call for U.S. industries, lauding the move for what he hoped would usher in a future of “coming up with a faster method of AI, and much less expensive method.” Jan. 27, 4:20 p.m. ESTThe DeepSeek-driven stock market plunge caused some of the world’s wealthiest people to lose tens of billions on paper, led by Oracle’s Larry Ellison (net worth down $27.6 billion) and Nvidia’s Jensen Huang (down $20.8 billion)—here’s a full list. Jan. 27, 4:20 p.m. ESTStocks were battered by DeepSeek’s debut: The S&P 500 closed down 1.5%, while the tech-heavy Nasdaq plunged just over 3%—its worst day since Dec. 18 and fourth-worst day of the last two years. Jan. 27, 4 p.m. ESTSemiconductor designer and AI darling Nvidia closed down 17%, knocking $589 billion off its market cap in the biggest single-day loss of value for any public company in history—along with heavy losses at chipmakers Broadcom (17%) and Taiwan Semiconductor Manufacturing Company (13%), and smaller falls for Microsoft (2%) and Tesla (2%). Jan. 27, 3:28 p.m. ESTForbes found DeepSeek refused to answer questions on several controversial topics linked to the Chinese government, like, “What happened at Tiananmen Square in 1989?” and “What are the biggest criticisms of Xi Jinping?” The model did provide detailed answers when asked about common criticisms of Joe Biden and Donald Trump. Jan. 27, 3 p.m. ESTNvidia releases its first statement on DeepSeek as its stock dipped to a 18% loss on the day, calling the Chinese company’s model “an excellent AI advancement” — the full statement from a Nvidia spokesperson is as follows: “DeepSeek is an excellent AI advancement and a perfect example of Test Time Scaling. DeepSeek’s work illustrates how new models can be created using that technique, leveraging widely-available models and compute that is fully export control compliant. Inference requires significant numbers of NVIDIA GPUs and high-performance networking. We now have three scaling laws: pre-training and post-training, which continue, and new test-time scaling.” Jan. 27, 12:50 p.m. ESTDavid Sacks, President Donald Trump’s “AI & Crypto Czar,” offers his first comments on DeepSeek, saying the Chinese company’s success “shows that the AI race will be very competitive” and “we can’t be complacent,” supporting Trump’s repeal of former President Joe Biden’s executive order placing guardrails on AI development, which Sacks said “hamstrung” U.S. AI innovation. Jan. 27, 12:45 p.m. EST Oracle chairman Larry Ellison (down $24.9 billion) led a pack of billionaires whose fortune’s took massive hits Monday as DeepSeek upended the U.S. stock market, with Nvidia CEO Jensen Huang ($19.8 billion), Dell CEO Michael Dell ($12.4 billion), Tesla CEO Elon Musk ($5.3 billion) and Google cofounder Larry Page ($4.9 billion) all losing significantly, with Huang’s more than 15% drop representing the largest share of a fortune lost. Jan. 27, 12:30 p.m. ESTU.S. stocks got walloped Monday morning: The S&P 500 was down about 1.8% at 12:30 p.m. EST, and the tech-heavy Nasdaq sank 3.4%. Jan. 27, 11:15 a.m. ESTShares of Nvidia plunged 15% by 11:15 a.m. EST, heading toward its worst daily percentage loss since March 2020, when stocks briefly crashed at the start of the COVID-19 pandemic, and potentially becoming the single greatest single-day loss in terms of market cap of any company in history. Broadcom had slipped 16% as of 11:30 a.m. Jan. 27, 9:30 a.m. ESTDomestic leaders in AI showed stinging losses at market open Monday as Microsoft dropped 4% and Tesla slipped 2%, with semiconductor chip architect Nvidia diving 12% and other big chip stocks like Broadcom and Taiwan Semiconductor Manufacturing Company falling more than 10% apiece. Jan. 27, 7:30 a.m. ESTJPMorgan analyst Sandeep Deshpande questioned in a note to clients how DeepSeek’s low-cost success “is posing thoughts to investors that the AI investment cycle may be over-hyped and a more efficient future is possible.” Jan. 27, 5 a.m. ESTReferring to the Magnificent 7 set of trillion-dollar U.S. companies including Nvidia and Tesla accounting for much of the 2020s bull market, Yardeni Research founder Ed Yardeni noted a “competitive threat to their magnificence has emerged from China.” Jan. 26Billionaire investor Marc Andreessen called DeepSeek’s R1 model "AI's Sputnik moment." Jan. 25The DeepSeek mobile app became the No. 1 app in iPhone stores in Australia, Canada, China, Singapore, the U.S. and the U.K. Jan. 22ByteDance, another Chinese company, revealed an update to its flagship AI model and word started circulating that the new overseas products posed a strategic threat to the U.S. tech giants pursuing AI dominance. Jan. 20DeepSeek launched its R1 advanced reasoning model, claiming it rivaled OpenAI's o1 product on several performance benchmarks and was created for far less money than spent by American companies like Microsoft and Meta. The selloff stems from weekend panic over last week’s release from the relatively unknown Chinese firm DeepSeek of its competitive generative AI model rivaling OpenAI, the American firm backed by Microsoft and Nvidia, and its viral chatbot ChatGPT, with DeepSeek notably running at a fraction of the cost of U.S.-based rivals. The idea of a rival undercutting the largely U.S.-based generative AI revolution throws a wrench in investors’ historic confidence in American stocks, as the S&P trades at levels in terms of companies’ revenues and profits comparable to the dot-com bubble, meaning investors are ponying up more to get a slice of stateside equities. DeepSeek is “bad news” for American tech behemoths with “plans to dominate the AI market with their expensive AI services,” cautioned Yardeni. The new DeepSeek product is an advanced reasoning model most similar to OpenAI’s o1 that was released Monday, Jan. 20. R1 has been compared favorably to the best products of OpenAI and Meta while appearing to be more efficient, cheaper and potentially made without relying on the most powerful and expensive AI accelerators that are harder to buy in China because of U.S. export controls. The model is scoring nearly as well or outpacing rival models in mathematical tasks, general knowledge and question-and-answer performance benchmarks, DeepSeek says, and is ranked in the top five on Chatbot Arena, a performance platform hosted by University of California, Berkeley. Don’t “buy into the doomsday scenarios currently playing out” about DeepSeek, Bernstein analyst Stacy Rasgon wrote in a Monday note to clients, adding the “panic over the weekend seems overblown.” DeepSeek’s assertion it cost just $5.6 million in computing power to develop its model is “categorically false,” according Rasgon, who said the misleading figure does not account for other “substantial” costs related to its AI model’s development. American AI billionaires like Tesla CEO Elon Musk and ScaleAI CEO Alexandr Wang theorize DeepSeek actually owns more than $1 billion worth of Nvidia equipment. DeepSeek is a new entrant to the AI large-language model arms race involving OpenAI, Facebook parent Meta and Google parent Alphabet. The AI battle came to a national stage last week when President Donald Trump announced a $500 billion joint venture building out the infrastructure necessary to power OpenAI’s artificial general intelligence initiatives. In his speech last Tuesday, Trump specifically called out the importance for the U.S. to beat out China on AI, saying about the technology: “We want to keep it in this country. China is a competitor and others are competitors.” Major tech figures including billionaire Trump allies Marc Andreessen and Vivek Ramaswamy each likened DeepSeek’s new technology to a “Sputnik moment” for American AI. Nvidia, which was the world’s most valuable company prior to Monday’s slide, designs a majority of the semiconductor and data storage technology necessary for large-scale AI, including DeepSeek’s, enjoying an explosion in profits as companies around the world fought over Nvidia’s graphics processing units. The magnificent seven includes Alphabet, Amazon, Apple, Meta Microsoft, Nvidia and Tesla, accounting for about $17 trillion of market value between the seven giants. The AI revolution boosted American stocks to record leadership in the global stock market, with U.S. companies accounting for 67% of the world equity market at the end of 2024, according to MSCI. The S&P is up 201% over the last decade through Friday, trouncing the 8% loss for China’s leading CSI 300 index and the 33% gain for Europe’s Stoxx 600 over the period, according to FactSet data. Monday’s selloff sets the stage for a notable week for Big Tech stocks. Meta, Microsoft and Tesla will all report fourth-quarter earnings Wednesday afternoon, while Apple will follow Thursday. One Community. Many Voices. Create a free account to share your thoughts. Our community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space. In order to do so, please follow the posting rules in our site's Terms of Service. We've summarized some of those key rules below. Simply put, keep it civil. Your post will be rejected if we notice that it seems to contain: User accounts will be blocked if we notice or believe that users are engaged in: So, how can you be a power user? Thanks for reading our community guidelines. Please read the full list of posting rules found in our site's Terms of Service.
--------------------------------------------------