List of news related to Meta stock price META:

Title: Why Did Reddit Stock Drop 10%?
URL: https://www.forbes.com/sites/greatspeculations/2025/09/29/why-did-reddit-stock-drop-10/
Time Published: 2025-09-29T10:30:00Z
Full Content:
ByTrefis Team, Contributor. Reddit stock (NYSE:RDDT) dropped nearly 10% in the past week, in contrast to the nearly stable performance of the S&P 500 Index. The fluctuations in Reddit’s stock price are particularly notable when compared to its competitors, including Meta Platforms – which fell about 3% during the week, Snap – gaining around 8%, and Pinterest – which dropped approximately 3%. The decline is indicative of investor worries regarding slower user growth and possible traffic challenges related to updates in Google’s search algorithms and AI-generated responses, which may impact engagement and advertising capacity on the platform. With the current share price hovering around $237, we believe Reddit could experience short-term challenges before stabilizing. Importantly, the stock is still significantly higher compared to its IPO valuation from early 2024 and has increased by 45% since late 2024, as outlined in our analysis of Why Reddit Stock Moved. However, for those looking for growth with less volatility than owning a single stock, the High Quality Portfolio is worth considering. It has significantly outperformed its benchmark, which consists of the S&P 500, Russell, and S&P MidCap indexes, achieving returns of over 91% since its launch. As a whole, the stocks in the HQ Portfolio have generated superior returns with reduced risk compared to the benchmark index; offering less of a tumultuous experience, as shown in HQ Portfolio performance metrics. Additionally, don’t miss – Uber Stock To $200? Some of the increase in Reddit’s stock since its IPO can be attributed to the approximately 30% rise in its revenues from 2022 to 2024. Revenue growth surged in 2023 due to the introduction of new ad products and licensing agreements, and this trend continued into 2024 with ongoing growth in advertising and AI-related data licensing. Nevertheless, growth started to slow somewhat in early 2025 amid worries regarding traffic sources and user engagement patterns. Although Reddit has experienced steady revenue growth, its PS multiple has not broadened significantly. The company's PS multiple rose from around 10x in 2024 to almost 12x by mid-2025. While the company’s PS is currently above historical averages, there may be potential downside when comparing the current multiple to previous peaks – roughly 15x in late 2024 and closer to 9x as recently as early 2023. In its latest quarter, Reddit declared revenue of approximately $240 million, reflecting an increase of more than 20% year-over-year, and recorded its second quarterly profit since its IPO. However, the daily active users count of 100 million was slightly under optimistic forecasts, raising concerns about market saturation and competition. For the full year of 2025, Reddit has projected revenue growth in the mid-20% range, but remarks regarding traffic uncertainty have made investors cautious. If the company can demonstrate resilience in user engagement and continue to enhance its ad products, the stock could potentially regain its upward trajectory. However, in the short term, volatility is expected to remain as investors weigh high valuation multiples against execution risks. The Trefis High Quality (HQ) Portfolio, featuring a selection of 30 stocks, has a history of consistently outperforming its benchmark inclusive of all three – S&P 500, Russell, and S&P midcap — and has generated returns above 91% since its inception. What accounts for this success? As a collective, the stocks in the HQ Portfolio deliver better returns with reduced risk compared to the benchmark index; resulting in less of a tumultuous experience, as shown in HQ Portfolio performance metrics.
--------------------------------------------------

Title: CEO Talks: Jamie Salter on Building Authentic Brands Into a $32 Billion Juggernaut Over 15 Years
URL: http://wwd.com/business-news/business-features/jamie-salter-authentic-brands-group-reebok-guess-champion-1238213033/
Time Published: 2025-09-29T04:01:00Z
Full Content:
Today's Digital Daily Today's Digital Daily The founder and chief executive officer of the brand management and entertainment firm expects to transition to executive chairman in around two years. Senior Editor, Men's Jamie Salter has come a long way in the past 15 years. The 62-year-old Toronto native started his career in sports marketing and was the cofounder of Ride snowboards in the early 1990s. After that company went public, he and Fanatics’ founder and executive chairman Michael Rubin created Global Sports Inc., which eventually became GSI Commerce. Once he exited that business, Salter turned his attention to licensing, cofounding Hilco Consumer Capital. After a difference of opinion with Hilco’s majority owner, he partnered with Leonard Green and created Authentic Brands Group. Related Articles Shoe Industry News Puma Shares Seesaw on Authentic Brands Group Takeover Speculation Fashion Features WWD's 115 Newsmakers: S to Z Today, Authentic has amassed a portfolio that encompasses more than 50 brands including Reebok, Brooks Brothers and Champion that generate annual retail sales of $32 billion globally. The addition of Guess by early year will bring that number to $38 billion. But that’s not good enough for Salter, whose goal is to reach $100 billion in sales within the next five years by purchasing brands that have sales of more than $1 billion with global expansion potential while also expanding his reach in the entertainment and hospitality sectors. You May Also Like Authentic, which is on track to post 7 percent organic growth from its brands this year, now has headquarters in New York, London and Shanghai and offices in Los Angeles, Miami, Tokyo and South Korea. It counts 1,800 licensing partners globally, and its licensees operate 16,000 stores and 29,000 shops-in-shop around the world. The group is by far the largest of what is a new wave of brand management companies, which are rewriting the fashion and retail landscape in the U.S. by snapping up brand seemingly every week. While it’s a model that first emerged in the U.S. almost 50 years ago, Authentic and the likes of WHP Global, Bluestar and Marquee Brands are now taking it to another level. Here, Salter talks about his journey, how he’s built Authentic and his plans to pass the reins to the newly named president, Matt Maddox, within the next two years. WWD: How has the licensing model evolved since you started 15 years ago? Jamie Salter: It’s dramatically different. When we came into the business, Iconix was really the prize in the industry. It was doing DTR [direct-to-retail] with big retailers, and it was very item driven and category specific. When I looked at the business back then, I always asked the question, “Why don’t they sell home and shoes and whatever?” Well, it wasn’t because they didn’t want to, but they had a DTR [strategy]. So I said, OK, I know they’re doing really well, but that’s not going to work for us. We have to have another angle on how can we do well in the licensing business. So we took a different approach. WWD: And what was that? J.S.: Our approach was we’re going to go after wholesalers, and we’re going to do it by category and by territory, and they’re going to have to sell into retailers. That was very different from what Iconix was doing. So you could say we got lucky, or you could say we’re smart. I would say it’s probably a little bit of both. But what it really proved to me was you could actually grow the businesses so much bigger. WWD: Was there a downside? J.S.: You could argue our model was more expensive to run than a traditional licensing model, because we had to put a lot of money from the royalties that we were collecting into marketing. In the beginning, we weren’t putting enough into the marketing side of the business, but we learned very early on — when my partner Nick [Woodhouse] came into the business — that we really had to spend money on marketing. But we couldn’t afford it. It was hard. WWD: But I assume you decided to make the investment? J.S.: I met a guy named Adam Kronengold who is still with me today. He’s our chief digital officer. He was one of our first employees and in his interview, he asked me how many social media followers I had. I said, “What do you mean? Me? Jamie Salter?” He said, “No, not you, your company.” I said, “I don’t really understand the question.” So he goes on Instagram and says, “You don’t have an account.” This is in 2010, and he said, “Marilyn Monroe has an account. She has 250,000 followers. You know you can talk to people, post stuff and market.” I said, “How much does that cost?” He says, “It’s free. You can put up a post, send your message and tell people where Marilyn Monroe is being sold. You can do whatever you want. It’s your channel.” WWD: Guess he convinced you. J.S.: I asked him how Instagram made money and he said it didn’t make a lot then, but their whole strategy was to get everybody on social media and eventually turn it into an advertising platform. I said, “I like free — you’re hired.” So we were one of the very early adopters in the social media world. I think that is really the base of Authentic Brands — we really built the company like a tech start-up. Here we are 15 years after and we’re still like a start-up in the way we think. We’re always on the cusp of what’s next. WWD: How do you differ from the other brand management companies you compete with today like WHP Global, Marquee Brands and Bluestar? J.S.: We welcome competition, and we want them to do well, because if they do well, it’s good for us. But everyone builds a niche for themselves. WHP is using the Iconix/Sequential playbook and they’ve transitioned from that a little bit. I think Yehuda [Shmidman, WHP’s chief executive officer] learned some good hard lessons through his experience there and he’s building a pretty good platform [at WHP]. But scale matters now in this business because of the money you have to spend in order to build these brands and keep them relevant in the marketplace. We have a big international platform and nobody else really has that. But where we’re really separate from them is that we have 80 people in the marketing department today, we have 700 million social media followers — that’s 10 percent of the people that live on the planet. We’re on TikTok and WeChat and Instagram and Red Note — we’re on every platform around the globe. We have social media influencers in 150 different languages. WWD: Is that why you’re often always the first call when a brand is for sale? J.S.: If you have an opportunity to partner with Authentic versus Bluestar versus WHP, you’re going to partner with Authentic if it’s the same economics, just because it’s a much bigger platform. We can actually pay more because our platform is so efficient. And we can run businesses more efficiently because of our sheer size. WWD: You swooped in at the last minute to buy Guess even though WHP already had a deal. What happened there? J.S.: They always say anything’s for sale for the right price. But that’s just not true. [Guess cofounder] Paul Marciano was looking for a partner and unless he got the best deal for his shareholders, he would never have sold the company. So he’s selling 51 percent to us, and the family [with CEO Carlos Alberini] will own other 49 percent. Relationships matter, strategy matters, legacy matters. Paul’s last name is on the door. Look at LVMH: the family is all involved in the business and I think that’s why it’s such an incredible company. They learned from their father and they care — the legacy lives on. My name is on the door too — Authentic is the Salters. My family will be involved with Authentic Brands forever, I hope. WWD: All four of your sons are in the business, right? J.S.: Yes. And at some point, Jamie Salter will have to hang up the skates as I get older. WWD: In January, you brought in Matt Maddox, the former CEO of Wynn Resorts, as president. What is his role? J.S.: He worked with Steve Wynn for 22 years and for the last four or five years, was CEO of Wynn Properties. Everyone asked me why I didn’t hire someone from the fashion business. Look, we’re in the licensing business, which means we’re effectively a landlord. We buy these great brands, we fix them up, we market them and we rent out rooms. And the rooms happen to be shoes and socks and intimate apparel and home goods. And we do that by territory, by category. Matt understood the retail luxury space, because he has his own mall at the Wynn. He understood that he has to rent out his rooms every day. He has to market. He understood the entertainment business and events and celebrities and athletes. He has relationships with all these. We knew a lot of the same people and were partners with the Wynn through our live events division. WWD: Sounds like a good match. J.S.: Matt was offered some of the biggest jobs in the United States and initially he said no to me [when I offered him the job]. I asked him why and he said, “I’ve looked at your business. It’s working really well. You’re doing an incredible job. You’re not going anywhere. You don’t need me.” So I called Steve [Wynn] and told him he had to convince Matt to take the job. He did and we hired Matt. WWD: What are your ultimate plans for Matt? J.S.: I made a commitment to Matt that he would become the CEO of the company in the next two years. I will move to executive chairman. And you know, people ask me, “Are you OK with that?” Well, I’m super excited. Matt is 49, he’s young, he’s beyond smart. He’s working incredibly well with the team. He’s working great with my children, which is really important to me. He’s mentoring my son, Corey, who, you know, I ultimately want one day to run the company with his brothers. But I’ve got an incredible partner in Matt, who I believe will lead Authentic to $100 billion. WWD: The business community is filled with founders who find they can’t actually step aside when they turn over the reins to someone else. Why is this different? J.S.: Like I told Matt, I’m not going anywhere. But we’ve got to stay young; we’ve got to stay nimble. He understands the loyalty side of the business better than me because they had a big loyalty program at the Wynn. He understands the digital side of the business. He’s doing an unbelievable job upgrading Authentic on the process side. And if we do decide to go public over the next year or two, he’ll be an excellent CEO that the Street can rely on. I’m excited to just continue doing what I’m really good at, which is building great relationships around the world and working on the M&A side, and I have a great partner in Matt to run the day-to-day. WWD: Sounds like hiring someone from outside the fashion industry is working out for you. J.S.: I’m a big believer in hiring outside the industry — not that we don’t hire inside the industry, because we still need merchants and great marketing people. But if you really look at Authentic, the average age here is about 35. And they come out of the digital space, the legal space, the finance system. Authentic is a big marketing department, a big legal department, a big digital department. So, we’re hiring people from Meta and Google and Microsoft and Amazon. You still need merchants to touch and feel and make great product, because you can have the greatest digital team and the greatest marketing team but if don’t have good product, then it doesn’t work. But at the end of the day, data is everything. WWD: What do you look for when you’re hiring people? J.S.: When you’re hot, you attract great talent. When I’m hiring someone, the first question I ask is, can AI do this job? If the answer is no, the second question is: is that person smarter than you? And we’re a loyal group, so if you’re really good, you’re going to be here forever. But Authentic is not for everyone. Do not come here if you’re looking for a 9-to-5 job because we work 24 hours a day, seven days a week. We’re a global company, so we’re always working. With the globalization of the world, the internet, social media, the news cycles and staying ahead of trends and culture, you always have to be on. WWD: You also have other components to your business beyond brand management. J.S.: Yes. Twenty-five percent of the platform is entertainment. [Our competitors] don’t have an entertainment business. And entertainment, in my opinion, drives fashion culture. The entertainment business is really music culture and sports culture, which is where we have a big edge. The other 75 percent of our turnover is rooted in the lifestyle space. WWD: How do you evolve the company going forward, where are the opportunities? J.S.: We think we’re just scratching the surface. I know people think that’s kind of crazy with a business that has about $32 billion in annual retail systemwide sales. But we think we can be about $100 billion within the next five years. It’s not as crazy as you think when we pull off deals like Guess, which does $6 billion at retail. There are lots of other brands that are in that $1 billion to $10 billion range that we could buy. And we really, truly believe that we will crack those opportunities. Over the next five years, we’ll do another four or five big deals and that’s another $50 billion. This year alone, and the year is not over, we added almost $7 billion in revenue. WWD: You were close to going public a couple of years ago and then decided against it. Are you revisiting the idea? J.S.: Authentic is a very different model. We trade like a tech company because we are a tech company. Think about it. When you have 75 percent margin, 99 percent cash conversion and virtually no capex, you trade like a software company. So could we be public? The answer is yes. Should we be public? I don’t know. There’s no need to be. Why is SpaceX not public? It doesn’t need to be. We trade at a very high multiple; we have 36 percent growth in the company. We’re low levered. We took our first money from Leonard Green in 2010 and the company has been self-funded since then. WWD: But you have other investors including General Atlantic, BlackRock, CVC Capital Partners, Simon Property Group and Brookfield, among others. J.S.: True. There’s been $9 billion of secondaries in the last three years, but that’s just one shareholder selling to a new buyer. There’s been no need for investment from outside. We actually just bought $1 billion of stock back and retired the shares, so the company’s very flush with cash. WWD: A lot of the brands you buy are distressed. Is that what you look for? J.S.: The brands aren’t necessarily distressed, the companies are. Reebok wasn’t a bad brand. Adidas just wasn’t putting the effort into one of the greatest athletic brands in the world. Their focus was on building Adidas. They milked Reebok as far as they possibly could, and they didn’t need it anymore. We’ve owned Reebok now for a couple years and we’ve almost doubled the business. We still have lots of work to do, but Reebok is a $6 billion business and our ambition is to grow to a $10 billion business over the next three years — and we feel very confident we’re going to get there. WWD: So what is the criteria you use when exploring a purchase? J.S.: A good brand but a broken business. Champion wasn’t broken but Hanes needed liquidity. Truth be told, I spoke to Gildan before we bought Champion. I said, “Let’s go buy Hanes together. I’ll take Champion. You take Hanes.” We ended up buying Champion. They ended up buying Hanes, which is interesting. We could have done the deal together. Anyway, our model is to license by category, by territory, to best-in-class partners. So you get the best underwear-maker, you get the best sock-maker, you get the best sportswear-maker. It means the business grows much quicker. But we have to unwind the overhead so we can run these companies much more efficiently. People always say, “When you buy a company, all the jobs go away.” It’s not true — lots of new jobs are created. When we look at our portfolio, I would say that probably 75 percent of the jobs either stay or new jobs are created. So maybe people lose their jobs in California, but there are new jobs in New York, and it’s more efficient. WWD: Where do you see the growth coming from in the future? J.S.: Entertainment and kids’ animation. Those are two really big areas for us. We believe entertainment really does drive lifestyle. So we’re going to continue to drive that. And when I say the kids’ space, think Disney, think Mattel, that type of stuff. And with Matt’s background, we’re moving into the hospitality business. We’ve done multiple deals now for hotels and condos. We have the Barneys hotel. We have Sports Illustrated resorts, we have Eddie Bauer lodges. We have Nautica condos going up in Mexico. Our hospitality business is bigger than you would think. Also, beauty. Our beauty business is over a couple billion dollars today, but there’s big opportunity there. And you’re going to see us do more deals like David Beckham and Shaq. WWD: Speaking of Beckham and Shaquille O’Neal, neither of them has been playing for a while. And you also own the rights to Elvis Presley and Marilyn Monroe, who are dead. J.S.: We don’t call them dead — they’re icons, and with AI coming into play, Marilyn Monroe is going to be on fire in 2026, which is her 100th anniversary [of her birth]. We’ve done an enormous number of deals around Marilyn Monroe. And don’t be surprised if you see her in movies again. And look at what’s going on with Elvis Presley. There was the movie and we now have an immersive theater production, Elvis Evolution, at the 02 in London. WWD: But how do you appeal to young people who don’t know Elvis and never saw Shaq or David Beckham play? J.S.: Shaq has never been bigger — no pun intended. Shaq’s business is 10 times as big as when we partnered with him in 2015. And David Beckham‘s business has doubled since we joined forces Now, we’ve only been working on David’s business for a couple years — Shaq’s we’ve owned much longer. I’m not going to say live celebrities are better, but there are bigger opportunities than if they’re not with us anymore. WWD: Let’s talk about the Authentic Luxury Group. Can you explain what that is and how it’s working? J.S.: ALG is a joint venture between Saks Global and us that licenses the IP of the Saks brands and select Authentic premium brands. Richard [Baker, executive chairman of Saks Global] has had a bit of a bumpy road. He is a total optimist and a great visionary, but he needs to prove to the world that financially, he’s set up properly. It seems he’s on the right track now but we’re going to continue to be careful. We’re going to continue to build the affordable luxury — or premium — side of our business. Luxury is a word you have to be careful with. LVMH is luxury, Kering is luxury, Prada is luxury. Vince is premium, Brooks Brothers is premium, Hugo Boss is premium. We’ll continue to play in the premium space in a big way, because it’s the next level from where we are today. We have the full support of Saks, Neiman’s and Amazon, because that’s the joint venture, and we’ll fully support Richard and his journey. But we’re going to be careful. WWD: Are you still looking to buy Marc Jacobs? J.S.: I can’t really comment on that. What I will tell you is we will continue to look at companies in that space, like Marc Jacobs, and we’ll see where it goes. WWD: Let’s talk about the whole department store and retail space where you have a lot of partners. It’s not easy out there. J.S.: We have to go where the customers go. If T.J. Maxx is a winner, we’ve got to sell them. if Burlington, Target and Walmart are winners, we’ve got to sell them. The consumption is the same as it was a year ago — people aren’t buying any less product. They’re just buying from different places. So we continue to go where the customers go, and that’s really been our model. We think independent retailers, or omnichannel retailers like Lucky or Brooks Brothers, are actually important to building these brands. It’s tough, but it’s important to the model. Today, we have about 6,000 licensed full-price/outlet stores around the globe. And then there are another 24,000 shops-in-shop. So when you really look at our portfolio, half of our volume is done through stores that have our name above the door, and that’s a big investment. It’s going to take a long time before Kohl’s and JCPenney and Macy’s are not here anymore. But they’ve got to continue to reinvent themselves. Great retailers survive. Look at Harrods: it’s packed wall-to-wall all the time. WWD: Why do you think that is? J.S.: It may be the model: a department store made up of all concessions. It doesn’t matter what concession [shop] you go into, one’s better than the next one — they’re all just amazing. Take food: you can’t just have a food hall anymore, you have to have restaurants. Look at David Simon [head of Simon Properties]: everyone asks why his stock is so high. It’s because he reinvents himself all the time. He never gets stale. So when you go into a Simon mall, it’s busier than everyone else’s because he’s constantly looking at the best brands and reshuffling things. I don’t think the mall is dead. I think the mall is very alive — if you’re in the right malls. And I don’t think the department store is dead. It just needs to be reinvented. Now, are we over-retailed in America? The answer is yes. That’s why going online is critical. If you want to be in this business, you’ve got to go where the customers go. WWD: There’s a lot of criticism about the licensing model. Why are you so enamored with it? J.S.: There are two types of licensing. One really comes out of the animation business. Look at Disney: it’s the greatest company in the world. And what do they do? They make movies. They make TV shows. Then they have the parks where they sell you a lot of merchandise. I’ve got that same attitude. Authentic has content and experiences and if we continue to do that, we can license our brands and be successful. If you’re just brand slapping and there’s no meat behind it, I think you will die a slow death. You have to treat your brands like your children. You can’t give them back. If you don’t constantly maintain your brands, you’re not going to win. And I think that’s where licensing gets a bad reputation. Disney has done an unbelievable job — we think they’re the best of the best of the best. They’re number one, we’re number two, and they’re way above us. But we’re working hard every single day to continue to make this a better place. Sign up for WWD news straight to your inbox every day Get all the top news stories and alerts straight to your inbox. Get all the top news stories and alerts straight to your inbox. Send us a tip using our anonymous form. WWD and Women's Wear Daily are part of Penske Media Corporation. © 2025 Fairchild Publishing, LLC. All Rights Reserved.
--------------------------------------------------

Title: The Case Against Generative AI
URL: https://www.wheresyoured.at/the-case-against-generative-ai/
Time Published: 2025-09-29T00:00:00Z
Full Content:
Soundtrack: Queens of the Stone Age - First It Giveth Before we go any further: This is, for the third time this year, the longest newsletter I've ever written, weighing in somewhere around 18,500 words. I've written it specifically to be read at your leisure — dip in and out where you'd like — but also in one go. This is my comprehensive case that yes, we’re in a bubble, one that will inevitably (and violently) collapse in the near future. I'll also be cutting this into a four-part episode starting tomorrow on my podcast Better Offline. I deeply appreciate your time. If you like this newsletter, please think about subscribing to the premium, which I write weekly. Thanks for reading. Alright, let’s do this one last time. In 2022, a (kind-of) company called OpenAI surprised the world with a website called ChatGPT that could generate text that sort-of sounded like a person using a technology called Large Language Models (LLMs), which can also be used to generate images, video and computer code. Large Language Models require entire clusters of servers connected with high-speed networking, all containing this thing called a GPU — graphics processing units. These are different to the GPUs in your Xbox, or laptop, or gaming PC. They cost much, much more, and they’re good at doing the processes of inference (the creation of the output of any LLM) and training (feeding masses of training data to models, or feeding them information about what a good output might look like, so they can later identify a thing or replicate it). These models showed some immediate promise in their ability to articulate concepts or generate video, visuals, audio, text and code. They also immediately had one glaring, obvious problem: because they’re probabilistic, these models can’t actually be relied upon to do the same thing every single time. So, if you generated a picture of a person that you wanted to, for example, use in a story book, every time you created a new page, using the same prompt to describe the protagonist, that person would look different — and that difference could be minor (something that a reader should shrug off), or it could make that character look like a completely different person. Moreover, the probabilistic nature of generative AI meant that whenever you asked it a question, it would guess as to the answer, not because it knew the answer, but rather because it was guessing on the right word to add in a sentence based on previous training data. As a result, these models would frequently make mistakes — something which we later referred to as “hallucinations.” And that’s not even mentioning the cost of training these models, the cost of running them, the vast amounts of computational power they required, the fact that the legality of using material scraped from books and the web without the owner’s permission was (and remains) legally dubious, or the fact that nobody seemed to know how to use these models to actually create profitable businesses. These problems were overshadowed by something flashy, and new, and something that investors — and the tech media — believed would eventually automate the single thing that’s proven most resistant to automation: namely, knowledge work and the creative economy. This newness and hype and these expectations sent the market into a frenzy, with every hyperscaler immediately creating the most aggressive market for one supplier I’ve ever seen. NVIDIA has sold over $200 billion of GPUs since the beginning of 2023, becoming the largest company on the stock market and trading at over $170 as of writing this sentence only a few years after being worth $19.52 a share. While I’ve talked about some of the propelling factors behind the AI wave — automation and novelty — that’s not a complete picture. A huge reason why everybody decided to “do AI” was because the software industry’s growth was slowing, with SaaS (Software As A Service) company valuations stalling or dropping, resulting in the terrifying prospect of companies having to “under promise and over deliver” and “be efficient.” Things that normal companies — those whose valuations aren’t contingent on ever-increasing, ever-constant growth — don’t have to worry about, because they’re normal companies. Suddenly, there was the promise of a new technology — Large Language Models — that were getting exponentially more powerful, which was mostly a lie but hard to disprove because “powerful” can mean basically anything, and the definition of “powerful” depended entirely on whoever you asked at any given time, and what that person’s motivations were. The media also immediately started tripping on its own feet, mistakenly claiming OpenAI’s GPT-4 model tricked a Taskrabbit into solving a CAPTCHA (it didn’t — this never happened), or saying that “people who don’t know how to code already [used] bots to produce full-fledged games,” and if you’re wondering what “full-fledged” means, it means “pong” and a cobbled-together rolling demo of SkyRoads, a game from 1993. The media (and investors) helped peddle the narrative that AI was always getting better, could do basically anything, and that any problems you saw today would be inevitably solved in a few short months, or years, or, well, at some point I guess. LLMs were touted as a digital panacea, and the companies building them offered traditional software companies the chance to plug these models into their software using an API, thus allowing them to ride the same generative AI wave that every other company was riding. The model companies similarly started going after individual and business customers, offering software and subscriptions that promised the world, though this mostly boiled down to chatbots that could generate stuff, and then doubled down with the promise of “agents” — a marketing term that’s meant to make you think “autonomous digital worker” but really means “broken digital product.” Throughout this era, investors and the media spoke with a sense of inevitability that they never really backed up with data. It was an era based on confidently-asserted “vibes.” Everything was always getting better and more powerful, even though there was never much proof that this was truly disruptive technology, other than in its ability to disrupt apps you were using with AI — making them worse by, for example, suggesting questions on every Facebook post that you could ask Meta AI, but which Meta AI couldn’t answer. “AI” was omnipresent, and it eventually grew to mean everything and nothing. OpenAI would see its every move lorded over like a gifted child, its CEO Sam Altman called the “Oppenheimer of Our Age,” even if it wasn’t really obvious why everyone was impressed. GPT-4 felt like something a bit different, but was it actually meaningful? The thing is, Artificial Intelligence is built and sold on not just faith, but a series of myths that the AI boosters expect us to believe with the same certainty that we treat things like gravity, or the boiling point of water. Can large language models actually replace coders? Not really, no, and I’ll get into why later in the piece. Can Sora — OpenAI’s video creation tool — replace actors or animators? No, not at all, but it still fills the air full of tension because you can immediately see who is pre-registered to replace everyone that works for them. AI is apparently replacing workers, but nobody appears to be able to prove it! But every few weeks a story runs where everybody tries to pretend that AI is replacing workers with some poorly-sourced and incomprehensible study, never actually saying “someone’s job got replaced by AI” because it isn’t happening at scale, and because if you provide real-world examples, people can actually check. To be clear, some people have lost jobs to AI, just not the white collar workers, software engineers, or really any of the career paths that the mainstream media and AI investors would have you believe. Brian Merchant has done excellent work covering how LLMs have devoured the work of translators, using cheap, “almost good” automation to lower already-stagnant wages in a field that was already hurting before the advent of generative AI, with some having to abandon the field, and others pushed into bankruptcy. I’ve heard the same for art directors, SEO experts, and copy editors, and Christopher Mims of the Wall Street Journal covered these last year. These are all fields with something in common: shitty bosses with little regard for their customers who have been eagerly waiting for the opportunity to slash contract labor. To quote Merchant, “the drumbeat, marketing, and pop culture of ‘powerful AI’ encourages and permits management to replace or degrade jobs they might not otherwise have.” Across the board, the people being “replaced” by AI are the victims of lazy, incompetent cost-cutters who don’t care if they ship poorly-translated text. To quote Merchant again, “[AI hype] has created the cover necessary to justify slashing rates and accepting “good enough” automation output for video games and media products.” Yet the jobs crisis facing translators speaks to the larger flaws of the Large Language Model era, and why other careers aren’t seeing this kind of disruption. Generative AI creates outputs, and by extension defines all labor as some kind of output created from a request. In the case of translation, it’s possible for a company to get by with a shitty version, because many customers see translation as “what do these words say,” even though (as one worker told Merchant) translation is about conveying meaning. Nevertheless, “translation” work had already started to condense to a world where humans would at times clean up machine-generated text, and the same worker warned that the same might come for other industries. Yet the problem is that translation is a heavily output-driven industry, one where (idiot) bosses can say “oh yeah that’s fine” because they ran an output back through Google Translate and it seemed fine in their native tongue. The problems of a poor translation are obvious, but the customers of translation are, it seems, often capable of getting by with a shitty product. The problem is that most jobs are not output-driven at all, and what we’re buying from a human being is a person’s ability to think. Every CEO talking about AI replacing workers is an example of the real problem: that most companies are run by people who don’t understand or experience the problems they’re solving, don’t do any real work, don’t face any real problems, and thus can never be trusted to solve them. The Era of the Business Idiot is the result of letting management consultants and neoliberal “free market” sociopaths take over everything, leaving us with companies run by people who don’t know how the companies make money, just that they must always make more. When you’re a big, stupid asshole, every job that you see is condensed to its outputs, and not the stuff that leads up to the output, or the small nuances and conscious decisions that make an output good as opposed to simply acceptable, or even bad. What does a software engineer do? They write code! What does a writer do? They write words! What does a hairdresser do? They cut hair! Yet that’s not actually the case. As I’ll get into later, a software engineer does far more than just code, and when they write code they’re not just saying “what would solve this problem?” with a big smile on their face — they’re taking into account their years of experience, what code does, what code could do, all the things that might break as a result, and all of the things that you can’t really tell from just looking at code, like whether there’s a reason things are made in a particular way. A good coder doesn’t just hammer at the keyboard with the aim of doing a particular task. They factor in questions like: How does this functionality fit into the code that’s already here? Or, if someone has to update this code in the future, how do I make it easy for them to understand what I’ve written and to make changes without breaking a bunch of other stuff? A writer doesn’t just “write words.” They jostle ideas and ideals and emotions and thoughts and facts and feelings into a condensed piece of text, explaining both what’s happening and why it’s happening from their perspective, finding nuanced ways to convey large topics, none of which is the result of a single (or many) prompts but the ever-shifting sand of a writer’s brain. Good writing is a fight between a bunch of different factors: structure, style, intent, audience, and prioritizing the things that you (or your client) care about in the text. It’s often emotive — or at the very least, driven or inspired by a given emotion — which is something that an AI simply can’t replicate in a way that’s authentic and believable. And a hairdresser doesn’t just cut hair, but cuts your hair, which may be wiry, dry, oily, long, short, healthy, unhealthy, on a scalp with particular issues, at a time of year when perhaps you want to change length, at a time that fits you, in “the way you like” which may be impossible to actually write down but they get it just right. And they make conversation, making you feel at ease while they snip and clip away at your tresses, with you having to trust that they’ll get it right. This is the true nature of labor that executives fail to comprehend at scale: that the things we do are not units of work, but extrapolations of experience, emotion, and context that cannot be condensed in written meaning. Business Idiots see our labor as the result of a smart manager saying “do this,” rather than human ingenuity interpreting both a request and the shit the manager didn’t say. What does a CEO do? Uhhh, um, well, a Harvard study says they spend 25% of their time on “people and relationships,” 25% on “functional and business unit reviews,” 16% on “organization and culture,” and 21% on “strategy,” with a few percent here and there for things like “professional development.” That’s who runs the vast majority of companies: people that describe their work predominantly as “looking at stuff,” “talking to people” and “thinking about what we do next.” The most highly-paid jobs in the world are impossible to describe, their labor described in a mish-mash of LinkedInspiraton, yet everybody else’s labor is an output that can be automated. As a result, Large Language Models seem like magic. When you see everything as an outcome — an outcome you may or may not understand, and definitely don’t understand the process behind, let alone care about — you kind of already see your workers as LLMs. You create a stratification of the workforce that goes beyond the normal organizational chart, with senior executives — those closer to the class level of CEO — acting as those who have risen above the doldrums of doing things to the level of “decisionmaking,” a fuzzy term that can mean everything from “making nuanced decisions with input from multiple different subject-matter experts” to, as ServiceNow Bill McDermott did in 2022, “[make] it clear to everybody [in a boardroom of other executives], everything you do: AI, AI, AI, AI, AI.” The same extends to some members of the business and tech media that have, for the most part, gotten by without having to think too hard about the actual things the companies are saying. I realize this sounds a little mean, and I must be clear it doesn’t mean that these people know nothing, just that it’s been possible to scoot through the world without thinking too hard about whether or not something is true. When Salesforce said back in 2024 that its “Einstein Trust Layer” and AI would be “transformational for jobs,” the media dutifully wrote it down and published it without a second thought. It fully trusted Marc Benioff when he said that Agentforce agents would replace human workers, and then again when he said that AI agents are doing “30% to 50% of all the work in Salesforce itself,” even though that’s an unproven and nakedly ridiculous statement. Salesforce’s CFO said earlier this year that AI wouldn’t boost sales growth in 2025. One would think this would change how they’re covered, or how seriously one takes Marc Benioff. It hasn’t, because nobody is paying attention. In fact, nobody seems to be doing their job. This is how the core myths of generative AI were built: by executives saying stuff and the media publishing it without thinking too hard. AI is replacing workers! AI is writing entire computer programs! AI is getting exponentially more-powerful! What does “powerful” mean? That the models are getting better on benchmarks that are rigged in their favor, but because nobody fucking explains it, regular people are regularly told that AI is “powerful.” The only thing “powerful” about generative AI is its mythology. The world’s executives, entirely disconnected from labor and actual production, are doing the only thing they know how to — spend a bunch of money and say vague stuff about “AI being the future.” There are people — journalists, investors, and analysts — that have built entire careers on filling in the gaps for the powerful as they splurge billions of dollars and repeat with increasing desperation that “the future is here” as absolutely nothing happens. You’ve likely seen a few ridiculous headlines recently. One of the most recent, and most absurd, is that that OpenAI will pay Oracle $300 billion over four years, closely followed with the claim that NVIDIA will “invest” “$100 billion” in OpenAI to build 10GW of AI data centers, though the deal is structured in a way that means that OpenAI is paid “progressively as each gigawatt is deployed,” and OpenAI will be leasing the chips (rather than buying them outright). I must be clear that these deals are intentionally made to continue the myth of generative AI, to pump NVIDIA, and to make sure OpenAI insiders can sell $10.3 billion of shares. OpenAI cannot afford the $300 billion, NVIDIA hasn’t sent OpenAI a cent and won’t do so if it can’t build the data centers, which OpenAI most assuredly can’t afford to do. NVIDIA needs this myth to continue, because in truth, all of these data centers are being built for demand that doesn’t exist, or that — if it exists — doesn’t necessarily translate into business customers paying huge amounts for access to OpenAI’s generative AI services. NVIDIA, OpenAI, CoreWeave and other AI-related companies hope that by announcing theoretical billions of dollars (or hundreds of billions of dollars) of these strange, vague and impossible-seeming deals, they can keep pretending that demand is there, because why else would they build all of these data centers, right? That, and the entire stock market rests on NVIDIA’s back. It accounts for 7% to 8% of the value of the S&P 500, and Jensen Huang needs to keep selling GPUs. I intend to explain later on how all of this works, and how brittle it really is. The intention of these deals is simple: to make you think “this much money can’t be wrong.” It can. These people need you to believe this is inevitable, but they are being proven wrong, again and again, and today I’m going to continue doing so. Underpinning these stories about huge amounts of money and endless opportunity lies a dark secret — that none of this is working, and all of this money has been invested in a technology that doesn’t make much revenue and loves to burn millions or billions or hundreds of billions of dollars. Over half a trillion dollars has gone into an entire industry without a single profitable company developing models or products built on top of models. By my estimates, there is around $44 billion of revenue in generative AI this year (when you add in Anthropic and OpenAI’s revenues to the pot, along with the other stragglers) and most of that number has been gathered through reporting from outlets like The Information, because none of these companies share their revenues, all of them lose shit tons of money, and their actual revenues are really, really small. Only one member of the Magnificent Seven (outside of NVIDIA) has ever disclosed its AI revenue — Microsoft, which stopped reporting in January 2025, when it reported “$13 billion in annualized revenue,” so around $1.083 billion a month. Microsoft is a sales MACHINE. It is built specifically to create or exploit software markets, suffocating competitors by using its scale to drive down prices, and to leverage the ecosystem that it’s created over the past few decades. $1 billion a month in revenue is chump change for an organization that makes over $27 billion a quarter in PROFITS. Don’t worry Satya, I’ll come back to you later. “But Ed, the early days!” Worry not — I’ve got that covered. This is nothing like any other era of tech. There has never been this kind of cash-rush, even in the fiber boom. Over a decade, Amazon spent about one-tenth of the capex that the Magnificent Seven spent in two years on generative AI building AWS — something that now powers a vast chunk of the web, and has long been Amazon’s most profitable business unit. Generative AI is nothing like Uber, with OpenAI and Anthropic’s true costs coming in at about $159 billion in the past two years, approaching five times Uber’s $30 billion all-time burn. And that’s before the bullshit with NVIDIA and Oracle. Microsoft last reported AI revenue in January. It’s October this week. Why did it stop reporting this number, you think? Is it because the numbers are so good it couldn’t possibly let people know? As a general rule, publicly traded companies — especially those where the leadership are compensated primarily in equity — tend to brag about their successes, in part because said bragging boosts the value of the thing that the leadership gets paid in. There’s no benefit to being shy. Oracle literally made a regulatory filing to boast it had a $30 billion customer, which turned out to be OpenAI, who eventually agreed (publicly) to spend $300 billion in compute over five years. Which is to say that Microsoft clearly doesn’t have any good news to share, and as I’ll reveal later, they can’t even get 3% of their 440 million Microsoft 365 subscribers to pay for Microsoft 365 Copilot. If Microsoft can’t sell this shit, nobody can. Anyway, I’m nearly done, sorry, you see, I’m writing this whole thing as if you’re brand new and walking up to this relatively unprepared, so I need to introduce another company. In 2020, a splinter group jumped off of OpenAI, funded by Amazon and Google to do much the same thing as OpenAI but pretend to be nicer about it until they have to raise from the Middle East. Anthropic has always been better at coding for some reason, and people really like its Claude models. Both OpenAI and Anthropic have become the only two companies in generative AI to make any real progress, either in terms of recognition or in sheer commercial terms, accounting for the majority of the revenue in the AI industry. In a very real sense, the AI industry’s revenue is OpenAI and Anthropic. In the year where Microsoft recorded $13bn in AI revenues, $10 billion came from OpenAI’s spending on Microsoft Azure. Anthropic burned $5.3 billion last year — with the vast majority of that going towards compute. Outside of these two companies, there’s barely enough revenue to justify a single data center. Where we sit today is a time of immense tension. Mark Zuckerberg says we’re in a bubble, Sam Altman says we’re in a bubble, Alibaba Chairman and billionaire Joe Tsai says we’re in a bubble, Apollo says we’re in a bubble, nobody is making money and nobody knows why they’re actually doing this anymore, just that they must do it immediately. And they have yet to make the case that generative AI warranted any of these expenditures. That was undoubtedly the longest introduction to a newsletter I’ve ever written, and the reason why I took my time was because this post demands a level of foreshadowing and exposition, and because I want to make it make sense to anyone who reads it — whether they’ve read my newsletter for years, or whether they’re only just now investigating their suspicions that generative AI may not be all it’s cracked up to be. Today I will make the case that generative AI’s fundamental growth story is flawed, and explain why we’re in the midst of an egregious bubble. This industry is sold by keeping things vague, and knowing that most people don’t dig much deeper than a headline, a problem I simply do not have. This industry is effectively in service of two companies — OpenAI and NVIDIA — who pump headlines out through endless contracts between them and subsidiaries or investments to give the illusion of activity. OpenAI is now, at this point, on the hook for over a trillion dollars, an egregious sum for a company that already forecast billions in losses, with no clear explanation as to how it’ll afford any of this beyond “we need more money” and the vague hope that there’s another Softbank or Microsoft waiting in the wings to swoop in and save the day. I’m going to walk you through where I see this industry today, and why I see no future for it beyond a fiery apocalypse. While everybody (reasonably!) harps on about hallucinations — which, to remind you, is when a model authoritatively states something that isn’t true — but the truth is far more complex, and far worse than it seems. You cannot rely on a large language model to do what you want. Even the most highly-tuned models on the most expensive and intricate platform can’t actually be relied upon to do exactly what you want. A “hallucination” isn’t just when these models say something that isn’t true. It’s when they decide to do something wrong because it seems the most likely thing to do, or when a coding model decides to go on a wild goose chase, failing the user and burning a ton of money in the process. The advent of “reasoning” models — those engineered to ‘think’ through problems in a way reminiscent of a human — and the expansion of what people are (trying) to use LLMs for demands that the definition of an AI hallucination be widened, not merely referring to factual errors, but fundamental errors in understanding the user’s request or intent, or what constitutes a task, in part because these models cannot think and do not know anything. However successful a model might be in generating something good *once*, it will also often generate something bad, or it’ll generate the right thing but in an inefficient and over-verbose fashion. You do not know what you’re going to get each time, and hallucinations multiply with the complexity of the thing you’re asking for, or whether a task contains multiple steps (which is a fatal blow to the idea of “agents.” You can add as many levels of intrigue and “reasoning” as you want, but Large Language Models cannot be trusted to do something correctly, or even consistently, every time. Model companies have successfully convinced everybody that the issue is that users are prompting the models wrong, and that people need to be “trained to use AI,” but what they’re doing is training people to explain away the inconsistencies of Large Language Models, and to assume individual responsibility for what is an innate flaw in how large language models work. Large Language Models are also uniquely expensive. Many mistakenly try and claim this is like the dot com boom or Uber, but the basic unit economics of generative AI are insane. Providers must purchase tens or hundreds of thousands of GPUs each costing $50,000 a piece, and hundreds of millions or billions of dollars of infrastructure for large clusters. And that’s without mentioning things like staffing, construction, power, or water. Then you turn them on and start losing money. Despite hundreds of billions of GPUs sold, nobody seems to make any money, other than NVIDIA, the company that makes them, and resellers like Dell and Supermicro who buy the GPUs, put them in servers, and sell them to other people. This arrangement works out great for Jensen Huang, and terribly for everybody else. I am going to explain the insanity of the situation we find ourselves in, and why I continue to do this work undeterred. The bubble has entered its most pornographic, aggressive and destructive stage, where the more obvious it becomes that they’re cooked, the more ridiculous the generative AI industry will act — a dark juxtaposition against every new study that says “generative AI does not work” or new story about ChatGPT’s uncanny ability to activate mental illness in people. So, let’s start simple: NVIDIA is a hardware company that sells GPUs, including the consumer GPUs that you’d see in a modern gaming PC, but when you read someone say “GPU” within the context of AI, they mean enterprise-focused GPUs like the A100, H100, H200, and more modern GPUs like the Blackwell-series B200 and GB200 (which combines two GPUs with an NVIDIA CPU). These GPUs cost anywhere from $30,000 to $50,000 (or as high as $70,000 for the newer Blackwell GPUs), and require tens of thousands of dollars more of infrastructure — networking to “cluster” server racks of GPUs together to provide compute, and massive cooling systems to deal with the massive amounts of heat they produce, as well as the servers themselves that they run on, which typically use top-of-the-line data center CPUs, and contain vast quantities of high-speed memory and storage. While the GPU itself is likely the most expensive single item within an AI server, the other costs — and I’m not even factoring in the actual physical building that the server lives in, or the water or electricity that it uses — add up. I’ve mentioned NVIDIA because it has a virtual monopoly in this space. Generative AI effectively requires NVIDIA GPUs, in part because it’s the only company really making the kinds of high-powered cards that generative AI demands, and because NVIDIA created something called CUDA — a collection of software tools that lets programmers write software that runs on GPUs, which were traditionally used primarily for rendering graphics in games. While there are open-source alternatives, as well as alternatives from Intel (with its ARC GPUs) and AMD (Nvidia’s main rival in the consumer space), these aren’t nearly as mature or feature-rich. Due to the complexities of AI models, one cannot just stand up a few of these things either — you need clusters of thousands, tens of thousands, or hundreds of thousands of them for it to be worthwhile, making any investment in GPUs in the hundreds of millions or billions of dollars, especially considering they require completely different data center architecture to make them run. A common request — like asking a generative AI model to parse through thousands of lines of code and make a change or an addition — may use multiple of these $50,000 GPUs at the same time, and so if you aspire to serve thousands, or millions of concurrent users, you need to spend big. Really big. It’s these factors — the vendor lock-in, the ecosystem, and the fact that generative AI only works when you’re buying GPUs at scale — that underpin the rise of Nvidia. But beyond the economic and technical factors, there are human ones, too. To understand the AI bubble is to understand why CEOs do the things they do. Because an executive’s job is so vague, they can telegraph the value of their “labor” by spending money on initiatives and making partnerships. AI gave hyperscalers the excuse to spend hundreds of billions of dollars on data centers and buy a bunch of GPUs to go in them, because that, to the markets, looks like they’re doing something. By virtue of spending a lot of money in a frighteningly short amount of time, Satya Nadella received multiple glossy profiles, all without having to prove that AI can really do anything, be it a job or make Microsoft money. Nevertheless, AI allowed CEOs to look busy, and once the markets and journalists had agreed on the consensus opinion that “AI would be big,” all that these executives had to do was buy GPUs and “do AI.” We are in the midst of one of the darkest forms of software in history, described by many as an unwanted guest invading their products, their social media feeds, their bosses’ empty minds, and resting in the hands of monsters. Every story of its success feels bereft of any real triumph, with every literal description of its abilities involving multiple caveats about the mistakes it makes or the incredible costs of running it. Generative AI exists for two reasons: to cost money, and to make executives look busy. It was meant to be the new enterprise software and the new iPhone and the new Netflix all at once, a panacea where software guys pay one hardware guy for GPUs to unlock the incredible value creation of the future. Generative AI was always set up to fail, because it was meant to be everything, was talked about like it was everything, is still sold like it’s everything, yet for all the fucking hype, it all comes down to two companies: OpenAI, and, of course, NVIDIA. NVIDIA was, for a while, living high on the hog. All CEO Jensen Huang had to do every three months was saying “check out these numbers” and the markets and business journalists would squeal with glee, even as he said stuff like “the more you buy the more you save,” in part tipping his head to the (very real and sensible) idea of accelerated computing, but framed within the context of the cash inferno that’s generative AI, seems ludicrous. Huang’s showmanship worked really well for NVIDIA for a while, because for a while the growth was easy. Everybody was buying GPUs. Meta, Microsoft, Amazon, Google (and to a lesser extent Apple and Tesla) make up 42% of NVIDIA’s revenue, creating, at least for the first four, a degree of shared mania where everybody justified buying tens of billions of dollars of GPUs a year by saying “the other guy is doing it!” This is one of the major reasons the AI bubble is happening, because people conflated NVIDIA’s incredible sales with “interest in AI,” rather than everybody buying GPUs. Don’t worry, I’ll explain the revenue side a little bit later. We’re here for the long haul. Anyway, NVIDIA is facing a problem — that the only thing that grows forever is cancer. On September 9 2025, the Wall Street Journal said that NVIDIA’s “wow” factor was fading, going from beating analyst estimates in by nearly 21% in its Fiscal Year Q2 2024 earnings to scraping by with a mere 1.52% beat in its most-recent earnings — something that for any other company, would be a good thing, but framed against the delusional expectations that generative AI has inspired, is a figure that looks nothing short of ominous. Per the Wall Street Journal: In any other scenario, 56% year-over-year growth would lead to an abundance of Dom Perignon and Huang signing hundreds of boobs, but this is NVIDIA, and that’s just not good enough. Back in February 2024, NVIDIA was booking 265% year-over-year growth, but in its February 2025 earnings, NVIDIA only grew by a measly 78% year-over-year. It isn’t so much that NVIDIA isn’t growing, but that to grow year-over-year at the rates that people expect is insane. Life was a lot easier when NVIDIA went from $6.05 billion in revenue in Q4 FY2023 to $22 billion in revenue in Q4 FY2024, but for it to grow even 55% year-over-year from Q2 FY2026 ($46.7 billion) to Q2 2027 would require it to make $72.385 billion in revenue in the space of three months, mostly from selling GPUs (which make up around 88% of its revenue). This would put Nvidia in the ballpark of Microsoft ($76 billion in the last quarter) and within the neighborhood of Apple ($94 billion in the last quarter), predominantly making money in an industry that a year-and-a-half ago barely made the company $6 billion in a quarter. And the market needs NVIDIA to perform, as the company makes up 8% of the value of the S&P 500. It’s not enough for it to be wildly profitable, or have a monopsony on selling GPUs, or for it to have effectively 10x’d their stock in a few years. It must continue to grow at the fastest rate of anything ever, making more and more money selling these GPUs to a small group of companies that immediately start losing money once they plug them in. While a few members of the Magnificent Seven could be depended on to funnel tens of billions of dollars into a furnace each quarter, there were limits, even for companies like Microsoft, which had bought over 485,000 GPUs in 2024 alone. To take a step back, companies like Microsoft, Google and Amazon make their money by either selling access to Large Language Models that people incorporate into their products, or by renting out servers full of GPUs to run inference (as said previously, the process to generate an output by a model or series of models) or train AI models for companies that develop and market models themselves, namely Anthropic and OpenAI. The latter revenue stream of which is where Jensen Huang found a solution to that eternal growth problem: the neocloud, namely CoreWeave, Lambda and Nebius. These businesses are fairly straightforward. They own (or lease) data centers that they then fill full of servers that are full of NVIDIA GPUs, which they then rent on an hourly basis to customers, either on a per-GPU basis or in large batches for larger customers, who guarantee they'll use a certain amount of compute and sign up to long-term (i.e. more than an hour at a time) commitments. A neocloud is a specialist cloud compute company that exists only to provide access to GPUs for AI, unlike Amazon Web Services, Microsoft Azure and Google Cloud, all of which have healthy businesses selling other kinds of compute, with AI (as I’ll get into later) failing to provide much of a return on investment. It’s not just the fact that these companies are more specialized than, say, Amazon’s AWS or Microsoft Azure. As you’ve gathered from the name, these are new, young, and in almost all cases, incredibly precarious businesses — each with financial circumstances that would make a Greek finance minister blush. That’s because setting up a neocloud is expensive. Even if the company in question already has data centers — as CoreWeave did with its cryptocurrency mining operation — AI requires completely new data center infrastructure to house and cool the GPUs, and those GPUs also need paying for, and then there’s the other stuff I mentioned earlier, like power, water, and the other bits of the computer (the CPU, the motherboard, the memory and storage, and the housing). As a result, these neoclouds are forced to raise billions of dollars in debt, which they collateralize using the GPUs they already have, along with contracts from customers, which they use to buy more GPUs. CoreWeave, for example, has $25 billion in debt on estimated revenues of $5.35 billion, losing hundreds of millions of dollars a quarter. You know who also invests in these neoclouds? NVIDIA! NVIDIA is also one of CoreWeave’s largest customers (accounting for 15% of its revenue in 2024), and just signed a deal to buy $6.3 billion of any capacity that CoreWeave can’t otherwise sell to someone else through 2032, an extension of a $1.3 billion 2023 deal reported by the Information. It was the anchor investor ($250 million) in CoreWeave’s IPO, too. NVIDIA is currently doing the same thing with Lambda, another neocloud that NVIDIA invested in, which also plans to go public next year. NVIDIA is also one of Lambda’s largest customers, signing a deal with it this summer to rent 10,000 GPUs for $1.3 billion over four years. In the UK, NVIDIA has just invested $700 million in Nscale, a former crypto miner that has never built an AI data center, and that has, despite having no experience, committed $1 billion (and/or 100,000 GPUs) to an OpenAI data center in Norway. On Thursday, September 25, Nscale announced it had closed another funding round, with NVIDIA listed as a main backer — although it’s unclear how much money it put in. It would be safe to assume it’s another few hundred million. NVIDIA also invested in Nebius, an outgrowth of Russian conglomerate Yandex, and Nebius provides, through a partnership with NVIDIA, tens of thousands of dollars’ worth of compute credits to companies in NVIDIA’s Inception startup program. NVIDIA’s plan is simple: fund these neoclouds, let these neoclouds load themselves up with debt, at which point they buy GPUs from NVIDIA, which can then be used as collateral for loans, along with contracts from customers, allowing the neoclouds to buy even more GPUs. It’s like that Robinhood infinite money glitch… …except, that is, for one small problem. There don’t appear to be that many customers. As I went into recently on my premium newsletter, NVIDIA funds and sustains Neoclouds as a way of funnelling revenue to itself, as well as partners like Supermicro and Dell, resellers that take NVIDIA GPUs and put them in servers to sell pre-built to customers. These two companies made up 39% of NVIDIA’s revenues last quarter. Yet when you remove hyperscaler revenue — Microsoft, Amazon, Google, OpenAI and NVIDIA — from the revenues of these neoclouds, there’s barely $1 billion in revenue combined, across CoreWeave, Nebius and Lambda. CoreWeave’s $5.35 billion revenue is predominantly made up of its contracts with NVIDIA, Microsoft (offering compute for OpenAI), Google (hiring CoreWeave to offer compute for OpenAI), and OpenAI itself, which has promised CoreWeave $22.4 billion in business over the next few years. This is all a lot of stuff, so I’ll make it really simple: there is no real money in offering AI compute, but that isn’t Jensen Huang’s problem, so he will simply force NVIDIA to hand money to these companies so that they have contracts to point to when they raise debt to buy more NVIDIA GPUs. Neoclouds are effectively giant private equity vehicles that exist to raise money to buy GPUs from NVIDIA, or for hyperscalers to move money around so that they don’t increase their capital expenditures and can, as Microsoft did earlier in the year, simply walk away from deals they don’t like. Nebius’ “$17.4 billion deal” with Microsoft even included a clause in its 6-K filing that Microsoft can terminate the deal in the event the capacity isn’t built by the delivery dates, and Nebius has already used the contract to raise $3 billion to… build the data center to provide compute for the contract. Here, let me break down the numbers: From my analysis, it appears that CoreWeave, despite expectations to make that $5.35 billion this year, has only around $500 million of non-Magnificent Seven or OpenAI AI revenue in 2025, with Lambda estimated to have around $100 million in AI revenue, and Nebius around $250 million without Microsoft’s share, and that’s being generous. In simpler terms, the Magnificent Seven is the AI bubble, and the AI bubble exists to buy more GPUs, because (as I’ll show) there’s no real money or growth coming out of this, other than in the amount that private credit is investing — “$50 billion a quarter, for the low end, for the past three quarters.” I dunno man, let’s start simple: $50 billion a quarter of data center funding is going into an industry that has less revenue than Genshin Impact. That feels pretty bad. Who’s gonna use these data centers? How are they going to even make money on them? Private equity firms don’t typically hold onto assets, they sell them or take them public. Doesn’t seem great to me! Anyway, if AI was truly the next big growth vehicle, neoclouds would be swimming in diverse global revenue streams. Instead, they’re heavily-centralized around the same few names, one of which (NVIDIA) directly benefits from their existence not as a company doing business, but as an entity that can accrue debt and spend money on GPUs. These Neoclouds are entirely dependent on a continual flow of private credit from firms like Goldman Sachs (Nebius, CoreWeave, Lambda for its IPO), JPMorgan (Lambda, Crusoe, CoreWeave), and Blackstone (Lambda, CoreWeave), who have in a very real sense created an entire debt-based infrastructure to feed billions of dollars directly to NVIDIA, all in the name of an AI revolution that's yet to arrive. The fact that the rest of the neocloud revenue stream is effectively either a hyperscaler or OpenAI is also concerning. Hyperscalers are, at this point, the majority of data center capital expenditures, and have yet to prove any kind of success from building out this capacity, outside, of course, Microsoft’s investment in OpenAI, which has succeeded in generating revenue while burning billions of dollars. Hyperscaler revenue is also capricious, but even if it isn’t, why are there no other major customers? Why, across all of these companies, does there not seem to be one major customer who isn’t OpenAI? The answer is obvious: nobody that wants it can afford it, and those who can afford it don’t need it. It’s also unclear what exactly hyperscalers are doing with this compute, because it sure isn’t “making money.” While Microsoft makes $10 billion in revenue from renting compute to OpenAI via Microsoft Azure, it does so at-cost, and was charging OpenAI $1.30-per-hour for each A100GPU it rents, a loss of $2.2 an hour per GPU, meaning that it is likely losing money on this compute, especially as SemiAnalysis has the total cost per hour per GPU at around $1.46 with the cost of capital and debt associated for a hyperscaler, though it’s unclear if that’s for an H100 or A100 GPU. In any case, how do these neoclouds pay for their debt if the hyperscalers give up, or NVIDIA doesn’t send them money, or, more likely, private credit begins to notice that there’s no real revenue growth outside of circular compute deals with neoclouds’ largest supplier, investor and customer? They don’t! In fact, I have serious concerns that they can’t even build the capacity necessary to fulfil these deals, but nobody seems to worry about that. No, really! It appears to be taking Oracle and Crusoe around 2.5 years per gigawatt of compute capacity. How exactly are any of these neoclouds (or Oracle itself) able to expand to actually capture this revenue? Who knows! But I assume somebody is going to say “OpenAI!” Here’s an insane statistic for you: OpenAI will account for — in both its own revenue (projected $13 billion) and in its own compute costs ($16 billion, according to The Information, although that figure is likely out of date, and seemingly only includes the compute it’ll use, and not that it has committed to build, and thus has spent money on) — about 50% of all AI revenues in 2025. That figure takes into account the $400m ARR for ServiceNow, Adobe, and Salesforce; the $35bn in revenue for the Magnificent Seven from AI (not profit, and based on figures from the previous year); revenue from neoclouds like CoreWeave, Nebius, and Lambda; and the estimated revenue from the entire generative AI industry (including Anthropic and other smaller players, like Perplexity and Anysphere) for a total of $55bn.OpenAI is the generative AI industry — and it’s a dog of a company. As a reminder, OpenAI has leaked that it’ll burn $115 billion in the next four years, and based on my estimates, it needs to raise more than $290 billion in the next four years based on its $300 billion deal with Oracle alone. That alone is a very, very bad sign, especially as we’re three years and $500 billion or more into this hype cycle with few signs of life outside of, well, OpenAI promising people money. Credit to Anthony Restaino for this horrifying graphic: This is not what a healthy, stable industry looks like. Alright, well, things can’t be that bad on the software side. Right? Right? As I covered on my premium newsletter a few weeks ago, everybody is losing money on generative AI, in part because the cost of running AI models is increasing, and in part because the software itself doesn’t do enough to warrant the costs associated with running them, which are already subsidized and unprofitable for the model providers. Outside of OpenAI (and to a lesser extent Anthropic), nobody seems to be making much revenue, with the most “successful” company being Anysphere, makers of AI coding tool Cursor, which hit $500 million ‘annualized” (so $41.6 million in one month) a few months ago, just before Anthropic and OpenAI jacked up the prices for “priority processing” on enterprise queries, raising its operating costs as a result. In any case, that’s some piss-poor revenue for an industry that’s meant to be the future of software. Smartwatches are projected to make $32 billion this year, and as mentioned, the Magnificent Seven expects to make $35 billion or so in revenue from AI this year. Even Anthropic and OpenAI seem a little lethargic, both burning billions of dollars while making, by my estimates, no more than $2 billion and $6.26 billion in 2025 so far, despite projections of $5 billion and $13 billion respectively. Outside of these two, AI startups are floundering, struggling to stay alive and raising money in several-hundred million dollar bursts as their negative-gross-margin businesses flounder. As I dug into a few months ago, I could find only 12 AI-powered companies making more than $8.3 million a month, with two of them slightly improving their revenues, specifically AI search company Perplexity (which has now hit $150 million ARR, or $12.5 million in a month) and AI coding startup Replit (which also hit $150 million ARR in September). Both of these companies burn ridiculous amounts of money. Perplexity burned 164% of its revenue on Amazon Web Services, OpenAI and Anthropic last year, and while Replit hasn’t leaked its costs, The Information reports its gross margins in July were 23%, which doesn’t include the costs of its free users, which you simply have to do with LLMs as free users are capable of costing you a hell of a lot of money. Problematically, your paid users can also cost you more than they bring in as well. In fact, every user loses you money in generative AI, because it’s impossible to do cost control in a consistent manner. A few months ago, I did a piece about Anthropic losing money on every single Claude Code subscriber, and I’ll walk you through it in a very simplified fashion: Anthropic is, to be clear, the second-largest model developer, and has some of the best AI talent in the industry. It has a better handle on its infrastructure than anyone outside of big tech and OpenAI. It still cannot seem to fix this problem, even with weekly rate limits. While one could assume that Anthropic is simply letting people run wild, my theory is far simpler: even the model developers have no real way of limiting user activity, likely due to the architecture of generative AI. I know it sounds insane, but at the most advanced level, model providers are still prompting their models, and whatever rate limits may be in place appear to, at times, get completely ignored, and there doesn’t seem to be anything they can do to stop it. No, really. Anthropic counts amongst its capitalist apex predators one lone Chinese man who spent $50,000 of their compute in the space of a month fucking around with Claude Code. Even if Anthropic was profitable — it isn’t, and will burn billions this year — a customer paying $200-a-month running up $50,000 in costs immediately devours the margin of any user running the service that day, if not that week or month. Even if Anthropic’s costs are half the published rates, one guy amounted to 125 users’ monthly revenue. That’s not a real business! That’s a bad business with out-of-control costs, and it doesn’t appear anybody has these costs under control. A few weeks ago, Replit — an unprofitable AI coding company — released a product called “Agent 3.” which promised to be “10x more autonomous” and offer “infinitely more possibilities,” “[testing] and [fixing] its code, constantly improving your application behind the scenes in a reflection loop.” In reality, this means you’d go and tell the model to build something and it would “go do it,” and you’ll be shocked to hear that these models can’t be relied upon to “go and do” anything. Please note that this was launched a few months after Replit raised its prices, shifting to obfuscated “effort-based” pricing that would charge “the full scope of the agent’s work.” Agent 3 has been a disaster. Users found tasks that previously cost a few dollars were spiralling into the hundreds of dollars, with The Register reporting one customer found themselves with a $1000 bill after a week: Another user complained that “costs skyrocketed, without any concrete results”: As I previously reported, in late May/early June, both OpenAI and Anthropic cranked up the pricing on their enterprise customers, leading to Replit and Cursor both shifting their prices. This abuse has now trickled down to their customers. Replit has now released an update that lets you choose how autonomous you want Agent 3 to be, which is a tacit admission that you can’t trust coding LLMs to build software. Replit’s users are still pissed off, complaining that Replit is charging them for activity when the agent doesn’t do anything, a consistent problem across its Reddit. While Reddit is not the full summation of all users across every company, it’s a fairly good barometer of user sentiment, and man, are users pissy. Traditionally, Silicon Valley startups have relied upon the same model of “grow really fast and burn a bunch of money, then “turn the profit lever.” AI does not have a “profit lever,” because the raw costs of providing access to AI models are so high (and they’re only increasing) that the basic economics of how the tech industry sells software don’t make sense. I’ll reiterate something I wrote a few weeks ago: In simpler terms, it is very, very difficult to imagine what one user — free or otherwise — might cost, and thus it’s hard to charge them on a monthly basis, or tell them what a service might cost them on average. This is a huge problem with AI coding environments. According to The Information, Claude Code was driving “nearly $400 million in annualized revenue, roughly doubling from a few weeks ago” on July 31 2025. That annualized revenue works out to about $33 million a month in revenue for a company that predicts it will make at least $416 million a month by the end of the year, and for a product that has become the most-popular coding environment in the world, from the second-largest and best-funded AI company in the world. …is that it? Is that all that’s happening here? $33 million dollars, all of it unprofitable, after it felt, at least based on social media chatter and discussing with multiple different software engineers, that Claude Code had become ubiquitous with anything to do with LLMs. To be clear, Anthropic’s Sonnet and Opus models are consistently some of the most popular for programming on Openrouter, an aggregator of LLM usage, and Anthropic has been consistently-named as “the best at coding.” Some bright spark out there is going to say that Microsoft’s Github Copilot has 1.8 million paying subscribers, and guess what, that’s true, and in fact, I reported it! Here’s another fun fact: the Wall Street Journal reported that Microsoft loses “on average more than $20-a-month-per-user,” with “...some users [costing] the company as much as $80.” And that’s for the most-popular product! If you believe the New York Times or other outlets that simply copy and paste whatever Dario Amodei says, you’d think that the reason that software engineers are having trouble finding work is because their jobs are being replaced by AI. This grotesque, abusive, manipulative and offensive lie has been propagated throughout the entire business and tech media without anybody sitting down and asking whether it’s true, or even getting a good understanding of what it is that LLMs can actually do with code. Members of the media, I am begging you, stop doing this. I get it, every asshole is willing to give a quote saying that “coding is dead,” and that every executive is willing to burp out some nonsense about replacing all of their engineers, but I am fucking begging you to either use these things yourself, or speak to people that do. I am not a coder. I cannot write or read code. Nevertheless, I am capable of learning, and have spoken to numerous software engineers in the last few months, and basically reached a consensus of “this is kind of useful, sometimes.” However, one very silly man once said that I don’t speak to people who use these tools, so I went and spoke to three notable, experienced software engineers, and asked them to give me the straight truth about what coding LLMs can do. In simple terms, LLMs are capable of writing code, but can’t do software engineering, because software engineering is the process of understanding, maintaining and executing code to produce functional software, and LLMs do not “learn,” cannot “adapt,” and (to paraphrase Brown), break down the more of your code and variables you ask them to look at at once. It’s very easy to believe that software engineering is just writing code, but the reality is that software engineers maintain software, which includes writing and analyzing code among a vast array of different personalities and programs and problems. Good software engineering harkens back to Brian Merchant’s interviews with translators — while some may believe that translators simply tell you what words mean, true translation is communicating the meaning of a sentence, which is cultural, contextual, regional, and personal, and often requires the exercise of creativity and novel thinking. My editor, Matthew Hughes, gave an example of this in his newsletter: Similarly, coding is not just “a series of text that programs a computer,” but a series of interconnected characters that refers to other software in other places that must also function now and explain, on some level, to someone who has never, ever seen the code before, why it was done this way. This is, by the way, why we are still yet to get any tangible proof that AI is replacing software engineers…because it can’t. Of all the fields supposedly at risk from “AI disruption,” coding feels (or felt) the most tangible, if only because the answer to “can you write code with LLMs” wasn’t an immediate, unilateral no. The media has also been quick to say that AI “writes software,” which is true in the same way that ChatGPT “writes novels”. In reality, LLMs can generate code, and do some software engineering-adjacent tasks, but, like all Large Language Models, break down and go totally insane, hallucinating more as the tasks get more complex. And, as I pointed out earlier, software engineering is not just coding. It involves thinking about problems, finding solutions to novel challenges, designing stuff in a way that can be read and maintained by others, and that’s (ideally) scalable and secure. The whole fucking point of an “AI” is that you hand shit off to it! That’s what they’ve been selling it as! That’s why Jensen Huang told kids to stop learning to code, as with AI, there’s no point. And it was all a lie. Generative AI can’t do the job of a software engineer, and it fails while also costing abominable amounts of money. Coding LLMs seem like magic at first, because they (to quote a conversation with Carl Brown) make the easy things easier, but they also make the harder things harder. They don’t even speed up engineers — they actually make them slower! Yet coding is basically the only obvious use case for LLMs. I’m sure you’re gonna say “but I bet the enterprise is doing well!” and you are so very, very wrong. Before I go any further, let’s establish some facts: All of this is to say that Microsoft has one of the largest commercial software empires in history, thousands (if not tens of thousands) of salespeople, and thousands of companies that literally sell Microsoft services for a living. And it can’t sell AI. A source that has seen materials related to sales has confirmed that, as of August 2025, Microsoft has around eight million active licensed users of Microsoft 365 Copilot, amounting to a 1.81% conversion rate across the 440 million Microsoft 365 subscribers. This would amount to, if each of these users paid annually at the full rate of $30-a-month, to about $2.88 billion in annual revenue for a product category that makes $33 billion a fucking quarter. And I must be clear, I am 100% sure these users aren’t all paying $30 a month. The Information reported a few weeks ago that Microsoft has been “reducing the software’s price with more generous discounts on the AI features, according to customers and salespeople,” heavily suggesting discounts had already been happening. Enterprise software is traditionally sold at a discount anyway — or, put a different way, with bulk pricing for those who sign up a bunch of users at once. In fact, I’ve found evidence that it’s been doing this a while, with a 15% discount on annual Microsoft 365 Copilot subscriptions for orders of 10-to-300 seats mentioned by an IT consultant back in late 2024, and another that’s currently running through September 30, 2025 through Microsoft’s Cloud Solution Provider program, with up to 2400 licenses discounted if you pay upfront for the year. Microsoft seems to do this a lot, as I found another example of an offer that ran from January 1 2025 through March 31 2025. An “active” user is someone who has taken one action on Copilot in any Microsoft 365 app in the space of 28 days. Now, I know. That word, active. Maybe you’re thinking “Ed, this is like the gym model! There are unpaid licenses that Microsoft is getting paid for!” Fine! Let’s assume that Microsoft also has, based on research that suggests this is the case for all software companies, another 50% — four million — of paid Copilot licenses that aren’t being used. That still makes this 12 million users, which is still a putrid 2.72% conversion rate. So, why aren’t people paying for Copilot? Let’s hear from someone who talked to The Information: Microsoft 365 Copilot has been such a disaster that Microsoft will now integrate Anthropic’s models in an attempt and make them better. Oh, one other thing: sources also confirm GPU utilization for Microsoft 365’s enterprise Copilot is barely scratching 60%. I’m also hearing that less than SharePoint — another popular enterprise app from Microsoft with 250 million users — had less than 300,000 weekly active users of its AI copilot features in August. So, The Information reported a few months ago that Microsoft’s projected AI revenues would be $13 billion, with $10 billion of that from OpenAI, leaving about $3 billion of total revenue across Microsoft 365 Copilot and any other foreseeable feature that Microsoft sells with “AI” on it. This heavily suggests that Microsoft is making somewhere between $1.5 billion and $2 billion on Azure or Microsoft 365 Copilot, though I suppose there are other places it could be making AI revenue too. Right? I guess. In any case, Microsoft’s net income (read: profit) in its last quarterly earnings was $27.2 billion. Pathetic. One of the comfortable lies that people tell themselves is that the AI bubble is similar to the fiber boom, or the dot com bubble, or Uber, or that we’re in the “growth stage,” or that “this is what software companies do, they spend a bunch of money then “pull the profit lever.” This is nothing like anything you’ve seen before, because this is the dumbest shit that the tech industry has ever done. AI data centers are nothing like fiber, because there are very few actual use cases for these GPUs outside of AI, and none of them are remotely hyperscale revenue drivers. As I discussed a month or so ago, data center development accounted for more of America’s GDP growth than all consumer spending combined, and there really isn’t any demand for AI in general, let alone at the scale that these hundreds of billions of dollars are being sunk into. The conservative estimate of capital expenditures related to data centers is around $400 billion, but given the $50 billion a quarter in private credit, I’m going to guess it breaks $500 billion, all to build capacity for an industry yet to prove itself. And this NVIDIA-OpenAI “$100 billion funding” news should only fill you full of dread, but also it isn’t fucking finalized, stop reporting it as if it’s done, I swear to god- Anyway, according to CNBC, “the initial $10 billion tranche is locked in at a $500 billion valuation and expected to close within a month or so once the transaction has been finalized,” with “successive $10 billion rounds are planned, each to be priced at the company’s then-current valuation as new capacity comes online.” At no point is anyone asking how, exactly, OpenAI builds data centers to fill full of these GPUs. In fact, I am genuinely shocked (and a little disgusted!) by how poorly this story has been told. Let’s go point by point: To be clear, when I say OpenAI needs at least $300 billion over the next four years, that’s if you believe its projections, which you shouldn’t. Let’s walk through its (alleged) numbers, while plagiarizing myself: According to The Information, here's the breakdown (these are projections): OpenAI's current reported burn is $116 billion through 2030, which means there is no way that these projections include $300 billion in compute costs, even when you factor in revenue. There is simply no space in these projections to absorb that $300 billion, and from what I can tell, by 2029, OpenAI will have actually burned more than $290 billion, assuming that it survives that long, which I do not believe it will. Don’t worry, though. OpenAI is about to make some crazy money. Here are the projections that CFO Sarah Friar signed off on: Just so we are clear, OpenAI intends to 10x its revenue in the space of four years, selling software and access to models in an industry with about $60 billion of revenue in 2025. How will it do this? It doesn’t say. I don’t know OpenAI CFO Sarah Friar, but I do know that signing off on these numbers is, at the very least, ethically questionable. Putting aside the ridiculousness of OpenAI’s deals, or its funding requirements, Friar has willfully allowed Sam Altman and OpenAI to state goals that defy reality or good sense, all to take advantage of investors and public markets that have completely lost the plot. I need to be blunter: OpenAI has signed multiple different deals and contracts for amounts it cannot afford to pay, that it cannot hope to raise the money to pay for, that defy the amounts of venture capital and private credit available, all to sustain a company that will burn $300 billion and has no path to profitability of any kind. So, as I said above, CNBC reported on September 23, 2025 that the NVIDIA deal will be delivered in $10 billion tranches, the first of which is “expected to close within a month,” and the rest delivered “as new capacity comes online.” This is, apparently, all part of a plan to build 10GW of data center capacity with NVIDIA. A few key points: So, let’s start simple: data centers take forever to build. As I said previously, based on current reports, it’s taking Oracle and Crusoe around 2.5 years per gigawatt of data center capacity, and nowhere in these reports does one reporter take a second to say “hey, what data centers are you talking about?” or “hey, didn’t Sam Altman say back in July that he was building 10GW of data center capacity with Oracle?” But wait, now Oracle and OpenAI have done another announcement that says they’re only doing 7GW, but they’re “ahead of schedule” on 10GW? Wait, is NVIDIA’s 10GW the same 10GW as Oracle and OpenAI are working on? Is it different? Nobody seems to know or care! Anyway, I cannot be clear enough how unlikely it is that (as NVIDIA has said) “the first gigawatt of NVIDIA systems will be deployed in the second half of 2026,” and that’s if it has bought the land and got the permits and ordered the construction, none of which has happened yet. But let’s get really specific on costs! Crusoe’s 1.2GW of compute for OpenAI is a $15 billion joint venture, which means a gigawatt of compute runs about $12.5 billion. Abilene’s eight buildings are meant to hold 50,000 NVIDIA GB200 GPUs and their associated networking infrastructure, so let’s say a gigawatt is around 333,333 Blackwell GPUs. Though this math is a little funky due to NVIDIA promising to install its new Rubin GPUs in these theoretical data centers, that means these data centers will require a little under $200 billion worth of GPUs. By my maths that’s $325 billion. I’m so tired of this. A number of you have sent me the following image with some sort of comment about how “this is how it’ll work,” and you are wrong, because this is neither how it works nor how it will work nor accurate on any level. In the current relationship, NVIDIA Is Not Sending OpenAI $100 Billion, nor will it send it that much money, because 90% of OpenAI’s funding is gated behind building 9 or 10 gigawatts of data center capacity. In the current relationship, OpenAI does not have the money to pay Oracle. Also, can Oracle even afford to give that much money to NVIDIA? It had negative free cash flow last quarter, already has $104 billion in debt, and its biggest new customer cannot afford a single fucking thing it’s promised. The only company in this diagram that actually can afford to do any of this shit is NVIDIA, and even then it only has $56 billion cash on hand. In any case, as I went over on Friday, OpenAI has promised about a trillion dollars between compute contracts across Oracle, Microsoft, Google and CoreWeave, 17 Gigawatts of promised data centers in America between NVIDIA and “Stargate,” several more gigawatts of international data centers, custom chips from Broadcom, and their own company operations. How exactly does this get paid for? Nobody seems to ask these questions! Why am I the asshole doing this? Don’t we have tech analysts that are meant to analyse shit? AHhhhh- Every time I sit down to write about this subject the newsletters seem to get longer, because people are so painfully attached to the norms and tropes of the past. This post is, already, 17,500 words — a record for this newsletter — and I’ve still not finished editing and expanding it. What we’re witnessing is one of the most egregious wastes of capital in history, sold by career charlatans with their reputations laundered by a tech and business media afraid to criticize the powerful and analysts that don’t seem to want to tell their investors the truth. There are no historic comparisons here — even Britain’s abominable 1800s railway bubble, which absorbed half of the country’s national income, created valuable infrastructure for trains, a vehicle that can move people to and from places. GPUs are not trains, nor are they cars, or even CPUs. They are not adaptable to many other kinds of work, nor are they “the infrastructure of the future of tech,” because they’re already quite old and with everybody focused on buying them, you’d absolutely see one other use case by now that actually mattered. GPUs are expensive, power-hungry, environmentally destructive and require their own kinds of cooling and server infrastructure, making every GPU data center and environmental and fiscal bubble unto themselves. And, whereas the Victorian train infrastructure still exists in the UK — though it has been upgraded over the years — a GPU has a limited useful lifespan. These are cards that can — and will — break after a period of extended usage, whether that period is five years or later, and they’ll inevitably be superseded by something better and more powerful, meaning that the resale value of that GPU will only go down, with a price depreciation that’s akin to a new car. I am telling you, as I have been telling you for years, again and again and again, that the demand is not there for generative AI, and the demand is never, ever arriving. The only reason anyone humours any of this crap is the endless hoarding of GPUs to build capacity for a revolution that will never arrive. Well, that and OpenAI, a company built and sold on lies about ChatGPT’s capabilities. ChatGPT’s popularity — and OpenAI’s hunger for endless amounts of compute — have created the illusion of demand due to the sheer amount of capacity required to keep their services operational, all so they can burn $8 billion or more in 2025 and, if my estimates are right, nearly a trillion dollars by 2030. This NVIDIA deal is a farce — an obvious attempt by the largest company on the American stock market to prop up the one significant revenue-generator in the entire industry, knowing that time is running out for it to create new avenues for eternal growth. I’d argue that NVIDIA’s deal also shows the complete contempt that these companies have for the media. There are no details about how this deal works beyond the initial $10 billion, there’s no land purchased, no data center construction started, and yet the media slurps it down without a second thought. I am but one man, and I am fucking peculiar. I did not learn financial analysis in school, but I appear to be one of the few people doing even the most basic analysis of these deals, and while I’m having a great time doing so, I am also exceedingly frustrated at how little effort is being put into prying apart these deals. I realize how ridiculous all of this sounds. I get it. There’s so much money being promised to so many people, market rallies built off the back of massive deals, and I get that the assumption is that this much money can’t be wrong, that this many people wouldn’t just say stuff without intending to follow through, or without considering whether their company could afford it. I know it’s hard to conceive that hundreds of billions of dollars could be invested in something for no apparent reason, but it’s happening, right god damn now, in front of your eyes, and I am going to be merciless on anyone who attempts to write a “how could we see this coming?” Generative AI has never been reliable, has always been unprofitable, and has always been unsustainable, and I’ve been saying so since February 2024. The economics have never made sense, something I’ve said repeatedly since April 2024, and when I wrote “How Does OpenAI Survive?” in July 2024, I had multiple people suggest I was being alarmist. Here’s some alarmism for you: the longer it takes for OpenAI to die, the more damage it will cause to the tech industry. On Friday, when I put out my piece on OpenAI needing a trillion dollars, I asked analyst Gil Luria if the capital was there to build the 17 Gigawatts that OpenAI had allegedly planned to build. He said the following: That doesn’t sound good! Anyway, as I discussed earlier, venture capital could run out in six quarters, with investor and researcher Jon Sakoda estimating that there will only be around $164 billion of dry powder (available capital) in US VC firms by the end of 2025. In July, The French Tech Journal reported (using Pitchbook data) that global venture capital deal activity reached its lowest first-half total since 2018, with $139.4 billion in deal value in the first half of 2025, down from $183.4 billion in the first half of 2024, meaning that any further expansion or demands for venture capital from OpenAI will likely sap the dwindling funds available from other startups. Things get worse when you narrow things to US venture capital. In a piece from April, EY reported that VC-backed investment in US companies hit $80 billion in Q1 2025, but “one $40 billion deal” accounted for half of the investment — OpenAI’s $40 billion deal of which only $10 billion has actually closed, and that didn’t happen until fucking June. Without the imaginary money from OpenAI, US venture would have declined by 36%. The longer that OpenAI survives, the longer it will sap the remaining billions from the tech ecosystem, and I expect it to extend its tendrils to private credit too. The $325 billion it needs just to fulfil its NVIDIA contract, albeit over 4 years, is an egregious sum that I believe exceeds the available private capital in the world. Let’s get specific, and check out the top 10 private equity firms’ available capital! Assuming that all of this capital is currently available, the top 10 private equity firms in the world have around $477 billion of available capital. We can, of course, include investment banks — Goldman Sachs had around $520 billion cash in hand available at the end of its last quarter, and JPMorgan over $1.7 trillion, but JP Morgan has only dedicated $50 billion in direct lending commitments as of February 2025, and while Goldman Sachs expanded its direct private credit lending by $15 billion back in June, that appears to be an extension of its “more than $20 billion” direct lending close from mid-2024. Include both of those, and that brings us up to — if we assume that all of these funds are available — $562 billion in capital and about $164 billion in US venture available to spend, and that’s meant to go to more places than just OpenAI. Sure, sure, there’s more than just the top 10 private equity firms and there’s venture money outside of the US, but what could it be? Like, another $150 billion? You see, OpenAI needs to buy those GPUs, and it needs to build those data centers, and it needs to pay its thousands of staff and marketing and sales costs too. While OpenAI likely wouldn’t be the ones raising the money for the data centers — and honestly, I’m not sure who would do it at this point? — somebody is going to need to build TWENTY GIGAWATTS OF DATA CENTERS if we’re to believe both Oracle and NVIDIA You may argue that venture funds and private credit can raise more, and you’re right! But at this point, there have been few meaningful acquisitions of AI companies, and zero exits from the billions of dollars put into data centers. Even OpenAI admits in its own announcement about new Stargate sites that this will be a “$400 billion investment over 3 years.” Where the fuck is that money coming from? Is OpenAI really going to absorb massive chunks of all available private credit and venture capital for the next few years? And no, god, stop saying the US government will bail this out. It will have to bail out hundreds of billions of dollars, there is no scenario where it’s anything less than that, and I’ve already been over this. While the US government has spent equivalent sums in the past to support private business (the total $440 billion dispersed during the Great Recession’s TARP program, where the Treasury bought toxic assets from investment banks to stop them from imploding a la Lehman, springs to mind), it’s hard to imagine any case where OpenAI is seen as vital to the global financial system — and the economic health of the US — as the banking system. Sure, we spent around $1tn — if we’re being specific, $953bn — on the Paycheck Protection Program during the Covid era, but that was to keep people employed at a time when the economy outside of Zoom and Walmart had, for all intents and purposes, ceased to exist. There was an urgency that doesn’t apply here. If OpenAI goes tits up, Softbank loses some money — nothing new there — and Satya Nadella has to explain why he spent tens of billions of dollars on a bunch of data centers filled with $50,000 GPUs that are, at this point, ornamental. And while there will be — and have been — disastrous economic consequences, they won’t be as systemically catastrophic as that of the pandemic, or the global financial crisis. To be clear, it’ll be bad, but not as bad. And there’s also the problem of moral hazard — if the government steps in, what’s to stop big tech chasing its next fruitless rainbow? — and optics. If people resented bailing out the banks after they acted like profligate gamblers and lost, how will they feel bailing out fucking Sam Altman and Jensen Huang? I do apologize for the length of this piece, but the significance of this bubble requires depth. There is little demand, little real money, and little reason to continue, and the sheer lack of responsibility and willingness to kneel before the powerful fills me full of angry bile. I understand many journalists are not in a position where they can just write “this shit sounds stupid,” but we have entered a deeply stupid era, and by continuing to perpetuate the myth of AI, the media guarantees that retail investors and regular people’s 401Ks will suffer. It is now inevitable that this bubble bursts. Deutsche Bank has said the AI boom is unsustainable outside of tech spending “remaining parabolic,” which it says “is highly unlikely,” and Bain Capital has said that $2 trillion in new revenue is needed to fund AI’s scaling, and even that math is completely fucked as it talks about “AI-related savings”: Even when stared in the face by a ridiculous idea — $2 trillion of new revenue in a global software market that’s expected to be around $817 billion in 2025 — Bain still oinks out some nonsense about the “savings from applying AI in sales, marketing, customer support and R&D,” yet another myth perpetuated I assume to placate the fucking morons sinking billions into this. Every single “vibe coding is the future,” “the power of AI,” and “AI job loss” story written perpetuates a myth that will only lead to more regular people getting hurt when the bubble bursts. Every article written about OpenAI or NVIDIA or Oracle that doesn’t explicitly state that the money doesn’t exist, that the revenues are impossible, that one of the companies involved burns billions of dollars and has no path to profitability, is an act of irresponsible make believe and mythos. I am nobody. I am not a financier. I am not anybody special. I just write a lot, and read a lot, and can do the most basic maths in the world. I am not trying to be anything other than myself, nor do I have an agenda, other than the fact that I like doing this and I hate how this story is being told. I never planned for this newsletter to get this big, and now that it has, I’m going to keep doing the same thing every week. I also believe that the way to stop this happening again is to have a thorough and well-sourced explanation of everything as it happens, ripping down the narratives as they’re spun and making it clear who benefits from them and how and why they’re choosing to do so. When things collapse, we need to be clear about how many times people chose to look the other way, or to find good faith ways to interpret bad faith announcements and leak. So, how could we have seen this coming? I don’t know. Did anybody try to fucking look? Subscribe today. It's free. Please. Great! You’ve successfully signed up. Welcome back! You've successfully signed in. You've successfully subscribed to Ed Zitron's Where's Your Ed At. Your link has expired. Success! Check your email for magic link to sign-in. Success! Your billing info has been updated. Your billing was not updated.
--------------------------------------------------

Title: Constellation Energy Corporation (CEG): A Bull Case Theory
URL: https://finance.yahoo.com/news/constellation-energy-corporation-ceg-bull-154035543.html
Time Published: 2025-09-28T15:40:35Z
Description: We came across a bullish thesis on Constellation Energy Corporation on Make Money, Make Time’s Substack by Oliver | MMMT Wealth. In this article, we will...
--------------------------------------------------

Title: Hello Group Inc. (MOMO): A Bull Case Theory
URL: https://finance.yahoo.com/news/hello-group-inc-momo-bull-154014565.html
Time Published: 2025-09-28T15:40:14Z
Description: We came across a bullish thesis on Hello Group Inc. on Value investing subreddit by hardervalue. In this article, we will summarize the bulls’ thesis on MOMO...
--------------------------------------------------

Title: Everyone’s wondering if, and when, the AI bubble will pop. Here’s what went down 25 years ago that ultimately burst the dot-com boom
URL: https://finance.yahoo.com/news/everyone-wondering-ai-bubble-pop-120500253.html
Time Published: 2025-09-28T12:05:00Z
Description: Sam Altman and Mark Zuckerberg have acknowledged the parallels.
--------------------------------------------------

Title: Everyone’s wondering if, and when, the AI bubble will pop. Here’s what went down 25 years ago that ultimately burst the dot-com boom
URL: https://fortune.com/2025/09/28/ai-dot-com-bubble-parallels-history-explained-companies-revenue-infrastructure/
Time Published: 2025-09-28T12:05:00Z
Full Content:
Dave Smith is a writer and editor who previously has been published in Business Insider, Newsweek, ABC News, and USA TODAY. The comparison between today’s artificial intelligence frenzy and the dot-com bubble of the late 1990s has become impossible to ignore. As AI companies command valuations reaching into the hundreds of billions—minting dozens of new billionaires in 2025 alone—and tech giants pour unprecedented sums into data centers, investors and analysts are asking a similar question: Are we watching history repeat itself? The similarities are striking. Like the internet companies of two decades ago, AI firms today attract massive investments based on transformative potential rather than current profitability. Global corporate AI investment reached $252.3 billion in 2024, according to research from Stanford University, with the sector growing thirteenfold since 2014. Meanwhile, America’s biggest tech companies—Amazon, Google, Meta, and Microsoft—have pledged to spend a record $320 billion on capital expenditures this year alone, much of it for AI infrastructure. Even OpenAI CEO Sam Altman, whose company is valued at approximately $500 billion despite launching ChatGPT just two years ago, acknowledges the parallels. “ Are we in a phase where investors as a whole are overexcited about AI? My opinion is yes,” Altman said in August. “Is AI the most important thing to happen in a very long time? My opinion is also yes.” But what actually caused the dot-com bubble to burst in March 2000, and what lessons does it offer for today’s AI boom? Let’s take a stroll down memory lane—or, if you weren’t born yet, some plain ole history. The dot-com crash wasn’t triggered by a single event, but rather a convergence of factors that exposed fundamental weaknesses in the late 1990s tech economy. The first critical blow came from the Federal Reserve, which raised interest rates multiple times throughout 1999 and 2000. The federal funds rate climbed from around 4.7% in early 1999 to 6.5% by May 2000, making speculative investments less attractive as investors could earn higher returns from safer bonds. The second catalyst was a broader economic recession that began in Japan in March 2000, triggering global market fears and accelerating the flight from risky assets. This one-two punch of higher rates and global uncertainty caused investors to reassess the astronomical valuations of internet companies. But the underlying problem ran much deeper: Most dot-com companies had fundamentally flawed business models. Commerce One reached a $21 billion valuation despite minimal revenue. TheGlobe.com, founded by two Cornell students with $15,000 in startup capital, saw its stock price jump 606% on its first day of trading to $63.50, despite having no revenue beyond venture funding. Pets.com burned through $300 million in just 268 days before declaring bankruptcy. Perhaps the most instructive parallel for today’s AI boom lies in the massive infrastructure overinvestment that preceded the dot-com crash. Telecommunications companies laid more than 80 million miles of fiber optic cables across the U.S., driven by WorldCom’s wildly inflated claim that internet traffic was doubling every 100 days—far beyond the actual annual doubling rate. Companies like Global Crossing, Level 3, and Qwest raced to build massive networks to capture anticipated demand that never materialized. The result was catastrophic overcapacity. Even four years after the bubble burst, 85% to 95% of the fiber laid in the 1990s remained unused, earning the nickname “dark fiber.” Corning, the world’s largest optical-fiber producer, saw its stock crash from nearly $100 in 2000 to about $1 by 2002. Ciena’s revenue fell from $1.6 billion to $300 million almost overnight, with its stock plunging 98% from its peak. The parallels to today’s AI infrastructure buildout are unmistakable. Meta CEO Mark Zuckerberg announced plans this year for an AI data center “so large it could cover a significant part of Manhattan”. The Stargate Project, backed by OpenAI, SoftBank, Oracle, and MGX, aims to develop a $500 billion nationwide network of AI data centers. Yet, crucial differences exist. Unlike many dot-com companies that had no revenue, major AI players are generating substantial income. Microsoft’s Azure cloud service, heavily focused on AI, grew 39% year-over-year to an $86 billion run rate. OpenAI projects $20 billion in annualized revenue by the end of the year, according to The Information, up from around $6 billion at the start of the year. The dot-com crash ultimately came down to a harsh reality: Most internet companies couldn’t justify their valuations with actual business results. Companies were valued based on website traffic and growth metrics rather than traditional measures like cash flow and profitability. Today’s AI companies face a similar test. While AI investment has reached historic levels, the revenue gap remains substantial. According to tech writer Ed Zitron, Microsoft, Meta, Tesla, Amazon, and Google will have invested about $560 billion in AI infrastructure over the last two years, but have brought in just $35 billion in AI-related revenue combined. A recent MIT study found that 95% of AI pilot projects fail to yield meaningful results, despite more than $40 billion in generative AI investment. This disconnect between investment and returns echoes the fundamental problem that ultimately doomed the dot-com bubble. The question facing investors today isn’t whether AI will transform the economy—most experts agree it will. The question is whether current valuations and infrastructure investments can be justified by near-term returns, or whether, like the fiber-optic cables of the 1990s, much of today’s AI infrastructure will sit unused while the market awaits demand to catch up with supply. As history shows, even transformative technologies can’t escape the gravitational pull of economics—so while the internet did change the world, it didn’t happen as quickly as some of its early champions promised, and several of those people who got ahead of themselves were humbled in the process. For this story, Fortune used generative AI to help with an initial draft. An editor verified the accuracy of the information before publishing. © 2025 Fortune Media IP Limited. All Rights Reserved. Use of this site constitutes acceptance of our Terms of Use and Privacy Policy | CA Notice at Collection and Privacy Notice | Do Not Sell/Share My Personal Information FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.
--------------------------------------------------

Title: Amazon’s fall hardware event: 5 Echo devices overdue for an upgrade
URL: https://www.pcworld.com/article/2917091/amazons-fall-hardware-event-5-echo-devices-overdue-for-an-upgrade.html
Time Published: 2025-09-28T12:00:00Z
Full Content:
When you purchase through links in our articles, we may earn a small commission. This doesn't affect our editorial independence. After skipping last year, Amazon is back with a big fall hardware event slated for next week, and we’re expecting plenty of new Echo smart speakers and displays that make the most of Alexa+, Amazon’s AI revamp of the Alexa voice assistant. Plenty of other hardware will also be unwrapped during Amazon’s September 30 event in New York City; for example, we’re sure to see new Kindle tablets, as well as Fire TV models and perhaps even some Ring cameras. For now, though, we’re concentrating on new Echo devices, and there are a few popular Echo speakers and displays that are ripe for an upgrade. We’re most interested in how the latest Echo hardware will take full advantage of Alexa+, the generative AI-enhanced Alexa that can carry on flowing conversations, take actions on your behalf, and control smart home devices based on natural-language commands. (It’s worth noting that most existing Echo speakers and displays already are compatible with Alexa+, so there’s no pressing need to upgrade if you don’t want to.) There haven’t been many leaks or rumors about specific new Echo devices we might see next week. That said, we do have a bead on some older but nonetheless popular Echo speakers and displays that are in dire need of a refresh. What is it: Amazon’s flagship Echo speaker that doubles as a smart home hub Latest release: 2020 (fourth generation) List price: $99.99 Michael Brown/Foundry It’s been nearly five years since Amazon released a new version of its top-of-the-line Echo, making it the oldest speaker in Amazon’s current Echo lineup. It’s high time for a new one. A larger version of the popular and inexpensive Echo Dot, the Amazon Echo shares many of the Dot’s features, including motion detection, a temperature sensor, and the ability to extend the range of Amazon’s line of Eero mesh Wi-Fi routers. The Echo also houses stereo tweeters and a three-inch woofer, making for a nice upgrade to the Echo Dot’s so-so audio performance. But the Echo has an ace up its sleeve: a full-on Zigbee home hub, capable of directly controlling Zigbee lights, sensors, switches, and other Zigbee-enabled devices. The Echo also packs a Thread radio, allowing it to act as a Thread border router. Plunk an Echo in your living room, and you have everything you need to launch your smart home—well, aside from a Z-Wave radio, which would be a cool feature for an updated Echo. (We’re not holding on breath on that one, as Z-Wave is not embraced by the Matter standard.) An all-new Echo would seem like a no-brainer for Amazon’s hardware event next week, complete with beefier hardware for smoother Alexa+ performance and perhaps even a physical makeover. What it is: Amazon’s budget-priced Echo workhorse Latest release: 2022 (fifth generation) List price: $49.99 Ben Patterson/Foundry If the Echo is Amazon’s flagship smart speaker, the Echo Dot is its smaller sibling, shedding the Zigbee smart hub but keeping the motion and temperature sensors as well as the Eero mesh extender functionality. Priced at $50 but often on sale for much less, the Echo Dot is a smart choice for putting Alexa in every room, what with its handsome design and good-enough audio performance. There are now cheaper Echos in Amazon’s lineup—see the $40 Echo Pop from 2023—but the Echo Dot hits the sweet spot in terms of price and performance. Now that it’s due to celebrate its third birthday, the Echo Dot is primed for a new Alexa+-enhanced version. I could see it sharing the same overall design as the new Echo—smaller form factor, of course—with a modest audio upgrade and even a Thread border router functionality, which would allow the Dot to act as a hub for Matter devices. What it is: A premium Echo speaker that does Dolby Atmos Latest release: 2023 (second generation) List price: $199.99 (no longer available) Amazon If you want an Amazon Echo speaker that can truly put on a sonic show, the Dolby Atmos-enabled Echo Studio is the obvious choice—if you can find one, that is. The second-generation Echo Studio has been out of stock for months now, making it a prime candidate for a makeover. Packing three two-inch mid-range speakers, a 20mm tweeter, and a 5.25-inch woofer, the Echo Studio has all the drivers its needs to belt out audiophile-quality sound. The Echo Studio isn’t just a great music speaker, though. Like the Echo, it offers a Zigbee home hub and a Matter hub. An upgraded version of the Studio with Alexa+ playing DJ could be a highlight of Amazon’s hardware event next week. What it is: An Echo display with a pivoting screen that follows you around the room Latest release: 2021 (third generation) List price: $249.99 (no longer available) Michael Brown/Foundry Hard to believe, but it’s been four years since the Echo Show 10 made its debut, and boy was it a showstopper. Yes, the Echo Show 10 boasts such smart home features as a Zigbee hub and a Thread border router (the unit’s Matter-over-Thread abilities were enabled after launch), 2.1-channel audio, a 13-megapixel camera, and an impressive 10-inch screen. But its killer feature was its swiveling display, which could follow you as you strolled around the room. That rotating display made the Echo Show 10 feel like the most aware Echo device yet, so just imagine how that would play with Alexa+ on board, looking out into your kitchen and making suggestions as you prepare a gourmet meal. Sure, Alexa+ can already work on the existing third-gen Echo Show 10, but we’re eager to see a new take on that motorized design. As with the Echo Studio, the Echo Show 10 has been unavailable via Amazon for some time, leading us to believe that a fourth generation of the display is imminent. What is it: Amazon’s Alexa-powered smart glasses Latest release: 2023 (third generation) List price: Varies depending upon style Ben Patterson/Foundry With the likes of Meta’s camera-enabled AI glasses on the scene, Amazon’s audio-only Echo Frames are looking decidedly old hat these days. First announced back in 2019, the Echo Frames came with a handsome design and mini speakers and microphones in the temples that promised to put Alexa in your head. The most recent release from 2023 offered updated looks and plenty of audio refinements, and the Frames are now compatible with Alexa+. Still, the basic conceit and limitations remain: it’s Alexa (or Alexa+) in your head, and only in your head. Meta, meanwhile, has supercharged the market for smart glasses that allow an AI companion to see the world around you, offering commentary and insights wherever you go (even if the results are a tad uneven). Will Amazon take the fight to Meta with vision-enabled Echo Frames with Alexa+? It’s a bit of a long shot, but I’m not ruling it out. This feature is part of TechHive’s in-depth coverage of the best smart speakers. Ben has been writing about technology and consumer electronics for more than 20 years. A PCWorld contributor since 2014, Ben joined TechHive in 2019, where he has covered everything from smart speakers and soundbars to smart lights and security cameras. Ben's articles have also appeared in PC Magazine, TIME, Wired, CNET, Men's Fitness, Mobile Magazine, and more. Ben holds a master's degree in English literature. Business Laptop Mobile PC Hardware Storage Deals TechHive Digital Magazine - Subscribe Digital Magazine - Info Gift Subscription Newsletters
--------------------------------------------------

Title: What is mNAV? How to calculate and trade it? Your DefiLlama guide to the metric for digital asset treasuries
URL: https://www.dlnews.com/articles/llama-u/hype-dat-ecosystem-case-study-for-mnav/
Time Published: 2025-09-27T14:00:00Z
Full Content:
About us Copy link Digital asset treasuries have become crypto’s hottest trade, with over 200 companies now holding billions in tokens on their balance sheets. But investors are calculating the same metric called mNAV in such different ways that this has created a hall of mirrors where the same stock can look like a 90% discount or a 500% premium. The problem isn’t trivial since investors are making million-dollar-bets based on data that’s off by multiples. The article below written by pseudonymous DefiLlama analyst Meta explains how to make sense of this complex metric and trade it accurately. mNAV is short for market-cap-to-net-asset-value multiple. It tells you how much equity value you’re paying for every $1 of crypto the company holds. mNAV = Fully Diluted MarketCap ÷ Treasury Value (USD) We run it three ways: Realized: shares that exist today Realistic: realized plus in-the-money dilution (options, warrants, convertibles, RSUs) Maximum: everything that could possibly printAll three are often incorrectly used interchangeably by people when discussing “fully diluted” sharecounts, marketcaps, and mNAVs. In practice, doing so inevitably leads to miscommunication, disagreement, and, most consequentially, trades executed without full knowledge of what the true values actually are. The lens you pick to perceive through will change the picture in potentially radical ways. Realized can look like a discount. Maximum often will show the extreme or “worst-case” scenario of a premium. The HYPE DAT ecosystem is one of the clearest examples of why mNAV matters and how it gets misread, miscalculated, and, even, misreported. The three main HYPE treasury plays right now are: HYPD (Hyperion DeFi), SONN (soon to merge into Hyperliquid Strategies, HSI), and LGHL (Lion Group). Galaxy Digital (GLXY) also holds HYPE however because of its broader business mix, it’s been left out deliberately as it is not a pure DAT-focused trade. Depending on which share count you use to calculate for marketcaps, these stocks can look like deep discounts or expensive premiums. One investor will say SONN is 0.06x. Another will say it’s 5.27x. Both are technically right. They’re just using different denominators.That contrast is exactly why the HYPE DATs make for a clean case study. We’ll break down each company, walk through the math, and show where people can get tripped up. Treasury: 1,535,772 HYPE × $48 = $73,717,056 Price: $10.34 Takeaway: On realized shares HYPD trades at 0.79x. That’s a discount. Once you layer in dilution it jumps to 5–8x, which is firmly premium. Treasury: 12,600,000 HYPE × $48 = $604,800,000 Price: $5.66 Takeaway: On today’s count SONN screens at 0.06x. That’s a massive discount. On the real post-merge base it’s a 5.27x premium. Same stock, two different answers. Treasury: - 194,726 HYPE × $48 = $9,346,848- 6,707 SOL × $220 = $1,475,540- Total = $10,822,388Price: $1.43 Takeaway: On realized and realistic shares LGHL trades under 0.1x. That’s a steep discount. On maximum it jumps to 4x premium. The swing is all about which share count you pick. Informed decision making becomes paramount when you consider such discrepancies. Yahoo currently shows: Three different answers from the same site. Now convert the float to ADS instead of ordinary:- 904,930,000 ÷ 2,500 = 361,972 ADS- Marketcap = $517,622- mNAV = 0.0478x Still wrong, but at least consistent. The correct counts from filings are 737,193 ADS (realized), 742,993 ADS (realistic), and 30,406,496 ADS (maximum). Those give 0.0974x, 0.0982x, and 4.0177x. Lesson: Yahoo Finance mixes units and lags filings. Always go back to the SEC. Key: <1x = Discount- 1x = Equal- >1x = Premium mNAV is the backbone of the DAT trade. It won’t replace judgment, but it grounds it. With clean numbers you know when you’re buying tokens at a discount, equal value, or paying a premium. That’s the difference between trading narratives and trading based on numbers. Prices move fast, narratives move faster, but underneath all the noise each ticker is just a wrapper around a pile of tokens. If you’re sloppy with the numbers, you’ll fool yourself. Everyone wants the shortcut. Use today’s SONN share count instead of the post-merge count and it’ll look like a steal at 0.06x. In reality, it’s a 5.27x premium. Take LGHL’s ordinary shares and multiply them by the ADS price and, suddenly, you end up with mNAVs in the hundreds or thousands of x. Rely on Yahoo’s “float” line and you may as well be pulling numbers out of thin air. The fix is simple. Stick with filings, pick your lens, and stay consistent or simply use DeFiLlama. This way you’ll actually know if you’re buying tokens at a discount, equal value, or paying a premium. mNAV won’t tell you everything. Sentiment, liquidity, and timing all still very much matter and should be factored in for. mNAV alone won’t replace judgment, but it grounds it. With clean numbers, you know when you’re buying tokens at a discount, equal value, or paying a premium. That’s how you avoid chasing what can look like free money and then getting steamrolled when the market reprices overnight. The edge in DATs is about doing the math right using the most-up-to-date data while others cut corners. All the mNAVs on DeFiLlama’s website are standardized to using tokens only, which is simpler to calculate but not the same as Enterprise Value as such you may find discrepancies when comparing mNAV values from MSTR’s website for example. Always check to see if there is an express mention of what variables are being utilized to calculate a reported mNAV when dealing with different sources.
--------------------------------------------------

Title: A $25 Billion Reason to Buy Meta Platforms Stock Here
URL: https://www.barchart.com/story/news/35080948/a-25-billion-reason-to-buy-meta-platforms-stock-here
Time Published: 2025-09-27T13:00:02Z
Description: Barclays says that the ability to monetize Instagram and Threads could represent $25 billion in revenue for Meta.
--------------------------------------------------

Title: Kingspan chases Magnificent Seven energy with plan to float unit riding on AI boom
URL: https://www.irishtimes.com/business/2025/09/27/kingspan-chases-magnificent-seven-energy-with-plan-to-float-unit-riding-on-ai-boom/
Time Published: 2025-09-27T05:45:00Z
Full Content:
Fed up with Kingspan shares drifting behind peers and the wider market, Gene Murtagh is seeking to tap into some of the energy of the Magnificent Seven (Mag-7), the US tech stocks that have driven a three-year bull run across global equity markets. The Kingspan chief executive revealed on Tuesday that the insulation giant founded 60 years ago by his father, Eugene, plans to float 25 per cent of its advanced building systems unit Advnsys, which is focused on supplying the global data centres boom, in Amsterdam. The mushrooming of data centres has been turbocharged by the artificial intelligence (AI) revolution that has driven the share prices in recent times of Mag-7 stalwarts such as chipmaker Nvidia, Microsoft, Google-parent Alphabet and Meta, owner of Facebook and Instagram. Close to $7 trillion (€6 trillion) will need to be spent on data centres globally by 2030, driven by demand for hubs equipped to handle AI processing loads, McKinsey, the management consultancy firm, estimated in a recent report. “We’re acutely cognisant of the fact that relevant sector peers – and these are not building sector peers, they’re tech-end peers that are supplying the data centre market – are trading at and above 20 times Ebitda,” Murtagh said on a call with analysts, referring to how others in the data centre space are being valued by the stock market at more than 20 times earnings before interest, tax, depreciation and amortisation. Valuing Advnsys along these lines would give it an initial market capitalisation of at least €6 billion. [ Kingspan shares soar on potential €6bn flotation of unit riding data centres boomOpens in new window ] Kingspan had lost more than a third of its market value in the four years before the move was announced – and was down 21 per cent on the year as it grappled with what Murtagh recently described as an ongoing “pretty unforgiving environment” for construction suppliers globally as households and businesses fret about a potential recession. The group is trading at about 10 times Ebitda – compared with its 10-year average of 13.5. Compare that with Vertiv, an Ohio-based provider of critical infrastructure and services for data centres, whose stock has soared more than 400 per cent over the past four years. Or with Trane Technologies, the Swords-headquartered but New York-listed maker of heating and cooling systems for commercial buildings, whose market value has more than doubled in the same period, to $90 billion, amid a surge in demand for its data centre air-cooling systems. The AI boom – like red-hot stock market trends before it – has attracted blatantly cynical pivots and rebrands from companies trying to jump on the bandwagon. But Kingspan has been a supplier to the data centres market since before Murtagh became CEO 20 years ago. The new Advnsys unit being lined up for an initial public offering (IPO) – which combines its data centre solutions and light, air and water businesses into one – is a world leader in bespoke critical infrastructure primarily focused on data centres, ventilation and daylighting. [ Kingspan trades profit for position in US roofing raceOpens in new window ] While about 40 per cent of Advnsys’s earnings currently come from providing infrastructure to the tech sector, particularly to data centres, this is expected to grow to about 75 per cent of an even bigger business in the next three to five years, according to the group. Citigroup analysts reckon the subsidiary could more than double its revenue and Ebitda between 2024 and 2030, to €3.2 billion and €525 million, respectively. Shares in Kingspan jumped as much as 13.5 per cent to €74.85 on Tuesday morning, but have since handed back almost half their gains as some analysts urged caution. “While we understand the [market] reaction, particularly in light of the stock’s weaker performance year-to-date, we do not yet understand how a partial IPO creates additional value, nor how the market will arbitrage valuation between the two businesses,” said JP Morgan analysts led by Elodie Rall in a note to clients. Advnsys may attract a higher valuation multiple, but this is likely to be offset by the market giving the rest of the business – comprising insulated panels, other insulation solutions and its roofing and waterproofing unit – a lower one, she said. [ Kingspan plans €650m share buy back as half year revenues rise 8% to record €4.5bnOpens in new window ] Bernstein’s Pujarini Ghosh said the market excitement earlier in the week had been “overdone” and her €70 price target on the group points to almost 3 per cent downside from here. A listing of Advnsys in New York “could potentially have helped unlock greater value given the business mix will be more heavily skewed to the US”, she said. About 45 per cent of the unit’s business is exposed to the US, but this is expected to rise well above 50 per cent in the coming years. Murtagh said the decision to float on Euronext Amsterdam is down to the high level of trading in stocks in that market, a lack of stamp duty there, too, and how the same accounting standard (IFRS) applies to companies in the Netherlands and Ireland. For sure, the level of trading in Euronext Dublin has slumped over the past five years amid a number of company exits and a dearth of fresh IPOs. [ How Kingspan stands to benefit from AI boomOpens in new window ] But to avoid the 1 per cent stamp duty applied to share trading in Irish companies, Kingspan will need to incorporate Advnsys as a public limited company – or naamloze vennootschap (NV) – in the Netherlands. A nice bonus from the planned IPO is that it would, according to Murtagh. leave both Kingspan and Advnsys “essentially with zero debt” – giving them plenty of scope to invest and grow by acquisition. Whereas Kingspan’s share price tends to move with the broader construction industry cycle, Advnsys’s stock will be far more sensitive to developments in AI, making it potentially much more volatile. Chinese tech group DeepSeek, for example, showed the world earlier this year that its approach to generative AI needs just a fraction of the computing power of more prominent US tools, such as ChatGPT. Could demand for data centres decline as AI systems become more efficient? One thing’s for sure: savvy investors in Advnsys in Amsterdam will have alerts set for anything coming from another company 9,000km away. For now, Nvidia in Santa Clara, California, remains the bellwether for all things AI. Get the latest business news and commentary from our expert business team in your inbox every weekday morning © 2025 The Irish Times DAC
--------------------------------------------------

Title: Oracle (ORCL) Stock: Analyst Reiterates $342 PT Amid AI Cloud and TikTok Deal Buzz
URL: https://finance.yahoo.com/news/oracle-orcl-stock-analyst-reiterates-231827643.html
Time Published: 2025-09-26T23:18:27Z
Description: Oracle Corporation (NYSE:ORCL) is one of the AI Stocks in the Spotlight This Week. On September 24, Citizens JMP analyst Patrick Walravens reiterated a...
--------------------------------------------------

Title: Harbor Capital Appreciation Fund Reduces Stake in Netflix Inc by 1.7%
URL: https://finance.yahoo.com/news/harbor-capital-appreciation-fund-reduces-230309131.html
Time Published: 2025-09-26T23:03:09Z
Description: Insights into the Fund's Strategic Moves in Q3 2025
--------------------------------------------------

Title: Adobe (ADBE) Stock Downgraded at Morgan Stanley on Slower AI Monetization
URL: https://finance.yahoo.com/news/adobe-adbe-stock-downgraded-morgan-225656119.html
Time Published: 2025-09-26T22:56:56Z
Description: Adobe Inc. (NASDAQ:ADBE) is one of the AI Stocks in the Spotlight This Week. On September 24, Morgan Stanley analyst Keith Weiss downgraded the stock from...
--------------------------------------------------

Title: Pure, Concentrated Risk
URL: https://dailyreckoning.com/pure-concentrated-risk/
Time Published: 2025-09-26T22:00:54Z
Full Content:
By Adam Sharp PostedSeptember 26, 2025 Over the past 10 years, a $10,000 investment in the S&P 500 would have grown to around $38,260. That’s based on the SPY ETF with dividends reinvested. But the tech-heavy Nasdaq 100 would have turned every $10,000 into $58,866 over the same period. That’s based on the QQQ ETF and also assumes dividends are reinvested. Historically speaking, these are abnormally high returns. Instead of the 8% per year long-term average, broad U.S. stock indexes have essentially doubled that (or more) over the past decade. The question investors should be asking is: is this sustainable? My answer: no. Take a look at the chart below. It shows the S&P 500’s CAPE (cyclically adjusted price/earnings) ratio. This metric looks at 10 years of price-to-earnings, and adjusts for inflation. Source: Multpl via Meb Faber It’s also known as the Shiller PE ratio. When it’s sky high (like today) that means stocks are overvalued and should have low returns going forward. The Shiller PE ratio today is at 39. That’s quite close to the 2000 highs of around 44. And far above the 1929 peak of 34. And according to Warren Buffett’s favorite valuation metric, stocks are even more expensive than 2000. More on that in last month’s Bubble Poponomics. To me, this is yet another signal that we’re nearing a local peak in U.S. markets. However, the market often ends these bubbly periods with one last great “blow-off top”. Whether this recent move qualifies is subjective, but my guess is that we might see at least one more sharp move up before the party ends. These big gains in both the S&P and the Nasdaq have been driven by one sector: big tech. Specifically, the “Magnificent 7”: Apple, Amazon, Alphabet, Meta, Microsoft, NVIDIA, and Tesla. Over the past 10 years, the Mag 7 has returned a ridiculous 39% per year on average. Even among these high-flyers, NVIDIA stands out. It is now the largest company in the world with a market capitalization of $4.3 trillion. NVIDIA currently makes up a whopping 7.7% of the S&P 500. So out of the 500 largest publicly-traded companies in America, a single stock makes up almost 8%. In total, the Mag 7 makes up about 34% of America’s standard benchmark index. The Nasdaq 100 is even more concentrated with big tech. NVIDIA makes up 9.42% of the Nasdaq 100. Microsoft accounts for 8.3%, and Apple 8.2%. The concentration risk here is extraordinary. At this point the fate of U.S. stock indexes are completely tied to this AI bubble. If (when) it falters, the house of cards will collapse. Consumer spending will plummet, then the broad market will follow. As tempting as it is to guess the exact moment when the bubble will pop, it’s ultimately futile. So besides a few tiny hedges, I am mostly avoiding shorting this market for now. Most of us who live in America have plenty of exposure to the U.S. economy. Through our jobs, investments, dollars, and homes. So it makes sense, in this environment, to hedge our bets. This is where gold and silver come into play. Miners too, of course. Precious metals are global assets which act as excellent hedges. In previous periods where bubbles popped, like after the dotcom one, precious metals and hard assets soared as formerly “hot sectors” plummeted. And our emerging market thesis is starting to pay off, with the iShares Brazil ETF (EWZ) now up around 20% since we first wrote up that story. Brazilian markets are cheap with big yields, and thus have a lot less far to fall if things go south. Oil is another contrarian bet I like. The energy sector is dirt cheap, offers fat dividend yields for compounding, and should offer significant protection against inflationary forces. More on that here. By now, you regular readers may be getting tired of me writing about how gold, silver, miners, oil, and emerging markets are excellent alternatives to the standard big U.S. indexes. But this is a point I really want to hammer home. We are entering what is sure to be a chaotic time for stocks, fiat currencies, and generally speaking, the world. Don’t let the new all-time index highs fool you. This is a precarious time. Look at gold and silver. They are sending a more urgent message. Something isn’t right, and savvy investors can feel it coming. Hedging our bets in this environment isn’t just a clever idea, it’s a necessity.
--------------------------------------------------

Title: Weekend reading: Livin’ la vida loca
URL: https://monevator.com/weekend-reading-livin-la-vida-loca/
Time Published: 2025-09-26T20:44:15Z
Full Content:
What caught my eye this week. I am definitely not saying that the massive megacap tech deals of the past fortnight will for sure end badly. Let alone that such deals must mark the top of this bull market. Credit with me some learning! After more than two decades of meddling in the markets – and nearly as long making public pronouncements on this blog and elsewhere – it’d be a sackable offence for me not to have learned a bit of humility along the way. Markets can remain irrational longer than you can believe what you’re reading on social media, as Keynes almost said. Markets also have a way of turning today’s ‘irrationality’ into tomorrow’s ‘crucial staging point that any fool could have identified’ if you wait long enough for the proper perspective. So yes, Nvidia investing $100bn in its major client OpenAI – or Oracle leveraging up to build out the data centre capacity required to fulfil the staggering $300bn compute deal it signed with OpenAI last week, which in turn inflated Oracle’s share price – may not be as Ponzi-ish as they look. But these mind-bendingly big deals at the very least represent a gear shift. Hitherto the hyperscalers (Meta, Google, Amazon et al) were just reinvesting their vast torrents of cashflow into building more data centres for paying customers. It was business as usual, albeit on steroids. However this new phase is more self-referential. Something akin to a tech oligarch blood pact, where they are going all-in on the AI revolution and they’ll sink or swim together. Sadly, I’m too old not to remember the Dotcom boom and bust at a time like this. Not just in terms of the high valuations. (I’m thinking here of the likes of Palantir and OpenAI rather than the Magnificent Seven tech giants, most of which still don’t seem truly crazily-priced given their sales growth and margins.) No, also in the way that Dotcom-era start-ups floated on an ocean of ultimately VC-funded advertising that paid the bills of a bunch of other start-ups, which ultimately took half of them down when somebody thought to ask “how many people are actually clicking on these things?” and pulled the plug when they got a straight answer. I mean, doesn’t nVidia investing in OpenAI so that OpenAI can get chips from nVidia have the whiff of that to you? Even so, you might imagine that none of this matters for your portfolio. But what if I quoted JP Morgan informing us this week that: AI related stocks have accounted for 75% of S&P 500 returns, 80% of earnings growth, and 90% of capital spending growth since ChatGPT launched in November 2022. This also seems like a pertinent point to remind you that US equities account for 60-70% or more of global tracker funds. Artificial Intelligence taking all the jobs or becoming super-intelligent is one thing. But this AI boom being exposed as productivity-sapping margin-crushing hype on a nation-state-GDP level would also cause us investors plenty of pain. Accordingly, I’ve been worried and underweight the US at least 18 months. And boy hasn’t it made keeping within spitting distance of the global market’s return difficult. Because once more with feeling: AI related stocks have accounted for 75% of S&P 500 returns, 80% of earnings growth, and 90% of capital spending growth since ChatGPT launched in November 2022. On the other hand, Wall Street’s obsession with big tech and AI has left lots of other stuff looking good value, especially outside of the US. And it’s fun to hunt around for it. The activist manager Saba, for example, is awaiting approval for a new ETF it’s launching that will enable value-minded investors to buy a basket of UK investment trusts – specifically because so many of them are still going cheap. Again, the parallels are obvious. Nobody wanted to own Warren Buffett’s Berkshire Hathaway at the peak of the Dotcom Bubble. Then in the years after the bubble bust, value soared. The set-up looks so easy, right? Yeah, too easy. We could be in 1996, say, not 1999. More importantly we’re actually in 2025, and stock market history rhymes rather than repeats. So all I’m saying for sure is that if this is a bubble and if it does burst, then you’ll hear a lot about nVidia putting $100bn into OpenAI in every future account of it. Oh, and incidentally people keep saying the hyperscalers are spending tens of billions ‘building out the AI infrastructure’ as if they were laying down concrete. But anyone who has ever bought a new nVidia graphics card to play the latest PC games will have found themselves confronted with jerky frame rates six months later. These things go stale faster than you can say “whatever happened to the Metaverse?” So if they are building out the AI infrastructure, they’re going to have to build it out again… Have a great weekend. Crypto ETNS: what you need to know – Monevator Last chance to buy some Monevator T-shirts before we rationalise our shop – Monevator From the archive-ator: Patient investing requires a little faith – Monevator New digital ID scheme to be rolled out across UK – GOV.UK Retail sales slump for twelfth month in a row – This Is Money UK forecast to have highest inflation rate among the rich nations – BBC Record number of savers and investors facing a tax bill… – Which …while half of the population live in households that get more in benefits than they pay in tax – T.I.M. Trump’s $100,000 H-1B fee sparks a global race for top talent – CNBC Reeves urged to take 2p off employee NI and add it to income tax in Budget – Guardian £2,000 savings buffer can be the turning point for financial wellbeing – Yahoo Finance HSBC demonstrates first-known quantum algorithmic trading with IBM – HSBC Wealthy investors from US, China, and Hong Kong apply for New Zealand’s ‘golden visa’ scheme – Guardian Momentum is crushing value this year. Again. – Sherwood Is Santander’s new Edge Explorer bank account worth it? – Which IKEA Family credit card review – Be Clever With Your Cash Nationwide trims mortgage rates despite BoE hold – This Is Money Get up to £1,500 cashback when you transfer your cash and/or investments to Charles Stanley Direct through this affiliate link. Terms apply – Charles Stanley How to avoid falling victim to a ‘money mule’ scam – Guardian Barclays cuts mortgage rates for home buyers with smaller deposits – This Is Money Get up to £200 cashback when you open or switch to an Interactive Investor SIPP. Terms and fees apply, affiliate link. – Interactive Investor How does home equity release work? – This Is Money Supermarket Christmas delivery slots – Be Clever With Your Cash Homes to rent for up to £1,800… in pictures – Guardian How can we solve the 60% tax trap without damaging the economy? – This Is Money Why the 5% Rule is the new 4% rule… – Of Dollars and Data …although US retirees actually tend to follow a 2% rule – A Wealth of Common Sense How to minimise active ETF bid/ask spreads [US but relevant] – Morningstar If sustained growth is the aim, the UK must alleviate child poverty – Observer Welcome to London, divorce capital of the world [Paywall] – FT How you can profit from the coming devaluation – Simple Living in Somerset Millions of Americans are becoming economically invisible – Bloomberg via AP Debunking the active fund ‘persistence scorecard’ debunking – FT Exploring capital efficiency [PDF, nerdy] – AQR What activist managers buy in Japan – Verdad Nope, sorry, the S&P 500 is not the new risk-free rate – FT How pensions windfall could turbocharge UK stock market [Affiliate link] – II The perils of concentration – Market Sentiment American Express: an empire of plastic – Quartr Flash Boys by Michael Lewis – £0.99 on Kindle Alchemy by Rory Sutherland – £0.99 on Kindle The Green Budget Guide by Nancy Birtwhistle – £0.99 on Kindle Techno Feudalism by Yanis Varoufakis – £0.99 on Kindle Or pick up one of the all-time investing greats – Monevator shop China has finally pledged to cut carbon emissions – Sherwood Demand for oil will not peak until 2030, warns BP – This Is Money New homes may be forced to fit water-saving toilets and showers – Sky The near-extinction of rhinos is at risk of being normalised – The Conversation Ocean acidity crosses critical threshold for marine life – Guardian The data centre blob [PDF] – JP Morgan Chatbait is taking over the Internet – The Atlantic [h/t Abnormal Returns] The algorithm will see you now – Works in Progress If Anyone Builds It, Everyone Dies review – Guardian AI generated workslop is here… – CNBC …and it’s destroying workplace productivity – Harvard Business Review American companies talk about AI, but can’t explain the upsides [Paywall] – FT The moral case against Nigel Farage – The Newsletter of (Not Quite) Everything From low taxes to economic fragility – Klement on Investing A left-wing version of Trump isn’t the answer – The Argument Why is Trump bailing out Argentina? – Paul Krugman Sometimes democracy works: on same-sex marriages – Aeon Letter from an ICE detention facility – Bitter Southerner Trump’s move against the media is an authoritarian classic – A.P. Who’s getting rich off your attention? – Kyla Scanlon Things are really bad folks – Freddie deBoer Why Putin can’t afford to let Ukraine prosper – WSJ National Railway Museum reopens after £11m refit – Guardian 25 interesting ideas from 2025 – Derek Thompson The king of coffee nerds – Financial Times [h/t Abnormal Returns] Is the Golden Age of TV officially over? – Stat Significant Perspective on life, money, and success from rock star Billy Corgan [Video] – via X Scammed into scamming – Reuters Mid-20th Century culture is getting erased – The Honest Broker Why every country needs to master the electric tech stack – Noahpinion ‘Very mean’ squirrel has sent two people to ER in Californian city – Associated Press “Greed is good because it makes things predictable. No need to coerce or enforce or foist any delusions when you have people volunteering to do the labor of self-persuasion.” – Carrie Sun, Private Equity: A Memoir Like these links? Subscribe to get them every Saturday. Note this article includes affiliate links, such as from Amazon and Interactive Investor. Thanks for reading! Monevator is a spiffing blog about making, saving, and investing money. Please do sign-up to get our latest posts by email for free. Find us on Twitter and Facebook. Or peruse a few of our best articles. “…while half of the population live in households that get more in benefits than they pay in tax” If you choose – misleadingly, in my view – t0 categorise the State Retirement Pension as a “benefit” that result seems almost inevitable. But if you used a better definition, is it still true? Yes, with the US market dominated by a very few big companies all at high PEs and all operating in roughly the same space (or at least whose fortunes are somewhat tied to “tech”) and that US market dominating global trackers it’s very hard to feel enthusiastic or even indifferent to just adding to your global trackers holding every month no matter how much of a passive investor I want to credit myself as being (and hard to feel enthusiastic about the US anyway with His Donaldness running the show). So much so I do wonder if I should be looking at putting 50% into a global tracker and the other 50% into “other” (world ex US tracker or Europe / UK / Asia trackers as suits your prejudice). Not the first person to wonder / worry about this of course (may even be the last person to actually start to think about doing something about it!). @David 14 – I very much share your discomfort. That discomfort is amplified by being essentially at my FI number. More and more, I keep thinking of mantras like ‘be fearful when others are greedy’ and ‘if you’ve won the game then don’t swing for the fences’. It would be great to get a Monevator article about CAPE ratios, esp as it pertains to those on the cusp of FI (though not necessarily RE) Imo there is a at one level a fairly normal cyclical AI bubble that should burst but leave behind a few winners (imo Google looks good, Meta etc can keep their AI video slop). Within that you have the normal slightly dodgy behavior – and Nvidia has always funded its customers aided by its high valuation and has a few red flags running through the accounts, but in these bubbles that is normal. But if you step back with a US focus you also have imo high house prices (see UK also), incredible household debt (lesser in UK), high earnings multiples across the board in the US (opposite to UK) and a Private Equity bubble to layer in (lesser in UK). Plus whatever crypto is (lesser in UK). On Private Equity, you have the likes of HubSpot that never really have earnings but get through the PE-cycle and list to now be worth $27bn while always losing money, now as a fully mature company. That in turn creates confusion over what value is – is it earnings or revenue? And that seeps out, so you have Palantir and Tesla valued on the idea of something vague in the future. That imo is not a part of the AI bubble, but results more from the PE bubble and from the debt bubble (eventually borrowing to speculate). And it’s quite confusing having multiple bubbles in play at once. In the end it feels to me like there is a broader growing volcano fed by the belief that all this can keep expanding. But it’s hard to read because it’s like a multiheaded snake. @Andy/David : I’m also in the “if you’ve won, quit playing so much” space – have toned down equities in my portfolio. I’ve even bought a chunk of long long term index-linked gilts, which in theory provide a guaranteed over-inflation return. Somehow, with the state of the UK I can’t quite feel fully confident in that however. Whilst nothing is a crystal ball, we are at CAPE levels only seen really in the dotcom crisis. They could of course go above and beyond that in theory, but I think there’s no shame in taking this time to review whether one’s asset allocation is appropriate. @Part-Time Analyst “…is it earnings or revenue?” Did you mean “profit or revenue”? I thought earnings and revenue are the same thing. Excellent comment, by the way. Only just saw also that Jonathan Clements from Humble Dollar passed away this week too, sad news. He was an excellent writer. Expensive US markets, highly concentrated, cause concern to many investors, it has caused me to mentally flip flop from sticking to plan and becoming more cautious , with some portfolio changes made, with poor conviction if I am honest. It would be fair to say that the magnificent 7 are very expensive, the rest of the US market has an elevated CAPE ( say 33). Looking at the All World , the 40% non US holdings are probably fairly valued, CAPE about 20 , the remaining US market is 60% of the whole, is expensive with around ⅓ of that being very expensive. On aggregate The All World is expensive but does that have sufficient predicative power to be more than a little cautious ? I am reminded of the Peter Lynch quote “Far more money has been lost by investors preparing for corrections, or trying to anticipate corrections, than has been lost in the corrections themselves.” dearieme – State Pension is a welfare benefit for almost all recipients, as their working life NI contributions fall way short of the value of the state pension they received – both in strict monetary terms, as well as the fact its zero risk, adjusted for inflation etc. @JDW — Indeed, very sad. I’ve included a few of Jonathan’s posts since he had his diagnosis but for some reason I felt uncomfortable including his final post in the links. I can’t explain exactly why… I think it was because it was written almost as a personal letter to US readers who have known him for decade, and it felt a bit inauthentic? A bit silly in retrospect if s. Here it is for those who enjoyed his writing: https://humbledollar.com/forum/farewell-friends/ @TI – thanks for adding that link to Jonathan Clements, sad news, I always enjoyed his posts. Interesting to see the back story, I hadn’t picked up that he was British. I have been underweight in US for years, even before the LLM AI appearance. I have no regrets. Even if/when this all shakes out I don’t see the need to take huge region concentration risks – if Japan was 70% of the world index, I wouldn’t be holding a single world index either, it’s not just an anti-AI protection move – at what point is a world index not diversified? ~70% in any one region must already be getting close. Although, if, like me, you are intentionally down on US but higher percentages elsewhere you probably saw fairly large japan and (asia-japan) index gains just recently. For the first time in a long time my rebalance involved selling quite a lot of japan and asia-japan. At the level of an individual investor, a 70% US weight in a world index leads to huge losses if the AI bubble bursts. Add to this political risk associated with US… Ironically, nvidia still has a good business if AI bust happens, as they were doing the exact same work/research pre-AI, just the gpu’s and underlying code was bought by end users for playing pc games instead. They will need to pay folk off and readjust back to normal growth etc, but all the efforts in improving their gpu offerings for both crypto and now AI will be just as useful in the future for what was once their core business. They aren’t holding huge inventory, so if AI goes pop they go back to putting complex mathematics in GPUs for games. Those companies that now have factories full of racks of nvidia gpus at high expense, they have real problems if AI takes a back seat. The sad thing about AI so far is if you put aside mediocre chat bots and summarising documents (with some hallucinations thrown in just to make the current output completely unusable if its important work or has accountability requirements), the only improved use case for this generation of AI is unmanned military drones etc, which is quite sad. The other uses of AI being thrown about like medical imaging and such is not new and been happening for decades, everyone is just throwing AI in to funding applications to win funding or to improve their “impact” scores. Thanks for bringing the ‘state of the rhino’ report to the attention of the readership. @TI – very timely. Last week I shuffled my defensive assets. I sold some BHMG to buy Pershing Square Holdings (I’m hoping at least one of them can repeat 2008 and hit it out of the park if SHTF). To counter the increase in US in PSH, I sold some HSBC FTSE All World and I’ll buy a All-World ex-US to keep US as is. Not very passivista, but there you go. I was a great follower of Jonathan Clements -he helped a lot of people and will be greatly missed He was of course a believer and promoter of “ indexing ” long before it became so fashionable Global indexing in equities and bonds have been a success with funding my 23 years of retirement -so far I don’t really feel any urgent need to change and certainly am constantly unable to second guess the market One global index fund for equities and bonds respectively certainly makes investing life cheap ,very easy to understand and manage Very boring of course especially if your interest is the stockmarket and its various shenanigans Some very special investors can beat the market return-sadly I realised fairly early into my investing career that I was not amongst the lucky few I suppose it was always true that only a very few companies actually move the stockmarket-5%?-also these successful companies tend to be different every year etc etc Sitting tight here xxd09 @TI: The “Millions of Americans are becoming economically invisible” Bloomberg article seems to be the antithesis of the theme of last weeks weekend reading. The picture the article paints sounds, at best, somewhat unstable to me. Any thoughts? Thanks for all the other interesting links too. Those subheadings 😉 I’m partying like it’s 1999 in my head! @Curlew – Earnings was perhaps a bit careless on my part to use as it can have a dual meaning, but I meant in terms of profits. So earnings as in the E in EBIT or EBTIDA. Now is the LLM winter of our discontent, made glorious ASI summer by this Son of Neural Nets. LLMs predict language. They don’t predict for the World. They’re the perfect info mirror. But there’s nothing new in the mirror. Just a reflection looking back at us. Without true novelty there can’t be the real breakthroughs needed for additional growth, less still a tech / econ singularity to solve the many ills ailing the world. Aside from the fundamental foundational flaw (another ’empty box’ as SBF put it for crypto), there’s also the technical barrier of current approaches: exponential increases needed for linear improvement using compute / parameter scaling. LLMs alone can’t be the solution. Maybe they are part of the solution. Maybe they’re a distraction and dead end. But investment into AGI based on LLMs alone *will* fail that objective. This emphatically doesn’t mean though that the search for AGI ends. We know it is possible empirically from nature – Darwinism produced us. We know it is possible from our well tested foundational model of physics. Generalised intelligence (and autonomous super intelligence) is/will be just emergent complexity from quarks and fields. Like everything else. In truth, all just Atoms and the Void, as Democritus put it. Echoing the caution in this thread about LLM (mis-sold as AI) driven market froth, I’ve tracked similar skepticism for the past year via 100+ comments now on Monevator’s May 2024 “First they came for the call centres” piece over here: https://monevator.com/weekend-reading-first-they-came-for-the-call-centres/ TL:DR: Starting with barbell strategies tilting to momentum ETFs like SPYO for AI upside, while hedging with ex US small cap value for mean reversion, my views evolved: following LLM critics like Gary Marcus / Ed Zitron, doubting scaling to AGI, and likening it to 1990s nanotech hype constrained by physics. And in the @TI above linked “Queasy about US Valuations” piece (also 2024), this also extended to broader market unease, advocating modest shifts (e.g., 20% to bonds) for asymmetric protection, toy models show 2:1 upside/downside ratios favoring small tweaks, plus return stacking via WTEF ETF to cut S&P exposure from 65% to 42% while boosting total allocation to the equivalent of 130% with gilts and ex US equities. We need to know our history on this. It’s not just a rerun of Dot.com from 1996-99 or the Nifty Fifty from 1970-72. There’s a longer term pattern here. Natural Language Processing’s post-1958 timeline (Mark 1 Perceptron, 1st artificial neural net) amplifies the current AI winter risks: ELIZA (1966) ignited hype, but AI winters still struck hatd (1974-80, 1987-93) post-over promises. Revivals via 1980s stat based NLPs, early attempts at World models, and development of what became the Internet led to hiatus until 2010s deep learning (Word2Vec 2013), Transformers (2017), and multimodal advances (GPT-4o 2024, Grok-4 2025). Now hallucinations and inevitable near term ROI shortfalls (on the truly staggering over investment into increasingly rapidly obsolescent intensive GPU / TPU/ NPU data centre architectures) all loudly signal pending disillusionment. Yet, this trough could yet still seed ASI breakthroughs via much neglected hybrid neural symbolic approaches. Portfolio fallout? An AI winter craters Magnificent 7 like Dot.com’s 75% plunge. So I’m staying underweight US tech, diversifying globally: history cycles, rewarding patient investors eyeing the thaw. Enjoyed (if that’s the right word) the ‘who’s getting rich off your attention’ article. Great context to the broader theme of omni-slop AI content, while being suitably bleak for a grey Sunday morning. Two interesting articles in the Economist, one relevant to this. Apparently the use of AI in internet searches is destroying the value of ads on the internet (rather than going to the usual items with ads in them, internet users are going to the AI search to get their answer). If true, advertisers will surely notice and down go the huge ad revenues. Hoist by one’s own petard comes to mind. Unrelated, the Economist also did a lucid piece on a looming UK Government debt crisis. It cites Labour’s ideological unwillingness to do the one thing which can avoid the bond market making life impossible ie cutting the welfare bill (15% of working age people on benefits etc). @Hospitaller Re the Economist article: “… It cites Labour’s ideological unwillingness to do the one thing which can avoid the bond market making life impossible ie cutting the welfare bill” The article clearly stated two things not one (“…it is abundantly clear that the fiscal adjustment should start with pensions and the welfare budget.“) before expanding on these two things. The article is available at https://www.economist.com/leaders/2025/09/25/britain-is-slowly-going-bust though it’s paywalled (but if you set up create a free account they let you read a few items gratis). RC #12 DH #19 – the thing is, the ability to summarise something automatically is pretty useful, summarising is probably selling the technique a little short, being able to wrangle information into the way you want to consume it is almost a superpower. The WWW provided a means to access information, through a delivery mechanism and search facility. It sounds dull but it turned out to be revolutionary. The ability to curate the worlds knowledge into a format that suits you, automagically and within seconds, to aid its consumption may well be equally revolutionary? That said, being revolutionary doesn’t preclude huge busts en-route as per 1999. The previous AI winters were really because the theory was great but none of it actually did anything useful. That isn’t now the case, we’ve seen huge step changes in performance of AI models across multiple pardigms, CV (CNNs), RNNs (inc. LLMs), RL etc. the difference being some new, novel architectures but critically, the compute to support it. Chat-bots and drones doesn’t really cover it. You don’t need AGI for all this to be game-changeingly useful. Novelty isn’t where 99.9% of the work unfolds. RC #12, Rhino #23: Current monetised LLMs (OpenAI, Anthropic, Mistral, Grok, etc) together generates in the low billions of revenue (and larger losses) annually. That’s a rounding error against even one hyperscaler’s merely current yearly Capex (~$60–100 bn). McKinsey boldly est ~$6.7 Tn data centre Capex to 2030, roughly $5.2 Tn of which targets frontier model grade compute. *If* that happens, then Nvidia likely becomes a $800-$1,100/share ($20-27 Tn cap) stock (~4-7x from now). But No Guests = No Party. Sure sunk + fully legally committed investments raise floor, as site builds already started (land, power, cooling) & multi yrs supply contracts mean they’ll be some extra capacity led min. level of additional demand persistence. However, will several trillions+ of GPU Capex actually show up in just the next few yrs? It all doesn’t add up to much unless and until enterprise + individual LLM specific profits – not revenues – are nearing $1 Tn in 2030. My sense on that number is that it’s a LoL one. And, while hyperscalers can repurpose racks from one workload to another (cloud/HPC, enterprise inference, simulation, gov/sovereign projects), all this alleged future demand ultimately depends upon LLMs being sufficiently commercially transformative (to the accounting bottom line, and not just with BS generation) that staff can be replaced at scale (many millions laid off), thereby justifying businesses spending the well over $1 Tn in 2030 (likely very substantially more) which will be necessary to generate ~$1 Tn in profits for model providers that year to keep feeding the insaitable Capex monster. Seems one hell of stretch from here just now. The only scaling I see are in OpenAI’s losses. This could be Metaverse times 100 or WeWork times 1,000. LLM’s are the reason for all the recent public AI hype and investment, and these are where most the problems lie, not AI in the general sense – every LLM tool has a disclaimer along the lines “results may be innacurate”. The most useful areas where modern inference approaches will contribute anything to society or even in business is in areas where work has been progressing for decades long before chat GPT i.e. not LLM’s. In terms of investing, the useful inference work would still be happening at maybe only a reduced rate without LLM’s – the funding and progress has increased as researchers are gaming the funding applications process by putting things under AI and with more hardware etc, so we do have some benefits, and some good research is happening. However, as someone who has formally researched in statistical inference and spent a career in the application of statistical inference, I stand by my opinion that chat GPT spurred huge investments in technology that will struggle to ever lose the disclaimers about innacuracies – to me as someone who cares about correctness, this is a problem. Whether this lack of rigour leads to stock market implosions is not something I know, but I choose where I invest my money, and the AI hype is being driven by biased, hallucinating, LLMs tools. I am not that interested to be investing in these tools despite my entire and current career being in areas concerned with the methodologies. I might be proved wrong in a decade, but that is fine, I make my money from building useful models, not from investing in inference tools that are… mostly ok, probably close to what your training data says, but might be wrong in places sometimes, give wrong sources, and plain make stuff up in others? That is my position. If chat GPT didn’t get released, the AI investments of recent years would not have happened. So the decision to invest to support it is not about general inference and AI (which has solid foundations and happening for decades), but whether you think LLM’s justify the hype. @RC #25: it’s so hard to know/guess what to do. Never bet against America says Buffett. But, the US underperformed (for example) EMs horrendously in 2000-2008. As Soros puts it (paraphrasing heavily), every bubble has a rational foundation, and an irrational response to it. Businesses will be built on, or adjacent to, LLMs, but which will reward investors? Which have even sustainable business models? Does ~50x for Nvidia make sense on a 30 year ‘risk free’ rate of 5%? Example (recalling point (6) in #88 (21 June 25) in the “First they came for the call centres” thread): when the car was first fully commercialised there were hundreds of listed manufacturers. Most went bust. But even if you’d had the luck or foresight to hold a successful one like Ford, then during 1980 to 2020 you ‘only’ made 23x. However, of all the companies out there, it was Walmart which benefited most from the car, as shoppers could visit massive suburban stores off the highway (a 1,600x return over that same period). This feels like one of the more difficult times to be an investor. Not because of deglobalisation, populist nonsense, or the sinister shadows of staflation; but owing instead to the recent, seeming emergent, exogenous shock of a ‘new’ technology which is so hyped, but still just might be a progenitor of sorts to the supposed solution of all our problems (or the harbinger of misaligned doom). Maybe diversification is the only rational response: https://www.telegraph.co.uk/business/2025/09/25/history-shows-investors-that-it-pays-to-diversify/ But how much (and how to*) diversify away from the US? What is too much (or too little) risk to, in effect, ‘go short’ the US tech darlings (or at least the semis) by under weighting them vis a vie their cap weights? *Tom Stevenson has a rose tinted view of the attributes of active managed funds IMO; but for DM and EM micro and nano cap or Frontier Markets you do have to fall back on specialist ITs and open ended funds because there just aren’t passive alternatives. Leave a Comment Name * Email * Website Comment Notify me of followup comments via e-mail. You can also subscribe without commenting. Δ Next post: The Slow and Steady passive portfolio update: Q3 2025 Previous post: Crypto ETNs: what you need to know The Latest Articles Essential Reading Better Investing Property Posts Get Money Motivated Monevator is a place for my thoughts on money and investing. Read our disclaimer. Subscribe to get all our free posts via email. Follow us on Twitter, Facebook, or via RSS. You can also send us a message. Copyright © 2007-2025 Monevator. All rights reserved.Disclaimer: When investing, your capital is at risk and you may get back less than invested. Past performance doesn’t guarantee future results. All content is for informational purposes only. I make no representations as to the accuracy, completeness, suitability or validity of any information on this site and will not be liable for any errors or omissions or any damages arising from its display or use. Full disclaimer and privacy policy. This site uses cookies and features affiliate links. Copyright © 2007-2025 Monevator. All rights reserved. Disclaimer: When investing, your capital is at risk and you may get back less than invested. Past performance doesn’t guarantee future results. All content is for informational purposes only. I make no representations as to the accuracy, completeness, suitability or validity of any information on this site and will not be liable for any errors or omissions or any damages arising from its display or use. Full disclaimer and privacy policy. This site uses cookies and features affiliate links.
--------------------------------------------------

Title: ‘South Park’: A guide to every Trump-era parody in Season 27 (so far)
URL: https://www.denverpost.com/2025/09/26/south-park-guide/
Time Published: 2025-09-26T18:03:28Z
Full Content:
Kaitlyn Huamani, Los Angeles Times Every episode of “South Park” opens with a disclaimer: “All characters and events in this show — even those based on real people — are entirely fictional. All celebrity voices are impersonated … poorly. The following program contains coarse language and due to its content it should not be viewed by anyone.” While some of that language must be required by an exhausted legal team behind the scenes, the long-running satirical cartoon is known for pressing hot-button topics and rapidly churning out searing parodies. Season 27, which premiered in July, is no exception, focusing on President Donald Trump, his associates, policies and other current events. Some members of Trump’s Cabinet have been outspoken about their likeness appearing in “South Park,” but others have shrugged it off. Over the years, the animated series has depicted conservatives and liberals alike, leaving almost no public figure, politician or activist shielded from critique or crude depiction. ‘South Park’ lays into FCC chair over freedom of speech in new episode This season has had an unusual cadence of episodes, with the first two arriving on a weekly schedule, then biweekly before the arrival of Episode 5, which aired three weeks later on Wednesday. The delayed episode arrived after the shooting death of conservative activist Charlie Kirk, whose debate style was depicted in the Episode 2. However, “South Park” creators Matt Parker and Trey Stone told the Denver Post the delay was unrelated to recent events, like Jimmy Kimmel’s suspension, or the content: “No one pulled the episode, no one censored us, and you know we’d say so if true.” The pair had issued a statement on Sept. 17 saying the episode wasn’t finished in time. Future episodes will air every two weeks through Dec. 10. Here is a guide to every parody and reference so far on this season of “South Park.” Cartman is dismayed to find out National Public Radio has lost its federal funding after he tunes in to hear static — an NPR program is his “favorite show,” he says, where “all the liberals b— and whine about stuff.” He rants to his friends about how the government “can’t cancel a show” and wonders what might be next on the chopping block. In July, the Senate voted to approve the Trump White House’s proposal to claw back roughly $1 billion in federal funding previously allocated for public broadcasting. NPR and PBS are still operating despite the funding cuts, but layoffs and reduced programming are expected. Head of South Park Elementary PC Principal, whose name was a play on the initialism for politically correct, announces to the school that his name now stands for “Power Christian Principal.” He holds an assembly where he says that “our Lord and savior Jesus Christ” is the only thing that can bring back some normalcy to these “corrupt times.” He proceeds to welcome Jesus to the assembly as a guest speaker. When the students go back home, their parents and the people of South Park are alarmed to hear about the emphasis on Christianity — and the presence of Jesus — in the town’s public school. Trump has previously endorsed displaying the Ten Commandments in classrooms amid a push to incorporate more Christianity into public schools. The phrase frequently used by Trump was inscribed on a T-shirt Cartman wears after he realizes the concept of “wokeness” is no longer prominent. “Everyone hates the Jews, everyone’s fine with using gay slurs,” he says, lamenting that he no longer feels purpose if there’s no wokeness to contest. The White House press secretary is depicted corralling the president, sporting a large cross necklace, as she often does during press briefings. Leavitt tells Trump a lot of his supporters are starting to turn against him and begs him to talk to them, adding that they’re “really riled up.” Trump’s base has expressed frustration over the administration’s approach to sharing information about the Jeffery Epstein case after he promised more transparency about the convicted sex offender, who died by suicide in 2019, and the sex trafficking investigation involving the late financier. Trump appears this season with an image of his face over an animated body, frequently repeating the phrase “Relax, guy” and threatening lawsuits against anyone who’s in his way. He is shown berating a White House portrait painter for an unflattering depiction of him and there are references to the size of the president’s genitalia. He’s also depicted as being in an abusive relationship with Satan — in which Trump is the abuser. “South Park” has previously depicted Satan as being the victim in an abusive relationship with Saddam Hussein. Satan laments the speculation that Trump’s name is on the “Epstein list,” a purported list of his alleged clients. In reality, the Justice Department has said no such list exists, walking back comments Atty. Gen. Pam Bondi made in a Fox News interview earlier this year that the list was “sitting on my desk” in preparation for release. When the list is brought up in the series, fictional Trump says, “Are we still talking about that?,” mirroring comments he made in real life. The stopwatch featured in the introduction to “60 Minutes” is strapped to a bomb when it appears on “South Park.” The hosts of the show are visibly nervous and continue praising the president while covering his lawsuit against the town of South Park, adding that they don’t agree with Trump’s detractors. The scene references the legal tussle between Trump and Paramount Global, the parent company of CBS, which airs “60 Minutes.” The president sued over edits to a “60 Minutes” interview with then-Vice President Kamala Harris, which led to Paramount agreeing to pay $16 million to settle the lawsuit in July; shortly after, the Federal Communications Commission, led by a Trump appointee, approved Paramount’s merger with Skydance. Between the settlement and merger approval, CBS announced it is canceling “The Late Show With Stephen Colbert.” Colbert frequently skewers the president on his show, and Trump praised the cancellation. Paramount also recently bought the global streaming rights to “South Park” in a lucrative $1.5 billion deal for Parker and Stone. During the episode’s fictitious “60 Minutes” segment over Trump’s lawsuit against the town, Jesus comes to visit the townspeople. Through whispers, he tells them, “I didn’t want to come back and be in the school, but I had to because it was part of a lawsuit and the agreement with Paramount.” “The president’s suing you?” a protester asks. Jesus, through clenched teeth, explains: “The guy can do what he wants now that someone backed down. … You guys saw what happened to CBS? Well, guess who owns CBS? Paramount! You really want to end up like Colbert? You guys gotta stop being stupid. … If someone has the power of the presidency and also has the power to sue and take bribes, then he can do anything to anyone.” “All of you, shut the f— up or South Park is over!” Jesus says. The people of South Park end up settling their lawsuit with the president for $3.5 million, saying it will be fine as long as they cut some funding for their schools, hospitals and roads. And as part of the settlement, they have to agree to “pro-Trump messaging.” Cut to a live-action deepfake video of Trump trekking through the desert in a show of loyalty to his supporters before he strips naked. [Note: This episode aired on Aug. 6, more than a month before political commentator Charlie Kirk, who is parodied throughout the episode, was shot and killed.] This episode is focused on the ongoing raids carried out across the country by Immigration and Customs Enforcement and Department of Homeland Security officials since earlier this year. When South Park Elementary counselor Mr. Mackey is fired — the government is doing away with needless spending in schools, he’s told — he signs up for a job with ICE, enticed by a generous signing bonus and a higher salary. Mackey watches a promotional video, complete with animations of officers wearing gaiters and a theme song: “We don’t ask for experience, just show up/ We don’t care if you’ve read a book or grown up/ If you’re crazy or fat and lazy, we don’t care at all … If you need a job, it’s a job to have.” Mackey is hired with alarming speed and proceeds to go on his first raid, targeting a “Dora the Explorer” live show, which has a not-so-intimidating audience of young children and abuelitas. After ICE agents hear from protesters that there are “many Latinos in heaven,” they make the pearly gates their next stop. The Department of Homeland Security secretary leads ICE agents through a series of raids this episode, but she first appears in an orientation video. She tells the new recruits, “A few years ago, I had to put my puppy down by shooting it in the face because sometimes doing what’s important means doing what’s hard,” and she proceeds to going on a shooting spree targeting yelping puppies (including Krypto the Superdog) throughout the episode. In her 2024 book, Noem wrote about how she killed her 14-month-old dog for exhibiting aggressive behavior. She’s also seen rounding up as many immigrants as possible in raids, shouting orders like, “If it’s brown, it goes down.” And in a running gag, her face periodically melts off, requiring a glam squad equivalent to a pit crew, and at one point, it seems to take on a life of its own. Trump also says her face “freaks me out” during the episode. Noem responded to the depiction on Glenn Beck’s podcast, calling it “lazy” to target her looks. “If they wanted to criticize my job, go ahead and do that, but clearly they can’t, they just pick something petty like that,” she said. While conservative political commentator Charlie Kirk does not appear as a character in this episode, his style of debate content — and his name — are featured. Loudmouthed Cartman is frustrated that so many others, namely his classmate Clyde Donovan, are profiting off of “his shtick” of arguing against liberal views. Clyde has a debate podcast, inviting viewers to watch as he “totally destroys these woke liberal students.” He’s set up in a tent on a college campus where he waits as a line of students come to speak with him, and he challenges them to “prove me wrong.” Cartman eventually takes over, saying that he is the “master debater” and sporting a haircut similar to Kirk’s. He shuts down his opponents’ arguments with phrases like, “You just hate America and you love abortions.” Clyde and Cartman’s content replicates Kirk’s well-known style. The founder of the conservative organization Turning Point USA frequently toured college campuses and hosted events just like the one depicted in the episode. The phrase “prove me wrong” was used frequently by Kirk to promote his events, inviting students to challenge his political and cultural views. On Sept. 10, Kirk was shot and killed while hosting such an event at Utah Valley University, the first stop of his “American Comeback” tour. Weeks before he was killed, Kirk responded to the episode with a 30-minute YouTube video, finding it humorous. “I think a lot of it was hilarious towards me,” he said. “Some of it was very funny and I don’t think we should have too thick of skin.” He also touched on the reach of his organization and events, noting that his name is enshrined in “The Charlie Kirk Award for Young Masterdebaters” that Cartman and Clyde compete for in the episode. “So a campus thing I’ve been doing for 13 years to debate random college kids has now been so important that it gets prominent prime-time placement on Comedy Central?” he asked through laughs. “I think the whole thing is just awesome and hilarious.” When Mr. Mackey is rewarded for good work as an ICE agent, he’s flown to Trump’s Mar-a-Lago estate, where he frequently stays and hosts events. He’s greeted by giggling women who hand him a drink and put flower leis around his neck before the president meets him and gives him a brief tour of Mar-a-Lago. While there, Mackey accidentally walks in on two older men receiving massages from younger women, one of whom is a tearful Dora, detained in the raid that took place earlier in the episode. The scene is likely a reference to Epstein and accounts from survivors who say they were forced to give massages to him and his associates. Trump said this summer that Epstein “stole” young women who worked at the Mar-a-Lago spa, which caused them to have a falling-out. The vice president is depicted as a version of Tattoo, the character from late-’70s drama “Fantasy Island,” and is animated similarly as Trump, except the photo used for his face is lifted directly from viral memes. He often does the president’s bidding, calling him “boss.” In turn, Trump frequently calls Vance “stupid.” Acknowledging the caricature, Vance wrote on X, “Well, I’ve finally made it.” Randy’s hemp farm business, Tegridy Farms, is the site of an immigration raid at the the beginning of this episode. While Randy is shooting a commercial, complete with calming guitar music and a trite script, ICE officers interrupt by detaining almost all the workers. “You sons of b—,” Randy screams after the vans as they drive away. “Those are my Mexicans!” In July, chaotic raids targeting a cannabis company’s growing site and greenhouse in Santa Barbara and Ventura counties drew national attention after a man who was fleeing immigration officials died. With his business in shambles, Randy rethinks his strategy with the help of an over-complimentary AI chatbot. Perhaps in a nod to Trump’s former ally and onetime “special government employee” Elon Musk, the billionaire businessman behind Tesla, SpaceX and X, Randy turns to ketamine. Randy insists a slew of “tech guys” are taking small doses of ketamine and the drug “gives their minds the edge to work with AI.” Ketamine “bolsters our focus and creativity,” he tells his partner Towelie. Under the influence of the drug, Randy transforms Tegridy Farms from a “quaint farm” into an “AI-powered marijuana platform for global solutions.” Musk’s use of ketamine and other drugs has been previously reported, with the tech leader saying in a 2024 interview that ketamine has been prescribed to him and is “helpful for getting one out of a negative frame of mind.” He has denied abusing it. “If you use too much ketamine, you can’t really get work done. I have a lot of work, I’m typically putting in 16-hour days,” he said. “So I don’t really have a situation where I can be not mentally acute for an extended period of time.” Musk supported Trump’s campaign and served as an advisor to the president, helming the Department of Government Efficiency earlier this year with the goal of slashing spending. Meta and Apple chief executives Mark Zuckerberg and Tim Cook, who were both present at Trump’s inauguration and have maintained friendly relationships with him, are both portrayed in this episode as members of a long line outside of the Oval Office waiting to bestow a gift on the president. “Mr. President, your ideas for the tech industry are so innovative,” Cook says to Trump. Cook gives the president a gift on behalf of Apple, which actually happened this summer. Zuckerberg is later seen giving the president a gift that appears to be a gold and bejeweled Meta virtual reality headset. Qatar’s leader is also seen in line holding a model gold plane with a tag that says “Air Force One.” Like everyone else, the leader compliments the president and insists his genitalia is not small before giving him the gift. Trump and the Defense Department accepted a luxury Boeing 747 aircraft from Qatar for President Trump to use as Air Force One this summer, despite ongoing questions about the ethics and legality of taking the expensive gift from a foreign nation. When Towelie takes a trip to the capital in this episode, he sees armed troops guarding monuments like the Washington and Lincoln memorials and the Capitol surrounded by tanks and jets. In the episode, the Lincoln Memorial has been replaced by a statue of a stern-faced Trump with exposed genitalia. In August, Trump called up National Guard troops to Washington, D.C., to assist federal law enforcement in his bid to “reestablish law and order” by targeting criminals — though crime has been down in the city — and the homeless. Although troops were not initially armed, Defense Secretary Pete Hegseth later ordered them to carry service-issued weapons. Randy sends Towelie to meet with Trump and give him a gift in hopes of persuading him to reclassify marijuana on the national level. (The gift is Towelie himself.) Randy, in the form of a hologram, tells Trump he thinks they can work out a mutually beneficial arrangement. Trump said in an August press conference that his administration was considering reclassifying marijuana as a less dangerous drug, which would be a significant change in policy but would not make the drug legal across the country. The clerk at the City Pop-Up — rebranded from City Wok — the lone purveyor of Labubus in the area, says the popular dolls are hard to keep in stock, and they’re very expensive because of tariffs. The “mystery box” that Butters has to purchase for the chance of getting the exact Labubu his girlfriend wants sets him back $85, and later, the price shoots up to $120 to offset a rise in tariffs. (The real-life dolls often fetch much more than that on resale sites, especially if they are rare.) When Butters balks at the price, the store owner explains that the cost of tariffs is passed onto the customer. This episode shows a clip from a Fox News segment where an anchor is overly complimentary of the president. The anchor says the president will take questions from a “diverse crowd of reporters” after returning to the U.S. from a historic tariff summit, only to reveal all of the reporters are from Fox. The Fox News reporters also fixate on President Trump’s relationship with his wife, Melania, and his increasingly frequent appearances with Satan. There’s a heavy use of wordplay that suggests the anchors could be asking about the affair between the president and Satan or about whether Trump is actually the devil himself. Fox News reporters check in with Trump ally Kid Rock after breaking the news that — buckle up — Trump has impregnated Satan. A sobbing Kid Rock tells the reporters, “I’m just so happy.” The musician is a friend and ardent supporter of Trump, having performed at his inaugural rally in January and spoken many times publicly about his support of the president. Kyle becomes irate when his classmates place bets on a popular market prediction app that his mother would “strike Gaza and destroy a Palestinian hospital.” This episode marks the first time this season that the show has touched on the current conflict in Gaza, and it referenced real-life Israeli strikes on hospitals in the area. Trump’s eldest son appears in this episode as someone with many roles — he’s a strategic adviser for predictive markets, he answers the phone for the Commodity Futures Trading Commission and also acts as a special adviser to Israel. Although he wears all those hats, the series doesn’t portray him as particularly bright — he has a complete conversation over the phone with himself. He’s also animated to look as if he’s had extensive plastic surgery and he speaks with a strained voice, as if he can’t move his face. Trump Jr. holds several key roles in his family’s business and his father’s political sphere in real life, and he serves as an adviser to both Polymart and Kalshi, two prediction market apps that are named and spoofed in this episode. Less keen on the baby he’s expecting with Satan, Trump looks for different ways to harm the pregnancy in hopes of terminating it. He asks Satan if he wants to smoke and hang out in a hot tub, holds up a wire hanger, tries to get him to trip down the stairs or fall under a pile of cat feces, and even makes Satan a soup full of emergency contraceptive pills. In reality, Trump has repeatedly shifted his messaging on abortion but has most recently said he believes specific abortion policies and access should be decided not by federal law but by individual states. The chairman of the Federal Communications Commission comes into the fold this episode when Kyle goes through several hoops to try to file a complaint over the bet involving his mom, which he finds offensive. The FCC is “dealing with all the offensive stuff now,” Kyle is told. Carr says he needs to speak with the president after learning about the offensive content, but he ends up falling victim to all of Trump’s antics in his attempt to terminate Satan’s pregnancy, which send him to the hospital. The doctors say they’re “afraid he may lose his freedom of speech.” Vance later threatens Carr, who keeps interfering with Trump’s attempts to end Satan’s pregnancy (Vance doesn’t want anything to mess with his proximity to the presidency). “We can do this the easy way, or we can do this the hard way,” Vance says to Carr. Those words match the phrase Carr said in real life a week before this episode aired in reference to his call on ABC to act on comments late-night host Jimmy Kimmel made about Kirk’s suspected killer and his death. Carr has remained in the headlines since then as backlash grew against the FCC’s role in Kimmel’s suspension. Frustrated by the bet about her and the ongoing conflict in Gaza, Kyle’s mom storms into the office of the Israeli prime minister. “Just who do you think you are, killing thousands and flattening neighborhoods, then wrapping yourself in Judaism like it’s some shield from criticism?” she says. “You’re making life for Jews miserable and life for American Jews impossible.” She continues to berate him and a group of officials while the credits roll. Netanyahu does not say anything in response. ©2025 Los Angeles Times. Visit latimes.com. Distributed by Tribune Content Agency, LLC.
--------------------------------------------------

Title: ‘South Park’: A guide to every Trump-era parody in Season 27 (so far)
URL: https://www.bostonherald.com/2025/09/26/south-park-guide/
Time Published: 2025-09-26T18:03:28Z
Full Content:
Kaitlyn Huamani, Los Angeles Times Every episode of “South Park” opens with a disclaimer: “All characters and events in this show — even those based on real people — are entirely fictional. All celebrity voices are impersonated … poorly. The following program contains coarse language and due to its content it should not be viewed by anyone.” While some of that language must be required by an exhausted legal team behind the scenes, the long-running satirical cartoon is known for pressing hot-button topics and rapidly churning out searing parodies. Season 27, which premiered in July, is no exception, focusing on President Donald Trump, his associates, policies and other current events. Some members of Trump’s Cabinet have been outspoken about their likeness appearing in “South Park,” but others have shrugged it off. Over the years, the animated series has depicted conservatives and liberals alike, leaving almost no public figure, politician or activist shielded from critique or crude depiction. This season has had an unusual cadence of episodes, with the first two arriving on a weekly schedule, then biweekly before the arrival of Episode 5, which aired three weeks later on Wednesday. The delayed episode arrived after the shooting death of conservative activist Charlie Kirk, whose debate style was depicted in the Episode 2. However, “South Park” creators Matt Parker and Trey Stone told the Denver Post the delay was unrelated to recent events, like Jimmy Kimmel’s suspension, or the content: “No one pulled the episode, no one censored us, and you know we’d say so if true.” The pair had issued a statement on Sept. 17 saying the episode wasn’t finished in time. Future episodes will air every two weeks through Dec. 10. Here is a guide to every parody and reference so far on this season of “South Park.” Cartman is dismayed to find out National Public Radio has lost its federal funding after he tunes in to hear static — an NPR program is his “favorite show,” he says, where “all the liberals b— and whine about stuff.” He rants to his friends about how the government “can’t cancel a show” and wonders what might be next on the chopping block. In July, the Senate voted to approve the Trump White House’s proposal to claw back roughly $1 billion in federal funding previously allocated for public broadcasting. NPR and PBS are still operating despite the funding cuts, but layoffs and reduced programming are expected. Head of South Park Elementary PC Principal, whose name was a play on the initialism for politically correct, announces to the school that his name now stands for “Power Christian Principal.” He holds an assembly where he says that “our Lord and savior Jesus Christ” is the only thing that can bring back some normalcy to these “corrupt times.” He proceeds to welcome Jesus to the assembly as a guest speaker. When the students go back home, their parents and the people of South Park are alarmed to hear about the emphasis on Christianity — and the presence of Jesus — in the town’s public school. Trump has previously endorsed displaying the Ten Commandments in classrooms amid a push to incorporate more Christianity into public schools. The phrase frequently used by Trump was inscribed on a T-shirt Cartman wears after he realizes the concept of “wokeness” is no longer prominent. “Everyone hates the Jews, everyone’s fine with using gay slurs,” he says, lamenting that he no longer feels purpose if there’s no wokeness to contest. The White House press secretary is depicted corralling the president, sporting a large cross necklace, as she often does during press briefings. Leavitt tells Trump a lot of his supporters are starting to turn against him and begs him to talk to them, adding that they’re “really riled up.” Trump’s base has expressed frustration over the administration’s approach to sharing information about the Jeffery Epstein case after he promised more transparency about the convicted sex offender, who died by suicide in 2019, and the sex trafficking investigation involving the late financier. Trump appears this season with an image of his face over an animated body, frequently repeating the phrase “Relax, guy” and threatening lawsuits against anyone who’s in his way. He is shown berating a White House portrait painter for an unflattering depiction of him and there are references to the size of the president’s genitalia. He’s also depicted as being in an abusive relationship with Satan — in which Trump is the abuser. “South Park” has previously depicted Satan as being the victim in an abusive relationship with Saddam Hussein. Satan laments the speculation that Trump’s name is on the “Epstein list,” a purported list of his alleged clients. In reality, the Justice Department has said no such list exists, walking back comments Atty. Gen. Pam Bondi made in a Fox News interview earlier this year that the list was “sitting on my desk” in preparation for release. When the list is brought up in the series, fictional Trump says, “Are we still talking about that?,” mirroring comments he made in real life. The stopwatch featured in the introduction to “60 Minutes” is strapped to a bomb when it appears on “South Park.” The hosts of the show are visibly nervous and continue praising the president while covering his lawsuit against the town of South Park, adding that they don’t agree with Trump’s detractors. The scene references the legal tussle between Trump and Paramount Global, the parent company of CBS, which airs “60 Minutes.” The president sued over edits to a “60 Minutes” interview with then-Vice President Kamala Harris, which led to Paramount agreeing to pay $16 million to settle the lawsuit in July; shortly after, the Federal Communications Commission, led by a Trump appointee, approved Paramount’s merger with Skydance. Between the settlement and merger approval, CBS announced it is canceling “The Late Show With Stephen Colbert.” Colbert frequently skewers the president on his show, and Trump praised the cancellation. Paramount also recently bought the global streaming rights to “South Park” in a lucrative $1.5 billion deal for Parker and Stone. During the episode’s fictitious “60 Minutes” segment over Trump’s lawsuit against the town, Jesus comes to visit the townspeople. Through whispers, he tells them, “I didn’t want to come back and be in the school, but I had to because it was part of a lawsuit and the agreement with Paramount.” “The president’s suing you?” a protester asks. Jesus, through clenched teeth, explains: “The guy can do what he wants now that someone backed down. … You guys saw what happened to CBS? Well, guess who owns CBS? Paramount! You really want to end up like Colbert? You guys gotta stop being stupid. … If someone has the power of the presidency and also has the power to sue and take bribes, then he can do anything to anyone.” “All of you, shut the f— up or South Park is over!” Jesus says. The people of South Park end up settling their lawsuit with the president for $3.5 million, saying it will be fine as long as they cut some funding for their schools, hospitals and roads. And as part of the settlement, they have to agree to “pro-Trump messaging.” Cut to a live-action deepfake video of Trump trekking through the desert in a show of loyalty to his supporters before he strips naked. [Note: This episode aired on Aug. 6, more than a month before political commentator Charlie Kirk, who is parodied throughout the episode, was shot and killed.] This episode is focused on the ongoing raids carried out across the country by Immigration and Customs Enforcement and Department of Homeland Security officials since earlier this year. When South Park Elementary counselor Mr. Mackey is fired — the government is doing away with needless spending in schools, he’s told — he signs up for a job with ICE, enticed by a generous signing bonus and a higher salary. Mackey watches a promotional video, complete with animations of officers wearing gaiters and a theme song: “We don’t ask for experience, just show up/ We don’t care if you’ve read a book or grown up/ If you’re crazy or fat and lazy, we don’t care at all … If you need a job, it’s a job to have.” Mackey is hired with alarming speed and proceeds to go on his first raid, targeting a “Dora the Explorer” live show, which has a not-so-intimidating audience of young children and abuelitas. After ICE agents hear from protesters that there are “many Latinos in heaven,” they make the pearly gates their next stop. The Department of Homeland Security secretary leads ICE agents through a series of raids this episode, but she first appears in an orientation video. She tells the new recruits, “A few years ago, I had to put my puppy down by shooting it in the face because sometimes doing what’s important means doing what’s hard,” and she proceeds to going on a shooting spree targeting yelping puppies (including Krypto the Superdog) throughout the episode. In her 2024 book, Noem wrote about how she killed her 14-month-old dog for exhibiting aggressive behavior. She’s also seen rounding up as many immigrants as possible in raids, shouting orders like, “If it’s brown, it goes down.” And in a running gag, her face periodically melts off, requiring a glam squad equivalent to a pit crew, and at one point, it seems to take on a life of its own. Trump also says her face “freaks me out” during the episode. Noem responded to the depiction on Glenn Beck’s podcast, calling it “lazy” to target her looks. “If they wanted to criticize my job, go ahead and do that, but clearly they can’t, they just pick something petty like that,” she said. While conservative political commentator Charlie Kirk does not appear as a character in this episode, his style of debate content — and his name — are featured. Loudmouthed Cartman is frustrated that so many others, namely his classmate Clyde Donovan, are profiting off of “his shtick” of arguing against liberal views. Clyde has a debate podcast, inviting viewers to watch as he “totally destroys these woke liberal students.” He’s set up in a tent on a college campus where he waits as a line of students come to speak with him, and he challenges them to “prove me wrong.” Cartman eventually takes over, saying that he is the “master debater” and sporting a haircut similar to Kirk’s. He shuts down his opponents’ arguments with phrases like, “You just hate America and you love abortions.” Clyde and Cartman’s content replicates Kirk’s well-known style. The founder of the conservative organization Turning Point USA frequently toured college campuses and hosted events just like the one depicted in the episode. The phrase “prove me wrong” was used frequently by Kirk to promote his events, inviting students to challenge his political and cultural views. On Sept. 10, Kirk was shot and killed while hosting such an event at Utah Valley University, the first stop of his “American Comeback” tour. Weeks before he was killed, Kirk responded to the episode with a 30-minute YouTube video, finding it humorous. “I think a lot of it was hilarious towards me,” he said. “Some of it was very funny and I don’t think we should have too thick of skin.” He also touched on the reach of his organization and events, noting that his name is enshrined in “The Charlie Kirk Award for Young Masterdebaters” that Cartman and Clyde compete for in the episode. “So a campus thing I’ve been doing for 13 years to debate random college kids has now been so important that it gets prominent prime-time placement on Comedy Central?” he asked through laughs. “I think the whole thing is just awesome and hilarious.” When Mr. Mackey is rewarded for good work as an ICE agent, he’s flown to Trump’s Mar-a-Lago estate, where he frequently stays and hosts events. He’s greeted by giggling women who hand him a drink and put flower leis around his neck before the president meets him and gives him a brief tour of Mar-a-Lago. While there, Mackey accidentally walks in on two older men receiving massages from younger women, one of whom is a tearful Dora, detained in the raid that took place earlier in the episode. The scene is likely a reference to Epstein and accounts from survivors who say they were forced to give massages to him and his associates. Trump said this summer that Epstein “stole” young women who worked at the Mar-a-Lago spa, which caused them to have a falling-out. The vice president is depicted as a version of Tattoo, the character from late-’70s drama “Fantasy Island,” and is animated similarly as Trump, except the photo used for his face is lifted directly from viral memes. He often does the president’s bidding, calling him “boss.” In turn, Trump frequently calls Vance “stupid.” Acknowledging the caricature, Vance wrote on X, “Well, I’ve finally made it.” Randy’s hemp farm business, Tegridy Farms, is the site of an immigration raid at the the beginning of this episode. While Randy is shooting a commercial, complete with calming guitar music and a trite script, ICE officers interrupt by detaining almost all the workers. “You sons of b—,” Randy screams after the vans as they drive away. “Those are my Mexicans!” In July, chaotic raids targeting a cannabis company’s growing site and greenhouse in Santa Barbara and Ventura counties drew national attention after a man who was fleeing immigration officials died. With his business in shambles, Randy rethinks his strategy with the help of an over-complimentary AI chatbot. Perhaps in a nod to Trump’s former ally and onetime “special government employee” Elon Musk, the billionaire businessman behind Tesla, SpaceX and X, Randy turns to ketamine. Randy insists a slew of “tech guys” are taking small doses of ketamine and the drug “gives their minds the edge to work with AI.” Ketamine “bolsters our focus and creativity,” he tells his partner Towelie. Under the influence of the drug, Randy transforms Tegridy Farms from a “quaint farm” into an “AI-powered marijuana platform for global solutions.” Musk’s use of ketamine and other drugs has been previously reported, with the tech leader saying in a 2024 interview that ketamine has been prescribed to him and is “helpful for getting one out of a negative frame of mind.” He has denied abusing it. “If you use too much ketamine, you can’t really get work done. I have a lot of work, I’m typically putting in 16-hour days,” he said. “So I don’t really have a situation where I can be not mentally acute for an extended period of time.” Musk supported Trump’s campaign and served as an advisor to the president, helming the Department of Government Efficiency earlier this year with the goal of slashing spending. Meta and Apple chief executives Mark Zuckerberg and Tim Cook, who were both present at Trump’s inauguration and have maintained friendly relationships with him, are both portrayed in this episode as members of a long line outside of the Oval Office waiting to bestow a gift on the president. “Mr. President, your ideas for the tech industry are so innovative,” Cook says to Trump. Cook gives the president a gift on behalf of Apple, which actually happened this summer. Zuckerberg is later seen giving the president a gift that appears to be a gold and bejeweled Meta virtual reality headset. Qatar’s leader is also seen in line holding a model gold plane with a tag that says “Air Force One.” Like everyone else, the leader compliments the president and insists his genitalia is not small before giving him the gift. Trump and the Defense Department accepted a luxury Boeing 747 aircraft from Qatar for President Trump to use as Air Force One this summer, despite ongoing questions about the ethics and legality of taking the expensive gift from a foreign nation. When Towelie takes a trip to the capital in this episode, he sees armed troops guarding monuments like the Washington and Lincoln memorials and the Capitol surrounded by tanks and jets. In the episode, the Lincoln Memorial has been replaced by a statue of a stern-faced Trump with exposed genitalia. In August, Trump called up National Guard troops to Washington, D.C., to assist federal law enforcement in his bid to “reestablish law and order” by targeting criminals — though crime has been down in the city — and the homeless. Although troops were not initially armed, Defense Secretary Pete Hegseth later ordered them to carry service-issued weapons. Randy sends Towelie to meet with Trump and give him a gift in hopes of persuading him to reclassify marijuana on the national level. (The gift is Towelie himself.) Randy, in the form of a hologram, tells Trump he thinks they can work out a mutually beneficial arrangement. Trump said in an August press conference that his administration was considering reclassifying marijuana as a less dangerous drug, which would be a significant change in policy but would not make the drug legal across the country. The clerk at the City Pop-Up — rebranded from City Wok — the lone purveyor of Labubus in the area, says the popular dolls are hard to keep in stock, and they’re very expensive because of tariffs. The “mystery box” that Butters has to purchase for the chance of getting the exact Labubu his girlfriend wants sets him back $85, and later, the price shoots up to $120 to offset a rise in tariffs. (The real-life dolls often fetch much more than that on resale sites, especially if they are rare.) When Butters balks at the price, the store owner explains that the cost of tariffs is passed onto the customer. This episode shows a clip from a Fox News segment where an anchor is overly complimentary of the president. The anchor says the president will take questions from a “diverse crowd of reporters” after returning to the U.S. from a historic tariff summit, only to reveal all of the reporters are from Fox. The Fox News reporters also fixate on President Trump’s relationship with his wife, Melania, and his increasingly frequent appearances with Satan. There’s a heavy use of wordplay that suggests the anchors could be asking about the affair between the president and Satan or about whether Trump is actually the devil himself. Fox News reporters check in with Trump ally Kid Rock after breaking the news that — buckle up — Trump has impregnated Satan. A sobbing Kid Rock tells the reporters, “I’m just so happy.” The musician is a friend and ardent supporter of Trump, having performed at his inaugural rally in January and spoken many times publicly about his support of the president. Kyle becomes irate when his classmates place bets on a popular market prediction app that his mother would “strike Gaza and destroy a Palestinian hospital.” This episode marks the first time this season that the show has touched on the current conflict in Gaza, and it referenced real-life Israeli strikes on hospitals in the area. Trump’s eldest son appears in this episode as someone with many roles — he’s a strategic adviser for predictive markets, he answers the phone for the Commodity Futures Trading Commission and also acts as a special adviser to Israel. Although he wears all those hats, the series doesn’t portray him as particularly bright — he has a complete conversation over the phone with himself. He’s also animated to look as if he’s had extensive plastic surgery and he speaks with a strained voice, as if he can’t move his face. Trump Jr. holds several key roles in his family’s business and his father’s political sphere in real life, and he serves as an adviser to both Polymart and Kalshi, two prediction market apps that are named and spoofed in this episode. Less keen on the baby he’s expecting with Satan, Trump looks for different ways to harm the pregnancy in hopes of terminating it. He asks Satan if he wants to smoke and hang out in a hot tub, holds up a wire hanger, tries to get him to trip down the stairs or fall under a pile of cat feces, and even makes Satan a soup full of emergency contraceptive pills. In reality, Trump has repeatedly shifted his messaging on abortion but has most recently said he believes specific abortion policies and access should be decided not by federal law but by individual states. The chairman of the Federal Communications Commission comes into the fold this episode when Kyle goes through several hoops to try to file a complaint over the bet involving his mom, which he finds offensive. The FCC is “dealing with all the offensive stuff now,” Kyle is told. Carr says he needs to speak with the president after learning about the offensive content, but he ends up falling victim to all of Trump’s antics in his attempt to terminate Satan’s pregnancy, which send him to the hospital. The doctors say they’re “afraid he may lose his freedom of speech.” Vance later threatens Carr, who keeps interfering with Trump’s attempts to end Satan’s pregnancy (Vance doesn’t want anything to mess with his proximity to the presidency). “We can do this the easy way, or we can do this the hard way,” Vance says to Carr. Those words match the phrase Carr said in real life a week before this episode aired in reference to his call on ABC to act on comments late-night host Jimmy Kimmel made about Kirk’s suspected killer and his death. Carr has remained in the headlines since then as backlash grew against the FCC’s role in Kimmel’s suspension. Frustrated by the bet about her and the ongoing conflict in Gaza, Kyle’s mom storms into the office of the Israeli prime minister. “Just who do you think you are, killing thousands and flattening neighborhoods, then wrapping yourself in Judaism like it’s some shield from criticism?” she says. “You’re making life for Jews miserable and life for American Jews impossible.” She continues to berate him and a group of officials while the credits roll. Netanyahu does not say anything in response. ©2025 Los Angeles Times. Visit latimes.com. Distributed by Tribune Content Agency, LLC.
--------------------------------------------------

Title: Wall Street Can’t Get Enough of Nvidia Stock. Is It a Buy Below $180?
URL: https://www.barchart.com/story/news/35065072/wall-street-cant-get-enough-of-nvidia-stock-is-it-a-buy-below-180
Time Published: 2025-09-26T16:24:42Z
Description: Nvidia is a big tech stock that remains at the epicenter of the artificial intelligence megatrend. Is NVDA stock still a good buy right now?
--------------------------------------------------

Title: Up 85% YTD, More Returns In Store For Micron Stock?
URL: https://www.forbes.com/sites/greatspeculations/2025/09/26/up-85-ytd-more-returns-in-store-for-micron-stock/
Time Published: 2025-09-26T09:30:24Z
Full Content:
ByTrefis Team, Contributor. As generative AI transforms various industries, one of the most essential – yet frequently overlooked – elements driving this change is memory. Memory manufacturer Micron (NASDAQ:MU) is central to this evolution, supplying the high-bandwidth memory (HBM) and DRAM necessary to keep extensive AI models operating at both speed and scale. As AI workloads become increasingly complex, memory is becoming vital for hyperscalers and cloud service providers. While GPUs and accelerators capture attention, memory is the discreet backbone that dictates the speed and efficiency of these systems. The stock price of Micron reflects this rising demand, having surged roughly 85% year-to-date in 2025. Nonetheless, is the stock still worthy of consideration at present valuations? Regardless of its appeal, investing in a single stock carries significant risk. The Trefis High-Quality Portfolio has been designed to lessen stock-specific risk while providing upside potential. The figures from Micron’s results speak for themselves. For the quarter ending in August, Micron’s revenue reached $11.32 billion, an increase of 46% year-over-year, while adjusted net income skyrocketed by 157% to $3.47 billion ($3.03 per diluted share). Remarkably, sales in the cloud memory segment more than tripled to $4.5 billion. CEO Sanjay Mehrotra informed analysts that the demand for Micron’s DRAM and NAND offerings was stronger than previously anticipated, enhancing the company’s outlook. Robust DRAM shipments across all end markets, strong pricing due to constrained supply and low inventory levels, along with slower transitions to newer process nodes limiting total output, are all factors contributing to growth. Micron anticipates a favorable demand-supply balance for DRAM in 2026, which will support ongoing profitability. For Q1 2026, Micron projects revenue of $12.5 billion, plus or minus $300 million, marking an increase of approximately 61% year-over-year at the midpoint. HBM is an ultra-fast, low-latency memory primarily crafted for AI accelerators and GPUs to swiftly process vast model data, while DRAM provides larger-capacity, general-purpose memory supporting AI workloads by storing large volumes of data, albeit at slower transfer speeds than HBM. Micron serves as a primary memory and storage partner for Nvidia’s Blackwell GB200 and GB300 platforms, supplying both HBM3E and LPDDR5X solutions, and is also a key supplier for AMD’s Instinct MI350 GPUs. Nvidia’s latest systems incorporate 33% more memory per node compared to previous generations, as AI models increasingly adopt a multimodal approach – integrating text, video, and speech – heightening the demand for memory. Refer to our note on how Micron Stock Surges 2x To $300 To underscore the magnitude of investment in AI, Amazon (NASDAQ:AMZN), Alphabet (NASDAQ:GOOG), Microsoft (NASDAQ:MSFT), and Meta (NASDAQ:META) have suggested that they could collectively commit $364 billion to capital expenditures in their respective current fiscal years. Earlier in September, Oracle revealed it has entered into contracts worth hundreds of billions of dollars to offer cloud computing services to OpenAI and other large clients. While these infrastructure agreements will necessitate computing power – either GPUs or custom ASICs, as well as server and networking equipment, memory will also be vital, and Micron stands to gain significantly from this expansion. With the ascent of AI adoption throughout the economy, Micron is poised for sustained growth. Indications suggest that the most compute-intensive phase of AI training may start to plateau, with the industry pivoting toward inference – the application of trained models to fresh data in real-time and at massive scale. Inference is less demanding per task but takes place continuously across millions of users and applications. HBM is critical for enabling AI inference at scale, thanks to its bandwidth and power efficiency benefits, complementing high-performance GPUs primarily utilized for training. This trend undeniably favors specialized, power-efficient suppliers like Micron. However, supply may struggle to keep up. Manufacturing HBM is more complex than producing standard DRAM, and supply levels remain tight. Creating HBM is wafer-intensive—it necessitates around three times more wafers than standard DRAM to yield the same volume of bits due to its lower bit density and complex 3D stacking, resulting in a natural bottleneck. While Micron has been increasing its HBM production capabilities, its output for 2025 has already been sold out, with strong demand expected for 2026. The company allocated $13.8 billion for capital expenditures in FY’25 and plans to further boost spending in 2026, chiefly to enhance DRAM capacity for AI workloads. For Q1 2026 alone, Micron aims to invest $4.5 billion, with the majority of capex focused on DRAM. This figure serves as a baseline for what investors can anticipate each quarter, indicating that total capital expenditures for the year will likely exceed $18 billion. Despite this notable rally, Micron stock is valued at approximately 10 times estimated earnings for 2026. Projected growth appears robust: anticipated revenues are expected to increase by 42% in 2026, based on consensus forecasts. Nevertheless, the memory market has historically been cyclical. DRAM and NAND are susceptible to variations in supply and demand, along with price volatility. At this point, it seems that HBM acts as a partially secular growth factor, given the relentless investment by major tech firms over the last three years. However, HBM currently represents only a small fraction of total sales, meaning the company is not completely shielded from traditional market cycles. The Trefis High Quality (HQ) Portfolio, comprising 30 stocks, boasts a history of consistently outperforming its benchmark, which includes the S&P 500, Russell, and S&P midcap — and has achieved returns exceeding 91% since its inception. What is the reason for this? Collectively, HQ Portfolio stocks have provided superior returns with lower risk compared to the benchmark index; resulting in a less tumultuous experience, as demonstrated by the HQ Portfolio performance metrics.
--------------------------------------------------

Title: Alibaba stock’s AI-powered run isn’t done
URL: https://www.livemint.com/companies/alibaba-stock-s-ai-powered-run-isn-t-done-11758862823323.html
Time Published: 2025-09-26T06:30:09Z
Full Content:
This is a Mint Premium article gifted to you. Subscribe to enjoy similar stories. Last autumn, Alibaba was rallying on China’s stimulus plans. Now, its artificial intelligence moves are powering the stock, and it looks like there will be more gains to come. Shares of Alibaba Group Holding have jumped some 77% since Barron’s recommended them last fall. While the stock might not rally at such breakneck speed going forward, it appears poised to keep climbing—especially since it doesn’t look too pricey. China’s determination to stand on equal AI footing with the U.S. is a major factor in the stock’s favor, as Alibaba is pushing to be a central player in the country’s ongoing AI and cloud adoption. On Wednesday, Alibaba released a flurry of updates that sent its American depositary shares higher. The company plans to boost its AI spending, open new data centers across Asia, Europe, and North and South America—while also unveiling its largest AI language model on record, Qwen3-Max, with more than a trillion parameters. The company is also partnering with Nvidia to integrate the superstar chip maker’s products into tools like robots and self-driving cars. Many on Wall Street like what they’re seeing, with nearly 90% of analysts tracked by FactSet bullish on Alibaba. Citigroup’s Alicia Yap reiterated a Buy rating on the stock following the latest AI announcement. She also boosted her price target for Alibaba’s ADRs to $217 from $187 to account for her more optimistic revenue estimates for its cloud division. “Being one of the five to six global super cloud platforms with full-stack AI services, we believe Alibaba is well-positioned to capture the artificial superintelligence evolution," she wrote. It’s not just that Alibaba is seeing so many technological advances. Rather, it’s becoming an integrated one-stop shop for AI and cloud services, emulating major Western players’ full-stack model, which means they’re in control of the process and development from start to finish. “Alibaba will build Alibaba Cloud into a full-stack AI service provider, similar to what we see with Amazon Web Services/Google Cloud Platform, including the compute layer to power AI training/inference and offering proprietary open-source models within its own cloud environment," writes Baird analyst Colin Sebastian, He has an Outperform rating on Alibaba, and raised his price target to $174 from $153 on Wednesday. Perhaps even more importantly, however, Alibaba’s recent winning streak and announcements show that it’s no longer on the outs with Beijing. China has shown that it is committed to rivaling the U.S. when it comes to AI capabilities. As Barron’s notes, the fact that Alibaba has been able to notch so many AI victories suggests that it has done so with the Chinese government’s blessing. Although China’s chip capabilities are rapidly advancing, Nvidia chips are still the gold standard in many cases. Therefore, Alibaba’s Nvidia partnership likely required government approval, considering the company passed over domestic semiconductor companies, Gavekal analyst Tilly Zhang noted. That suggests China potentially “has more regulatory flexibility" when it comes to promoting AI evolution, she adds, with Alibaba at the forefront. Of course, investing in Chinese companies will always take some leap of faith: Government favor can change and other corporate information may not be readily forthcoming, leading to valuation gaps. Nonetheless, with Alibaba’s ADRs changing hands for just over 17 times the next fiscal year’s expected earnings, it looks worth the risk. It goes without saying they are far less expensive than even the cheapest of the Magnificent Seven—Google parent Alphabet and Facebook parent Meta Platforms trade in the mid-20 times range. There are other legitimate worries, however. The Zephirin Group analyst Lenny Zephirin, an Alibaba bear, argues that U.S. tech companies’ spending and advancement still far outstrip those of China, meaning the upside for Alibaba has been exaggerated. Still, as long as the company is increasingly backed by Beijing—and the tech halo extends beyond the U.S.—the shares are likely to keep outperforming while the AI trade dominates. Alibaba may never be on par with U.S. tech companies in a number of metrics. Yet it doesn’t need to be for its stock to keep winning. Download the Mint app and read premium stories Log in to our website to save your bookmarks. It'll just take a moment. You are just one step away from creating your watchlist! Oops! Looks like you have exceeded the limit to bookmark the image. Remove some to bookmark this image. Your session has expired, please login again. You are now subscribed to our newsletters. In case you can’t find any email from our side, please check the spam folder. This is a subscriber only feature Subscribe Now to get daily updates on WhatsApp
--------------------------------------------------

Title: Top companies keep talking about AI – but can’t explain the upsides
URL: https://www.irishtimes.com/business/work/2025/09/26/top-companies-keep-talking-about-ai-but-cant-explain-the-upsides/
Time Published: 2025-09-26T04:00:00Z
Full Content:
The biggest US-listed companies keep talking about artificial intelligence. But other than the “fear of missing out,” few appear to be able to describe how the technology is changing their businesses for the better. That is the conclusion of a Financial Times analysis of hundreds of corporate filings and executive transcripts at S&P 500 companies last year, providing one of the most comprehensive insights yet into how the AI wave is rippling through American industry. Big Tech giants such as Microsoft, Alphabet, Amazon and Meta have regularly extolled AI’s benefits, pledging to invest $300 billion (€254 billion) this year alone to develop the infrastructure around large language models. Large companies far from Silicon Valley, from beverages giant Coca-Cola to sportswear maker Lululemon, are also discussing AI at ever-greater length in their regulatory filings. But they also largely paint a more sober picture of the technology’s usefulness, expressing concern over cybersecurity, legal risks and the potential for it to fail. Customer service support and data-heavy businesses have found it easiest to explain their use of the technology. Paycom, a payroll services provider, reported in filings that AI is an “important differentiator” for attracting and retaining clients. The filings do reveal a number of innovative uses of the technology. Huntington Ingalls, a military supplier, is applying AI “for battlefield decisions”. Animal health group Zoetis is using the technology to speed up medical tests for horses. Dover Corporation, a manufacturer, has a new process for tracking “hail-damaged vehicles” through to their repair. But AI adoption has not necessarily led to more growth. Dover Corporation’s stock has done the best of those three companies since the launch of ChatGPT in November 2022, almost matching the S&P 500 Equal Weighted index. [ AI’s replacement of humans in HR is emblematic of what could happen across the workplaceOpens in new window ] This index does not allow the size of the so-called Magnificent Seven tech stocks – Apple, Microsoft, Amazon, Alphabet, Meta, Nvidia and Tesla – to dominate results, and is better for comparing whether a stock has performed better than others in the index. “When it comes to AI adoption, many companies aren’t guided by strategy but by ‘Fomo’,” said Haritha Khandabattu, senior director analyst at consultancy Gartner. “For some leaders, the question isn’t ‘What problem am I solving?’ but ‘What if my competitor solves it first?’” The FT has used AI tools to identify these mentions of the technology in SEC 10-k filings and earnings transcripts, then to categorise each mention. The results were then checked and analysed to help draw a nuanced picture about what companies were saying to different audiences about the technology. SEC filings require companies to disclose risks to the businesses, and are necessarily more cautious than the sales pitches made by executives on earnings calls. But the increasing array of risks described in filings appears not to be weighing on executives in the public pronouncements. Of the S&P 500, 374 companies mentioned AI on earnings calls in the past 12 months – with 87 per cent of the calls logged as wholly positive about the technology with no concerns expressed. Over the past five years, the boom of the Magnificent Seven tech stocks has driven a large portion of the S&P 500’s growth. While non-tech companies are upbeat about AI, their filings suggest less clear upsides. During an earnings call in February, Coca-Cola was excited about the technology – even though the key use was in the production of a TV commercial. The FT sought to categorise the expected positive benefits of the technology. Most of the anticipated benefits, such as increased productivity, were vaguely stated and harder to categorise than the risks. Companies anticipated being able to optimise workflows through automation, and hope to achieve market differentiation through their use of AI. Some hoped to be able to use the technology to improve the personalisation of their products. Meta, which has spent billions of dollars to hire a team of researchers dedicated to building ‘superintelligence’, was among the Big Tech groups to warn it could incur large legal settlements over allegations ‘that we used various copyrighted books and materials to train our artificial intelligence models' Filings do reveal that the companies able to give clear AI upsides include those that serve the rising AI-driven data-centre boom. Energy companies First Solar and Entergy cited AI as a demand driver. Freeport-McMoran, which has a stockpile of copper, stated that “data centres and artificial intelligence developments” would support the metal’s price. The company also said the technology can help with material characterisation and mineral extraction. Equipment manufacturer Caterpillar reported that its energy business was benefiting from supporting “data centre growth related to cloud computing and generative artificial intelligence”. As the number of companies discussing AI has grown, fewer businesses are expressing positive views about the technology than they did in 2022. The most commonly cited concern was cybersecurity, which was mentioned as a risk by more than half of the S&P 500 in 2024. Online dating group Match warned that “the use of AI has been known to result in, and may in the future result in, cybersecurity incidents that implicate the personal data of end users of AI-enhanced services”. [ AI begins to bite: Recruiters attribute a slump in professional services hiring to job automationOpens in new window ] Companies expressed particular concern that other businesses and customers could prove to be weak links. Lululemon said it was concerned about security risks posed by advanced AI technologies, which could lead to sensitive information, such as transaction data, being compromised. Microsoft struck a dramatic tone, saying “[i]neffective or inadequate AI development or deployment practices by Microsoft or others could result in incidents that impair the acceptance of AI solutions, cause harm to individuals, customers or society, or result in our products and services not working as intended”. “Companies tend to see AI as a risk because they’re not used to having systems or processes which they can’t rely upon 100 per cent,” said Ray Eitel-Porter, an AI governance expert and author. The second-largest concern among US companies is the fear that their efforts to introduce the technology will not be successful. Recent research led by Aditya Challapally at the MIT Media Lab found 95 per cent of generative AI pilots in the workplace failed. This was because the current generation of AI tools lack features such as long-term memory and customisation, which would make them easier to plug into existing company systems. “When we spoke to executives, they would often say the internal tool was very successful,” said Challapally. “But when we spoke to employees we found zero usage.” In 174 annual reports, another common concern is the rise of regulatory and legal concerns over implementing AI. Meta, which has spent billions of dollars to hire a team of researchers dedicated to building “superintelligence”, was among the Big Tech groups to warn it could incur large legal settlements over allegations “that we used various copyrighted books and materials to train our artificial intelligence models”. Other companies with less AI exposure have raised similar worries. PepsiCo said “our use of artificial intelligence may result in increased claims of infringement or other claims, including those based on unauthorised use of third-party technology or content”. The FT’s analysis shows that companies are a lot clearer about the potential problems with AI than the upsides. “[T]here can be no assurance that the usage of AI will enhance our products or services or be beneficial to our business, including our efficiency or profitability,” Meta wrote in its 10k form last year. “We may not be successful in our artificial intelligence initiatives, which could adversely affect our business, reputation or financial results.” – Copyright The Financial Times Limited 2025 © 2025 The Irish Times DAC
--------------------------------------------------

Title: This bold Oracle move could be the beginning of something big
URL: https://www.thestreet.com/technology/this-bold-oracle-move-could-be-the-beginning-of-something-big-
Time Published: 2025-09-26T01:03:00Z
Description: Two insiders now lead Oracle’s next chapter. The move could be visionary — or risky.
--------------------------------------------------

Title: Up nearly 150% in 5 years with plans to double data centre profits by FY27, does this ASX 200 stock have further to run?
URL: https://www.fool.com.au/2025/09/26/up-nearly-150-in-5-years-with-plans-to-double-data-centre-profits-by-fy27-does-this-asx-200-stock-have-further-to-run/
Time Published: 2025-09-25T23:30:00Z
Description: Will this ASX 200 stock continue to benefit from the AI boom?
The post Up nearly 150% in 5 years with plans to double data centre profits by FY27, does this ASX 200 stock have further to run? appeared first on The Motley Fool Australia.
--------------------------------------------------

Title: Stock market today: Live updates
URL: https://www.cnbc.com/2025/09/25/stock-market-today-live-updates.html
Time Published: 2025-09-25T22:08:25Z
Description: Investors are awaiting the release of August's personal consumption expenditures price index out Friday.
--------------------------------------------------

Title: Morgan Stanley warns AI could sink 42-year-old software giant
URL: https://www.thestreet.com/technology/morgan-stanley-warns-ai-could-sink-42-year-old-software-giant-
Time Published: 2025-09-25T18:03:00Z
Description: Market braces for fallout if AI risk plays out
--------------------------------------------------

Title: Nvidia Is on a Dealmaking Spree: Should You Buy NVDA Stock Amid Fears of an AI Bubble?
URL: https://www.barchart.com/story/news/35040319/nvidia-is-on-a-dealmaking-spree-should-you-buy-nvda-stock-amid-fears-of-an-ai-bubble
Time Published: 2025-09-25T17:25:06Z
Description: Nvidia has announced a flurry of deals this month, even as concerns linger over AI being a bubble. NVDA’s forecast looks positive, though as global AI...
--------------------------------------------------

Title: Jim Cramer Says “Entergy Has a Number of Things Going for It”
URL: https://finance.yahoo.com/news/jim-cramer-says-entergy-number-170549405.html
Time Published: 2025-09-25T17:05:49Z
Description: Entergy Corporation (NYSE:ETR) is one of the relatively cheap S&P 500 stocks Jim Cramer talked about. Cramer discussed the company’s growth and valuation, as...
--------------------------------------------------

Title: Is Meta Stock a Buy as User Growth Rises?
URL: https://www.barchart.com/story/news/35037389/is-meta-stock-a-buy-as-user-growth-rises
Time Published: 2025-09-25T15:16:51Z
Description: Meta’s Instagram has surpassed 3 billion monthly active users, a milestone that reflects the benefits of AI.
--------------------------------------------------

Title: Presentation: Panel: Next Generation Inclusive UIs
URL: https://www.infoq.com/presentations/inclusive-xr-environment/
Time Published: 2025-09-25T14:15:00Z
Full Content:
A monthly overview of things you need to know as an architect or aspiring architect. View an example We protect your privacy. Facilitating the Spread of Knowledge and Innovation in Professional Software Development Unlock the full InfoQ experience by logging in! Stay updated with your favorite authors and topics, engage with content, and download exclusive resources. Ramya Krishnamoorthy shares a detailed case study on rewriting Momento's high-performance data platform from Kotlin to Rust. She covers the technical challenges, including garbage collection bottlenecks and multithreaded contention, and the business trade-offs involved in adopting a new language to achieve predictable low tail latencies and maximize cost efficiency for their serverless services. In this episode, Suhail Patel joins Thomas Betts for a discussion about growing yourself as your company grows. When he started at Monzo, Patel was one of four engineers on the then new platform team–there are now over 100 people. The conversation covers how to thrive when the company and the systems you’re building are going through major growth. Large Language Model (LLM) inference faces a fundamental challenge: the same hardware that excels at processing input prompts struggles with generating responses, and vice versa. Disaggregated serving architectures solve this by separating these distinct computational phases, delivering throughput improvements and better resource utilization while reducing costs. David Grizzanti shares a roadmap for senior software developers, architects, and engineering leaders. He discusses how to overcome the "performance cliff" after a promotion, navigate ambiguity, grow your influence, and shape engineering culture. He explains how to design a fulfilling career by understanding what truly motivates you beyond a job title. Holly Cummins discusses how to eliminate waste in software development. She shares strategies like "LightSwitchOps" and build-time initialization to improve machine efficiency. She explains how these changes can lead to "double wins," benefiting sustainability and business goals while also improving developer experience and challenging conventional ideas about productivity and efficiency. Learn how senior devs at Mercedes-Benz, DKB & Zalando are solving critical dev challenges. Last chance to register. Your team looks to you for what's next. Get the foresight to lead them through software's biggest shifts. Early Bird ends Oct 14. Trying to run AI at scale? Find the blueprints for enterprise AI from leaders who built them. Early Bird ends Oct 14. Leadership asking for innovation? Get the evidence to bet on the right tech and lead with confidence. Early Bird ends Oct 14. InfoQ Homepage Presentations Panel: Next Generation Inclusive UIs The panelists discuss creating inclusive XR environments. They explain how to prioritize accessibility in user testing, the importance of designing for diverse users from day one, and how team culture and modular UIs can foster innovation. They also highlight the business case for making accessibility a core part of an MVP to avoid technical debt. Erin Pañgilinan is Spatial Computing, AI Leader and author of "Creating Augmented and Virtual Realities: Theory and Practice for Next-Generation Spatial Computing". Colby Morgan is Technical Director @Mighty Coconut. Dylan Fox is Director of Operations @XR Access, previously UC Berkeley researcher & UX designer, expert on Accessibility for Emerging Technologies. Software is changing the world. QCon San Francisco empowers software development by facilitating the spread of knowledge and innovation in the developer community. A practitioner-driven conference, QCon is designed for technical team leads, architects, engineering directors, and project managers who influence innovation in their teams. Doyle: We're going to do a Q&A panel. We're going to dig in a little bit more on how augmented, virtual, and extended, and mixed reality unlock the ability to integrate the power of computers more seamlessly into our physical three-dimensional world. Designing that user experience of these next generation UIs to be as inclusive as possible comes with a lot of challenges. We're going to sit down and talk about what are some of the insights and strategies for creating more inclusive and accessible XR environments. Our speakers today, we have Colby Morgan, we've got Dylan Fox, and Erin Pañgilinan. How does the process of user testing differ when accessibility is a priority, and what are some best practices? Erin Pañgilinan: My friend, who's a co-founder of my previous non-profit that I co-founded with her for women that were working in ARVR, it was called ARVR Academy, Suzanne Leibrick, who used to actually be in Mixed Reality at Intel at the time, she talks about the concept of gameplay testing. If you really think about even in like AI development, you're not going to start with the most gigantic foundation model and the most amount of data. You're going to start off with something really small and simple and test it on 10 people. What I always encourage people to do since 2016 is to try as many different VR or AR, XR, demos as much as possible. When you're actually developing for a single experience, you're going to start with maybe just a few interactions at a single level and see if it works with actual people. If you get more than 60%, maybe you're in a good range. A lot of the time you'll actually try it in a bunch and you'll realize, this actually doesn't work. That way you're saving a lot of time when you're gameplay testing. That's the first thing I would say. It's pretty easy. It's just most people who haven't developed for games before, like I said in the background, but it's also in AI, in that space that haven't done it, I think you're going to always rapidly prototype the smallest MVP possible. Dylan Fox: I think for me, one of the challenges that we see with XR, as opposed to more mobile and desktop technology, is that it generally assumes that most people have either a desktop or a mobile phone at home, and that they are able to turn these on and operate them and use the application, often remotely, without necessarily needing any external help. If you want to have inclusive XR experiences, the unfortunate reality right now is that there are a lot of people who would be interested in using these, but may not have a headset at home, and even if they did have a headset at home, may not be able to take it out, get through the setup process, and put it on themselves and activate your application independently. Something that I noticed when I was running the experiments we did at UC Berkeley on using the HoloLens for low vision folks, is that these systems were not necessarily created with the idea that the person who is in the experience may not be the one who is operating the experience. I would love to see more support for experimenters, more support for caretakers. There's a lot of times, especially with new technology like XR, where you want to empower the person who is wearing the headset to just focus on the experience, and you want to offload some of that setup and execution to somebody who is helping them on the side. Making sure that you have those good tools, so that if I'm trying to run an experiment or user test for somebody who is totally blind, I can hand them the headset, they can put it on, and then I can get them into the application, get them set up, and monitor their progress. That's something that's not super well supported right now. It would be lovely to see better support for it. Colby Morgan: Especially when it comes to accessibility, I think that trying to get that early in your process, so as you're developing those features, it's part of your design process early on as well. Again, you're having opportunities to develop or solve issues before they become issues, especially when it comes to accessibility. I think a lot of it is just that early mindset, too. Accessibility and inclusive design is really about good design in general, so just really trying to make good products and good experiences that have a lot of that baked in. Again, you're reducing the amount that you have to do later on down the pipeline. I think, especially for user testing, obviously it's a really critical part of that, and so I think as much as possible trying to work with your users or the communities, people that can really give you the solid feedback about the accessibility tools that you may be working on or integrating. I think the big thing I always think about, too, is it's really easy to check a box or just get a feature in that it checks the box and does the bare minimum of it, but a lot of times finding what's giving users value is really critical to that step, and especially with XR in general. Again, it's such an immersive technology, and so you just want to make sure that the tools that you're putting in actually provide value for users. Erin Pañgilinan: My friend Nathan Ventura, who co-founded a company called Vinci Games, so he's YC backed. He's doing VR basketball. His game, Blacktop Hoops, when I first tried it, it was literally just like, here's the environment and shoot a basketball. He didn't have characters yet, which is now tied to a lot of IP and film, but I actually had, it was a demo at the Philippine Consulate, so he's Filipino, I'm Filipino. One of our other friends, he's number two in the world at combat design for Street Fighter, but he's a combat designer in most games. He probably played everything on every console, X-Men. I asked him, I was like, how was it? Did you break presence when you tried this? He's like, I didn't, but when I actually tried it, second time, I broke presence, which is something really common when you have VR, is like, I feel like I'm really in this environment, but it skips too much, or it'll have the most buggy things. You'll do a ton of work, but in practice, when you find out, I've spent maybe hundreds of hours developing this game, and find out it doesn't work. Another one I'll mention is a friend, Jazmin Cano, who actually has a chapter in my book. She's a technical 3D artist and an accessibility products manager. Her game, which was from Owlchemy Labs, so they were acquired by Google. If you've ever played Vacation Simulator or Job Simulator, this was their latest version. We tried it at Meta Connect, and most basic thing, Wi-Fi doesn't work. When we think about design, obviously Dylan's work focused a lot on differently-abled or disabled folks, and you're trying to expand the amount of diverse content creators, trying to get as inclusive as possible with your design. When it comes right down to it, it's not just good design, it's just basic engineering and functionality of Wi-Fi is not working at Meta, and so when I'm playing in this headset, I hear voices of other headsets being mixed together in a multiplayer environment with only less than 10 people. I'm like, that's pretty bad. That's not the fault of Owlchemy. It might have been the event people who were organizing at this conference. I like to think of gameplay testing in every type of environment, no matter how big or small. It's the one thing I'll say lastly, too. With Horizon, if you thought about during the pandemic, you're watching Meta Connect in VR, you could probably have hundreds of voices, but once you scale to thousands of people attending, couldn't really do that. Same idea. It's also just basic engineering when you think about latency and functionality at the end of the day, not just good design, but basic practices, and like, does this work or not? Doyle: How do we ensure that inclusivity and accessibility are integral parts of the UI design process from day one rather than add it on later when we maybe find it in testing? Colby Morgan: I think part of that is, it touches back to the culture of a team and just making sure that the team behind it, the team behind the designs, the UI, the concept, the development, have a lot of those concepts. Part of their workflows, and everyone's on the same page as far as what you're working towards. The culture is part of that. For me, XR is such an immersive technology, and the social presence and the connection is such a huge part of that, and so you want to make that as inclusive as possible and as easy as possible to get into. I think for a lot of people, XR is just a lot. It can be a cognitive overload of trying to get into an experience. Obviously, it takes over your vision and all that. I think just, again, leaning back to just good XR design to make things simple and easy to operate and easy to get people in regardless of their experience level, because I think with every new technology there's always going to be people that are new to it, and there's always going to be that struggle. Again, just relying on those designs that make it really easy to get people in and participating. Dylan Fox: I think the single biggest thing in my mind to make sure that you have accessibility on the radar from the start is simply to have folks with disabilities on your team. If you're part of an organization that has a lot of folks with disabilities, then it's naturally going to be a part of the conversation, because you aren't going to ship something that doesn't work for your own people. Failing that, making sure you have people with disabilities in the loop as early and as frequently as possible way before you get to the alpha, like part of the design process, is just going to be really important. I think another thing that we often talk about when it comes to just the cold, hard cash of development is that it is far cheaper to build something in than to retrofit it. If you get to launch, you get to beta testing, and then you find out, actually, it's not accessible, we need to do this screen reader, or we need to be able to scale our UI. That is way easier to do when you're first building it out than after you have a million interconnected systems that it breaks. If you ever think accessibility is going to be an issue for your game, your app, your organization, which it probably will be if you ever get successful enough, then it's better to think about it from the start and save yourself a whole lot of time and headache and money and have just a better product right from the get-go. Erin Pañgilinan: I put Dylan on all of those points when you think about the end user itself, and thinking about different senses we're targeting. We saw a talk with Google AR, like how do visually impaired people see and not see. If you're mute, that's completely different. If you're someone that does not have an arm, you're not going to have a hand controller or a hand. These are really difficult challenges. Something really basic which I opened in my talk was with avatars. I was actually talking with Jazmin about the entire process of the app. She's like, what? You skipped over my entire part at the very beginning of like, create an avatar. I started off as a bald, it looked like a Nigerian man. I remember the very early prototypes for Oculus, by default, I was a very tall golden man. It was only metallic colors. I was like, I don't really identify with this, but it's really cool. I love Jeremy Bailenson's work, but it is a little problematic to say like, I can achieve empathy because now I can have blackface on. I'm like, that's not what this is for. To be culturally relevant I want an avatar or an agent that looks like me. One of the other user tests I've actually been doing at Meta, I can't say too much about it, but they ask you about skin color. I was like, that's really new and interesting. They never have asked that before. I think they are, at least some of the market leaders in headsets and manufacturing, just trying to think of, how are we being inclusive of more people that are end users, not just the people creating the products? That was never thought of I think five years ago, it was just like, that was a throwaway and a nice to have. Now it's like, we're actually thinking about this first. That wasn't the case. Also, in the game for Owlchemy Labs that we played at Meta Connect, I was talking to her about like, teleporting is really different. Previously you had to have a controller, whether you're using HTC VIVE or anything in the Oculus and Meta ecosystem, now it was all hands. It made me think like, but I don't naturally teleport by putting my hand out to go to the next portal. Is that the most inclusive UI if you don't have a hand? It really depends who you're targeting. I think you need to think about, who is that type of user? What senses do they have and prefer? I wouldn't say there's just flat-out bad design. There's just different points of accessibility that people identify with. The last thing I'll mention to you from the AI community is for black women or brown folks like myself. I'm a light-skinned, privileged Filipino woman. I will say, people don't trust AI that are black. Straight up, why? Because the algorithms, if you look at it, basic recognition for imaging on skin. It's why I'll go to the bathroom and my air blow dryer will work or water, but that won't work previously. This is because accessibility is not thought of. It's the last thing on the list for AI developers. For XR it was a little bit better. It still was at first. We weren't design inclusive by default. I think that's now changing. It's going to take a lot more work, I think, to be much more inclusive. Not just the content and the people developing it. Thinking on base level, what is the data and input that a machine is taking in? What's the sensory input that I'm receiving? You're thinking about I/O. What's the input and output on each end, inputting and receiving? I don't think that was thought of very critically before. It's definitely transformed and changed over a number of years. Doyle: What role does team culture play in building these accessible UIs? How do we foster a culture that values feedback and diverse perspectives? Colby Morgan: I think part of that is really focusing on getting a diverse team, so you have a diverse set of backgrounds and experiences to pull on from your team. As Dylan was pointing out, it's like, if you have a lot of different perspectives on your team, you can identify a lot of those things. It becomes easier, even as a culture element, if you have just a diverse team, to keep that top of mind with a lot of those different aspects. I'd say the diverse teams. Dylan Fox: I think in addition to the team, one thing you can do is spotlight your users and other stakeholders that are of different backgrounds, different abilities. We had a project with XR Access called the Stories Project, where we interviewed a number of disabled folks that had used XR, had an interest in it, enjoyed it, but obviously ran into challenges in using it. One thing we wanted to do was just spotlight those experiences. Because I think it's very easy for people to assume that everyone who uses a certain app is like themselves. I think we don't tend to think about people that aren't like ourselves unless we see some evidence that they exist. If you can spotlight those people that exist outside the norm and help to normalize that, this is for everybody. It's not just for your standard, usually in tech it's the standard cishet white dude. Then that can also be really helpful in making sure that your team doesn't just see this diversity of opinion in the team, but also in the people that you're creating for. Erin Pañgilinan: Outside of the obvious ones like race, gender, class, ethnicity, language, region is really important. In any application, interface is to me web development, not even XRs. It's like, how many different types of phones are there in the Philippines, for example? How many different screen sizes do I need to design for? I'll never be an Android developer, that's like too many. I was hardcore iOS for a really long time for a lot of different reasons. I think when you're thinking about targeting, accessibility, by default, it's a population and region. Outside of that, I also consider the type of discipline on the team. For a really long time with game design, it was only people who were AAA developers can be in XR. That was highly biased, especially for third-party independent developers like myself. I did not have that experience. I had a previous life in another career. There's a lot of bias there. Outside of non-traditional backgrounds, what I would say is it's actually not engineers to me that made the best experiences in VR in particular, it was architects. People who actually have an understanding of 3D space. When you think about AI, it's not necessarily machine learning engineers that have a statistics PhD and background. That used to be the case. I actually think psychologists have a lot to say. Cognitive scientists, anyone who actually works in real science and in the brain in life sciences, there's a lot that's to be worked on there if you're trying to achieve, to me, AGI or consciousness, when you think about presence in VR. I like to think of not just explicit insert my XYZ race, that they say, insert your identity here. I also think diversity and discipline of what you focus on is actually really valuable. That's now changing. The barrier to entry for people is also dropping. A lot of the classes I did teach from 2016 and on was everything from K-12 of students using Google Cardboard to employees at Cisco that were developing early prototypes for enterprise. We weren't getting people who were core C# developers. They were just anyone that worked as an engineer that was trying to think about, how do I think about networking and learning from first-person shooter games, but applying it at game design that's essentially B2C in a B2B environment. There's a lot of things that are cross-disciplinary by default that can make things more inclusive and new ways that you can put a lot of things together intersectionally that will create new and exciting experiences and that will actually be more inclusive. Not just, who's creating it because you're a cis straight white man and you're overrepresented. Instead of like, I think about Dylan as his expertise being like, you're focusing on populations that typically you wouldn't think of, or would be playing in an experience that is the most cutting edge and new that is by default much more human and accessible. Whether it's speech, voice, NLP, whether it's sensory, touch, gesture, get to the lowest common denominator of who cannot access those things. By targeting those audiences, I'm not going to say it's because it's a queer, trans black woman that is disabled. It's like, that's who you should target. I'm saying, if you actually support and target those things and put those people on your teams, they're probably going to have ten times richer the amount of experience, not because of who they are, but because of the disciplines that they have to think about and how they design, how they interact with the experience. Then on top of that, they're going to layer, here's my knowledge and statistics about why this doesn't work for this population and why that's not culturally relevant for my community, and why it does or does not work. It's actually multilayered. It isn't just straight up like, I'm going to hire a woman. Because of that, automatically it's going to be more diverse and automatically it's going to be a great experience. No, you can't take it at face value. It is much more deeper and multilayered in this process when we think about the words diversity. Diversity, not just like token Asian face, or token affirmative action card. It's really about like, what are you bringing to the table that is different and new and a different paradigm that you're contributing to innovation? Colby Morgan: One of the things I think I'll add too, with that, I think the other element of getting your team, but also just making sure that there's opportunities and everyone feels empowered to have a voice on your team, too. That's one thing, especially with new people on our team, we have to go through a phase of getting them really comfortable with giving feedback and feeling empowered to give feedback. Especially so you have a team where, again, I feel like a lot of projects and early in a project, it can be really easy to fall into a design hole or code silo where you're really focused and you almost don't want to get feedback because you're like, I'm really focused on this. I don't want to get some of that feedback. A big part of just having that culture that is open to feedback and everyone's empowered to give feedback on each of those steps, because I think there's a lot of those friction points that people run into that they just don't say anything. It's really easy, especially when you're working on XR experiences or features, it's really easy just to gloss over, it's like, that was hard, but I'm not going to really pay attention to it. Just making sure that everyone can call those things out, and really, it's like, yes, everyone was having a really hard time with this. We should actually try to make this better. Doyle: Then, how do you design UIs that adapt to individual users' needs and preferences? What are the current limitations you're seeing and where do you see this heading? Dylan Fox: I think the number one rule in my mind that I discussed earlier is that principle of modularity. You should have interfaces where the different inputs and the different outputs can all be done in multiple different ways. To our really great example of this, you can look at "The Last of Us Part II", which had an incredible suite of accessibility functions where people could do en masse, give me the hearing suite, give me the vision suite, but then tweak individual things. They would have any key thing, let's say there's like a scrap of material on the ground you can use to scavenge and use in crafting. If you turn the accessibility feature on, it wouldn't just light up, it would also make a sound, or the controller would vibrate. There is any number of ways where you could get that multi-modal feedback. I think making sure that your systems are modular like that, that you're thinking about things, and even things that maybe not what necessarily you think of as something that needs that. Things like eye contact in social VR, if I can set it so that I can literally feel everybody's eyes on me if they're all watching me, that could be a really powerful thing. This is also an area where I'm really excited for AI, because the ability for people to just say to the machine, make this thing bigger, or, can you outline X for me, and just adjust their experience on the fly, would be incredibly powerful. I think that is something that we're just barely starting to see, but will be very interesting to see if we can have systems that can accompany those types of requests in the near future. Erin Pañgilinan: Something really basic I mentioned earlier was your headset of choice is maybe informed by your "ethical moral values" of, I blame X about privacy, so I'm not going to use Meta. That's something I hear a lot. Or it's the same thing for Google. It's really tough because most of the companies that are developing these things do have legitimate privacy concerns with AI. Something really basic that they are doing right, which I think is great. I know if it's a Scarlett Johansson, but I actually had my mom pick, I was like, which ChatGPT voice do you want? It's like customize your version of Siri. I thought, that's a cool user choice. We didn't have that before. Being able to customize to the user based on a set of preferences, it's like, I didn't have it before that my avatar by default wasn't a man. If you think about cars, my brother's a big AZN racer, so we think about customizing, modifying the car constantly. Since the era of the '90s, it's a big thing. For Asian people, this is like the rice rocket movement. How would I customize my computer? Like CarPlay, take out the screen, put in your own screen, modify the UI. This is my custom window, and listen, now that's going to match the color of my car. Think about, what if you could customize the headset so that it would be much more accessible? Here's one thing when I think about more than just ergonomics. I love the Apple Vision Pro. It isn't great for accessibility with people with long hair. It's terrible. No one's gotten makeup right. Jazmin and I actually talk about this a lot, like, what eyeliner can you wear? Something really basic. People don't think about these things. Definitely not because there weren't that many women on these teams. If you think about even the car, how do we design a seatbelt? That was meant in terms of safety primarily for cis straight white men that were over 6 feet tall. I'm 4'10". When we think about accessibility, it's not just like, what is my programming language of choice as a developer? What is my headset choice? I was really excited about Apple. I'm like, you can customize the different type of colors of your computer. This is in the late '90s. There's so much more choice that we have now. There's still a lot of things that we don't have choice in. Part of the reason I'm so excited for Meta, and they haven't done this yet, they haven't open sourced their SDKs and APIs for anything with AR glasses. Many people are trying to hack them. It kind of works, and it kind of doesn't. I did talk with the director of product at Llama because they had shown some videos at Meta Connect about how they're using Llama 3, their latest model, with VR. Is it very accessible when you're talking about multi-modal models, but you're not open sourcing really basic stuff for people who are not doing model development to just basic software engineers? I think part of that problem is just because there's so much work to do within the ecosystem first before you open source something to that level of standard. Optionality and picking the different types of models, even the size of it, so that it's more affordable. It's the same thing for headsets. If I could have a cheaper option than an Apple Vision Pro where most of my community cannot afford a $3,500 headset, can they just get something as cheap as a Meta Quest S? That's probably like a $500 price point, would open up the doors for not only more consumers to enter but also designers and developers from the independent developer and third-party community that doesn't work at a big AAA game company or any of the other headset manufacturing companies. Colby Morgan: I think about adapting users and features and experiences for like specific users. Obviously, there's a lot of different things that you could do and handle. One of the powerful things I really like to rely on as much as possible is just finding tools and systems that can really just adapt to users. Trying to find those broad tools and systems that have a level of dynamic adaption to a player to more seamlessly meet some of their needs, to open up the experience. I want to just create more of a seamless experience that takes more of that friction out of there. Again, I think there's identifying some of those tools and systems that you get a lot of value out of for a lot of different users. One, how you identify those. Then, how you can make those as dynamic as possible. Dylan Fox: The more you can embrace users creating their own adjustments in terms of things like mods, things like 3D printing, custom controllers, or custom headbands, there's a lot of things you can do as a developer to embrace that and support that. Doyle: What about balancing simplicity and feature depth in the user interfaces, especially in the more immersive environments like VR and AR? Colby Morgan: Yes, especially XR, it's definitely a balancing act because it's really easy to go ham. As an XR developer, it's really exciting to make things. It's really exciting to add a bunch of features and effects and different things. I think just as good product design, I always really try to think of how do you focus your product? How do you focus your designs, and really think about your user's focus? What do you really want them to see? What do you want them to look at? What are you going to focus on? I think it's the balance back and forth of, how do you keep a real focused experience for the user, but how do you add more engaging features for users that have been using a product for longer? I think that's the balance of keeping it simple early on for a user, but then just having a clear path for a user to get more exposed to that depth and complexity. Also, any XR application lets users have the choice of, they want to keep the simple core experience. They don't necessarily want to try to get too deep with the features or anything like that. They have that opportunity to participate at the level in the experience they feel comfortable with. Dylan Fox: Some examples to look at are like Google Tilt Brush. You can start off in the simple mode, there's only a few tools on each of your little tool palettes. Then, when you're ready, open up the complex mode and get a bunch more controls, a bunch more customization. Thinking about things like that, thinking about when it comes to design for neurodiverse folks, having the option to turn off distractions, to really bring things down to the barest elements. You'll see that as well with some low vision support, things like, again, The Last of Us will have high contrast mode where it strips it down such that the player is in blue, the enemy is in red, new items are in yellow, and everything else is in gray. You get this extremely different aesthetic style. It becomes very minimalist. Then it makes it so that even if you're heavily visually impaired, you can still get that core sense of what's happening. I think thinking of ways that you can do that, of letting people scale their experience up and down is really good design philosophy. Erin Pañgilinan: Something I started off with when I was transitioning from frontend and mobile, thought about data science, this is probably like 10 years ago, but I was reading a book on microinteractions. I actually like to borrow a lot from even just really basic web devs. I was at WWDC's equivalent of ALT Conf. A bunch of the mobile iOS developer community always has a side conference that watches WWDC every year, which is Apple's developer conference. My friend Gary was actually trying to create this application where you're doing a lot of R&D in a lab, so you're looking at chemistry, beakers, and how you would actually do a bunch of different stuff. It was really cool. I said, but I can't tell what you're paying attention to, so reference the paper, 'Attention is All You Need', what do you focus on? I suggested to him, I was like, I think you need to use something equivalent to CSS and hover, really basic stuff, not a button, but on the actual objects themselves. Lo and behold, that day, Apple announced like, we now have hover effects. I was like, here, this is what you should use. Really basic stuff like that. I think WWDC has some basic standards, like WebXR, it takes a while, and it hasn't completely transferred into native yet just because it's so early in its development process. There's a lot of different microinteractions and paradigms that have been established already and tried and true, between responsive web and mobile development that do transfer over. Then, there are some principles that don't transfer. While I love Apple Vision Pro, a lot of it's very flat design, it actually doesn't optimize all the 3D space. Not everything should be a 2D visualization of the stock market, and, it's in VR, so I'm going to play it in Google Cardboard. This was an experience I tried way back in the day, it doesn't work very well. It was like, and now I can ride through the stock market like a rollercoaster. I'm like, this is horrible. I was really excited when I did a different conference, this was at Bloomberg Tech conference, and there was a demo for stock trading apps and database. I was super excited, it looked exactly the same as what you would have on a mobile app. I was like, this defeats the whole purpose of having it in Apple Vision Pro. There are some applications that can be transferred over, but, again, the chapter in my book is on data and machine learning, visualization and design and development, and it's about 3D in context of the environment, of how you would use that. We also have to think about, what can we borrow from tried-and-true principles of design and development from the web and mobile? Then, what makes it unique that it's in XR, or even adapting some things, not everything, with AI as well, that makes it much more inclusive, accessible, and something that users actually want. Participant 1: When we talk about in the planning phase, how much weightage should we give for introducing accessibility into our user experience? Do you think it's fair to say that the MVP, maybe that shouldn't be part of the MVP, or is it like, let's cater to the majority of the audience first. Then, as a second phase, we should be looking at the accessibility part, or it should be a discussion since day one? How do we balance out the fact that the majority of your audience, in a way, would be linked to the majority of the revenue for the product? How do we justify that accessibility should be part of the MVP, without that direct correlation to the revenue associated with that? Doyle: The question is, do you try to push for meeting accessibility requirements and standards in your MVP, or should that be a follow-up? If it should be part of the MVP, how do you push for prioritizing and arguing for the importance of baking accessibility in to that first version versus waiting later? Erin Pañgilinan: It really depends on your audience, it's very relative. I'm trying to create a productivity app, this is like a selfish dream, for myself, and so I conducted maybe 30 user research interviews since the end of last year. They were primarily women who were neurodivergent with ADHD, that were product managers, designers, and developers, that worked on open source, AR, VR, AI, and crypto, so very similar to me. I'm designing, essentially, for myself. That's a very specific audience, and even within that audience, there's a level of richness that I didn't expect. I was like, so some of you use paper planners, some people use mobile apps for planning, some people don't use anything at all, and they just look at their Google Calendar, and maybe they would love all of it if it worked in their Apple Vision Pro, or they'll only use it and pay for something if it also works in Android and on Linux, like every platform. It's really hard to satisfy people. Even in a target market of something that I thought was really small and specific, it comes down to user segmentation and that feature, and then, who is willing to pay for it? Take this quote from YC, Y Combinator, (make something people want) and we'll pay for it. While I like to think, yes, accessibility, design, inclusive design, and everything should be able to target this type of users or this population first. I really have to be honest with you, some people don't have the budget for that and won't prioritize it because it isn't a part of the bottom line. What it comes down to is like, what set of initial users for that problem are you solving? Then, within that set of users, what are the top three? Really narrow it down. Who are willing to pay for this price for that set of features that should be the real core of your product that is a part of the bottom line? Identifying that, what I realized was like, this is going to take some time. I thought I was trying to be even more narrow and specific, and even then, it's really hard and difficult. Again, it's all relative. If you are a B2B SaaS enterprise app that wants to do telepresence, this is a case for like Cisco or for a client I had in education, like we want hundreds of students to be in XR. We want them to also be able to design fashion and play fitness games and be safer. Two totally different use cases. I'm like, some of that is Meta Quest suite and some of that is Apple Vision Pro. Whatever you think you can prioritize, even just three things, it might be too much. You got to really chunk it down and get really specific, and even then, it still might be too much. Just get very granular to what that MVP is and who will pay for it so that you continue development. Unless you have endless amounts of money you can like self-fund. Like a lot of my friends in crypto who retired, they can just play computer all day and gameplay tests on all the things. Most people in reality can't do that. I would just get super specific and think about the context of who your customers are or who your investors are. I'm like, what is it that they want and what is it that you want? Were you willing to meet people in between for your users? Dylan Fox: These things are generally worth trying to make part of your MVP, and here's why. It's because something like a fully-fledged screen reader system or scalable UI or captions, if it's not 100% perfect right off the bat, that's fine. We all know MVPs can be very rough around the edges sometimes. The trap that I see people falling into over and again is they brainstorm a big list of features, they pick some as MVP, and then they build out something as fast as they possibly can that meets all of those MVP features. That decides the course of development. There's a lot of decisions that are made when it comes to developing during that MVP phase that become set in stone and very hard to change after the fact. If scalable UI is part of your MVP, then you will be building towards that from the start. You'll be making those choices for your development infrastructure that take that into account. If it's slated for your 1.1, what might happen is you develop to get something out the door and then you realize, actually, if we wanted this, we would have needed to develop the core engine and core aspects differently. Which means now it's much more work to do, so maybe it gets shifted from 1.1 to 1.2, and you just start accruing technical debt that if you ever then want to get some of these features in, you'll need to have a big effort. Because, again, a lot of these accessibility features come down to modularity. That is the type of thing that you really want to build in at the start. Do you need to have everything ready to go? Not necessarily. Think about localization. Yes, obviously, if our main user base is in English, then we're just going to focus on English for v1. If you're thinking about localization as part of phase one, then I guarantee you when it comes time to record all your lines in Spanish, in Chinese, in whatever else, it's going to be like a few lines of code to change all those out, instead of, "Our text is hard baked into the game. We can't change it at all. This is going to be a mess". For that reason, I would say, yes, at least some of these accessibility features should be in the MVP. Colby Morgan: Echoing both those points, and I think just to add, especially for Mighty Coconut, I think for us, in that early planning phase, it's important that we have that accessibility mindset of just how we're identifying the friction point, as I think the friction points or the potential friction points, are the really big piece for us. Just knowing what those friction points are, you can better tackle those down the road if you can plan for those of knowing what's coming or anything like that. Erin Pañgilinan: I was developing a productivity app with AI, and I literally was like, this is so fun. Then, I realized this is really broad. You do anything in AI, you think about, the first thing, if you've done any workshop with AWS, this is the amount of money I have for compute and spend. Early in the planning process, through user research, before I even build anything, I'm just trying to extrapolate that list of features and narrowing it down to the smallest possible thing. Because even if you think like, I can make this part of the prototype, it's still a lot of work, so before you spend any money, I would do a good amount of user testing before you build. Then when you actually spend, you'll realize whether or not it was a waste of money or not. Participant 1: Actually, one point that stands out, you mentioned, it collects as a technical debt. I think that's part of that culture. Because this whole accessibility and inclusion bit, I come from the financial industry, it's just in the start. My engineers have raised a lot of technical debt, but accessibility is not something that has anybody raise their hand that we should have this. We now have it as an organizational principle that it should be there, but, as an engineer, nobody has raised that. Maybe that's like, start from that culture, saying that, we need to start looking at this thing. Even if it's not part of the MVP, maybe if it comes up, if people are raising that this is a technical debt, then maybe towards the course of action, it might get an action done. Erin Pañgilinan: You do have a designer in the room at all when you're doing this? Participant 1: Yes. Erin Pañgilinan: I just think about Apple, it's like, when a designer comes in the room, somebody would say, they're like God, I'm like, it helps. Participant 1: Yes, that helps. Again, the designer is also, as you said, like a phone, where this phone has been two centuries old, to understand that, where we come from. It's like, that kind of thought process takes a bit of time to come, but it does come in. You mentioned we attended Bloomberg conference, so there should be a difference between the Bloomberg version versus any of the Meta conferences, and things like that. That mentality is still growing. I think that was a good test, that if engineers start thinking that way, that this is a technical debt, then, at some point in time, it's going to have to be introduced. Erin Pañgilinan: Technical debt and financial debt, like my cost of computing, we used to say, this is saving developers this amount of time and spend, and to talk really less on productivity, and developer experience, DevEx. It's like, if I can identify the amount of time and money saved for an engineering team because we included design first, and it affects the amount of compute that we're going to spend and the amount of time we're going to spend engineering this feature or product line, then I think it's easier to make that call. Harder to do for something like a newer problem, because you mentioned MVP, but if it's for an existing legacy system, that's how I would quantify it, to be able to get a little bit more buy-in, to include it as more first principles earlier on. Doyle: If you had to pick one piece of advice, what would you tell newcomers to the field who want to make inclusiveness a core focus? Colby Morgan: I think I would tell newcomers to the space, one, really look at your user base, look who your target audience is. Find ways to connect more with them directly. Just identify the needs of that audience. Dylan Fox: If you're looking for problems to solve that actually mean something, look to disabled communities, because there's a lot of places in the more privileged parts of the world where we've started to invent some bullshit problems. There's also a lot of people out there who have real problems that, with just a little bit of design thinking and actually listening to the people with those problems, and off-the-shelf XR AI technology, I think there's a ton of stuff that could be made that just hasn't been yet. There's a ton of low-hanging fruit and unsolved problems that really affect people's day-to-day lives. Please do think about that. We have a lot of resources at XR Access that talk about how to design and develop accessibly, so check those out. Try to make sure that what you're doing is really going to be making a difference in people's lives and not just something shiny and novel because the technology is there for it. Erin Pañgilinan: Be open. Try everything, at least once. Expect the unexpected. There are so many new developments. Some of my friends, they clairvoyantly predicted this was going to happen in XR, and I was like, no. Some of that was Michael Abrash, and we always knew glasses were going to come out and things of that nature. Look to history, so what you're thinking is going to come in the future. Also, there are things that are popping up now that I did not expect, so in any new emerging technology, that's going to happen, be really open-minded. When I say try everything, that's because I literally have probably tried every headset and experience I could get my hands on, because you'll find a bunch of stuff that works and a bunch of stuff that doesn't. I don't just say that for developers and designers, I say that for consumers because that's a really good way to, one, do user research. Then, basically testing of like, yes, that did not work at all, we're not going to spend any more engineering hours, or time, or money on this because we assumed this would work functionally, and it actually didn't. We expected something that works in principle, is like, the PowerPoint slides or the video, should work. It did not work, even though I gameplay tested it about 10 times over and over now. Yes, be open, try everything, and expect the unexpected. See more presentations with transcripts Recorded at: Sep 25, 2025 by Erin Pañgilinan Colby Morgan Dylan Fox A round-up of last week’s content on InfoQ sent out every Tuesday. Join a community of over 250,000 senior developers. View an example We protect your privacy. Get proven, real-world solutions directly from senior engineering leaders navigating Europe's toughest technical challenges. Learn directly from leaders at: InfoQ.com and all content copyright © 2006-2025 C4Media Inc. Privacy Notice, Terms And Conditions, Cookie Policy
--------------------------------------------------

Title: Analyst Says Meta Platforms (META) is One of the Best AI Stocks to Buy Now
URL: https://finance.yahoo.com/news/analyst-says-meta-platforms-meta-131433677.html
Time Published: 2025-09-25T13:14:33Z
Description: We recently published Trending Analyst Calls: Top 10 Stocks. Meta Platforms Inc (NASDAQ:META) is one of the stocks analysts were recently talking about...
--------------------------------------------------

Title: H-1B blow will reshape tech hiring
URL: https://www.thehindubusinessline.com/opinion/h-1b-blow-will-reshape-tech-hiring/article70090196.ece
Time Published: 2025-09-25T00:30:00Z
Full Content:
-386.47 -112.60 + 143.00 -1,325.00 -1,105.00 -386.47 -112.60 -112.60 + 143.00 + 143.00 -1,325.00 Get businessline apps on Connect with us TO ENJOY ADDITIONAL BENEFITS Connect With Us Get BusinessLine apps on The silver lining for India is that irrespective of Trump’s hike in visa fees, it will lead to more offshoring. The labour cost is still lower in India | Photo Credit: DEEPAK KR Much before US President Trump’s decision to increase H-1B visa fees to $100,000 from the existing fees ranging between $2,500 and $5,000, the red line was drawn when he hosted 33 Silicon Valley leaders (including five Indian-origin top executives such as Sundar Pichai and Satya Nadella) at the White House. Although the meeting was about artificial intelligence and US investment, behind the scenes the talk was about a paradigm shift — how AI programming tools can now generate thousands of lines of code quickly, reducing demand for junior software engineers. This may explain why major US tech companies such as Amazon, Intel, Meta and Microsoft, have been consistently laying off workers in recent times, particularly before the hike in H-1B visa fees. In fact, the US-based IT firms are more dependent on H-1B visas than Indian IT firms. Even in India, the top six IT firms added just 3,847 employees in Q1FY26, a 72 per cent drop from Q4FY25. TCS made national headlines for laying off 12,200 employees, which is about 2 per cent of its global workforce. Although we are worried about the fate of around 400,000 Indian IT workers whose H-1B visas may not be renewed in the event of this fee hike, such a thing was bound to happen. Region-wise, India was the largest beneficiary of H-1B visas, accounting for 71 per cent of 3,99,395 in H-1B visas 2024, while China was a distant second at 11.7 per cent. Market participants had anticipated a sharp fall in stock prices of Indian IT companies heavily reliant on the US market when the stock market opened on Monday after the announcement. By the end of trading day, these stocks declined an average of 3.4 per cent. AI, automation, and cloud computing are changing the face of tech hiring, something which came too quickly, especially when there is a growing pool of computer science graduates specialising in coding that has been growing over the years. Graduating with a degree in computer science became a fad, with top tech executives, billionaires, and even US presidents promoting the field and encouraging students to learn coding. Throughout the past decade, a degree in computer science was yielding results, with fresh graduates in the US starting off with salaries exceeding $100,000 plus substantial bonuses and stock grants. Same trends were noticed in India and elsewhere across the globe. Like in the US, in India, there is a craze for admitting students to computer science programmes, with recent estimates suggesting India is producing in excess of one million engineering graduates every year. This has led to excess supply, particularly in the age of AI driven technological change. This is akin to the cobweb model in economics, where farmers grow a particular crop in response to higher price signals in the present period, only to realise there is excess supply in the next period. We are witnessing a similar event now but spread across a longer time horizon to adjust for the technological change. Entry-level hiring by Indian IT firms has dropped sharply from pre-Covid levels. The same can perhaps be said of employment generation, generally speaking, in the organised sector. India (like elsewhere in the world) is slowly transforming into a gig economy where the labour market is increasingly characterised by the prevalence of short-term contracts or freelance work. Private studies have shown that over half of Indian companies have more than 20 per cent of their workforce as contingent workers. The Periodic Labour Force Surveys corroborate this trend. In fact, most of the hiring in manufacturing, whether by the government or by private corporate enterprises, is now being increasingly outsourced to private contract suppliers. That things change so rapidly, requiring adjustments from both industry and the education system, is not new. Even the advent of computers and technology that marked the rise in productivity during the last century required adjustments. Alongside computers, electricity, combustible engines and refrigeration aided economic growth through a more productive labour force and necessary training. This has led to the creation of thousands of jobs in manufacturing. In the age of big data analytics, machine and deep learning, there is an apprehension that machines are increasingly taking over jobs performed by humans. But that is not entirely true. Newer types of jobs are opening up and it is in this transition phase that things will be little difficult. According to an August 2025 report from the Federal Reserve Bank of New York, among college graduates ages 22 to 27, computer science and computer engineering majors are facing some of the highest unemployment rates, ranging between 6.1 per cent and 7.5 per cent, respectively. That is more than double the unemployment rate among recent biology and art history graduates, which is just around 3 per cent. In an ironic twist, job applicants leverage AI tools such as Simplify to mass-customise their resumes and applications, only to have companies use similar AI technology to automatically screen them out. The silver lining for India is that irrespective of Trump’s hike in visa fees, it will lead to more offshoring. The labour cost is still lower in India, which has a high number of STEM graduates. It will only bolster investment in Global Capability Centres (GCCs). India accounts for 55 per cent of the world’s GCC centres (according to IBEF), employing around 1.9 million people. For the existing talented Indian IT workers other opportunities are opening up, for instance, China now announced issuance of K visa after Trump announced a hike in visa fees. Middle-East countries and the UK are other places waiting to welcome these skilled workers from India. The writer is Professor, School of Management, Mahindra University Published on September 25, 2025 Copyright© 2025, THG PUBLISHING PVT LTD. or its affiliated companies. All rights reserved. BACK TO TOP Comments have to be in English, and in full sentences. They cannot be abusive or personal. Please abide by our community guidelines for posting your comments. We have migrated to a new commenting platform. If you are already a registered user of TheHindu Businessline and logged in, you may continue to engage with our articles. If you do not have an account please register and login to post comments. Users can access their older comments by logging into their accounts on Vuukle. Terms & conditions | Institutional Subscriber
--------------------------------------------------

Title: Oracle slips on reports of unexpected debt plan
URL: https://www.thestreet.com/investing/oracles-15-billion-bond-sale-underlines-ai-expansion-costs-
Time Published: 2025-09-25T00:13:42Z
Description: Oracle stock slips as it raises $15 billion cash by selling debt
--------------------------------------------------