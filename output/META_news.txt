List of news related to Meta stock price META:

Title: US stock futures on the move today: Dow, S&P 500 and Nasdaq trade higher as Big Tech rallies; Meta, Nvidia and Tesla active in early trade
URL: https://economictimes.indiatimes.com/news/international/us/us-stock-futures-on-the-move-today-dow-sp-500-and-nasdaq-trade-higher-as-big-tech-rallies-meta-nvidia-and-tesla-active-in-early-trade/articleshow/125785687.cms
Time Published: 2025-12-05T09:22:13Z
Full Content:
US stock futures rose early Friday as traders awaited the delayed September PCE inflation report that could shape the Fed’s Dec. 10 rate call. S&P 500 futures gained 0.2%. Nasdaq 100 rose 0.4%. Dow futures were flat at 47,906. Markets now price an 87% chance of a rate cut. Labor data showed 71,000 layoffs, but jobless claims hit a three-year low. Listen to this article in summarized format Unlock AI Briefing and Premium Content (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. Explore More Stories Amazon warns over 300 million users of major Black Friday impersonation scams targeting personal data What is Canada’s new colour-coded alert system and how it will ensure public safety during extreme weather Canada launches new alert system for extreme weather; Colour-coded system marks shift to impact-based forecasting Canadian Olympic swimming champion Penny Oleksiak suspended for two years over anti-doping whereabouts failures Who is Colleen Jones? Two-time World champion curler and veteran Canadian broadcaster dies at 65 What exactly is the Canada Pension Plan? New CPP payments rolling out nationwide on November 26; Check all the payment dates of 2025-26 - Why is Quebec not part of CPP? Madeleine Poulin, Radio-Canada’s first female correspondent in Ottawa and Paris, dies at 87 Yoplait recalls 'Yop yogurt' drinks in Canada over plastic contamination fears under Class 1 category - Check out which flavor and best-before dates beverage are subject to recall CMA Awards: Vince Gill honored with prestigious Willie Nelson Lifetime Achievement Award at 59th CMA Awards in Tennessee MGK rocks Canadian fans with explosive Grey Cup halftime show; Are Megan Fox, MGK really working on their relationship post daughter’s birth? Roughriders end 12-year drought, beat Alouettes for 5th Grey Cup title Who is Dr Sanjeev Sirpal? Trouble mounts for New Brunswick doctor accused of sexual assault in hospitals as he faces additional charges; what do we know so far Russian humanoid robot 'AIDOL' shockingly faceplants during much-hyped public debut - WATCH PM Modi-Putin Summit: Manpower mobility gets a boost ‘Symbolism & Substance’: Tharoor decodes Modi–Putin diplomacy IndiGo cancels 500+ flights; DGCA waives off pilot rest norms Russia eyes Indian fish, meat; wants joint trout venture 'Made us aware of everything': Modi-Putin dialogue covers Ukraine war PM Modi & Putin hold a joint press meeting at Hyderabad House, New Delhi RBI cuts repo rate by 25 bps in Dec amid low inflation, strong growth Putin receives Tri-Services Guard of Honour at Rashtrapati Bhavan Putin’s India visit: Can trade jump from $70 Billion to $100 Billion? RBI monetary policy statement LIVE by Governor Sanjay Malhotra PM Modi-Putin Summit: Manpower mobility gets a boost ‘Symbolism & Substance’: Tharoor decodes Modi–Putin diplomacy IndiGo cancels 500+ flights; DGCA waives off pilot rest norms Russia eyes Indian fish, meat; wants joint trout venture 'Made us aware of everything': Modi-Putin dialogue covers Ukraine war PM Modi & Putin hold a joint press meeting at Hyderabad House, New Delhi RBI cuts repo rate by 25 bps in Dec amid low inflation, strong growth Putin receives Tri-Services Guard of Honour at Rashtrapati Bhavan Putin’s India visit: Can trade jump from $70 Billion to $100 Billion? RBI monetary policy statement LIVE by Governor Sanjay Malhotra Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Prime Articles Top Commodities Top Slideshow Private Companies Top Story Listing Top Definitions Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Stories you might be interested in
--------------------------------------------------

Title: Reddit's CEO says the platform is ditching a key part that 'sucks'
URL: https://www.businessinsider.com/reddit-ceo-steve-huffman-removes-popular-feed-2025-12
Time Published: 2025-12-05T07:15:58Z
Full Content:
Every time Aditi publishes a story, you’ll get an alert straight to your inbox! Enter your email By clicking “Sign up”, you agree to receive emails from Business Insider. In addition, you accept Insider’s Terms of Service and Privacy Policy. Reddit is getting rid of one of its oldest fixtures. The platform's CEO, Steve Huffman, said in a post that Reddit would be removing its r/popular feed from the homepage for new users to promote a more personalized and relevant user experience. The popular feed, located on the left sidebar of the website, displays the most liked recent posts across the platform. "In theory, it's what's most popular on Reddit, but it's actually what is liked by the most active users on Reddit—which is not the same thing," he said. "Having it as a default feed gives the false impression of a singular Reddit culture, one that is neither representative of Reddit nor appealing to new users (or anyone at all, IMO)." He summed up his disdain for the feature by saying, "r/popular sucks, and we're moving away from it, and towards better, more relevant and personalized feeds." Huffman, who has been the platform's CEO since 2015, said Reddit would stop showing the popular feed in the sidebar unless users read it regularly. He said his favorite part of Reddit was that every community on the platform had its own unique culture, rules, and sense of humor. "And if your perspective isn't represented, you can create the community you want to see," he said. "The freedom to build your own corner of the internet is what makes Reddit, Reddit." The platform gets 116 million visitors daily, he said. Reddit's stock price has risen about 44% in the past year. In the post, he announced a few other changes, like limiting the number of high-traffic communities a single person can moderate, and changing the way it shows community sizes. "These changes are all part of the same goal: making Reddit more conducive to how people actually use it today," he said. This is not Reddit's first effort to nudge its users into smaller community groups, as it recalibrates its platform alongside competitors like Quora, and beyond that, the likes of Meta. In October, Reddit removed its public chat feature and urged users to chat on private group chats as a way to "connect with communities in smaller, focused spaces." Jump to
--------------------------------------------------

Title: Are trillion-dollar valuations for Nvidia and AI giants built on fairy tale? Aswath Damodaran decodes
URL: https://economictimes.indiatimes.com/markets/stocks/news/are-trillion-dollar-valuations-for-nvidia-and-ai-giants-built-on-fairy-tale-aswath-damodaran-decodes/articleshow/125780915.cms
Time Published: 2025-12-05T04:47:05Z
Full Content:
Valuation guru Aswath Damodaran questions if trillion-dollar market caps, particularly Nvidia's, are driven by genuine performance or investor fantasy. He uses a 'possible, plausible, probable' framework to assess Nvidia's revenue needs and warns of the 'Big Market Delusion' in AI, where aggregate valuations outstrip realistic revenue potential. Listen to this article in summarized format Unlock AI Briefing and Premium Content (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025, Share Market on Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price (What's moving Sensex and Nifty Track latest market news, stock tips, Budget 2025, Share Market on Budget 2025 and expert advice, on ETMarkets. Also, ETMarkets.com is now on Telegram. For fastest news alerts on financial markets, investment strategies and stocks alerts, subscribe to our Telegram feeds .) Subscribe to ET Prime and read the Economic Times ePaper Online.and Sensex Today. Top Trending Stocks: SBI Share Price, Axis Bank Share Price, HDFC Bank Share Price, Infosys Share Price, Wipro Share Price, NTPC Share Price Friday's rate cut suggests too early to call time on RBI easing cycle ONGC’s long-awaited recovery falters as performance slips back How UPI boom in rest of India hides a paradox in wealthy states Why Leyland and Iveco stand between Tata Motors' return to glory From near collapse to INR50k cr value: The journey of MCX AI is forcing a rethink. Can Indian IT finally build a serious corporate VC muscle? All Mutual Funds Top Tax Saving Mutual Funds Better Than Fixed Deposits Low Cost High Return Funds Best Hybrid Funds Best Large Cap Funds SIP’s starting Rs. 500 Top Performing Mid Caps Promising Multi Cap Funds Top Rated Funds Top Performing Index Funds Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Prime Articles Top Performing MF Top Definitions Top Commodities Top Slideshow Top Story Listing Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Worry not. You’re just a step away. It seems like you're already an ETPrime member with Login using your ET Prime credentials to enjoy all member benefits Log out of your current logged-in account and log in again using your ET Prime credentials to enjoy all member benefits. Big Price Drop! Flat 40% Off Offer Exclusively For You Save up to Rs. 700/- ON ET PRIME MEMBERSHIP Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get 1 Year Free With 1 and 2-Year ET prime membership Offer Exclusively For You Get Flat 40% Off Then ₹ 1749 for 1 year Offer Exclusively For You ET Prime at ₹ 49 for 1 month Then ₹ 1749 for 1 year Special Offer Get flat 40% off on ETPrime What’s Included with ETPrime Membership Trump temper on H-1B visas is forcing Indians to do these things to stay put in US What Adani’s US indictment means for India Inc’s overseas fundraising Why veterans like Reliance, L&T are on acquisition spree? Aswath Damodaran has an answer. Will China’s dollar bond sale in Saudi Arabia trump the US in financial world? Huawei launches its own OS to compete with Google and Apple. But can it win beyond China? The problem with lab grown diamonds Why a falling rupee is a better option for the economy A list of top 20 momentum stocks that have delivered massive returns in one year Investment Ideas Grow your wealth with stock ideas & sectoral trends. Stock Reports Plus Buy low & sell high with access to Stock Score, Upside potential & more. BigBull Portfolio Get to know where the market bulls are investing to identify the right stocks. Stock Analyzer Check the score based on the company's fundamentals, solvency, growth, risk & ownership to decide the right stocks. Market Mood Analyze the market sentiments & identify the trend reversal for strategic decisions. Stock Talk Live at 9 AM Daily Ask your stock queries & get assured replies by ET appointed, SEBI registered experts. ePaper - Print View Read the PDF version of ET newspaper. Download & access it offline anytime. ePaper - Digital View Read your daily newspaper in Digital View & get it delivered to your inbox everyday. Wealth Edition Manage your money efficiently with this weekly money management guide. TOI ePaper Read the PDF version of TOI newspaper. Download & access it offline anytime. Deep Explainers Explore the In-depth explanation of complex topics for everyday life decisions. Health+ Stories Get fitter with daily health insights committed to your well-being. Personal Finance+ Stories Manage your wealth better with in-depth insights & updates on finance. New York Times Exclusives Stay globally informed with exclusive story from New York Times. TimesPrime Subscription Access 20+ premium subscriptions like Spotify, Uber One & more. Docubay Subscription Stream new documentaries from all across the world every day. Leadership | Entrepreneurship People | Culture Leadership | Entrepreneurship People | Culture Leadership | Entrepreneurship People | Culture Leadership | Entrepreneurship People | Culture Leadership | Entrepreneurship People | Culture Stories you might be interested in
--------------------------------------------------

Title: Citizens Asserts Market Outperform Rating on Meta Platforms Inc. (META) Buoyed by AI Strategy
URL: https://finance.yahoo.com/news/citizens-asserts-market-outperform-rating-031018907.html
Time Published: 2025-12-05T03:10:18Z
Description: Meta Platforms Inc. (NASDAQ:META) is one of the best augmented reality stocks to buy right now. On November 24, analysts at Citizens reiterated a Market...
--------------------------------------------------

Title: Fluence Energy, Inc. (FLNC): A Bull Case Theory
URL: https://finance.yahoo.com/news/fluence-energy-inc-flnc-bull-025239425.html
Time Published: 2025-12-05T02:52:39Z
Description: We came across a bullish thesis on Fluence Energy, Inc. on Capitalist Letters’s Substack by Oguz Erkan. In this article, we will summarize the bulls’ thesis ...
--------------------------------------------------

Title: Stock market today: S&P 500, Nasdaq, Dow rise as Fed-favored PCE inflation data looms
URL: https://finance.yahoo.com/news/live/stock-market-today-sp-500-nasdaq-dow-rise-as-fed-favored-pce-inflation-data-looms-234850919.html
Time Published: 2025-12-04T23:48:50Z
Description: The focus is on the delayed September PCE report on consumer inflation, the gauge favored by the Fed, to sanity-check rate-cut bets.
--------------------------------------------------

Title: Major Wall Street bank drops jaw-dropping Oracle stock price target
URL: https://www.thestreet.com/investing/stocks/major-wall-street-bank-drops-jaw-dropping-oracle-stock-price-target
Time Published: 2025-12-04T23:07:00Z
Description: Oracle (ORCL) has been looking to break into the AI big leagues for years, and Wells Fargo’s latest note just gave it an endorsement that effectively flips...
--------------------------------------------------

Title: Stocks Settle Mixed on Higher Bond Yields
URL: https://www.barchart.com/story/news/36464136/stocks-settle-mixed-on-higher-bond-yields
Time Published: 2025-12-04T21:34:51Z
Description: The S&P 500 Index ($SPX ) (SPY ) on Thursday closed up by +0.11%, the Dow Jones Industrials Index ($DOWI ) (DIA ) closed down by -0.07%, and the Nasdaq 100...
--------------------------------------------------

Title: Elon Musk Says His 'Running Robot' Will 'Actually Eliminate Poverty' As He Shares Video Of Tesla Optimus Jogging
URL: https://finance.yahoo.com/news/elon-musk-says-running-robot-213110677.html
Time Published: 2025-12-04T21:31:10Z
Description: On Tuesday, Tesla Inc. (NASDAQ:TSLA) CEO Elon Musk shared a video showing the company's Optimus humanoid robot running across a lab floor for the first time....
--------------------------------------------------

Title: Wall Street Is Cheering Metaverse Spending Cuts at Meta Platforms, But Is META Stock a Buy Here?
URL: https://www.barchart.com/story/news/36462238/wall-street-is-cheering-metaverse-spending-cuts-at-meta-platforms-but-is-meta-stock-a-buy-here
Time Published: 2025-12-04T19:39:39Z
Description: Meta stock inches up on reports Mark Zuckerberg will soon announce steep cuts to metaverse spending. Jim Cramer recommends buying META shares heading into...
--------------------------------------------------

Title: ChatGPT Thinks Meta Stock Price Will Close At This Level By The End of 2025
URL: https://finance.yahoo.com/news/chatgpt-thinks-meta-stock-price-191237921.html
Time Published: 2025-12-04T19:12:37Z
Description: Shares of Meta have been under pressure in recent weeks as investors absorb a post-earnings reset tied to rising AI infrastructure spending. The stock trades...
--------------------------------------------------

Title: Top Stock Movers Now: Meta, Dollar General, Kroger, and More
URL: https://www.investopedia.com/top-stock-movers-now-meta-dollar-general-kroger-and-more-kr-dg-meta-11861926
Time Published: 2025-12-04T18:10:14Z
Full Content:
Major U.S. equities indexes wavered between gains and losses Thursday afternoon, as tech stocks climbed but consumer staples stocks lost ground. The Dow Jones Industrial Average edged 0.1% lower in recent trading, while the S&P 500 and Nasdaq ticked up 0.1%. Dollar General (DG) led gains on the S&P 500, with its stock up close to 12% after the discount retailer became the latest to post solid quarterly results, after a strong report from rival Dollar Tree (DLTR) yesterday. Meta Platforms (META) shares also surged, with shares jumping 4% following a Bloomberg report the Facebook and Instagram parent is looking to slash spending on its metaverse segment next year. Kroger (KR) was the largest decliner in the S&P 500. Its shares fell 6% after the grocery giant reported quarterly sales that missed analysts' expectations. Snowflake (SNOW) shares tumbled 11% after the cloud data analytics company issued a disappointing margin forecast, raising some worries on Wall Street about the company's AI-related investments. Intel's (INTC) stock sank 6%, giving up most of its gains earlier in the week. Reuters reported the embattled chipmaker, which has explored selling parts of its business to improve its finances, plans to keep its networking and communications segment after a strategic review. Oil and gold futures rose. The yield on the 10-year Treasury note climbed to 4.10%. The U.S. dollar lost ground to the euro and yen, while gaining on the pound. The price of Bitcoin slipped to trade just above $92,000 and Ethereum gained, while most other major cryptocurrencies lost ground.
--------------------------------------------------

Title: Wall Street Loves CrowdStrike Stock After Q3 Earnings. Should You?
URL: https://www.barchart.com/story/news/36460190/wall-street-loves-crowdstrike-stock-after-q3-earnings-should-you
Time Published: 2025-12-04T17:30:59Z
Description: CrowdStrike reports its third-quarter results, and Wall Street analysts are in love with it.
--------------------------------------------------

Title: The Pullback in Oracle Stock Just Created a Buying Opportunity
URL: https://www.barchart.com/story/news/36458748/the-pullback-in-oracle-stock-just-created-a-buying-opportunity
Time Published: 2025-12-04T16:48:31Z
Description: Oracle stock is down nearly 40% from its 52-week high, presenting an opportunity for long-term investors.
--------------------------------------------------

Title: Bank of America unveils surprise 2026 stock-market forecast
URL: https://www.thestreet.com/investing/bank-of-america-unveils-surprise-2026-stock-market-forecast
Time Published: 2025-12-04T16:29:27Z
Description: Wall Street always loves a good consensus, especially when the stock market’s rip-roaring. That’s exactly when Bank of America’s fresh 2026 forecast becomes ...
--------------------------------------------------

Title: Alphabet chips could unlock $900 billion windfall
URL: https://rollingout.com/2025/12/04/alphabet-chips-could-unlock-900-bilion/
Time Published: 2025-12-04T16:27:40Z
Description: Alphabet investors have discovered a new reason to celebrate beyond search engines and advertising revenue. The company’s homegrown semiconductors, long viewed as an internal advantage, are now being recognized as a potential standalone business worth nearly …
--------------------------------------------------

Title: Stocks Pressured as Bond Yields Rise and Chip Stocks Fall
URL: https://www.barchart.com/story/news/36458296/stocks-pressured-as-bond-yields-rise-and-chip-stocks-fall
Time Published: 2025-12-04T16:17:34Z
Description: The S&P 500 Index ($SPX ) (SPY ) is down by -0.06%, the Dow Jones Industrials Index ($DOWI ) (DIA ) is down by -0.04%, and the Nasdaq 100 Index ($IUXX ) (QQQ...
--------------------------------------------------

Title: Booking Holdings Inc. (BKNG): A Bull Case Theory
URL: https://finance.yahoo.com/news/booking-holdings-inc-bkng-bull-154119764.html
Time Published: 2025-12-04T15:41:19Z
Description: We came across a bullish thesis on Booking Holdings Inc. on Nikhs’s Substack. In this article, we will summarize the bulls’ thesis on BKNG. Booking Holdings ...
--------------------------------------------------

Title: Why is US stock market down today? Dow, S&P 500, Nasdaq all in red — Is Fed rate-cut expectation holding investors back?
URL: https://economictimes.indiatimes.com/news/international/us/why-is-us-stock-market-down-today-dow-sp-500-nasdaq-all-in-red-is-fed-rate-cut-expectation-holding-investors-back/articleshow/125769281.cms
Time Published: 2025-12-04T15:15:54Z
Full Content:
US stock market down today: The US market slipped early as the Dow fell to 47,847, the S&P 500 eased to 6,847, and the Nasdaq dropped to 23,423. Traders stayed cautious. Tech moved unevenly. Nvidia, Meta, and Tesla gained, but broader sentiment weakened. Investors watched Fed cut expectations closely. Uncertainty kept indexes in tight, negative trade. Listen to this article in summarized format Unlock AI Briefing and Premium Content (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. Explore More Stories Amazon warns over 300 million users of major Black Friday impersonation scams targeting personal data What is Canada’s new colour-coded alert system and how it will ensure public safety during extreme weather Canada launches new alert system for extreme weather; Colour-coded system marks shift to impact-based forecasting Canadian Olympic swimming champion Penny Oleksiak suspended for two years over anti-doping whereabouts failures Who is Colleen Jones? Two-time World champion curler and veteran Canadian broadcaster dies at 65 What exactly is the Canada Pension Plan? New CPP payments rolling out nationwide on November 26; Check all the payment dates of 2025-26 - Why is Quebec not part of CPP? Madeleine Poulin, Radio-Canada’s first female correspondent in Ottawa and Paris, dies at 87 Yoplait recalls 'Yop yogurt' drinks in Canada over plastic contamination fears under Class 1 category - Check out which flavor and best-before dates beverage are subject to recall CMA Awards: Vince Gill honored with prestigious Willie Nelson Lifetime Achievement Award at 59th CMA Awards in Tennessee MGK rocks Canadian fans with explosive Grey Cup halftime show; Are Megan Fox, MGK really working on their relationship post daughter’s birth? Roughriders end 12-year drought, beat Alouettes for 5th Grey Cup title Who is Dr Sanjeev Sirpal? Trouble mounts for New Brunswick doctor accused of sexual assault in hospitals as he faces additional charges; what do we know so far Russian humanoid robot 'AIDOL' shockingly faceplants during much-hyped public debut - WATCH Modi-Putin share car ride to 7 LKM, signal rare diplomatic warmth Putin lands in Delhi, Modi breaks protocol to receive ‘friend’ Piyush Goyal urges Indian businesses to explore Russian market India-Russia defence ministers’ meeting ahead of Modi-Putin summit India, Russia set big defence talks on S-400 and Su-57 jets Ex-TMC MLA Kabir criticises Mamata of RSS links, Temple Funding 'Fake news is a threat to our democracy': Ashwini Vaishnaw ‘Government blocks opposition from meeting foreign leaders’: Rahul Gandhi Jaishankar on 6,000 F-1 (US student visa) revocations in RS IndiGo delays, cancellations surge nationwide after FDTL crew shortage Modi-Putin share car ride to 7 LKM, signal rare diplomatic warmth Putin lands in Delhi, Modi breaks protocol to receive ‘friend’ Piyush Goyal urges Indian businesses to explore Russian market India-Russia defence ministers’ meeting ahead of Modi-Putin summit India, Russia set big defence talks on S-400 and Su-57 jets Ex-TMC MLA Kabir criticises Mamata of RSS links, Temple Funding 'Fake news is a threat to our democracy': Ashwini Vaishnaw ‘Government blocks opposition from meeting foreign leaders’: Rahul Gandhi Jaishankar on 6,000 F-1 (US student visa) revocations in RS IndiGo delays, cancellations surge nationwide after FDTL crew shortage Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Definitions Top Prime Articles Top Market Pages Top Story Listing Top Slideshow Private Companies Top Commodities Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Stories you might be interested in
--------------------------------------------------

Title: Stocks Pressured by Higher Bond Yields and Chip Stock Weakness
URL: https://www.barchart.com/story/news/36456921/stocks-pressured-by-higher-bond-yields-and-chip-stock-weakness
Time Published: 2025-12-04T15:15:22Z
Description: The S&P 500 Index ($SPX ) (SPY ) is down up by -0.06%, the Dow Jones Industrials Index ($DOWI ) (DIA ) is down by -0.11%, and the Nasdaq 100 Index ($IUXX ) (...
--------------------------------------------------

Title: Decoding brand sentiments: Leveraging customer reviews for insightful brand perception analysis using natural language processing and Tableau
URL: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0334330
Time Published: 2025-12-04T14:00:00Z
Full Content:
Traditional survey-based feedback has given way to real-time online reviews, yet transforming this unstructured text into actionable knowledge remains difficult. Focusing on the highly competitive smartphone market, where customer sentiment shapes brand perception and product strategy, this study proposes an end-to-end analytics pipeline that combines Machine Learning (ML), Deep Learning (DL), topic modelling, and interactive visualisation. Reviews for ten smartphone brands from Amazon (n ≈ 68 k) were pre-processed and class-imbalanced data were mitigated through class weighting. Sentiment classification was performed with ML models (Decision Trees, Logistic Regression, SVM, Naive Bayes) and DL models (Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM)). CNN achieved the highest accuracy 85.07% and balanced performance across positive and negative classes, although all models struggled with neutral reviews. Underlying themes were extracted with Latent Dirichlet Allocation (LDA) and Non-Negative Matrix Factorization (NMF); quantitative evaluation using the Coherence Score (CS) showed that NMF produced more interpretable topics (CS = 0.54) than LDA (CS = 0.41). Topic-level sentiment was assessed with the Valence Aware Dictionary and Sentiment Reasoner (VADER), linking features such as battery life and camera quality to positive or negative customer attitudes. Results are delivered through an interactive Tableau dashboard that allows practitioners to track sentiment trends, drill into coherent topics, and compare brand performance. The study also discusses ethical considerations, such as potential bias from imbalanced or culturally nuanced language, and outlines future work on cross-domain generalisation and fairness auditing. Overall, the integrated pipeline demonstrates that coupling CNN-based sentiment analysis with high-coherence NMF topics provides richer, business-ready insights than sentiment analysis alone. Citation: Hu JJH, Ahmad F, Bader-El-Den M (2025) Decoding brand sentiments: Leveraging customer reviews for insightful brand perception analysis using natural language processing and Tableau. PLoS One 20(12): e0334330. https://doi.org/10.1371/journal.pone.0334330 Editor: Ankit Gupta, CCET: Chandigarh College of Engineering and Technology, INDIA Received: January 29, 2025; Accepted: November 11, 2025; Published: December 4, 2025 Copyright: © 2025 Hu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Data Availability: The dataset used in this study, Amazon Cell Phones Reviews, is publicly available without restrictions from Kaggle. It was originally published by Griko Nibras and can be accessed at: https://www.kaggle.com/datasets/grikomsn/amazon-cell-phones-reviews. Funding: The author(s) received no specific funding for this work. Competing interests: The authors declare that they have no competing interests. Before the advent of the Internet, people typically visited physical stores to purchase products. Businesses could only provide feedback forms to customers for them to fill out to provide feedback on their products or customer experiences. The traditional manual feedback collection methods were often time-consuming for customers as they required filling out lengthy questionnaires and some customers might hesitate to complete the forms due to inconvenience. Hence, the data collected was limited for businesses to analyse and gain insights into customer opinions and preferences. The rise of online e-commerce platforms has transformed this landscape. Customers can now leave reviews at any time, making feedback collection faster and more efficient. Businesses can access these reviews in real-time, allowing for quicker responses and more informed decision-making. The Internet has increased the volume and significance of customer reviews, turning them into a crucial resource. A study by Forrester found that over 30% of Internet users have shared their opinions on products online. Consumers are more likely to trust the feedback from other customer rather than relying on company advertisements [1]. Consumers gradually trust the experiences of other buyers over advertisements, which has shifted the focus of businesses toward analysing online reviews to improve customer satisfaction and product offerings. In the rapidly growing smartphone market, brands like Samsung and Apple dominate, and e-commerce platforms like Amazon play a critical role in shaping consumer behaviour. Online reviews for smartphones have become important tools for both businesses and consumers, providing not only numerical ratings but also detailed feedback that helps buyers make informed purchasing decisions. The smartphone industry, with its constant innovation and competition, presents a unique opportunity to explore how sentiment analysis can help brands understand customer perceptions and stay competitive. Despite the abundance of online reviews, extracting actionable insights from large datasets remains a challenge. Traditional sorting methods, such as filtering by ratings, fail to capture the nuances in customer sentiment. Sentiment analysis, powered by Natural Language Processing (NLP), addresses this by categorizing reviews into positive, negative, or neutral sentiments. While sentiment analysis has been applied across industries, limited research exists on its application within the smartphone sector. Existing studies often lack integration with topic detection and fail to utilize interactive dashboards for deeper insights. This study bridges this gap by addressing the research question: By incorporating these techniques, this research aims to offer a holistic approach to analysing customer feedback, aiding businesses in improving brand perception and competitive positioning. The objective of this research is to explore the growing importance of customer reviews in the smartphone industry. By leveraging Machine Learning (ML) algorithms to analyse Amazon customer reviews, this study aims to address gaps in existing research. Amazon’s extensive consumer feedback makes it an ideal dataset for this research. Through text mining, sentiment analysis, and topic detection, this study seeks to: This research will deepen the understanding of how customer reviews shape brand perception and provide businesses with practical tools to enhance their brand image in a competitive market. This study introduces a novel end-to-end pipeline that combines Convolutional Neural Network (CNN) sentiment classification with Non-Negative Matrix Factorization (NMF) topic detection and deploys the joint results in an interactive Tableau dashboard. Earlier work either relied on separate sentiment or topic models or required resource-intensive Large Language Models (LLMs), leaving practitioners without a single, interpretable workflow for real-time brand monitoring. By unifying CNN, NMF, and dashboard visualisation, our approach links polarity scores to specific discussion themes at scale and presents them in an operationally ready format. Beyond this technical novelty, we analyse customer reviews for ten leading smartphone brands, applying multiple ML algorithms to benchmark performance and demonstrate that our lightweight CNN-NMF pipeline achieves competitive accuracy while remaining resource efficient. The resulting interactive dashboards provide businesses with practical tools to track sentiment-topic trends, diagnose emerging issues, and tailor strategic responses. Consequently, the study advances academic understanding of integrated sentiment-topic modelling and delivers actionable guidance for industry stakeholders seeking to enhance brand reputation, customer loyalty, and product development. The structure of this research is as follows: Section 1 introduces the research topic, detailing its background, objectives, and contribution. Section 2 reviews relevant literature, summarizing key findings and identifying gaps in current knowledge. Section 3 outlines the research methodology, describing the methods and techniques employed in the study. Section 4 presents the results and discussion, including a detailed analysis and interpretation of the data. Section 5 concludes with recommendations based on the research findings. The remaining sections include the references list and appendix with supplementary materials. Online customer reviews are closely linked to brand perception, as they directly influence how consumers view a company’s products and services. This perception develops through multiple channels such as traditional advertising, word-of-mouth recommendations, and customer service experiences. However, the influence of digital platforms has become increasingly prominent. Online reviews, social media interactions, and digital marketing campaigns now play a key role in shaping consumer perceptions to make brand management more complex. According to [2] study, brand perception is considered a multi-dimensional construct, containing experimental, symbolic, emotional, and cognitive dimensions. This framework views brand perception through several lenses: the experimental dimension, which relates to direct interactions and experiences with the brand; the symbolic dimension, which relates to the brand’s image and associations; the emotional dimension, reflecting the feelings and emotional responses caused by the brand; and the cognitive dimension, which involves the intellectual evaluation and beliefs about the brand. Each of these dimensions contributes to how consumers form and adjust their perceptions of a brand. Building on Keller’s framework [2], Christodoulides [3] further categorize brand perception into three critical types: brand experience, brand affect, and brand trust. Brand experience focuses on the experiential interactions consumers have with the brand, brand affect captures the emotional responses towards it, and brand trust deals with the cognitive sense of reliability and safety when engaging with the brand. These dimensions are essential for understanding consumer behaviour, especially in the context of online apparel purchases where brand perception is continually shaped by digital interactions. For instance, a brand that good in delivering positive direct experiences and consistently communicates a strong image is more likely to foster positive emotional responses and be perceived as trustworthy and dependable. These dimensions are interrelated and often reinforce one another. In today’s digital landscape, the accessibility of online reviews allows companies to respond promptly to customer concerns and preferences, thereby strengthening customer relationships and building brand loyalty. A study by Vanani [4] found that brand communities on social networks, where customers share experiences and viewpoints, play a crucial role in shaping brand perception. Positive customer reviews can significantly enhance a brand’s reputation by amplifying favourable opinions and attract new customers. These reviews can help to build trust, reinforce brand identity, and contribute to long-term brand loyalty and success. By analysing a broad range of tweets, this study also showed that there is a significant correlation between customer support interactions and brand perception, indicating that good customer service can influence future company reputation, customer loyalty, and churn rates. Rapid and effective responses to customer inquiries and issues can lead to the improvement of customer sentiments about the brand. Customer reviews have become an essential component of brand perception as they provide insights into consumer experiences and sentiments, significantly influencing how a brand is perceived in the market. In the past, customer reviews were primarily collected through surveys or questionnaires, which provided limited data. For instance, a study [5] conducted a survey for H&M brands to analyse how social media can be used for branding purposes in Norway. The study found that client engagement with the brand was much higher on social media than through traditional methods, suggesting that brands should focus more on their social media presence. The authors also noted that the 28 questions in the questionnaire were not sufficient to cover the research subject comprehensively. In contrast, today’s digital landscape offers more dynamic ways to collect customer reviews through social media, e-commerce platforms, and public data sources. This modern approach allows businesses to quickly adapt to consumer needs and refine their market strategies. Analysing customer opinions is crucial for companies’ global growth, as feedback serves as a valuable tool for evaluating reviews and addressing criticisms effectively [6]. Social media platforms like Twitter have become useful resources for sentiment analysis, with tools like Tweepy, a Twitter streaming API, enabling the collection of tweets on specific topics [7]. For example, research [8] used Tweepy to gather 99,850 tweets mentioning “Nike” and “Adidas” across various dates in 2018 as part of a comparative study to gauge public opinion on these leading international apparel brands. Their research revealed that most customers rely on online product reviews before making a purchase, highlighting the growing importance of public customer reviews as a vital resource for businesses aiming to improve product design and offerings. Positive reviews and high ratings significantly influence potential buyers and enhance a brand’s reputation. Further highlighting the significance of customer sentiment reflected in reviews, study [9] conducted an aspect-based sentiment analysis on a dataset of various car brands obtained from the Kaggle website. Their findings demonstrated that a higher sentiment score is linked with an increased likelihood of consumers choosing that brand, particularly in the competitive automotive industry. These insights are helpful for brand managers and stakeholders, who can use them to sustain brand reputation and profitability by proactively addressing consumer concerns related to product reliability. They found that Lamborghini achieved the highest sentiment score among the car brands analysed, reflecting strong customer satisfaction, particularly in areas such as comfort and price justification. This illustrates how a higher sentiment score can significantly boost customer preference, with Lamborghini owners expressing satisfaction with the quality and value of their vehicles. This case highlights the critical role that positive sentiment plays in enhancing a brand’s reputation and influencing consumer choices. Sentiment analysis is the process of extracting and interpreting textual data to understand its emotional content through text mining and processing techniques. NLP techniques are used in sentiment analysis to categorise sentiments as positive, neutral, or negative. This powerful tool is widely used across diverse industries such as marketing, finance, healthcare, and politics to analyse public opinion, improve product development, and support strategic decision-making. Another research [10] utilised NLP techniques to examine game reviews and categorise them into positive or negative sentiments. NLP offers several benefits in game studies, such as automated review analysis and the identification of gameplay patterns that can help improve game design. However, NLP techniques also face challenges, including difficulty in capturing language nuances such as sarcasm and irony, potential inaccuracies with context-specific language, limited generalisation of diverse player perspectives, and dependence on domain expertise for accurate interpretation. Moreover, techniques for sentiment analysis range from lexicon-based methods to advanced ML and Deep Learning (DL) models. Lexicon-based approaches, like those used by [11] and [12] in social media sentiment analysis, assign predefined sentiment scores to words or phrases. The opinion lexicon-based method, where a lexicon consisting of positive and negative opinion words is used to evaluate sentiment in sentences as positive, negative, or neutral. This widely used method involves applying a scoring function to each sentence, based on the presence of these opinion words. These methods are simple and computationally efficient but often lack the contextual understanding needed for accurate sentiment interpretation. For example, sarcasm, irony, or idiomatic expressions can easily lead to misinterpretation because the lexicon-based approach does not account for context beyond the predefined sentiment scores. Despite these drawbacks, lexicon-based methods continue to be widely used, especially in scenarios where speed is prioritized over depth of analysis. They serve as a foundational tool in sentiment analysis, often combine with more advanced techniques to enhance accuracy. As data grow in complexity, ML-based sentiment analysis models, such as Naïve Bayes and Support Vector Machine (SVM), offer powerful tools for analysing social media data, as demonstrated by [13–15]. These models can adapt to new data and capturing complex sentiment patterns. However, they necessitate large, labelled datasets and substantial computational resources. Their findings revealed that SVM achieved the highest predictive accuracy after cross-validation, outperforming the other models in most cases. This underscores the general observation that SVMs often deliver better performance compared to other classification models. With the increasing volume of data, traditional classification models often face efficiency challenges, making DL models particularly advantageous for sentiment analysis. These models, such as CNN, Simple Recurrent Neural Network (RNN), and Long Short-Term Memory (LSTM), offer benefits like automatic feature extraction, faster computation with accelerated hardware, and robust performance with large datasets [16,17]. Studies show that LSTM outperforms CNN and Simple RNN due to its ability to retain word sequences and capture long-range dependencies, which are crucial for accurate sentiment analysis. While overfitting was initially a challenge, it was addressed by optimizing parameters. Another research [18] also found that LSTM outperformed lexicon-based methods for calculating brand sentiment, though its high resource demands limited analysis to shorter timeframes. In recent years, the use of LLMs like BERT, GPT, and Llama has become increasingly common in sentiment analysis. Study [19] demonstrated the effectiveness of LLMs over traditional transformers in identifying depressive content in Bengali social media posts, yielding good outcomes. These models, which are trained on huge amounts of text, are capable of understanding and human-like language with high accuracy. Bidirectional Encoder Representations from Transformers (BERT), introduced by Google in 2018, was one of the first LLMs to make a significant impact in this area. Generative Pre-trained Transformer (GPT), known for powering tools like ChatGPT, has also gained widespread recognition. Llama2, a more recent model from Meta, builds on the foundational transformer architecture with some enhancements. A study by Kwon [20] explored the use of these models for sentiment classification, comparing their performance with traditional and DL models. The study found that BERT and GPT outperformed others, achieving an F1-score above 0.9. However, the research also highlighted challenges associated with these LLMs. For instance, training these models, required considerable computational time and resources [21]. Llama, despite being a powerful model, showed lower accuracy in this study and demanded significant resources in terms of memory and training time. Additionally, further fine-tuning Llama proved to be time-consuming, making it less practical compared to the more efficient BERT and GPT models. Beyond sentiment analysis, topic detection plays a crucial role in interpreting large volumes of customer feedback, particularly from platforms like Twitter, where texts are often brief and incorporate slang. As short-text analysis gains prominence, [22] and [23]proposed two widely used methods: Latent Dirichlet Allocation (LDA) and NMF for clustering these texts into coherent topics. Their findings suggest that while both models are effective, NMF generally outperforms LDA, offering more distinct topic classifications in short-text analysis. Furthermore, [24] conducted a systematic review of the airline industry, applying sentiment analysis and topic modelling to demonstrate their practical utility in various industries. Integrating these techniques enables a deeper understanding of consumer feedback, proving invaluable for businesses seeking actionable insights. Brand sentiment analysis focuses on evaluating consumer perceptions of a brand, informing marketing strategies, product development, and brand management. As customer feedback volume increases, sentiment classification has become a significant research area, helping businesses leverage customer opinions for better decision-making. This analysis predicts customer attitudes towards brand products and services and provides insights into consumer behaviour by systematically examining feedback to understand brand perception. Another research [13] emphasize sentiment analysis as a crucial tool for understanding customer sentiment, allowing businesses to strategically target advertisements based on positive reviews. A study [12] demonstrated the efficiency of sentiment analysis over traditional surveys by using Twitter data to create visual representations that can help businesses in understanding customer opinions. The study [25] underscore the importance of sentiment analysis in extracting actionable insights from reviews, although challenges such as sarcasm and nuanced language can affect accuracy. The process of gathering and labelling data for ML can be time-consuming, especially with large datasets [26,27]. Correlating sentiment analysis with customer ratings helps reveal how reviews impact overall satisfaction and supports data-driven decision-making. Another research [28] used sentiment analysis at the document, sentence, and aspect levels to categorise Amazon mobile phone reviews, capturing overall sentiment, specific preferences, and detailed product features. Nevertheless, the study encountered limitations, such as the reliance on the Afinn lexicon, which may yield different results with other tools, and the manual extraction of main product features, which could vary with different methods. The research also emphasised the need for validation with other corpora and the inclusion of n-gram features and qualifiers. In contexts like Twitter, where specific sentiment labels may be missing, Valence Aware Dictionary and Sentiment Reasoner (VADER) are an effective tool for assessing sentiment. Specifically designed for social media, VADER able to measure both the polarity and intensity of emotions, considering language tones and even emojis. Pai [29] highlighted its ability to classify tweets into positive, negative, or neutral categories based on sentiment scores, making it particularly useful for short-text analysis. Mishra [9] applied VADER in the automotive industry, finding that higher sentiment scores were linked to increased brand preference. These insights are valuable for brand managers to enhance reputation and address consumer concerns. VADER is easy to implement and does not require extensive training data, making it accessible for both researchers and businesses looking to perform sentiment analysis without needing complex ML models. Prior investigations typically addressed sentiment analysis and topic modelling in isolation or required resource‑intensive LLMs that limit practical deployment. Few works link polarity, topic context, and decision‑support visualisation in a unified workflow. By integrating a lightweight CNN for sentiment classification with Non‑Negative Matrix Factorization (NMF) for topic extraction and presenting the joint results in an interactive Tableau dashboard, our study overcomes those fragmentation and scalability challenges. This end‑to‑end pipeline demonstrates that near‑state‑of‑the‑art accuracy, granular topic insights, and real‑time business intelligence can coexist without the computational overhead of LLMs. Consequently, the proposed method advances the state of the art by delivering an interpretable, resource‑efficient, and operationally ready framework that directly maps consumer narratives to actionable brand strategies. This study utilized a comprehensive dataset of Amazon reviews, obtained through Kaggle [30]for its accessibility and relevance. This dataset was selected due to its easier accessibility compared to data from social media platforms, which require payment. Additionally, Amazon is one of the world’s largest online retailers, making its review data highly comprehensive. The Amazon customer review dataset consists of two CSV files: ‘items’ and ‘reviews’. The ‘items’ CSV file provides summarised information such as Product ASIN, Product Brand, Product Name, Product URL, Product Image URL, Product Avg. Rating, Product Review Page URL, Product Total Reviews, Product Price ($), and Product Original Price ($). The ‘reviews’ CSV file contains detailed customer reviews including Product ASIN, Reviewer Name, Reviewer Rating (on a scale of 1–5), Review Date, Valid Customer Indicator, Review Title, Review Content, and Helpful Feedback. This dataset encompasses 67,987 Amazon customer reviews across ten different smartphone brands: ASUS, Apple, Google, HUAWEI, Motorola, Nokia, OnePlus, Samsung, Sony, and Xiaomi, ranging from November 24, 2003, to December 25, 2019. Moreover, the reviews in the dataset are accompanied by ratings ranging from 1 to 5, where 1 denotes the lowest rating and 5 signifies the highest. There is detailed content associated with each rating as well as information on the product and brand name. Overall, the dataset includes a total of 714 products across ten brands, making it a good source for conducting detailed sentiment analysis. Data processing involved refining the dataset by removing null values, duplicates, and unnecessary columns (e.g., URLs). The ‘items’ and ‘reviews’ files were merged using an inner join on the product “ASIN” attribute, resulting in a consolidated dataset named “Amazon_phone_review.csv”. Reviews were categorized using an automated Python-based heuristic labelling strategy: ratings of 1–2 were labelled as “Negative” 3 as “Neutral” and 4–5 as “Positive” as shown in Fig 1. This process resulted in a streamlined dataset of over 60,000 labelled reviews prepared for sentiment analysis. During model training, class weights were applied to mitigate the effects of class imbalance and ensure that underrepresented sentiment categories contributed proportionally to the loss function. This approach improved classification fairness without modifying the original data distribution. To implement this strategy, class weights were computed from the training set using the compute_class_weight function in the scikit-learn library. The resulting weight vector [Negative = 1.39, Neutral = 4.89, Positive = 0.50] reflects the inverse frequency of each sentiment class in the data. For traditional ML algorithms, these weights were supplied through the class_weight parameter (where supported) to ensure the loss function penalised mistakes on minority classes more heavily. For DL models, the same weights were passed to the fit method in Keras, thereby scaling the categorical cross-entropy loss during training. https://doi.org/10.1371/journal.pone.0334330.g001 To provide an overview of the dataset, multiple visualisations were generated using Python. First, Fig 2 reveals that the Samsung brand received the highest number of reviews, whereas the ASUS brand received the fewest. Apple, Nokia, and Xiaomi received a similar count of reviews. According to this distribution, there is a significant difference in customer engagement among brands, with Samsung dominating in terms of customer feedback volume. Next, Fig 3 shows that the average rating for all brands exceeds 3.5, with Nokia having the lowest average rating at around 3.3. While most brands have generally received positive reviews from their customers, Nokia’s products are likely to receive more critical reviews than other brands. https://doi.org/10.1371/journal.pone.0334330.g002 The red dashed line indicates the overall mean rating across all brands, serving as a benchmark for comparative evaluation. The red dashed line indicates the overall mean rating across all brands, serving as a benchmark for comparative evaluation. https://doi.org/10.1371/journal.pone.0334330.g003 Fig 4 presents the distribution of reviews over time by brand from 2003 to 2020. Initially, from 2003 to 2008, reviews were exclusively for Motorola mobile phones. This could be due to Motorola’s early entry into the market or its popularity during that period. Subsequently, reviews began to appear for other brands, and the number of reviews steadily increased over the years. This reflects the growing diversity and competition in the smartphone market. Notably, Samsung received the most reviews overall, indicating its popularity over the years. On the other hand, in the case of the Xiaomi brand, reviews only began to appear after 2018. This late entry into the review dataset indicates that Xiaomi’s market presence significantly increased around this period. The number of reviews has continually increased since then, peaking in 2020. This trend highlights Xiaomi’s rapid growth and rising consumer interest in recent years. The detailed analysis of these visualisations provides valuable insights into customer behaviour and market trends over time, which can be crucial for strategic decision-making. https://doi.org/10.1371/journal.pone.0334330.g004 Fig 5 displays the sentiment distribution of Amazon smartphone reviews. The dataset comprises 68.51 percent positive, 24.50 percent negative, and 6.99 percent neutral reviews based on the labelled ratings. To enhance statistical robustness, 95 percent confidence intervals were computed for each sentiment category using the normal approximation method for binomial proportions, from a total of over 60,000 reviews. The resulting estimates are presented in Table 1. https://doi.org/10.1371/journal.pone.0334330.t001 https://doi.org/10.1371/journal.pone.0334330.g005 To explore brand-specific sentiment differences, data from the most recent complete year, 2019, were analysed, as all ten brands were represented with sufficient review counts. As summarised in Table 2, Xiaomi, HUAWEI, and OnePlus received the highest proportions of positive reviews above 80%, reflecting strong consumer satisfaction. In contrast, Nokia showed the highest proportion of negative reviews 36.69%, indicating comparatively lower customer satisfaction. Samsung maintained a strong positive sentiment 71.50% consistent with its market leadership, whereas Apple exhibited a higher share of negative reviews 26.95%, possibly reflecting heightened user expectations. These differences demonstrate how brand reputation and product performance are reflected in sentiment patterns within the same market year. https://doi.org/10.1371/journal.pone.0334330.t002 However, other sources of imbalance such as the uneven temporal and brand distribution of reviews were not explicitly addressed. For example, some brands only appear in later years (e.g., Xiaomi), which may influence the model’s ability to generalize across brands and time periods. Future work could explore temporal resampling or brand-stratified evaluation to better account for these biases. Raw text data usually contains noise or irrelevant information that can impact the accuracy and effectiveness of sentiment analysis. An effective text data preprocessing is crucial for preparing raw text data for sentiment analysis. This process involves several key steps, including cleaning the data, lemmatizing with POS (part-of-speech) tagging, removing stop words, and tokenizing text. Each of these steps plays a vital role in transforming the raw data into a format that can be effectively analysed by ML algorithms. Firstly, text cleaning is performed by removing punctuation, special characters, and numbers. This step is important because cleaning the text helps reduce noise, making the core content more accessible and analysable. Removing irrelevant information allows the model to focus on the significant features of the text, leading to better performance in sentiment analysis. Additionally, the text is standardised by converting all characters to lowercase. For instance, “BUY” or “Buy” is converted to “buy.” Without this step, words that are the same could be treated differently by text processing algorithms simply due to case differences, thereby reducing the accuracy of results. This standardisation helps create a uniform dataset, which is crucial for accurate analysis. To further refine the dataset, the contractions in the text data is also expanded; for example, “don’t” is converted to “do not.” This ensures that words are not counted separately, thus maintaining consistency. After that, Natural Language Toolkit (NLTK)‘s predefined stop-words list is used to remove common stop words like “a,” “the,” and “is.” This enhances model performance by highlighting important words that carry the meaning of the text. In the last step of our text preprocessing, lemmatization with POS tagging is applied by using WordNet Lemmatizer from NLTK. POS tagging involves assigning a specific label such as noun, verb, adjective, etc, to each word in the sentence. This labelling is essential because it provides contextual information that helps in accurate lemmatization. Lemmatization helps to reduce words to their base form and standardise text data. For instance, the word “purchasing” is reduced to its base form “purchase.” By applying the lemmatization process, the text data was further cleaned and standardized, reducing words to their root forms while preserving their essential meanings. This comprehensive preprocessing ensures our dataset is well-prepared for subsequent sentiment analysis shown in Fig 6 and Fig 7. https://doi.org/10.1371/journal.pone.0334330.g006 https://doi.org/10.1371/journal.pone.0334330.g007 Following these preprocessing steps, the TF-IDF (Term Frequency-Inverse Document Frequency) method is employed for feature extraction. TF-IDF is calculated using the formula [15], which is illustrated in Equation 1: The TF-IDF scheme is particularly effective at emphasizing terms that frequently appear in each document. Term frequency (TF) quantifies the frequency of a term’s occurrence within a specific document. The TF-IDF method combines (Term Frequency) TF with the inverse document frequency (IDF) to highlight the significance of a term within a document relative to the entire dataset. The pre-processed text data is then converted into numerical features that can be used for ML models. The TfidfVectorizer not only computes the Term Frequency-Inverse Document Frequency (TF-IDF) values but also manages tokenization internally. These preprocessing and feature extraction techniques are essential for transforming raw text data into a format that enhances the effectiveness of subsequent analysis. Finally, the pre-processed text data was combined with essential attributes, such as “brand,” “rating,” and “sentiment,” for subsequent sentiment analysis. To prepare the data for model training and prediction with traditional classification models, data splitting was performed using the train_test_split function. This step divided the pre-processed dataset into training and testing subsets to ensure that the ML models could be effectively trained and evaluated. Specifically, 80% of the data was allocated to the training set, while 20% was reserved for the testing set. The testing set serves as a separate subset to evaluate the model’s performance and generalizability on unseen data. This split is crucial for assessing how well the model performs. On the other hand, DL models often work directly with raw or minimally processed data. Sentiment labels were converted into numerical format and then one-hot encoded using LabelEncoder. Texts were tokenized with the Tokenizer, configured to manage up to 10,000 words and out-of-vocabulary tokens. The tokenized sequences were then padded to a uniform length of 100 tokens. Subsequently, train_test_split was used again to divide the data into 80% of training and 20% of testing subsets. This ensured that both types of models received appropriately formatted and split datasets for effective training and evaluation. To ensure fair and systematic optimisation across models, a grid-search procedure was applied to both traditional ML and DL algorithms. For Decision Trees, the grid included max_depth ∈ {200, 400, 600, 800, 900}. Naïve Bayes was tuned with alpha ∈ {1.0, 0.5, 0.1, 0.05}. Logistic Regression explored C ∈ {0.1, 1.0, 10}, solver ∈ {lbfgs, saga, sag}, and max_iter ∈ {100, 200, 300}. The SVM grid covered C ∈ {1, 5, 10}, kernel ∈ {linear, rbf}, and gamma ∈ {scale, auto}. For DL models, the CNN grid comprised kernel_size ∈ {3, 5, 7}, filters ∈ {64, 128}, and dropout_rate ∈ {0.2, 0.5}; training epochs were capped at 20 with Early Stopping patience of 3. The RNN and LSTM grids varied units ∈ {64, 100}, dropout ∈ {0.2, 0.3}, and learning_rate ∈ {0.001, 0.0005}. All grids were evaluated with five-fold cross-validation on the training set, and the best hyperparameter combination for each algorithm was selected according to mean validation accuracy. These chosen settings form the basis of the fine-tuning results reported in Section 4. The selection of traditional ML models for this study was guided by their established performance and interpretability in text classification and sentiment analysis tasks. Tree-based model such as Decision Trees was included because of their ability to handle nonlinear relationships, mixed feature types, and feature importance estimation. Naive Bayes models were chosen for their probabilistic foundation and efficiency in high-dimensional text data, particularly where word independence assumptions hold approximately true. Logistic Regression models were selected for their robustness, ease of interpretation, and effectiveness as strong linear baselines in sentiment prediction problems. SVM models were included due to their proven capability to generalise well in sparse feature spaces and to achieve strong discriminative boundaries in text-based classification. The models were assessed based on accuracy, F1 score, precision, recall. Neutral sentiments may be underrepresented in the dataset compared to positive and negative reviews. This imbalance can lead the model to focus more on the majority classes and perform poorly on the minority class. If the features of neutral reviews are not distinct enough, the model may struggle to classify them accurately. Other ML were not considered in order to maintain methodological focus and computational efficiency, as the primary aim was to benchmark the performance of diverse learning paradigms (probabilistic, linear, and non-linear) against advanced DL models. The selected models therefore represent a balanced mix of interpretability, generalisability, and computational practicality, making them well-suited to the sentiment classification objectives of this study. 3.7.1.1 Decision Trees: Decision Trees model has a tree-like structure, where each node represents a decision or test on an attribute, branches indicate the possible outcomes of these decisions, and leaf nodes signify the final predictions. In the context of classifying customer reviews, a hierarchy of decision nodes is built based on review features to categorise the reviews into different sentiment categories. In the context of our dataset, entropy is a key concept used to measure the uncertainty or randomness in the data, specifically in how the data is classified into different sentiment categories. The formula of splitting criterion – Entropy from [31] is shown below in Equation 2. where S is the dataset that entropy is calculated, c is the sentiment classes in set S, and p(c) – the proportion of elements belonging to class c in the dataset S. 3.7.1.2 Naive Bayes Model: Naive Bayes is a probabilistic approach for text classification that operates under the assumption that documents are created by a distribution determined by unseen parameters. The model estimates these parameters from the training data and uses Bayes’ theorem to calculate the likelihood of each class. It classifies documents by selecting the class with the highest probability. Naive Bayes model would first calculate the probability of the class [31], which is illustrated as in Equation 3: Here c represents data belonging to a particular sentiment class, x is the data with an unknown class, P(c|x) represents the posterior probability of the class given the predictor, P(x|c) is the predictor probability of the given class, P(c) – prior probability of the class, P(x) is the prior probability of the predictor. 3.7.1.3 Logistic Regression Model: Logistic Regression is a supervised learning technique that predicts the probability of a target variable by modelling the likelihood of a data point belonging to a specific class [32]. This model utilizes the logistic function, which maps input values to a probability range between 0 and 1, allowing it to classify data into discrete categories. The formula of Logistic Regression model [33] is illustrated as in Equation 4: where S(x) represents logistic function or sigmoid function, p refers to the probability of the dependent variable belonging to a particular class, e is the exponential function, and x means linear combination of the input features. This method is applicable in both binary and multiclass classification scenarios. According to the dataset used for this study, this model will estimate whether a review belongs to a positive, negative, or neutral category, and assigns it to the most likely category. In this study, Logistic Regression was implemented using a multinomial (SoftMax) formulation to accommodate the three sentiment categories (positive, negative, and neutral). The model was trained using the LogisticRegression class in scikit-learn with the parameter setting multi_class = ‘multinomial’ and the solver lbfgs. This approach estimates a separate set of coefficients for each sentiment class relative to a common baseline and computes class probabilities through the SoftMax function. The predicted sentiment label is then assigned based on the class with the highest probability. This configuration ensures that the model captures the full range of sentiment categories within a unified probabilistic framework, providing interpretable and generalisable classification outputs. 3.7.1.4 Support Vector Machine Model: Support Vector Classifier (SVC) is a powerful supervised ML algorithm that is widely used in classification tasks. This model operates by identifying the optimal hyperplane that best separates different classes within a multidimensional space. The goal of the SVC is not just to find any hyperplane but to discover the one that maximizes the margin between classes, ensuring that the separation is as clear and distinct as possible [34,35]. The SVM model formula [14] is presented as follows in Equation 5: where W represents the weight of vector perpendicular to the hyperplane, X is the feature vector of a data point, and b is the bias term that adjusts the hyperplane from the origin. The margin is the distance between hyperplane and the closest data points from each class. The larger the margin, the better the model performance [32]. This combination of mathematical precision and strategic placement of the hyperplane makes SVC a highly effective tool in the realm of ML, particularly for tasks involving complex and high-dimensional data. 3.7.1.5 Training Procedure for Machine Learning Models: To ensure consistent evaluation across all ML classifiers, a standardized training procedure was adopted. Each model, Decision Trees, Naive Bayes, Logistic Regression, and SVM was implemented using the scikit-learn library in Python (version 1.2.2). Prior to training, the dataset was split into 80 percent training and 20 percent testing subsets using stratified sampling, as described in Section 3.5. Feature vectors were extracted using TF-IDF vectorization, preserving token frequency information critical for classification. Hyperparameters for each model were optimized through grid search with five-fold cross-validation, using validation accuracy as the scoring metric. For Decision Trees, the maximum depth was varied in the range of 200–900; Logistic Regression was optimized across different solvers (lbfgs, saga, sag) and regularization strengths (C = 0.1 to 10); SVM tuning involved kernel choice (linear, RBF), penalty parameter (C = 1–10), and gamma settings. Naive Bayes used smoothing values (alpha) between 0.05 and 1.0. Class weights were adjusted in all models where applicable to handle the sentiment imbalance described in Section 3.2. All models were trained and tested under the same random seed (42) to enable reproducibility. Final model performance was reported based on the test set using metrics described in Section 3.7.3. In addition to the traditional ML models, DL models were also explored in this study to provide a broader comparison. These models known for their ability to capture complex patterns in data were included to assess whether they could outperform traditional models. In this study, deep neural network models including CNN, RNN and long-short term memory (LSTM) classifiers were employed. 3.7.2.1 Convolutional Neural Network: CNN are powerful feedforward neural networks commonly applied in fields like image classification or object recognition. CNN have recently been adapted for text classification with impressive results due to their ability to automatically learn and extract meaningful features from raw data. A simple architecture of CNN is shown as Fig 8 below. https://doi.org/10.1371/journal.pone.0334330.g008 CNN consists of embedding layer, convolutional layer, pooling layer, flatten and dense layer. The process begins with an embedding layer, which converts raw text into numerical representations since ML and DL algorithms cannot process raw text directly. The convolutional layer identifies high-level features through a convolution operation by sliding the filters over the input sequence. After this, the pooling layer reduces the dimensionality of the feature maps to decrease computational complexity and highlight the most relevant features [16]. Sometimes, the flatten layer is used to convert the feature maps into a single column vector, making them suitable for input into the dense layer. The dense layer is then employed to determine the class label, utilizing SoftMax activation functions for tasks involving multi-class classification. In this study, this model begins with an embedding layer that is added to convert word indices into dense vectors of fixed size and followed by a Conv1D layer with 128 filters and a kernel size of 5. ReLU activation function is then applied to capture local features from the text. Next, a MaxPooling1D layer with a pool size of 2 is used to retain the most important features. A Dropout layer with a dropout rate of 0.5 is included to prevent overfitting. Following this, a GlobalMaxPooling1D layer further down-samples the input representation by taking the maximum value across the entire dimension to reduce the computation while retaining crucial features. The model then includes a Dense layer with 128 units and a ReLU activation function for additional processing, followed by another Dropout layer to further mitigate overfitting. The final layer is a Dense layer with 3 units, corresponding to the three sentiment classes, and a SoftMax activation function to output a probability distribution over the classes. The model is compiled using the categorical cross-entropy loss function, which is appropriate for multi-class classification problems, and the Adam optimizer, known for its efficiency and adaptive learning capabilities. The CNN was trained for 20 epochs using a batch size of 32. These parameters were selected through preliminary experiments involving a manual grid search approach. The kernel size of 5 was chosen based on its ability to capture short-range dependencies in review text, offering a balance between local pattern extraction and computational efficiency. Early experimentation showed that kernel sizes smaller than 5 underperformed in validation accuracy, while larger sizes increased training time without measurable gains. Similarly, the choice of 20 epochs was based on early stopping criteria and validation curve trends. The model exhibited peak performance around Epoch 15 and began showing signs of overfitting beyond that point. Training beyond 20 epochs offered minimal additional benefit while increasing the risk of overfitting and computational cost. These observations guided the final hyperparameter configuration, which is further discussed in the Results and Discussion sections. 3.7.2.2 Recurrent Neural Network: A RNN is a specialized form of artificial neural network designed to process sequential data, making it particularly effective for tasks such as language translation, NLP, and speech recognition [17]. RNN have a unique ability to retain information from previous inputs, which allows them to influence current and future outputs, enhancing their learning capability from training data [16] The formula for RNN model is shown as in Equation 6: where b is bias value, is the previous hidden state, which carries information from past time steps and is current input, which determines its influence on the current hidden state. This can be seen as a process where the RNN updates its memory (hidden state) at each time step by combining information from the previous hidden state and the current input, passing this combination through a non-linear activation function (tanh). This allows the network to process sequences of data in a way that invovle both the current input and the history of past inputs. The RNN model shown in Fig 9 in this study is designed with an Embedding layer, followed by a SpatialDropout1D layer with a dropout rate of 0.2 to reduce overfitting. A single LSTM layer with 100 units is used with both dropout and recurrent dropout rates of 0.2 to further prevent overfitting. Adding LSTM layer in a model helps capture more complex patterns and relationships in the data. The model also includes a Dense layer with 128 units and ReLU activation to capture complex features, and a final Dense layer with SoftMax activation for three-class sentiment classification. https://doi.org/10.1371/journal.pone.0334330.g009 3.7.2.3 Long Short-Term Memory: LSTM is a specialized form of RNN designed to capture and learn long-term dependencies in data [20]. The architecture of LSTM is outlined in Fig 10. In LSTM model, the pre-processed input data is represented as an embedding matrix. The LSTM layers with number of units will process the data, followed by fully connected layer for classification task. The final layer will use an activation function to reduce the dimensional input vector down to a single output. https://doi.org/10.1371/journal.pone.0334330.g010 Moreover, Fig 11 shows the mechanism of LSTM model. LSTM consists of a memory cell (ct) and three key non-linear gates: the input gate (it), the forget gate (ft) and the output gate (ot). The memory cells maintain a consistent state over time, while the gates control the flow of information into and out of the cell to ensure that relevant data is retained or discarded as needed. These mechanisms allow LSTMs to effectively retain relevant data over time. In short, LSTM networks employ a memory cell along with a set of gates to manage the storage, updating, and retrieval of information across extended sequences. These mechanisms allow LSTMs to effectively retain relevant data over time [17]. https://doi.org/10.1371/journal.pone.0334330.g011 In this study, the LSTM model was constructed starting with an Embedding layer, followed by a SpatialDropout1D layer, like the architecture used in the CNN and RNN models. This model consists of three LSTM layers, each with 100 units and dropout settings of 0.3 for both standard dropout and recurrent dropout. These layers enable the model to learn complex temporal relationships within the data. After the LSTM layers, there is a Dense layer with 128 units and ReLU activation for additional feature processing. To avoid overfitting, a Dropout layer with a 0.5 rate is included. The final output is a Dense layer with 3 units and a SoftMax activation, suited for multi-class sentiment classification. Additionally, Reduce Learning Rate On Plateau (ReduceLROnPlateau) is used to lower the learning rate of the model when validation accuracy has stopped improving. 3.7.2.4 Training Procedure for Deep Learning Models: All DL experiments followed a unified training protocol to support reproducibility. For every network, the dataset was shuffled and stratified into 80 percent training and 20 percent testing splits as described in Section 3.5. Models were built with the Keras implementation in TensorFlow 2.14 and trained on a single NVIDIA RTX 3060 GPU. The Adam optimizer was used with an initial learning_rate of 0.001 for the CNN and RNN, and 0.0005 for the LSTM network, reflecting the grid selections in Section 3.6. The batch_size was fixed at 32 across models for comparability. Early Stopping monitored validation loss with patience = 3 and restored the best performing weights. A ReduceLROnPlateau callback halved the learning rate if validation accuracy plateaued for two epochs. Each model was permitted a maximum of 20 epochs, although Early Stopping typically halted training earlier (CNN at epoch 7, RNN at epoch 9, LSTM at epoch 16). Training history, including loss and accuracy per epoch, was logged and the final weights were saved with a version tag corresponding to the best validation epoch. The same random seed (42) was set for NumPy and TensorFlow to ensure repeatability of results. To compare the effectiveness of various models, multiple evaluation metrics including accuracy, precision, recall, and F1-score are employed. By analysing these metrics, strengths and weaknesses across different models can be identified, allowing for the selection of the most effective model for the task. Each metric offers insights into how well the models classify data. where P refers to precision, TP is the True Positive, which the instances where the model correctly identifies the positive class, and FP is False Positive which the instances where the model incorrectly predicts a positive class. where, FN is False Negative. The instances where the model fails to identify a positive class and incorrectly predicts it as negative. During evaluation, cross validation was utilized to evaluate the effectiveness of the models. Cross validation is a technique used to assess the performance of a model by evaluating its ability to make accurate predictions on new data [14]. The models were cross validated 5 times to ensure robust evaluation in this study. All model evaluations, including those during hyperparameter tuning and final testing, were conducted using five-fold cross-validation with stratified sampling to preserve class distribution across folds. Random shuffling of the dataset was performed before splitting to ensure robustness and reduce ordering bias. The same random seed (42) was used across all experiments to support reproducibility. To determine the topics in this dataset, two topics modelling are used in this section. Topic modelling can also be used for a variety of tasks such as detecting trends on social media or uncovering hidden themes in large text datasets. In this study, three topic detection models including LDA, and NMF are used to reveal insights from the dataset. LDA model is a generative probabilistic model that assumes K latent topics are hidden in given N documents corpus. This method is particularly useful in revealing the thematic structure of the dataset and allows for a nuanced understanding of the dominant topics present in the customer reviews. The generative process for each document in the text archive is presented as Fig 12 below. https://doi.org/10.1371/journal.pone.0334330.g012 This process outlines how each document is generated in the entire corpus. Each document in the corpus is assumed to be a mix of these topics, and the words within the document are drawn from this mixture. The generative process is repeated for each document, leading to a probability model for the entire corpus. The model’s hidden variables, which represent the topic-word distributions (ϕ) and document-topic distributions (θ), are estimated using techniques like Gibbs sampling and variational algorithms by maximizing the probability P(D∣α, β) of the observed data given the model parameters. The formula of probability [22] is shown in Equation 11: The equation represents the likelihood of observing the entire corpus 𝐷, given the model's hyperparameters 𝛼 and 𝛽. The probability is denoted as 𝑃 (𝐷∣𝛼, 𝛽), where 𝛼 controls the distribution of topics within documents (document-topic distribution) and 𝛽 controls the distribution of words within topics (topic-word distribution). indicates that the likelihood is calculated as a product over all documents in the corpus (where 𝑁 is the total number of documents). The function 𝐹 (𝜃, 𝜙) represents the probability of observing all the words in document given the topic distribution and the topic-word distributions. In short, the process involves summing over all topic assignments for each word in each document and then multiplying these probabilities across all words and documents. The LDA model was constructed to uncover the five main topics within customer reviews across various brands. The text data was pre-processed and converted into a bag-of-words format. Using this corpus, an LDA model was constructed with a predefined number of topics, K as five topics. The model assumes that each review is a mixture of these topics, with each topic represented as a distribution over words. The final topics, represented by the top words within each topic, provide insights into the main themes filtered by each brand in customer reviews. NMF is a technique used to simplify complex data by breaking it down into non-negative components. NMF helps uncover hidden topics within the document by expressing each document as a combination of a few key themes. For each document, NMF represents it as a sum of these components, with specific weights showing how much each component contributes to that document. The process of NMF finding the best combination of components is done by minimizing the difference between the original data and the reconstructed version based on these components. The goal is to approximate the original matrix 𝐷 (which contains the data) as the product of two non-negative matrices, U and V. This is represented by the equation [22] below in Equation 12: where D is the original data matrix, U represents the topics, V shows how these components mix to recreate the original data and ∥ ⋅ ∥ F denotes the Frobenius norm, which measures the difference between the original and approximated matrices. Moreover, the formulas for U and V [22] are shown as below in Equation 13 and equation 14: These equations adjust U and V to minimize the difference between the original data and its approximation. The optimization process can be done by adjusting U to better fit the data D based on how well the current V represents D or adjusting V to better fit the data D based on how well the current U represents D. In this study, an NMF model was built to uncover five topics by brand. The process began by transforming the text data into a numerical format using Term Frequency-Inverse Document Frequency (TF-IDF) vectorization. This method captures the importance of words in each document while considering their frequency across the entire corpus. The top ten words associated with each topic were then extracted to provide insights into the primary themes present in the reviews. To evaluate the quality of topics generated by the LDA and NMF models, we calculated the Coherence Score (CS) using the c_v metric. The CS measures the degree of semantic similarity between the most relevant words within a topic, thereby reflecting its interpretability. A higher CS suggests that the top words in a topic are more meaningfully related and thus more easily understood by humans. This metric is widely used in topic modelling evaluations to provide a quantitative assessment of how coherent or useful the generated topics are. In this study, CS values were computed using the gensim library in Python. After identifying the topics, the VADER sentiment analyser was applied to assess the sentiment associated with each brand. VADER is well known at analysing the sentiment of texts, including those with emojis and other social media-specific elements that other libraries might overlook. VADER provides four different sentiment scores: positive, negative, neutral, and compound. The positive, negative, and neutral scores represent the proportion of the text that falls into each category, while the compound score is a combined metric that sums up the overall sentiment of the text. This compound score ranges from −1 (indicating extremely negative sentiment) to 1 (indicating very positive sentiment) [4]. In this study, only the compound score is used to assess sentiment. By linking the sentiment scores to the topics generated by the topic detection model, the average sentiment for each topic across all reviews was calculated. This approach provided us with insights into not only the key themes present in the customer feedback but also the overall sentiment associated with each theme. For example, a topic related to phone camera feature might have a positive sentiment, while another topic related to product quality might be neutral. The results were categorized into sentiment types, Positive, Neutral, and Negative, based on the average sentiment scores, allowing for a clear understanding of how customers feel about various aspects of the brands they reviewed. Brand sentiment analysis is crucial for businesses to understand how customers perceive their products and services. By evaluating sentiments, companies can gain valuable insights into customer satisfaction, identify areas for improvement, and tailor their marketing strategies effectively. Overall, this model shown in Fig 13 allowed us to effectively combine topic modelling and sentiment analysis to gain a deeper understanding of customer opinions for each brand. https://doi.org/10.1371/journal.pone.0334330.g013 In this section, the results from both traditional ML models and DL techniques are examined. The outcomes of each model are presented, with their performances compared to determine the most effective approach for the dataset. Additionally, the results of the brand topic detection model are explored, and each method is evaluated to identify the most suitable model. Finally, the VADER sentiment analysis tool is applied to assess the sentiment scores associated with the identified topics. As detailed in Table 3, the Decision Trees model achieved an average accuracy of 77.29% after running five cross-validation. It performs particularly well on the majority class, which is positive sentiments, with an average precision, recall, and F1 score of 0.87. In contrast, its performance on negative sentiments is less robust, with average metrics of 0.66. This indicates that the model is better at identifying and classifying positive reviews compared to negative ones. For neutral sentiments, the model struggles to recognize them, achieving only an F1-score of 0.20. The tree’s depth of 937 suggests that the model is quite complex, involving multiple decision nodes to classify the data. https://doi.org/10.1371/journal.pone.0334330.t003 To improve the performance of the Decision Trees model, fine-tuning was conducted by adjusting the key parameter, max_depth, to explore different values. Max Depth refers to the maximum number of splits allowed in a Decision Trees and determines how deep the tree can grow, with each level representing a decision based on a feature in the dataset. During fine-tuning, it was observed that the model’s performance did not improve significantly as demonstrated in Table 4 and Table 5. After running cross-validation for each max_depth value, a maximum depth of 600 yielded an average accuracy of 77.31%. https://doi.org/10.1371/journal.pone.0334330.t004 https://doi.org/10.1371/journal.pone.0334330.t005 The Naive Bayes model is known for its high speed and efficiency in text classification tasks. As shown in Table 6, it achieved an average accuracy of 78.01%, which is comparable to the Decision Trees model’s performance. The Naive Bayes model outperforms the Decision Trees model in terms of recall for positive sentiments, achieving a high recall rate of 0.99. This means that Naive Bayes is highly effective at identifying positive reviews. However, its precision is lower than that of the Decision Trees model, standing at 0.78. This indicates that while Naive Bayes is particularly good at detecting positive sentiments, it is less accurate in ensuring that all detected positive reviews are genuinely positive. Conversely, the Naive Bayes model struggles significantly with neutral sentiments, scoring zero across all evaluation metrics for this category. This suggests that the model fails to identify or predict neutral reviews, which might be attributed to factors such as dataset imbalance, insufficient representation of neutral sentiments, or the model’s inability to distinguish neutral reviews effectively. On the other hand, the model performs well with negative sentiments, showing a high precision of 0.88, meaning it correctly identifies negative reviews 88% of the time. Nonetheless, its recall for negative sentiments is only 0.47, indicating that it captures just 47% of all actual negative reviews. https://doi.org/10.1371/journal.pone.0334330.t006 To further enhance the performance of the Naive Bayes model, fine-tuning was performed by adjusting the key parameter, alpha. In Naive Bayes models, alpha is a smoothing parameter used to handle zero probabilities in the estimation of probabilities for unseen words in the training data. After fine-tuning, the model’s accuracy improved to 82.69%, outperforming the previous version with a smaller alpha value of 0.05. With a smaller alpha, the model is less likely to assume that all words occur with a uniform probability. As a result, the recall for negative sentiments improved significantly from 0.47 to 0.71, indicating a better ability to correctly identify negative reviews. Additionally, the F1 score for neutral sentiments also saw a slight improvement, reflecting some progress in predicting neutral reviews. Table 7 presents the results of the Naive Bayes model after fine-tuning. https://doi.org/10.1371/journal.pone.0334330.t007 For classification tasks, logistic regression is a supervised ML algorithm designed to predict the likelihood that a given instance belongs to a specific class. The logistic regression model achieved an accuracy of 85.05%, making it the best-performing model so far. Based on Table 8, it performs very well on positive sentiments, with f1-score of 0.92, and 0.78 on negative sentiments. Nonetheless, the model struggles with neutral sentiments, achieving only 26% precision, 2% recall, and a 4% F1-score. This low performance could be due to the limited number of neutral sentiment instances, meaning the model may not have enough examples to learn from. Additionally, logistic regression might be better at distinguishing between obvious different classes (positive vs. negative) and struggle with the minor distinctions required for neutral sentiments. https://doi.org/10.1371/journal.pone.0334330.t008 To improve the performance of the logistic regression model, fine-tuning was conducted by adjusting several parameters. Specifically, a range of values for the regularization strength parameter C was explored, which governs the trade-off between achieving a good fit on the training data and maintaining smaller model coefficients. Additionally, different solvers (sag, lbfgs, and saga) were assessed to determine the optimization algorithm used, and various settings for the max_iter parameter were examined, which specifies the maximum number of iterations allowed for the solver to converge. Although these adjustments were made, the enhanced logistic regression model did not improve significantly with accuracy of 85.07% as shown in Table 9. https://doi.org/10.1371/journal.pone.0334330.t009 Support Vector Machines (SVMs) are a type of supervised ML algorithm that works by finding the optimal boundary that best separates different classes. Table 10 and Table 11 present the detailed results of the SVM model, including its performance after fine-tuning. The SVM model achieved an accuracy of 85.02%, which is comparable to the logistic regression model. Like the logistic regression model, the SVM performs well in classifying positive sentiments, with an impressive F1-score of 0.92, and negative sentiments, with an F1-score of 0.78. The model also struggles with neutral sentiments, showing only 33% precision and 2% recall. This indicates the model correctly identifies only 2% of all actual neutral reviews, and one-third of the predictions it makes for neutral reviews are accurate. https://doi.org/10.1371/journal.pone.0334330.t010 https://doi.org/10.1371/journal.pone.0334330.t011 To further enhance the performance of the SVM model, we fine-tuned it by adjusting the regularization parameter C and setting the kernel to ‘linear’. Specifically, we increased the regularization parameter (C) to 10 to evaluate its effect on model performance. A higher C value in SVM typically signifies a greater emphasis on minimizing classification errors on the training set, potentially leading to improved model accuracy. Despite these adjustments, the tuned SVM model yielded an accuracy of 83.27%, which is slightly lower than the previous version. However, the larger C model shows a slight improvement in neutral sentiment detection, but overall performance remains low. In summary, while increasing C slightly improves the detection of neutral sentiments, it results in a decrease in overall accuracy, suggesting a potential overfitting to the training data. A CNN was employed to perform sentiment analysis and achieved an accuracy of 85.07%. The CNN model was initially set to train for 20 epochs but stopped early at the 7th epoch due to the Early Stopping criterion. Early Stopping was configured with a patience of 3 epochs, meaning the training would halt if no improvement in validation loss was observed for three consecutive epochs. The relatively small number of trainable parameters in the CNN architecture and the structured nature of the dataset contributed to rapid convergence. By the final epoch, the training accuracy reached 93.13%, while the validation accuracy had peaked earlier at 85.72% during the second epoch, indicating potential overfitting. Although the number of epochs completed was low, this was driven by clear validation trends suggesting that further training would not yield improved generalization. To enhance the performance, the fine-tuned CNN model included additional layers compared to the initial model. Firstly, a SpatialDropout1D layer with a dropout rate of 0.2 was added after the embedding layer to reduce overfitting. Then, two Conv1D layers were included: the first with 128 filters and the second with 64 filters, both with a kernel size of 5 and Rectified Linear Unit (ReLU) activation. Each Conv1D layer was followed by a MaxPooling1D layer and a Dropout layer with a 0.5 dropout rate to prevent overfitting. Additionally, the fine-tuned model included an extra Dense layer with 256 units and ReLU activation, followed by another Dropout layer, before the final Dense layer with 128 units and the output layer. These modifications aimed to enhance the model’s ability to capture complex patterns in the data and improve generalization. Fig 14 suggests that during the initial epochs, training accuracy steadily increases while training loss decreases, demonstrating effective learning. However, starting from Epoch 2, the validation loss begins to rise, and validation accuracy starts to decline, indicating overfitting. This trend suggests that the model becomes increasingly specialized to the training data and loses generalization capability on the validation set. Compared to the previous model, the fine-tuned CNN model achieved a slightly lower accuracy of 84.51%. https://doi.org/10.1371/journal.pone.0334330.g014 When evaluated on the test set, the RNN model achieved an accuracy of 84.56%, which is comparable to the CNN model. While the RNN showed improvement in accuracy over epochs during training, the trends displayed in Fig 15 reveal signs of early instability and eventual overfitting. From Epochs 0–3, both training and validation accuracy fluctuate noticeably, suggesting that the model struggled to generalize consistently during the early stages of training. A significant gain in performance is observed from Epoch 4 onward, culminating in peak validation accuracy around Epochs 6 and 7. However, validation accuracy begins to decline slightly after Epoch 8, even as training accuracy continues to rise, indicating that the model starts to overfit to the training data. https://doi.org/10.1371/journal.pone.0334330.g015 To further improve the model, an enhanced RNN configuration was implemented by introducing an additional LSTM layer with 100 units. This LSTM layer was paired with dropout and recurrent dropout rates of 0.3 to reduce overfitting. The additional layer helped capture more complex sequential dependencies in the input text. This was followed by a Dense layer with 128 units and Rectified Linear Unit (ReLU) activation to extract additional features, and a final Dense layer with SoftMax activation for three-class sentiment classification. As shown in the training plots, training and validation loss both decline steadily up to Epoch 6. After this point, training loss continues to drop, while validation loss begins to plateau and slightly increase from Epoch 8 onward. Similarly, training accuracy steadily increases across all epochs, but validation accuracy peaks around Epochs 7–8 and shows a slight decline afterward. These trends clearly indicate that while the model initially generalizes well, overfitting begins to emerge in the later epochs. The enhanced RNN model achieved a slightly improved accuracy of 85.01% on the test set, reflecting marginal but consistent gains over the baseline. The graphs indicate early instability followed by convergence and later-stage overfitting, as shown by the divergence between training and validation metrics after Epoch 8. The performance instability observed in the RNN model, particularly during the early and late training epochs, may be attributed to suboptimal hyperparameter settings or the model’s architectural complexity relative to the dataset. Although dropout techniques were employed to mitigate overfitting, the model’s generalization capacity appeared limited after a certain point in training. Further optimization, such as adjusting learning rates, increasing data volume, or exploring simplified architectures, may enhance performance stability in future work. To further improve the model, an enhanced RNN model was designed by adding an additional LSTM layer with 100 units. This layer is paired with dropout and recurrent dropout rates of 0.3 to help prevent overfitting. The addition of the extra LSTM layer allows the model to further capture more complex patterns and relationships within the data. Following the LSTM layers, the model includes a Dense layer with 128 units and ReLU activation to extract further features, and a final Dense layer with SoftMax activation for three-class sentiment classification. Initially, the model shows steady improvements, with both accuracy and loss trending positively as shown in Fig 16. Nevertheless, from Epochs 1–3, there is some fluctuation in the validation metrics, indicating instability in the learning process. A notable improvement occurs after Epoch 4, where validation accuracy increases significantly. Yet, after Epoch 9, the validation metrics begin to decline slightly, suggesting potential overfitting as the model continues to improve on the training set but shows less progress on the validation set. This indicates that the model’s generalization capacity may be nearing its limit, with the best performance observed around Epoch 8. The model achieved an accuracy of 85.01% on the test set, showing only a slight improvement over the previous RNN model. https://doi.org/10.1371/journal.pone.0334330.g016 The initial LSTM model’s training performance shows an improvement over epochs, though with some fluctuations. According to Fig 17, the model’s accuracy gradually increases as the loss decreases from Epoch 1 to Epoch 4, reflecting a positive learning curve. A significant improvement occurs around Epoch 5, where the model’s accuracy increases, especially in validation accuracy, which increase from 70% to 85%. This trend continues as the model reaches its peak performance in Epoch 7, where the validation accuracy stabilizes around 85.97%. Conversely, in subsequent epochs, the model’s performance starts to drop, with minor increases in accuracy and slight increases in validation loss, indicating potential overfitting. The final accuracy achieved on the test set is 85.04%, which suggests the model is may have limited further improvement beyond this point. https://doi.org/10.1371/journal.pone.0334330.g017 The enhanced LSTM model uses a slightly reduced learning rate (0.0005), which appears to stabilize the learning process more effectively. Validation accuracy and loss metrics demonstrate a more consistent improvement across epochs as presented in Fig 18. The validation accuracy continues to improve up to Epoch 16 before showing signs of minor fluctuations, while the first model started showing signs of overfitting by Epoch 9. Both models ultimately achieve similar final test accuracies of 85%. Yet, the second model achieves this through a more stable learning process, suggesting potentially better generalization to unseen data, even though the improvement in accuracy is minimal. In summary, the enhanced LSTM model shows improvements in training stability, overfitting control, and consistent performance across epochs. Although both models achieve similar final accuracies, the second model’s training process suggests a better-tuned model with improved learning dynamics. https://doi.org/10.1371/journal.pone.0334330.g018 To compare the performance of various models on a sentiment classification task, the overall accuracy of each model is provided in Table 12 below. These accuracy scores provide a straightforward measure of how well each model performs in correctly classifying sentiment across a large dataset. Following the accuracy comparison, Table 13 and Table 14 offer a more granular analysis by presenting key performance metrics, including precision, recall, F1 score, and support for each sentiment class (negative, neutral, and positive). These tables provide insight into the strengths and weaknesses of each model, not just in terms of overall accuracy, but in their ability to manage the nuances of sentiment classification across various categories. https://doi.org/10.1371/journal.pone.0334330.t012 https://doi.org/10.1371/journal.pone.0334330.t013 https://doi.org/10.1371/journal.pone.0334330.t014 When examining the accuracy scores, the Logistic Regression and CNN models achieved the highest overall accuracy at 85.07%, slightly outperforming LSTM (85.05%), and SVM (85.02%). Although the differences in accuracy are relatively small, these results indicate that even slight variations in model architecture or algorithm choice can impact performance in sentiment analysis tasks. The comparative performance of traditional classification models, Decision Trees, Naive Bayes, Logistic Regression, and SVM across different sentiment classes highlights significant differences in effectiveness. For negative sentiments, both Logistic Regression and SVM demonstrate impressive performance, each achieving an F1 Score of 0.78. The Decision Trees model, however, shows more modest performance with an F1 Score of 0.66. Regarding neutral sentiments, the Decision Trees model performs best among the models with an F1 Score of 0.20, but this reflects a limitation in capturing neutral sentiments effectively, as it recalls only 17% of these cases. The other models perform even worse, particularly in terms of recall, with values falling below 0.05. This underscores the difficulty all models face in accurately classifying neutral sentiments. In summary, Logistic Regression and SVM are particularly effective for classifying both positive and negative sentiments, while they struggle with neutral sentiments. The Decision Trees model performs slightly better on neutral sentiments compared to others but is still limited. The overall effectiveness of Logistic Regression and SVM makes them more robust for handling sentiment classification, although the underrepresentation of neutral sentiments in the training data likely contributes to the models’ struggles with accurately identifying and classifying these less frequent cases. The evaluation of DL models including CNN, RNN, and LSTM models reveals performance characteristics across the sentiment categories of negative, neutral, and positive. For negative sentiment classification, all models exhibit good performance, with an average F1 Score of 0.77. For positive sentiment classification, all three models perform strongly. The CNN model achieves an F1 Score of 0.92, with high precision of 0.90 and recall of 0.94. The RNN model follows closely with an F1 Score of 0.91, precision of 0.89, and recall of 0.94. The LSTM model also performs well, reaching an F1 Score of 0.92 with a precision of 0.88 and recall of 0.96. In contrast, classifying neutral sentiments remains challenging for all models. Each model reports extremely low scores across precision, recall, and F1 Score for this category. The CNN model shows a slightly better performance with a precision of 0.41 and recall of 0.02, but these figures remain notably low. The RNN model performs worse with a precision of 0.30 and recall of 0.01, while the LSTM model struggles significantly, with all metrics at zero. This poor performance in identifying neutral sentiments is likely due to the imbalanced representation of neutral sentiments in the dataset, which provides insufficient context for the models to learn and generalize effectively. Based on the provided results, the CNN and LSTM Model are the best models due to their strong performance across positive and negative sentiments. Logistic Regression has the highest accuracy but is not the best in all sentiment-specific metrics compared to CNN and LSTM. For neutral sentiment classification, all models are faced with challenges. If overall accuracy and balanced performance across sentiment categories are prioritized, the CNN Model might be preferred due to high F1 Scores in both positive and negative sentiments. The LSTM Model is also a strong candidate as it able to capture positive sentiment with high recall. To evaluate whether the observed accuracy differences are statistically meaningful, a paired t-test was applied to the five-fold cross-validation accuracies of the CNN against each baseline model. Table 15 reports the resulting p-values (df = 4). A threshold of 0.05 was used to determine significance. The CNN outperforms Decision Trees and Naïve Bayes with statistically significant margins, while its advantage over Logistic Regression, SVM, RNN, and LSTM is not significant at the 0.05 level. https://doi.org/10.1371/journal.pone.0334330.t015 These results support the descriptive metrics in Table 12: although CNN shares similar mean accuracy with Logistic Regression and LSTM, its superiority is statistically confirmed only over the lower-performing traditional models. Consequently, conclusions about model ranking should emphasise practical as well as statistical considerations. After classification, the identification of main subjects within the Amazon customer review dataset is facilitated through the utilization of two topic detection algorithms: LDA and NMF. The purpose of this is to reveal the main topics people are talking about in the Amazon customer review dataset. The LDA model was employed to discover five primary topics for each brand within the Amazon customer reviews dataset. These topics are characterised by a distribution of words that summarise the key themes prevalent in the reviews. The main points include: By detecting these topics across different brands, the LDA model provides valuable insights into the aspects of phone performance that matter most to consumers. The topic explanations for each brand can be found in Table 1–10 of Appendix A in S1 File. After that, the NMF model was also employed to discover five primary topics for each brand within the Amazon customer reviews dataset. The key points identified by NMF model include: This explanation highlights that the NMF model captured not only performance-related aspects but also emotional themes. The topic explanations for each brand can be found in Tables 11–20 of Appendix B in S1 File. To provide an objective assessment of topic quality, we calculated the CS using the widely adopted c_v metric. Higher CS values indicate greater semantic similarity among the top words in a topic, resulting in more interpretable themes. The LDA model achieved a CS of 0.41, whereas the NMF model obtained a higher CS of 0.54. These quantitative results corroborate the qualitative findings in Sections 4.4.1 and 4.4.2, confirming that the NMF topics are more coherent and therefore better suited for analysing brand perception in this dataset. In evaluating the performance of these two topic-detection approaches, the NMF model emerges as the most effective for this study. NMF produces more focused, detailed, and interpretable topics, making it the strongest tool for understanding brand perceptions within customer reviews. The LDA model tends to capture topics that are closely related to phone features yet often overlapping. Themes such as “battery” and “camera” frequently intersect with broader topics like overall user satisfaction, limiting LDA’s ability to separate distinct aspects of user experience, especially in the smartphone domain, where multiple features influence perception simultaneously. By contrast, the NMF model delivers more precise and distinguishable topics. It not only identifies general themes like user satisfaction but also uncovers specific issues such as product condition upon arrival or mixed feedback on certain models (e.g., Asus Zenfone). NMF further highlights detailed topics such as camera performance and connectivity issues, each treated as a distinct subject with its own sentiment profile. This granularity enables deeper analysis of how customers perceive individual phone features. When NMF reveals, for instance, that camera performance is a significant concern for a brand, product development and marketing teams can address that issue directly. The clarity and specificity of NMF topics thus provide actionable insights, facilitating improved brand management and customer satisfaction. In conclusion, NMF proves to be the most effective topic-modelling technique for this study. Its capacity to extract distinct, focused topics and capture a wide range of user sentiments and product attributes makes it the preferred choice for understanding and analysing brand perception in customer reviews. By leveraging NMF, business owners gain a deeper and more actionable understanding of how customers perceive different aspects of their products, enabling more targeted improvements and more effective communication with consumers. After selecting the best topic detection model, brand sentiments were generated by applying the VADER sentiment analysis on the results. Sentiment scores help categorize customer opinions into positive, neutral, or negative, and provide a clear measure of consumer sentiment. The sentiment scores for each brand can be found in Table 21 of Appendix C in S1 File. Here is a summary of the sentiment scores for various smartphone brands: Overall, these sentiment analyses provide a comprehensive view of customer perceptions, enabling brands to address concerns. This information also can guide strategic decisions, such as enhancing product features that are well-received, addressing common complaints, or refining marketing messages to align with customer expectations. Following the sentiment analysis and topic detection, which offered a deeper understanding of the underlying themes and sentiments within the dataset, we now shift our focus to visualizing the broader aspects of the data. Visualization is essential for uncovering patterns, trends, and insights. This section presents a series of visualizations that offer a comprehensive overview of the dataset, employing both Python and Tableau for this purpose. Several graphs were created using Python to provide a detailed analysis of the dataset. These Python-generated graphs offer an initial exploration of the data. The top ten products with the most customer reviews are presented in Fig 19, allowing business owners to identify which products were customer favourites during this timeframe. Most of these products are from the Samsung brand, with only one product each from Xiaomi and Nokia. By knowing the popular brand among the smartphone users, a business owner can determine if a particular feature or product brand resonates more with consumers, enabling them to focus on those aspects in future inventory management and marketing strategies. Besides, Fig 20 plots the top three products for each brand, providing insights into the best-selling products for each brand. This information can help business owners understand which products are most popular among customers for each specific brand. For instance, a business owner can manage product inventory more effectively by deciding whether to stock up on popular items, reduce stock for less favoured ones, or import similar products with popular features. https://doi.org/10.1371/journal.pone.0334330.g019 https://doi.org/10.1371/journal.pone.0334330.g020 Additionally, a comprehensive dashboard was created in Tableau to compile and extend these insights as seen in Fig 21. The Tableau dashboard includes visualizations such as reviews over time, average ratings by brand, total reviews by brand, sentiment distribution across categories for each brand, and a summary of the top ten products by brand in terms of review count and average rating. This dashboard serves as a powerful tool for gaining a comprehensive view of Amazon customer reviews across distinct brands, allowing for a deeper understanding of brand performance and customer perception. https://doi.org/10.1371/journal.pone.0334330.g021 In conclusion, this study addressed the challenge of extracting actionable insights from the extensive volume of customer reviews, particularly within the smartphone industry. By applying sentiment analysis techniques, topic detection, and an interactive Tableau dashboard, this research filled a gap in the literature on brand sentiment analysis for smartphone brands. The results showed that the CNN model, which achieved the highest accuracy at 85.07%, provided balanced performance across sentiment categories and proved to be particularly effective for overall sentiment analysis. Although Logistic Regression achieved similar accuracy, it fell short in comparison to CNN across sentiment-specific metrics. All models struggled with classifying neutral sentiments, which may be attributed to the less emotionally charged nature of these reviews. While early stopping and dropout were applied to address overfitting in the CNN model, we acknowledge that the observed gap between training and validation accuracy suggests room for further improvement. Due to the scope of the current study, additional regularization techniques such as L2 weight decay, batch normalization, and text augmentation were not explored. These strategies are being investigated in ongoing follow-up work aimed at enhancing model generalization and robustness. All DL models were capped at 20 global epochs to maintain parity of training time across the benchmark. While early stopping indicated convergence in most cases, this cap may have curtailed the models’ ability to extract deeper feature hierarchies. Ongoing work is experimenting with extended epoch schedules, cosine learning-rate decay, and warm-up strategies to determine whether additional training yields measurable gains in generalisation. Building on these findings, the research made significant contributions. Firstly, the development of an interactive Tableau dashboard enables businesses to monitor customer sentiment trends and brand perception effectively. This tool provides businesses with a comprehensive visual analysis of customer feedback, helping them to make data-driven decisions that enhance brand image and customer satisfaction. Secondly, this study proposed a new framework that applies sentiment analysis, topic detection and brand topic sentiments. This approach provides a holistic view of customer feedback, which is essential for businesses in the competitive smartphone market. However, certain limitations must be acknowledged. The dataset used only includes information up to 2019, which may not reflect the most recent trends or shifts in language usage. Additionally, challenges in text preprocessing, such as handling multilingual content and slang, may have impacted model performance. Future research should consider using real-time social media analytics, if possible, to capture more up-to-date customer feedback. The dataset also revealed a clear imbalance in sentiment labels. This imbalance posed a risk of model bias during classification. To mitigate this, class weighting was applied during model training, ensuring that minority classes contributed more significantly to the loss function. Preliminary experiments showed that weighted training improved the recall of Negative and Neutral classes by three to five percentage points compared with an unweighted baseline. Techniques such as Synthetic Minority Over-sampling Technique (SMOTE), data augmentation, or ensemble re-weighting were not employed in this study; future work could explore these alternatives to determine whether they further mitigate imbalance without introducing noise. In this study, we adopted a conventional 80/20 random train-test split to benchmark model performance, which allowed for a balanced distribution across sentiment categories. However, we recognise that this approach may not fully capture the complexities of real-world generalisation. The observed similarity in model performance could, in part, stem from the homogeneity introduced by this split strategy. As such, we acknowledge the value of more challenging evaluation frameworks. Future work will explore brand-wise, temporally stratified, and cross-platform data splits to better evaluate model robustness and generalisability across diverse product lines and evolving consumer contexts. Other sources of imbalance, such as the uneven temporal and brand distribution of reviews, were also not explicitly addressed. For example, some brands only appear in later years (e.g., Xiaomi), which may influence the model’s ability to generalize across brands and time periods. Future work could explore temporal resampling or brand-stratified evaluation to better account for these biases. Reviews were categorized using an automated Python-based heuristic labelling strategy, which relied in part on the VADER lexicon-based approach. While this facilitated efficient labelling of over 60,000 reviews, it may oversimplify sentiment classification, particularly for neutral or ambiguous cases. Lexicon-driven methods such as VADER are constrained by their dependence on pre-defined word lists and heuristics, which can struggle to capture contextual nuances, sarcasm, or domain-specific terminology. These limitations introduce potential ambiguity in the dataset and may affect model training and evaluation outcomes. Future iterations of this study may therefore explore more robust labelling methods, such as manually annotated datasets, semi-supervised learning approaches, or transformer-based sentiment labelling techniques, to improve contextual sensitivity and reliability. Due to computational constraints, hyperparameter tuning for CNN, RNN, and LSTM models was limited to a focused grid of empirically selected values. While this ensured fair benchmarking, we acknowledge that a broader search might have yielded better-optimised configurations. Each model was tuned via five-fold cross-validation, with the best settings selected based on mean validation accuracy. In future work, we aim to adopt more systematic tuning methods, such as Bayesian or random search, to explore a wider range of architectural and optimisation parameters and further improve model robustness. While the current pipeline relies on conventional ML and foundational DL architectures, recent advances in NLP demonstrate that richer text representations can be obtained through Word Embeddings such as Word2Vec and GloVe, and through Transformer-based LLM such as BERT, Robustly Optimized BERT Pretraining Approach (RoBERTa), and GPT. These models capture context-dependent semantics, idiomatic expressions, and subtle sentiment cues that conventional bag-of-words and static embeddings may overlook. Future work will therefore integrate pre-trained contextual embeddings or fine-tuned transformer encoders into the sentiment-classification stage, benchmark their performance against the current CNN baseline, and evaluate the trade-offs among accuracy, interpretability, and computational cost. While the present work focuses on Amazon smartphone reviews, we recognize that broader applicability requires careful consideration. The proposed pipeline is adaptable to other e-commerce platforms and consumer domains where reviews share structural similarities, such as hospitality, consumer electronics, and healthcare. However, differences in linguistic styles, platform-specific rating systems, and domain-specific terminology may limit direct transferability. To strengthen generalizability, future research should evaluate the framework across multiple datasets and platforms, potentially using domain adaptation or transfer learning techniques to account for variations in language and context. This would ensure that the approach remains robust and reliable when applied to diverse industries beyond the Amazon ecosystem. Beyond technical performance, this study also acknowledges the ethical implications of deploying automated sentiment analysis systems. Bias in training data, such as imbalanced sentiment classes, skewed brand representation, or culturally specific language, can propagate through the model and result in unfair or inaccurate predictions. For instance, reviews written in non-standard dialects or by speakers from diverse linguistic backgrounds may be misclassified due to underrepresentation in the training set. Automated sentiment classifiers may also inadvertently amplify stereotypes or marginalize minority voices if not properly audited. To ensure responsible AI practices, future work should incorporate fairness evaluation metrics, conduct bias audits, and explore mitigation techniques such as adversarial debiasing or fairness-aware training. Transparency, accountability, and inclusivity should be core principles in the development and deployment of sentiment analysis models used for real-world decision-making. In conclusion, this study contributes to a deeper understanding of customer sentiment analysis and provides practical tools for businesses to improve their brand perception and customer satisfaction in the highly competitive smartphone market. At the same time, the ethical implications and challenges of generalizability must not be overlooked. By embedding fairness, transparency, and adaptability into future work, sentiment analysis frameworks can achieve both technical robustness and responsible application across diverse domains. Appendix A: Topic explanations for each brand using the LDA model. Table I: LDA Topic Detection for Motorola Brand. Table II: LDA Topic Detection for Nokia Brand. Table III: LDA Topic Detection for Samsung Brand. Table IV: LDA Topic Detection for Huawei Brand. Table V: LDA Topic Detection for Sony Brand. Table VI: LDA Topic Detection for Apple Brand. Table VII: LDA Topic Detection for Google Brand. Table VIII: LDA Topic Detection for Asus Brand. Table IX: LDA Topic Detection for OnePlus Brand. Table X: LDA Topic Detection for Xiaomi Brand. Appendix B: Topic explanations for each brand using the NMF model. Table XI: NMF Topic Detection for Motorola Brand. Table XII: NMF Topic Detection for Nokia Brand. Table XIII: NMF Topic Detection for Samsung Brand. Table XIV: NMF Topic Detection for Huawei Brand. Table XV: NMF Topic Detection for Sony Brand. Table XVI: MF Topic Detection for Apple Brand. Table XVII: NMF Topic Detection for Google Brand. Table XVIII: NMF Topic Detection for Asus Brand. Table XIX: NMF Topic Detection for OnePlus Brand. Table XX: NMF Topic Detection for Xiaomi Brand. Appendix C: Topic-based sentiment scores for each brand using the VADER method. Table XXI: Topic-Based Sentiment Score for each brand using VADER. https://doi.org/10.1371/journal.pone.0334330.s001 (DOCX)
--------------------------------------------------

Title: Stocks Muted Before the Open as Rally Pauses, U.S. Jobless Claims Data on Tap
URL: https://www.barchart.com/story/news/36450274/stocks-muted-before-the-open-as-rally-pauses-u-s-jobless-claims-data-on-tap
Time Published: 2025-12-04T11:19:04Z
Description: December S&P 500 E-Mini futures (ESZ25) are up +0.02%, and December Nasdaq 100 E-Mini futures (NQZ25) are down -0.01% this morning, taking a breather after...
--------------------------------------------------

Title: AI Mode, Activate; The Trade Desk Bends On Agency Incentives
URL: http://www.adexchanger.com/daily-news-roundup/ai-mode-activate-the-trade-desk-bends-on-agency-incentives/
Time Published: 2025-12-04T05:03:19Z
Full Content:
AI Stat Padding Google and Meta love bragging about how widely their AI tools are being used by consumers. But are those metrics legit? For example, Mark Zuckerberg noted during Meta’s quarterly earnings in October that “more than one billion monthly actives already use Meta AI.” Wow! Sounds like a lot. Usage has also increased, Zuckerberg added, as the underlying models improve. But guess what? The basic search function on Instagram was recently replaced by Meta AI, and the app’s entire user base now defaults to that experience even if someone doesn’t want to use the feature. Meanwhile, Google is funneling people to its AI Mode for search regardless of their search engine preferences. As noted by Search Engine Roundtable, anyone who uploads a photo or document to Google is now sent to AI Mode by default instead of a traditional Google Search or Image Search. Meanwhile, in September, Google quietly began sliding a button into the Chrome URL address bar that directs queries straight into AI Mode rather than traditional search. The Defrayed Desk It’s been knives out for The Trade Desk’s 20% take rate all year. And now the largest independent DSP actually appears open to cutting its own fees. Although The Trade Desk historically has been inflexible in pricing negotiations, it’s offering agency discounts and incentives this Q4, Digiday reports. What’s changed? Mainly, increased competition from other top DSPs, Amazon in particular. Amazon DSP has been courting agencies with 0% tech fees for Amazon-owned media and 1% fees for third-party ads. Plus, TTD is under pressure to meet or exceed expectations this Q4, after missing its fourth quarter 2024 revenue guidance earlier this year. One indie agency buyer says TTD offered 1% to 2% discounts on ad tech fees for individual clients – if the agency committed to spending $500,000 more in Q4 than originally budgeted. Another buyer says they were offered post-auction discounts if they spent at least $750,000 in Q4. At the holding company level, one buyer says, TTD is making its development team available for working on tailored programmatic solutions free of charge. Another observes that TTD’s account reps are more responsive lately. All told, evidence is accumulating of an increasingly cutthroat DSP market. Open Up The Elsagates Good news: YouTube has finally found a reliable audience for the AI-generated content that’s been flooding the platform. Bad news: It’s toddlers (again). YouTube creators are increasingly monetizing by generating generic, low-quality AI slop videos intended for children, reports Bloomberg. The trend is particularly popular among entrepreneur-focused creators that make content about making money on YouTube, such as Monique Hinton and Isabella Kotsias. Both have posted videos specifically advocating that their viewers attempt to copy popular YouTube Kids trends and products, like “Baby Shark” and “Cocomelon.” This might trigger alarm bells for those who remember 2017’s Elsagate, a YouTube epoch marked by nonsensical videos of popular children’s characters (mostly Spider-Man and Elsa from “Frozen”) engaging in strange or disturbing activities. This “luridly-colored vomit,” as Forbes called it at the time, became enough of a problem that YouTube changed its community guidelines, purged thousands of videos and removed monetizable ads from millions more. Although, some might argue that these content farms didn’t disappear so much as move into new genres. But Wait! There’s More Let’s get real about agentic AI. [Cynopsis] Spotify leaned hard into human creative for its Wrapped this year. [Adweek] Kohler’s smart toilet camera, which offers feedback on gut health, isn’t actually end-to-end encrypted, and the company can access consumer data and use it to train AI, according to a former FTC advisor. [blog] The London Stock Exchange Group struck a deal with OpenAI to make its licensed financial news and data available on ChatGPT. [Bloomberg] In other data-sharing news, predictive market (aka “gambling”) company Kalshi will now supply its data to CNN’s newsrooms. [Axios] Target changes the price of some products based on consumer data. Now, thanks to a new law, New York residents know about it. [Wired] As PlayStation celebrates its 30th anniversary, here’s how Sony built its upstart gaming brand into a mainstream pop cultural touchstone. [AP] You’re Hired! Smartly appoints Brianna Gays as CMO. [blog] Here’s today’s AdExchanger.com news round-up… Want it by email? Sign up here.
--------------------------------------------------

Title: Analyst who bought Palantir below $10 revamps stock price target
URL: https://www.thestreet.com/investing/stocks/analyst-who-bought-palantir-below-10-revamps-stock-price-target
Time Published: 2025-12-04T03:03:00Z
Description: The artificial intelligence revolution is running full tilt, with few signs of slowing three years after OpenAI’s ChatGPT shocked the world by becoming the...
--------------------------------------------------

Title: Anthropic CEO: Some AI companies ‘YOLOing,’ pulling the ‘risk dial too far’
URL: https://finance.yahoo.com/news/anthropic-ceo-some-ai-companies-yoloing-pulling-the-risk-dial-too-far-223738240.html
Time Published: 2025-12-03T22:37:38Z
Description: Anthropic CEO Dario Amodei warns that some competitors are taking overspending risks too far.
--------------------------------------------------

Title: Orezone Intercepts 3.28 g/t Gold Over 26.00m and 5.55 g/t Gold Over 15.00m at P17 Zone in Advance of Hard Rock First Gold
URL: https://www.globenewswire.com/news-release/2025/12/03/3199416/0/en/Orezone-Intercepts-3-28-g-t-Gold-Over-26-00m-and-5-55-g-t-Gold-Over-15-00m-at-P17-Zone-in-Advance-of-Hard-Rock-First-Gold.html
Time Published: 2025-12-03T22:29:00Z
Full Content:
December 03, 2025 17:29 ET | Source: Orezone Gold Corporation Orezone Gold Corporation VANCOUVER, British Columbia, Dec. 03, 2025 (GLOBE NEWSWIRE) -- Orezone Gold Corporation (TSX: ORE | ASX: ORE | OTCQX: ORZCF) (the “Company” or “Orezone”) is pleased to report shallow, high-grade confirmatory grade control drill results from the P17 Zone at its flagship Bomboré Gold Mine. The P17 Zone is a high-grade hard rock deposit outcropping at surface located at the southern end of the Bomboré mining lease. In addition to several phased oxide pits, which have locally been advanced into the hard rock, the P17 Zone will be a primary mill feed source in 2026 for the new hard rock plant, currently being commissioned. Selected Drill Highlights1: Patrick Downey, President and CEO stated, “The results of the near-surface P17 Zone grade control drill program were successful in confirming the P17 resource and reserve models. Furthermore, the results serve to underscore the high-grade nature and overall continuity of mineralization within the P17 Zone. This initial grade control drill program is centered on the first six months of planned production from the P17 Zone. Mining activities in this area of the pit are now underway, with mined ore scheduled to be fed to the mill in early 2026 once commissioning is complete. ___________________________________1. True widths of mineralization are between 75-80% of drilled lengths. Commissioning of the stage 1 hard rock plant is well advanced, with the jaw crusher now commissioned and a crushed ore stockpile established. The SAG mill is now turning, with grinding media being added and first ore through the mill expected to follow very soon. Water testing of the CIL circuit is now complete, with the tanks to be filled and fresh carbon to be added by the end of the week. Overall, commissioning activities remain on schedule, with first gold expected in the coming days. This is truly an exciting time for the Company, and I want to thank everyone involved for all their hard work and dedication. The commencement of production from the stage 1 hard rock plant represents a major milestone for Orezone, with overall gold production at Bomboré set to increase by 45% to 170,000 to 185,000oz in 2026. This will mark a significant cash flow inflection point, underscored by the Company’s solid balance sheet and record high gold prices.” Figure 1: Stage 1 Hard Rock Expansion Commissioning Figure 2: Bomboré Plan Map – Highlighting Location of P17 Grade Control Drilling and Associated Sections Figure 3: P17 Composite Long Section – Highlighting Location of Grade Control Cross Sections and Further Exploration Upside Down Plunge of US$1,740/oz Pit Shell (Looking West) Figure 4: P17 Grade Control Cross Section A-A’ (Looking North) Figure 5: P17 Grade Control Cross Section B-B’ (Looking North) Table 1: P17 Grade Control Drill Results * Mineralized intervals are reported as downhole lengths. True widths of mineralization are between 75-80% of drilled lengths.**Composite parameters: 0.45g/t Au cut-off with maximum 3m of internal dilution. No top cut applied.***Assay Results Pending (ARP), No Significant Result (NSR). About Orezone Gold Corporation Orezone Gold Corporation (TSX: ORE, ASX: ORE, OTCQX: ORZCF) is a West African gold producer engaged in mining, developing, and exploring its 85%-owned flagship Bomboré Gold Mine in Burkina Faso. Construction of the stage 1 hard rock expansion is substantially complete, with first gold expected in early December. Combined production from the oxide and stage 1 hard rock operations is forecasted to total between 170,000 and 185,000 ounces in 2026.2 The Company is also advancing the stage 2 hard rock expansion, which is forecasted to increase annual production to between 220,000 and 250,000 ounces.3 The technical report entitled Bomboré Phase II Expansion, Definitive Feasibility Study is available on SEDAR+ and the Company’s website. Contact Information Patrick DowneyPresident and Chief Executive Officer Kevin MacKenzieVice President, Corporate Development and Investor Relations Tel: 1 778 945 8977 info@orezone.com / www.orezone.com For further information please contact Orezone at +1 (778) 945 8977 or visit the Company’s website at www.orezone.com. This announcement is authorised for release by Patrick Downey, President, CEO and Director. The Toronto Stock Exchange neither approves nor disapproves the information contained in this news release. Qualified Person and Competent Persons Statement Alastair Gallaugher (CGeol), Exploration Manager for Orezone, is the Qualified Person under NI 43-101 and has reviewed and approved the scientific and technical information contained in this news release. Information in this press release that relates to grade control drilling and exploration results is based on, and fairly represents, information and supporting documentation prepared by Mr. Gallaugher, a Competent Person who is a Member of the Geological Society of London. Mr. Gallaugher has sufficient experience that is relevant to the style of mineralisation and type of deposit under consideration and to the activity which he is undertaking to qualify as a ‘Competent Person’ as defined in the 2012 Edition of the ‘Australasian Code for Reporting of Exploration Results, Mineral Resources and Ore Reserves’ (JORC Code). Mr. Gallaugher is an employee of the Company and consents to the inclusion in this announcement of all technical statements based on his information in the form and context in which it appears. ___________________________________2. Refer to the Company’s prospectus dated and lodged with ASIC on July 11, 2025 (the “ASX Prospectus”), a copy of which is available on the Company’s website. The Company confirms it is not aware of any new information or data that materially affects the information included in the Prospectus and that all material assumptions and technical parameters underpinning the mineral resources in the Prospectus continue to apply and have not materially changed. Please also see the Company’s MD&A for the three and nine months ended September 30, 2025.3. Refer to footnote 2. QA/QC The mineralized intervals are based on a lower cut-off grade of 0.45g/t Au. Grade control samples are generated from in-house and contractor-owed reverse circulation (“RC”) drill rigs using face sampling hammers. Samples were collected directly from a cone splitter attached to the rig-side cyclone at 1m intervals by Orezone employees. The samples are received at the on-site assay laboratory operated by Intertek, split to 1kg, pulverised and leached using the PAL-1000 method. The slurry sample produced is analysed using atomic absorption spectrometry (“AAS”) for gold giving a total cyanide extractable gold value. The leach residues from all samples with a leach grade greater than or equal to 0.25g/t Au were prepared by Intertek and split to 50g using RSDs. A 50g aliquot was analyzed by fire assay at Intertek Bomboré lab. Orezone employs a rigorous Quality Control Program including a minimum of 10% standards, blanks and duplicates. The composite width and grade include the final leach residue assay results for most of the drill intercepts reported. Cautionary Note Regarding Forward-Looking Statements This press release contains certain information that constitutes “forward-looking information” within the meaning of applicable Canadian Securities laws and “forward-looking statements” within the meaning of applicable U.S. securities laws (together, “forward-looking statements”). Forward-looking statements are frequently characterized by words such as “plan”, “expect”, “project”, “intend”, “believe”, “anticipate”, “estimate”, “potential”, “possible” and other similar words, or statements that certain events or conditions “may”, “will”, “could”, or “should” occur. Forward-looking statements in this press release include, but are not limited to statements with respect to the commencement of production from the stage 1 hard rock plant representing a major milestone for Orezone, with overall gold production at Bomboré set to increase by 45% to 170,000 to 185,000oz in 2026, the high-grade nature and overall continuity of mineralization within the P17 Zone and the exploration program at Bomboré . Forward-looking statements are not guarantees of future performance and involve known and unknown risks, uncertainties, assumptions and other important factors, many of which are beyond the control of the Company, its Directors, and management, and which could cause actual results or events to differ materially from those expressed or implied. Past performance is not a guide to future performance. Such risks and uncertainties include, but are not limited to, terrorist or other violent attacks, the failure of parties to contracts to honour commitments, unexpected changes in laws, rules or regulations or their enforcement, social or labour unrest, changes in commodity prices, failure or inadequacy of infrastructure, project cost overruns or unanticipated costs and expenses, accidents and equipment breakdowns, political risk, unanticipated changes in key management personnel, the spread of diseases, epidemics and pandemics, adverse market or business conditions, failure of exploration or drilling programs to deliver anticipated results, uncertainties relating to the availability and costs of future financing, and other factors described in the Company’s most recent audited annual consolidated financial statements, annual MD&A, Annual Information Form for the year ended December 31, 2024, and in Section 4 of the Prospectus, copies of which are available on SEDAR+ (www.sedarplus.ca) and the Company’s website. Readers are cautioned not to place undue reliance on forward-looking statements. Forward-looking statements are based on the applicable assumptions and factors management considers reasonable as of the date hereof, based on the information available to management at such time. These assumptions and factors include, but are not limited to, assumptions and factors related to the Company’s ability to carry on current and future operations, including: development and exploration activities; the timing, extent, duration and economic viability of such operations, including any mineral resources or reserves identified thereby; the accuracy and reliability of estimates, projections, forecasts, studies and assessments; the Company’s ability to meet or achieve estimates, projections and forecasts; the availability and cost of inputs; the price and market for outputs, including gold; foreign exchange rates; taxation levels; the timely receipt of necessary approvals or permits; the ability to meet current and future obligations; the ability to obtain timely financing on reasonable terms when required; the current and future social, economic and political conditions; and other assumptions and factors generally associated with the mining industry. Although the forward-looking statements contained in this press release are based upon what management of the Company believes are reasonable assumptions, the Company cannot assure investors that actual results will be consistent with these forward-looking statements. These forward-looking statements are made as of the date of this press release and are expressly qualified in their entirety by this cautionary statement. Subject to applicable securities laws, the Company does not assume any obligation to update or revise the forward-looking statements contained herein to reflect events or circumstances occurring after the date of this press release. Appendix – JORC Code, 2012 Edition Section 1 – Sampling Techniques and Data Section 2 – Reporting of Exploration Results Photos accompanying this announcement are available at: https://www.globenewswire.com/NewsRoom/AttachmentNg/00aa5f90-15d2-4cba-af6d-0a0074d00a29 https://www.globenewswire.com/NewsRoom/AttachmentNg/95296683-06ac-4182-8e08-5e75369348a1 https://www.globenewswire.com/NewsRoom/AttachmentNg/0071e22a-6ac8-4430-97a3-ef5c72f8af6f https://www.globenewswire.com/NewsRoom/AttachmentNg/f43b8878-bb3c-4836-875f-08d8fdcf9a85 https://www.globenewswire.com/NewsRoom/AttachmentNg/0b765956-cf73-4586-869b-aac4c30f87e5 All dollar amounts are in USD unless otherwise indicated and abbreviation “M” means million. VANCOUVER, British Columbia, Nov. 12, 2025 (GLOBE NEWSWIRE) -- Orezone Gold Corporation (TSX: ORE | ASX:... VANCOUVER, British Columbia, Nov. 04, 2025 (GLOBE NEWSWIRE) -- Orezone Gold Corporation (TSX: ORE | ASX: ORE | OTCQX: ORZCF) will announce its third quarter 2025 results on Wednesday, November 12,...
--------------------------------------------------

Title: Trillion Dollar Market Caps: Fairy Tale Pricing or Business Marvels?
URL: https://www.blogger.com/comment/fullpage/post/8152901575140311047/7632903359064770058
Time Published: 2025-12-03T18:14:00Z
Description: None
--------------------------------------------------

Title: This Meta Quest 3 charging dock won't stop beeping at me, but damn does it keep my VR setup neat and tidy
URL: https://www.gamesradar.com/hardware/vr/prismxr-d1-charging-stand-review/
Time Published: 2025-12-03T18:03:08Z
Full Content:
When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. The PrismXR charging dock is certainly one of the neatest stands for the Quest 3 you'll find on the shelves. It keeps things low-profile, charges the headset and its controllers, and doesn't take up much room on a shelf or desk. But there are some definite annoyances that prevent this from being an easy recommendation. Charges the controllers and the headset Supplies rechargeable batteries for the controllers Neat, tidy look while on display Handy indicator LEDs to show how much each element is charged Compatible with headstraps from other brands Annoying, incessant beeping Doesn't seem to turn itself off when the headset is fully charged Separate version for the Quest 3S -Not the fastest method of charging Why you can trust GamesRadar+ Our experts review games, movies and tech over countless hours, so you can choose the best for you. Find out more about our reviews policy. Pretty soon after setting up my Quest 3, I realised how quickly the controllers lose battery. In fact, even if I didn't use them or the headset for a week or two, I'd frequently come back to find them completely drained. Having only used a charging stand that gave power to the headset itself, I knew my budget for batteries would thank me if I tried something that charged the controllers too. So, to the best Meta Quest accessories I turned, and of all the available charging stands, PrismXR's filled the most gaps in the market for me. It charges the headset and the controllers, but also feels perfect for anyone who wants a pretty low-profile way of displaying their VR loadout. It doesn't have fancy RGB or stand too high for a lot of shelfing units, and its aesthetic matches the Quest 3's as though it was made by Meta itself. For $69.99 / £69.99, it's roughly on par with the cost of most other charging docks, so let's see how it performs. Having just reviewed the PrismXR charging belt for Quest 3 and 3S, I had high hopes for this dock as a follow-up. Just like the charging belt, this is fairly self-explanatory. The Carina D1 is a dock that you can plug in via USB-C that'll magnetically charge your headset and controllers. Rather annoyingly, because this was designed with the Meta Quest 3 in mind before the 3S arrived on the scene, it has a fairly snug design that's bespoke for the original VR headset. For that reason, you'll need to opt for a separate version of this device for the Quest 3S, which leaves the door open for wrong purchases, but does help to create a neater match with whichever headset you own. From a quick search of both charging docks on Amazon and at PrismXR's own website, they seem to do the exact same thing, and for the most part, are the same price. That said, I'd think about looking into the price history of either at your own leisure because, like any and all Quest 3 accessories, their prices fluctuate madly. To keep the controllers charged, the D1 dock comes with rechargeable batteries, as well as different grip plates for your controllers so that they can attach magnetically. These feel exactly the same as the stock ones when using the controllers during VR play, and only take a minute to swap out. Weekly digests, tales from the communities you love, and more Magnetics are the name of the game here, as magnetic charging pins are used to connect the bottom of the headset to the charging dock. For the overall aesthetic of the Carina D1, this helps to keep things nice and neat - there are no cables to be seen from the front. Perhaps my favorite thing about the dock's design is that it has a handy head strap pedestal at the back, which allows for more compatibility with third-party accessories. I was worried my KIWI Design Comfort Battery Strap wouldn't fit, but thanks to this handy add-on, I had no problems. In terms of technicals, the Carina D1 Charging Dock can Fast Charge up to 27W, which PrismXR says will take your Quest 3 from 0% to 50% in 45 minutes, and fully charge in 1hr50. The controllers have a quoted charging time of 2hr30. There are also some handy LED indicators on the front of the stand that tell you what level of battery the headset and two controllers are, and as I'll come on to, there are audible indicating bleeps too. I really like the look of the PrismXR charging dock. Its nest design means I was spoiled for choice for where to put it in my living space. It could fit in one of the shelves in my cube unit because it isn't too tall. It's not obnoxiously wide, so it can sit nicely with the other gaming hardware on my desk or a shelf. But at the same time, it still looks neat and tidy, and its white design lines up exactly with the color of the headset. The only real test of this dock, besides its looks, is how it charges the headset and controllers. If I'm honest, I'd like it to be a bit quicker, but that's mainly because I'm used to plugging it in at the wall with a super-fast charger and seeing it juice up pretty speedily. Arguably, for a charging stand, I don't think it necessarily needs to be super quick because it's where you put it when you know it'll be sitting to rest between sessions. Still, I found it took around an hour to charge the headset up to its 50% mark while the controllers were also connected - which I suppose matches up with the quoted 45-minute mark that I'll assume refers to just the headset being connected. The times when I've used this charging stand and haven't been faced with annoying bleeps fill me with more confidence that this isn't an issue you'll definitely run into At least the indicating LEDs are a handy way to keep tabs on charging progress. What isn't so handy is a very loud beeping tone that the D1 will pierce your eardrums with. When you first connect the headset and controllers, it'll beep. When it finishes charging them? It'll beep, and sometimes, keep beeping. I've seen reports of these bleeps being buggy and incessant for multiple users. Certainly, the first time I used the D1, that's the experience I had when my headset reached full charge. Other reports seem to suggest that the beeping is due to a faulty connection, which would line up with my experience of other times when the headset reached full charge, then didn't beep at all. Either way, these beeps are loud and a very annoying point of convenience-gone-wrong if they continually bug out for people. What's more unclear is whether or not the dock can turn itself off when the Quest 3 reaches full charge, because if not, it could cause you battery life issues further down the road. Unless you go and unplug the dock entirely or remove the headset so the magnetic pins aren't connected, it could keep charging your headset, or, in my case, beeping loudly. The times when I've used this charging stand and haven't been faced with annoying bleeps fill me with more confidence that this isn't an issue you'll definitely run into, but since this is a known issue for other users who have had larger connection problems, it's all a little unclear. Considering this brand's charging belt will turn itself off when it detects a fully charged headset, it's a bit of a shame that the charging dock isn't more upfront that it will do so as well. If you touch the LEDs, they'll go to sleep, but I'm not sure whether that actually turns the charging power off. Thankfully, I've found that my headset will still sit fine on the dock when it's just out of place enough that the pins aren't touching. This isn't ideal though, and goes against the snug aesthetic the charging stand is going for. Irritating beeping aside, I do think this charging stand is one of the better and more versatile ones available for the Quest 3. PrismXR has made something that's well designed and caters to a large cross-section of VR gamers who have lots of storage needs and headstraps already integrated into their setups. It's a shame that the charging isn't quicker, and there's definite friction with those indicating bleeps - which seem to be the most frequently reported issue in most customer reviews. Regardless, this is a charging stand I'll be keeping in my loadout, mainly thanks to its convenience of charging the headset along with its controllers, which can prove tricky otherwise. I integrated the PrismXR Carina D1 Charging Dock into my gaming setup for a number of weeks before this review was written. Since receiving the testing sample from PrismXR, it's been my main method of charging my VR headset and controllers. To put it to the test, I set a timer on how long it took to charge the headset in various scenarios: when it was at 0%, when it was at 50% going to 100%, and a full charge. I compared my experience to my time spent with other Quest 3 accessories. For more on how we test the latest gadgets, check out the GamesRadar+ hardware policy. Happy with flat screen games for now? Take a look at the best PC controllers, the best gaming PCs, and the best gaming monitors One of my earliest memories is playing SuperMario64 and wondering why the controller I held had three grips, but I only had two hands. Ever since I've been in love with video games and their technology. After graduating from Edinburgh Napier University with a degree in Journalism, I contributed to the Scottish Games Network and completed an Editorial Internship at Expert Reviews. Over the last decade, I’ve been managing my own YouTube channel about my love of games too. These days, I'm one of the resident hardware nerds at GamesRadar+, and I take the lead on our coverage of gaming PCs, VR, controllers, gaming chairs, and content creation gear. Now, I better stop myself here before I get talking about my favourite games like HUNT: Showdown, Dishonored, and Towerfall Ascension. You must confirm your public display name before commenting Please logout and then login again, you will then be prompted to enter your display name. GamesRadar+ is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036. Please login or signup to comment Please wait...
--------------------------------------------------

Title: Cathie Wood Is Buying Up Google Stock at Record Highs. Should You?
URL: https://www.barchart.com/story/news/36436820/cathie-wood-is-buying-up-google-stock-at-record-highs-should-you
Time Published: 2025-12-03T17:15:25Z
Description: Alphabet’s rally looks unstoppable, but chasing a stock near record highs could be a risky move.
--------------------------------------------------

Title: Michael Burry warns of a market crash worse than 2000, says brutal selloff is coming
URL: https://economictimes.indiatimes.com/news/international/us/michael-burry-warns-of-a-market-crash-worse-than-2000-says-brutal-selloff-is-coming/articleshow/125744858.cms
Time Published: 2025-12-03T17:05:04Z
Full Content:
Michael Burry warns the U.S. stock market could face a crash worse than 2000. He says AI and tech stock valuations are dangerously inflated. Over half of U.S. equities are in passive funds, leaving few active investors to stabilize the market. Nvidia, Palantir, and AI-heavy firms could see sharp sell-offs. Accounting tricks, like stretched depreciation on hardware, hide real risks. Burry has closed his hedge fund and taken bearish positions personally. Michael Burry warns stock market crash worse than 2000 dot‑com surge — AI valuations fuel risk (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. Explore More Stories Amazon warns over 300 million users of major Black Friday impersonation scams targeting personal data What is Canada’s new colour-coded alert system and how it will ensure public safety during extreme weather Canada launches new alert system for extreme weather; Colour-coded system marks shift to impact-based forecasting Canadian Olympic swimming champion Penny Oleksiak suspended for two years over anti-doping whereabouts failures Who is Colleen Jones? Two-time World champion curler and veteran Canadian broadcaster dies at 65 What exactly is the Canada Pension Plan? New CPP payments rolling out nationwide on November 26; Check all the payment dates of 2025-26 - Why is Quebec not part of CPP? Madeleine Poulin, Radio-Canada’s first female correspondent in Ottawa and Paris, dies at 87 Yoplait recalls 'Yop yogurt' drinks in Canada over plastic contamination fears under Class 1 category - Check out which flavor and best-before dates beverage are subject to recall CMA Awards: Vince Gill honored with prestigious Willie Nelson Lifetime Achievement Award at 59th CMA Awards in Tennessee MGK rocks Canadian fans with explosive Grey Cup halftime show; Are Megan Fox, MGK really working on their relationship post daughter’s birth? Roughriders end 12-year drought, beat Alouettes for 5th Grey Cup title Who is Dr Sanjeev Sirpal? Trouble mounts for New Brunswick doctor accused of sexual assault in hospitals as he faces additional charges; what do we know so far Russian humanoid robot 'AIDOL' shockingly faceplants during much-hyped public debut - WATCH ‘Jab Aap Cheekhte Hain....’: Jaya Bachchan swipes BJP in RS Bengal: PM maps 2026 strategy, Mamata drums up a show in Malda RS: Raghav Chaddha raises alarm over toxic water in Punjab Revanth Reddy’s ‘Hindu gods analogy’ sparks outrage Guwahati’s massive 6-lane Brahmaputra bridge nears completion Sanchar Saathi: Telecom Minister Scindia rejects snooping charge How did Op Sindoor impact Pakistan’s economy? Navy Chief Tripathi reveals EAM flags risks of mobility, citing migration, trafficking and terror Russia eyes bigger trade role with India, China ahead of Modi talks 'Sardar Patel stopped Nehru from using govt funds for…' Rajnath’s Big Claim ‘Jab Aap Cheekhte Hain....’: Jaya Bachchan swipes BJP in RS Bengal: PM maps 2026 strategy, Mamata drums up a show in Malda RS: Raghav Chaddha raises alarm over toxic water in Punjab Revanth Reddy’s ‘Hindu gods analogy’ sparks outrage Guwahati’s massive 6-lane Brahmaputra bridge nears completion Sanchar Saathi: Telecom Minister Scindia rejects snooping charge How did Op Sindoor impact Pakistan’s economy? Navy Chief Tripathi reveals EAM flags risks of mobility, citing migration, trafficking and terror Russia eyes bigger trade role with India, China ahead of Modi talks 'Sardar Patel stopped Nehru from using govt funds for…' Rajnath’s Big Claim Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Slideshow Top Prime Articles Top Definitions Most Searched IFSC Codes Top Story Listing Private Companies Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Stories you might be interested in
--------------------------------------------------

Title: Forget Palantir, another AI stock is up 180% in 2025
URL: https://www.thestreet.com/investing/stocks/forget-palantir-another-ai-stock-is-up-180-in-2025
Time Published: 2025-12-03T17:04:41Z
Description: While Palantir Technology has been one of the most talked-about AI winners this year, another AI player, Credo Technology, is growing faster and is up more...
--------------------------------------------------

Title: 7 SEO, Marketing, And Tech Predictions For 2026 via @sejournal, @Kevin_Indig
URL: https://www.searchenginejournal.com/seo-marketing-and-tech-predictions-for-2026/562373/
Time Published: 2025-12-03T14:30:56Z
Full Content:
Our fith annual State of SEO Report is here! It’s packed with valuable insights. Uncover the top factors currently affecting SEO, and what this means for your strategy. Wrap up the year with big savings! Lock in your 2026 SEJ sponsorships now and save up to 15%! Reserve your seat to see where your brand stands in the 2026 AI search race. Wrap up the year with big savings! Lock in your 2026 SEJ sponsorships now and save up to 15%! Wrap up the year with big savings! Lock in your 2026 SEJ sponsorships now and save up to 15%! Wrap up the year with big savings! Lock in your 2026 SEJ sponsorships now and save up to 15%! 2026 marks the beginning of the “Agentic Era,” where AI stops just consuming the web and starts writing to it. Previous predictions: 2018 | 2019 | 2020 | 2021 | 2022 | 2023 | 2024 This is my 8th time publishing annual predictions. As always, the goal is not to be right but to practice thinking. For example, in 2018, I predicted “Niche communities will be discovered as a great channel for growth” and “Email marketing will return” in 2019. It took another 6 years. That same year, I also wrote “Smart speakers will become a viable user-acquisition channel in 2018”. Well… Boost your skills with Growth Memo’s weekly expert insights. Subscribe for free! For the past three years, we have lived in the “generative era,” where AI could read the internet and summarize it for us. 2026 marks the beginning of the “agentic era,” where AI stops just consuming the web and starts writing to it – a shift from information retrieval to task execution. This isn’t just a feature update; it is a fundamental restructuring of the digital economy. The web is bifurcating into two distinct layers: A big question mark is advertising, where Google’s expansion of ads into AI Mode and ChatGPT showing ads to free users could alleviate pressure on CPCs, but AI Overviews (AIOs) could drive them up. 2026 could be a year of wild price swings where smart teams (your “holistic pods”) move budget daily between Google (high cost/high intent) and ChatGPT (low cost/discovery) to exploit the spread. It is not the strongest of the species that survives, nor the most intelligent; it is the one most adaptable to change. — Leon C. Megginso Prediction: I forecast an “Extinction Event” in Q3 2026 for the standalone AI visibility tracking category. Rather than a simple consolidation, our analysis shows the majority of pure-play tracking startups might fold or sell for parts as their 2025 funding runways expire simultaneously without the revenue growth to justify Series B rounds. Why: Context: Consequences: Prediction: It’ll be harder for spammers to influence AI visibility in 2026 with link spam, mass-generated AI content, and cloaking. By 2026, agents will likely use Multi-Source Corroboration to eliminate this asymmetry. Why: Context: Consequences: Prediction: AI Overviews (AIOs) scale to 75% of keywords for big sites. AI Mode rolls out to 10-20% of queries. Why: Context: Consequences: Prediction: By 2026, “identity spoofing” will become the single largest cybersecurity risk for public companies. We move from, Is this content real? to Is this source verified? Why: Context: Consequences: Prediction: OpenAI shifts to a hybrid pricing model in 2026: An “ad-supported free tier” and “credit-based pro tier.” Why: Context: Consequences: Prediction: Perplexity will be acquired in late 2026 for $25-$30 billion. After its user growth plateaus at ~50 million MAU, the “unit economics wall” forces a sale to a giant that needs its technology (real-time RAG), not its business model. Why: Context: Consequences: Prediction: Nvidia stock will correct by >20% in 2026 as its largest customers successfully shift 15-20% of their workloads to custom internal silicon. This causes a P/E compression from ~45x to ~30x as the market realizes Nvidia is no longer a monopoly, but a “competitor” in a commoditized market. (Not investment advice!) Why: Context: Consequence: Featured Image: Paulo Bobita/Search Engine Journal Kevin Indig is a Growth advisor who helps the world’s market leaders define and evolve their Organic Growth strategy. Once ... Join 75,000+ Digital Leaders. Learn how to connect search, AI, and PPC into one unstoppable strategy. Join 75,000+ Digital Leaders. Learn how to connect search, AI, and PPC into one unstoppable strategy. Join 75,000+ Digital Leaders. Learn how to connect search, AI, and PPC into one unstoppable strategy. In a world ruled by algorithms, SEJ brings timely, relevant information for SEOs, marketers, and entrepreneurs to optimize and grow their businesses -- and careers. Copyright © 2025 Search Engine Journal. All rights reserved. Published by Alpha Brand Media.
--------------------------------------------------

Title: How To Maximize Paid Ads Profitability With A Strategic Landing Page Audit
URL: https://www.searchenginejournal.com/how-to-maximize-paid-ads-profitability-with-a-strategic-landing-page-audit/560166/
Time Published: 2025-12-03T12:00:54Z
Full Content:
Our fith annual State of SEO Report is here! It’s packed with valuable insights. Uncover the top factors currently affecting SEO, and what this means for your strategy. Wrap up the year with big savings! Lock in your 2026 SEJ sponsorships now and save up to 15%! Reserve your seat to see where your brand stands in the 2026 AI search race. Wrap up the year with big savings! Lock in your 2026 SEJ sponsorships now and save up to 15%! Wrap up the year with big savings! Lock in your 2026 SEJ sponsorships now and save up to 15%! Wrap up the year with big savings! Lock in your 2026 SEJ sponsorships now and save up to 15%! Maximize ad profit. Stop wasting budget on weak pages. Learn the strategic landing page audit process to boost your conversion rates. Your campaigns are only as strong as the pages they lead to. You can have the most targeted ads, the sharpest copy, and a budget that makes your CFO nervous. But if your landing page doesn’t deliver on what the ad promised, you’re leaving money on the table and feeding poor signals back into your campaign algorithms. Landing pages are where intent meets experience. When they align, conversion rates increase. When they don’t, even high-quality traffic bounces, and your cost-per-acquisition (CPA) spirals upward. This post walks through the core elements of a high-performing landing page strategy. This strategy is one that not only converts visitors, but also strengthens your ad campaigns. Whether you’re running Google Ads or Meta campaigns, these landing page strategies apply. Most advertisers focus heavily on the ad itself: the creative, the targeting, the bid strategy. That makes sense. But the landing page is where the actual conversion happens. It’s the final step in the funnel, and it has a direct impact on campaign performance. Here’s why landing page audits should be a regular part of your paid media workflow: When more visitors convert, your cost per conversion drops. That gives you more room to scale or reinvest budget into other channels. Platforms like Google and Meta rely on conversion data to optimize your campaigns. If your landing page isn’t converting, the algorithm receives weak or misleading signals, which limits its ability to find high-intent users. Google rewards landing pages that are relevant, fast, and user-friendly. A higher quality score can lower your cost-per-click (CPC) and improve ad placement. In short, your landing page isn’t just a conversion tool. It’s a feedback loop that shapes how well your campaigns perform over time. The first rule of landing page optimization is simple: Match the message. If your ad promises “free shipping on running shoes,” your landing page should immediately confirm that offer. If the ad targets “B2B marketing automation tools,” the page should speak directly to that audience and use case. Message match builds trust. When a visitor clicks an ad and lands on a page that looks, feels, and sounds different, they bounce. Fast. Here’s how to ensure relevance: The fewer mental leaps a visitor has to make, the more likely they are to convert. Your call-to-action (CTA) is the most important element on the page. It’s where intent turns into action. But too many landing pages bury the CTA, use vague language, or overwhelm visitors with multiple competing actions. That creates friction and kills conversions. Here’s how to get CTAs right: Your CTA should feel like the natural next step, not a sales pitch. Zoho CRM’s website is an excellent example of a landing page leveraging these points: Specific offer: The header “Get started with your 15-day free trial” is highly specific, clarifying the duration and type of offer, addressing the vagueness of a simple “Get Started.” Visual contrast: The primary CTA button, “GET STARTED,” is a high-contrast, bright red that immediately draws the eye away from the surrounding white and blue elements. Action-oriented copy: While the button copy is “GET STARTED,” the text immediately below it clarifies the action as a free trial sign-up, maintaining clarity. Furthermore, the page limits distractions, focusing the user on the single action of signing up for the trial. This approach effectively guides the user toward the intended conversion. Visuals aren’t just decoration. They communicate value, build trust, and guide the visitor’s attention. The right images can make your offer feel tangible and desirable. The wrong ones create confusion or undermine credibility. Here’s what works: Strong visuals support your copy. They don’t compete with it. Superside’s landing page demonstrates using a portfolio of images to support the message that they can handle diverse creative needs for clients across different industries: Show the outcome: Instead of a single generic image, the page prominently features a collage of actual client deliverables (app interfaces, product packaging, social media graphics) for brands like Amazon, Reddit, and Zapier. This directly illustrates the quality and range of the service’s outcome. Communicate value and trust: By showing recognized brand logos and diverse project types, the imagery instantly builds credibility and reinforces the claim that they can “Scale your in-house creative team with top global talent.” Avoid clutter (in context): While it’s a collage, the consistent presentation style and the grouping of images in a grid are purposefully designed to communicate a broad portfolio quickly, which directly reinforces the main headline: “Your creative team’s creative team.” This strategy uses visuals to provide immediate, tangible proof of the service’s capability. Your landing page needs to answer one critical question: Why should I choose you over the competition? This is where you articulate your unique value proposition (UVP). It’s not just about listing features. It’s about showing how your product or service solves a specific problem better than the alternatives. Here’s how to communicate your UVP effectively: Your UVP should be immediately visible, ideally above the fold. If a visitor has to scroll to understand what you’re offering, you’ve already lost some of them. Social proof reduces risk. It shows visitors that other people (ideally, people like them) have chosen your product or service and been satisfied. But not all social proof is created equal. The key is to use a mix of formats and place them strategically throughout the page. Here are the most effective types of social proof to look for when you are doing a landing page audit: Short, specific quotes from real customers carry more weight than generic praise. Include the customer’s name, title, and company (if B2B) to increase credibility. “We increased conversions by 30%” is more compelling than “Great service!” Quantifiable outcomes resonate, especially with data-driven buyers. If well-known brands use your product, feature their logos. Recognition builds instant trust. Aggregate ratings (e.g., “4.8/5 stars from 1,200+ customers”) provide quick validation. Link to third-party review sites like G2, Trustpilot, or Capterra for added credibility. Security seals, industry certifications, and compliance badges (e.g., SOC 2, GDPR) that are visible on landing pages reassure visitors that their data is safe. Place social proof near your CTA. That’s where hesitation peaks, and reassurance matters most. The Reddit Ads landing page demonstrates the effective use of logos of recognizable clients or partners to build instant trust and social proof: Client credibility: At the bottom of the page, a prominent line on the landing page reads, “Trusted businesses across all industries and sizes use Reddit Ads to meet their goals.” This statement is immediately backed up by a scrolling horizontal display of recognizable brand logos, including Mars, GameStop, Capital One, and Maybelline. Instant trust: For a potential advertiser, seeing global, established brands using the platform reduces the perceived risk of signing up. If major companies trust Reddit Ads with their budget, a new user can be reassured the platform is legitimate and effective. Strategic placement: The logo section is placed below the main registration form and the tool to explore audience, providing reinforcement just before a user might scroll away or hesitate. It offers a final, compelling piece of proof that supports the core message of reaching a “niche audience.” This visual list of successful clients serves as powerful validation for the service. A beautiful landing page means anything if it doesn’t load quickly or breaks on mobile devices. Technical performance directly impacts conversion rates and campaign quality scores. Google prioritizes fast, mobile-friendly pages, and visitors abandon slow-loading sites within seconds, noting that 53% of visits are likely to be abandoned if pages take longer than three seconds to load. Here’s what to audit: Technical problems aren’t just annoying. They cost you conversions and damage your campaign performance. Where you place your CTA matters just as much as what it says. Most landing pages include a primary CTA above the fold, and that’s a really good start. But high-converting pages use multiple CTAs placed at natural decision points throughout the page. Here’s a strategic approach: Each CTA should feel contextual, not pushy. It should align with where the visitor is in their journey down the page. Your landing page isn’t just a conversion tool. It’s a data generator. Every click, scroll, and form submission sends signals back to your ad platform. These signals teach the algorithm which audiences convert, which creatives work, and how to allocate budget more efficiently. When your landing page converts well, those signals are strong and accurate. The algorithm learns faster and optimizes better. When your landing page underperforms, the data becomes noisy. The algorithm struggles to find patterns, and your campaigns stagnate. This is why landing page audits are essential. A small improvement in conversion rate doesn’t just boost revenue. It improves the quality of data feeding back into your campaigns, creating a compounding effect over time. Start by identifying your lowest-performing landing pages. Run A/B tests on headlines, CTAs, and imagery. Measure the impact not just on conversions, but on downstream metrics like CPA, return on ad spend (ROAS), and customer lifetime value (LTV). The better your landing pages perform, the smarter your campaigns become. More Resources: Featured Image: one photo/Shutterstock Sarah Stemen is a paid search marketer with 17+ years of experience helping businesses drive real results from Google Ads. ... Join 75,000+ Digital Leaders. Learn how to connect search, AI, and PPC into one unstoppable strategy. Join 75,000+ Digital Leaders. Learn how to connect search, AI, and PPC into one unstoppable strategy. Join 75,000+ Digital Leaders. Learn how to connect search, AI, and PPC into one unstoppable strategy. In a world ruled by algorithms, SEJ brings timely, relevant information for SEOs, marketers, and entrepreneurs to optimize and grow their businesses -- and careers. Copyright © 2025 Search Engine Journal. All rights reserved. Published by Alpha Brand Media.
--------------------------------------------------

Title: META’s New SAM 3 AI Model Drives Analyst Optimism and a $900 Price Target
URL: https://finance.yahoo.com/news/meta-sam-3-ai-model-101607631.html
Time Published: 2025-12-03T10:16:07Z
Description: Meta Platforms, Inc. (NASDAQ:META) is one of the Buzzing AI Stocks on Wall Street. On November 24, Citizens reiterated its Market Outperform rating on the...
--------------------------------------------------

Title: Bitget Stock Futures Break Through $10 Billion as Global Traders Rush Into Tokenized Equities
URL: https://financialpost.com/globe-newswire/bitget-stock-futures-break-through-10-billion-as-global-traders-rush-into-tokenized-equities
Time Published: 2025-12-03T10:09:38Z
Description: VICTORIA, Seychelles, Dec. 03, 2025 (GLOBE NEWSWIRE) — Bitget, the world’s largest Universal Exchange (UEX), today announced that its US stock futures have surpassed $10 billion in cumulative trading volume. The milestone comes just two weeks after crossing t…
--------------------------------------------------

Title: Bitget Stock Futures Break Through $10 Billion as Global Traders Rush Into Tokenized Equities
URL: https://www.globenewswire.com/news-release/2025/12/03/3198658/0/en/Bitget-Stock-Futures-Break-Through-10-Billion-as-Global-Traders-Rush-Into-Tokenized-Equities.html
Time Published: 2025-12-03T10:08:00Z
Full Content:
December 03, 2025 05:08 ET | Source: Bitget Limited Bitget Limited Seychelles Seychelles VICTORIA, Seychelles, Dec. 03, 2025 (GLOBE NEWSWIRE) -- Bitget, the world’s largest Universal Exchange (UEX), today announced that its US stock futures have surpassed $10 billion in cumulative trading volume. The milestone comes just two weeks after crossing the $5 billion mark, highlighting extraordinary market momentum and accelerating user demand for tokenized stock futures. The rapid climb reflects a perfect intersection of macro tailwinds and product innovation. As US equity markets continue their record-breaking run, traders have increasingly turned to Bitget’s stock futures to express directional views, hedge exposure, and participate in global equity movements with crypto-native execution. Among all pairs, the most actively traded contracts include Tesla (TSLA) leading the charge with $2.72 billion, Meta (META) at $2.14 billion and Strategy (MSTR) with $1.45 billion, showcasing strong interest in technology and crypto. Bitget introduced USDT-margined perpetual futures tied to more than 30 leading US stocks, offering up to 25x leverage and a highly competitive fee rate of 0.0065%. The product line has quickly become one of the fastest-growing components of the Bitget futures suite, appealing to retail and institutional traders seeking seamless access to both traditional and crypto markets under a unified platform. To support this surge in adoption and lower the barriers for new entrants, Bitget is running a limited-time 90% trading fee reduction campaign across all stock futures pairs. The promotion, which runs until January 31, allows traders to explore the expanding universe of tokenized stock futures with ultra-low fees, aligning with the UEX vision of inclusive and efficient global access. “Seeing traders jump into stock futures this quickly has been incredible,” said Gracy Chen, CEO of Bitget. “It’s clear users want a simple way to tap into both crypto and traditional markets, and this milestone shows how fast that shift is happening.” The milestone further reinforces Bitget’s UEX vision, bridging traditional markets with digital assets through a single, unified account. By blending tokenized stock products, crypto derivatives, and AI-powered insights, Bitget continues to expand access to global investment opportunities while enhancing transparency, flexibility, and cost efficiency. About Bitget Established in 2018, Bitget is the world's largest Universal Exchange (UEX), serving over 120 million users with access to millions of crypto tokens, tokenized stocks, ETFs, and other real-world assets, while offering real-time access to Bitcoin price, Ethereum price, XRP price, and other cryptocurrency prices, all on a single platform. The ecosystem is committed to helping users trade smarter with its AI-powered trading tools, interoperability across tokens on Bitcoin, Ethereum, Solana, and BNB Chain, and wider access to real-world assets. On the decentralized side, Bitget Wallet is an everyday finance app built to make crypto simple, secure, and part of everyday finance. Serving over 80 million users, it bridges blockchain rails with real-world finance, offering an all-in-one platform for on- and off-ramping, trading, earning, and paying seamlessly. Bitget is driving crypto adoption through strategic partnerships, such as its role as the Official Crypto Partner of the World's Top Football League, LALIGA, in EASTERN, SEA and LATAM markets. Aligned with its global impact strategy, Bitget has joined hands with UNICEF to support blockchain education for 1.1 million people by 2027. In the world of motorsports, Bitget is the exclusive cryptocurrency exchange partner of MotoGP™, one of the world’s most thrilling championships. For more information, visit: Website | Twitter | Telegram | LinkedIn | Discord | Bitget Wallet For media inquiries, please contact: media@bitget.com Risk Warning: Digital asset prices are subject to fluctuation and may experience significant volatility. Investors are advised to only allocate funds they can afford to lose. The value of any investment may be impacted, and there is a possibility that financial objectives may not be met, nor the principal investment recovered. Independent financial advice should always be sought, and personal financial experience and standing carefully considered. Past performance is not a reliable indicator of future results. Bitget accepts no liability for any potential losses incurred. Nothing contained herein should be construed as financial advice. For further information, please refer to our Terms of Use. A photo accompanying this announcement is available at https://www.globenewswire.com/NewsRoom/AttachmentNg/d5337e3f-16c7-4d0a-96e0-236b5cfd9070 Bitget enhances GetAgent with smarter answers, expanded quotas, and a cleaner interface to make advanced AI trading more accessible. VICTORIA, Seychelles, Dec. 04, 2025 (GLOBE NEWSWIRE) -- Bitget, Universal Exchange (UEX) terbesar di dunia, telah melancarkan video kedua dalam siri kolaborasi LALIGA, kali ini menampilkan juara...
--------------------------------------------------

Title: DeFi markets are finally pricing fundamentals — but only after months, new study shows
URL: https://www.dlnews.com/articles/defi/defi-markets-are-finally-pricing-fundamentals-new-study-shows/
Time Published: 2025-12-03T08:44:58Z
Full Content:
About us Copy link A version of this article appeared in our The Decentralised newsletter on December 2. Sign up here. Hey all, Liam here. Decentralised finance has a reputation for pulling projects’ valuations out of thin air, but new research suggests those values aren’t just a fugazi. Greenfield, a Berlin-based venture firm, argues that three key metrics provide far more explanatory power for why valuations move in any direction than any other variable. By closely tracking the fees a protocol generates, its total value locked, and its revenue, Greenfield concludes that investors can typically make better bets on which projects will succeed. What’s more, a model that uses these indicators typically outperforms analytical models that track Bitcoin and Ethereum performance, as well as models that incorporate social sentiment, such as followers on X. This thesis holds at three and six-month horizons. Most importantly, however, it shows that the so-called fundamentals narrative that’s been kicking around X this year is much more than a meme. “The longer you give the market to play out, the more you actually see that there is a divergent performance based on fundamentals versus just everything being correlated to broader market moves,” Felix Machart, a partner at Greenfield and the paper’s co-author, told DL News. It’s not a silver bullet, of course. Investors also need to be aware of temporary spikes in activity related to token incentives, as well as a product’s defensibility amid mounting competition. And fickle social sentiment can create a noisy investing landscape, at least in the short term. Over one month, for example, fundamental measures offer less explanatory power for valuations than the model that tracks the price of Bitcoin and Ether alone, according to Greenfield’s analysis. The analysts also highlight the importance of a token’s volume on decentralised exchanges, active users, daily transactions, and a protocol’s treasury value as additional metrics, albeit with less explanatory power. For those outside of the crypto space, the analysis seems pretty intuitive. A company’s stock will typically rise if it experiences higher revenues quarter after quarter. So, why shouldn’t DeFi protocols? For one, protocols aren’t companies. Their decentralised nature and how they create investor value can differ. Machart says, for instance, that one can consider token buybacks and yield from staking as revenue, since value accrues to token holders regardless. DeFi protocols are also far younger than traditional capital markets. Greenfield’s analysis, spanning 2021 to 2025, isn’t the final word on the matter, either. Far from it. The report ends with additional research questions to expand the data set used, incorporate even more onchain analytics, and extend the timeline for measuring the thesis. Still, the analysis is meaningful — especially as institutional investors begin tiptoeing into the sector. “It just proves that you can invest based on an expectation of future fundamentals playing out,” Machart said. “Market outcomes are not just random and purely hype driven.” “We actually can see trends that show the market is maturing.” Liam Kelly is DL News’ Berlin-based DeFi correspondent. Have a tip? Get in touch at liam@dlnews.com.
--------------------------------------------------

Title: Criteo CEO Michael Komasinski on agentic commerce, experiments with LLMs, and M&A rumors
URL: http://digiday.com/media-buying/criteo-ceo-michael-komasinski-on-agentic-commerce-experiments-with-llms-and-ma-rumors/
Time Published: 2025-12-03T05:01:00Z
Full Content:
Save 50% on a 3-month Digiday+ membership. Ends Dec 12. In early 2025, Criteo entered a new chapter, with its current CEO, Michael Komasinski, taking the reins as the fourth chief executive of the company in its 20-year history — a sign that investors expect bold strategic recalibration for the Nasdaq-listed outfit. That transition comes amid a turbulent backdrop: over the last several years, its share price and market cap have fluctuated amid speculation over “signal-loss,” albeit Google’s U-turn on its earlier plans for Chrome augured well in Komasinski’s time in office, not to mention the disruptive emergence of AI. In response, Criteo has attempted to rebrand itself from a heavy-hitting retargeting outfit to a commerce media platform that’s now experimenting with LLMs, publishers, and retailers alike to hone monetization in the AI-first era. Komasinski sat down with Digiday to discuss these efforts on the sidelines of a recent press event, explaining his strategy as he approaches his one-year anniversary in office. The conversation below has been edited for brevity and clarity. I think there are two tracks in terms of how it changes things. The first is the self-service… we will launch Commerce Go as a self-service tool by the end of Q1 next year. That means an advertiser can go online, put in their credit card information, and have campaigns up and running in 10 minutes. It is competitive with some of the self-service tools from Meta with Advantage+ or from Google with Performance Max –the differentiation versus those platforms is that it’s cross-channel. Criteo has always had a healthy amount of managed service that was required to drive the platform, and I see that changing quite a bit over the next couple of years. The second track around agentic with retail, that really is an extension of what we do today — the ability to power sponsored ads or improved relevancy for a retailer — that’s just an extension of capabilities that we serve on product detail pages currently. Nothing to disclose on revenue models or forecasts yet, but it is exciting. One of the reasons it is exciting is that it leverages existing infrastructure, so we don’t have to reinvent the way crawling monetization is resolved. It’s using the RTB pipes that the BidSwitch is built on, and for mid-to-longtail publishers, which is a segment that’s like really underserved in the LLM free-for-all that’s going on. So, we’re encouraged by the pilot with RTB, and looking to find other publishing partners to do further testing with, then we’ll start to refine that monetization model, and hopefully that will turn out to be a viable product for mid-to-longtail publishers and us. When you’re a publicly traded company, right, you are always looking for ways to maximize value for shareholders. But no, we’re not in a process of any kind today; the redomiciling of the parent-level entity is really designed to improve our ability to attract passive capital to our shares and to improve trading liquidity. It doesn’t really change the operations of the business. Our tech team is still based in Paris, as are many of our back office functions, and we don’t see any changes to that. So it should help the stock become more easily included in passive indices like ETFs, which should be good for our shareholders. I don’t have anything firm to say on that, other than, again, as a publicly traded company, you always have a responsibility to look at your portfolio of assets and to make sure that everything’s a good fit for the strategy that you’re pursuing. As we continue to make progress with the whole set, commerce media is the north star, and all of the different segments are laddering up to that pretty well, but it is a responsible thing to always be looking at your portfolio. We are excited about it, but I think the reason we don’t talk more about it is that the test isn’t complete yet. There’s testing that’s happening over the course of this month, so we don’t want to get ahead of that, although I’m pretty confident that the test results will be positive. When you’re dealing with a third party that you’re dependent on, it’s not about what you think; it’s about what they want to do, but I think the results show an uplift in relevancy. It’s up to them as to what they want to do with that. Is that something they want to pay for, or is that something that shapes how they think about native ad units powered by intelligence? [That’s up to them]. Amid fierce DSP competition, media agencies are finding The Trade Desk’s reps in a negotiating mood. As tensions over TID and GPID peak, Tech Lab is convening a council to hash out commercial ground rules. The staffing consultancy moved to acquire performance agency Markacy and creative shop Futureman, adding them to tech platform-turned-agency SketchDeck Get access to tools and analysis to stay ahead of the trends transforming media and marketing Visit your account page to make changes and renew. Get Digiday's top stories every morning in your email inbox. Follow @Digiday for the latest news, insider access to events and more.
--------------------------------------------------

Title: Trump DOJ Sides With Roundup Manufacturer Over Cancer Victims in Supreme Court Case
URL: https://www.commondreams.org/news/trump-backs-bayer-monsanto-roundup
Time Published: 2025-12-02T21:46:16Z
Full Content:
To donate by check, phone, or other method, see our More Ways to Give page. Daily news & progressive opinion—funded by the people, not the corporations—delivered straight to your inbox. Bottles of Roundup weed and grass killer are stacked at a Costco Wholesale store on March 11, 2025, in San Diego, California. An attorney at Food & Water Watch said the DOJ sent a "clear message... to sick Americans harmed by toxic pesticides: Trump has Bayer’s back, not theirs." The Trump administration is pushing for the US Supreme Court to shield the manufacturer of Roundup from thousands of state lawsuits alleging that its widely used herbicide product causes cancer. On Monday, US Solicitor General D. John Sauer recommended that the high court agree to hear a challenge to a Missouri jury's verdict in 2023 that awarded $1.25 million to a man named John Durnell, who claimed that the product caused him to develop non-Hodgkin lymphoma. Bayer, the agribusiness giant that purchased the manufacturer of Roundup, the agribusiness giant Monsanto, in 2018, immediately challenged the verdict. In 2015, the World Health Organization's International Agency for Research on Cancer (IARC) classified glyphosate, the active ingredient in Roundup, as "probably carcinogenic to humans" based on "limited evidence." That evidence became less limited in 2019, when a prominent meta-analysis by a team of environmental health researchers found that people exposed to glyphosate at the highest levels had a 41% higher risk of developing non-Hodgkin lymphoma than those who weren't. There are nearly 4,500 Roundup claims currently pending in federal court, and at least 24 cases have gone to trial since October 2023. They make up just a fraction of the more than 170,000 claims filed. According to Bloomberg, Bayer has already been forced to pay out more than $10 billion in verdicts and settlements over the product, which has caused a massive drain on the company's stock price. In what it said was an effort to “manage litigation risk and not because of any safety concerns,” Bayer removed glyphosate-based herbicides from the residential market in 2023, switching to formulas that “rely on alternative active ingredients.” That didn't stop the lawsuits from coming. Durnell's victory was the first successful case brought against Bayer outside California, the only state that labels the product as carcinogenic. That in Missouri opened the floodgates in other states, and plaintiffs subsequently won sizable payouts in Georgia and Pennsylvania. But now the Trump administration is trying to help the company skirt further accountability. Sauer, who is tasked with arguing for the government in nearly every Supreme Court case, filed a 24-page brief stating that there is a lack of clarity on whether states have the authority to determine whether Bayer and Monsanto violated the law by failing to warn customers about potential cancer risks from Roundup. Bayer argues that these cases are preempted by the Federal Insecticide, Fungicide, and Rodenticide Act (FIFRA), which forbids states from enacting labeling requirements more stringent than those recommended by the federal government. Sauer agreed with Bayer, stating in the brief that the US Environmental Protection Agency "has repeatedly determined that glyphosate is not likely to be carcinogenic in humans, and the agency has repeatedly approved Roundup labels that did not contain cancer warnings." In 2016 and again in 2020, the EPA indeed classified glyphosate as "not likely to be carcinogenic to humans" following agency assessments. However, in 2022, the 9th US Circuit Court of Appeals voided this assessment, finding that the agency applied “inconsistent reasoning” in its review of the science. Among the justifications for the ruling were that the EPA relied heavily on unpublished, non-peer-reviewed studies submitted to regulators by Monsanto and other companies that manufacture glyphosate. The agency also largely disregarded findings from animal studies included by the IARC, which showed a strong link between glyphosate and cancer. "The World Health Organization has recognized glyphosate as a probable carcinogen while the EPA continues to twist itself into pretzels to come to the opposite conclusion," Lori Ann Burd, a staff attorney and director of the Center for Biological Diversity's environmental health program, told Common Dreams. Notably, Health and Human Services Secretary Robert F. Kennedy Jr. built his national profile campaigning against the dangers of pesticides and railing against regulatory capture by big business. Kennedy served as an attorney for Dewayne Johnson, the first plaintiff to win damages against Monsanto in 2018, where a jury determined that Roundup had contributed to his cancer. "If my life were a Superman comic, Monsanto would be my Lex Luthor," Kennedy said in a 2020 Facebook post. "I've seen this company as the enemy of every admirable American value." During Kennedy's 2024 presidential run, he pledged to "ban the worst agricultural chemicals already banned in other countries." But after he was sworn in as President Donald Trump's HHS Secretary, he began to sing a different tune. As Investigate Midwest noted, his "Make America Healthy Again" commission's introductory report made no mention of glyphosate. Meanwhile, he reassured the pesticide industry that it had nothing to worry about: "There’s a million farmers who rely on glyphosate. 100% of corn in this country relies on glyphosate. We are not going to do anything to jeopardize that business model," he said during a Senate Appropriations Committee hearing. The Trump EPA has deregulated toxic chemicals across the board over the past year. It rolled back protections against per- and polyfluoroalkyl substances (PFAS), often referred to as "forever chemicals," in drinking water, which have many documented health risks. It has also declined to ban the widely used insecticide chlorpyrifos, which has been linked to neurodevelopmental disorders in children. Elizabeth Kucinich, the former director of policy at the Center for Food Safety, described the US Department of Justice's effort to shield Bayer as another "betrayal of MAHA health promises." Her husband, the two-time Democratic presidential candidate Dennis Kucinich, worked as the campaign manager for RFK Jr.'s 2024 presidential bid. “This is regulatory capture, not public protection,” she said. “This action shields chemical manufacturers from accountability by elevating a captured federal regulatory process over the lived harm of real people. That is anti-life, and it is exactly what millions of MAHA voters believed they were voting against.” Food & Water Watch staff attorney Dani Replogle said the DOJ filing "encourages the Supreme Court to slam judiciary doors in the faces of cancer patients across the country." "No political posturing can undo the clear message this brief sends to sick Americans harmed by toxic pesticides," she continued. "Trump has Bayer’s back, not theirs." The Trump administration is pushing for the US Supreme Court to shield the manufacturer of Roundup from thousands of state lawsuits alleging that its widely used herbicide product causes cancer. On Monday, US Solicitor General D. John Sauer recommended that the high court agree to hear a challenge to a Missouri jury's verdict in 2023 that awarded $1.25 million to a man named John Durnell, who claimed that the product caused him to develop non-Hodgkin lymphoma. Bayer, the agribusiness giant that purchased the manufacturer of Roundup, the agribusiness giant Monsanto, in 2018, immediately challenged the verdict. In 2015, the World Health Organization's International Agency for Research on Cancer (IARC) classified glyphosate, the active ingredient in Roundup, as "probably carcinogenic to humans" based on "limited evidence." That evidence became less limited in 2019, when a prominent meta-analysis by a team of environmental health researchers found that people exposed to glyphosate at the highest levels had a 41% higher risk of developing non-Hodgkin lymphoma than those who weren't. There are nearly 4,500 Roundup claims currently pending in federal court, and at least 24 cases have gone to trial since October 2023. They make up just a fraction of the more than 170,000 claims filed. According to Bloomberg, Bayer has already been forced to pay out more than $10 billion in verdicts and settlements over the product, which has caused a massive drain on the company's stock price. In what it said was an effort to “manage litigation risk and not because of any safety concerns,” Bayer removed glyphosate-based herbicides from the residential market in 2023, switching to formulas that “rely on alternative active ingredients.” That didn't stop the lawsuits from coming. Durnell's victory was the first successful case brought against Bayer outside California, the only state that labels the product as carcinogenic. That in Missouri opened the floodgates in other states, and plaintiffs subsequently won sizable payouts in Georgia and Pennsylvania. But now the Trump administration is trying to help the company skirt further accountability. Sauer, who is tasked with arguing for the government in nearly every Supreme Court case, filed a 24-page brief stating that there is a lack of clarity on whether states have the authority to determine whether Bayer and Monsanto violated the law by failing to warn customers about potential cancer risks from Roundup. Bayer argues that these cases are preempted by the Federal Insecticide, Fungicide, and Rodenticide Act (FIFRA), which forbids states from enacting labeling requirements more stringent than those recommended by the federal government. Sauer agreed with Bayer, stating in the brief that the US Environmental Protection Agency "has repeatedly determined that glyphosate is not likely to be carcinogenic in humans, and the agency has repeatedly approved Roundup labels that did not contain cancer warnings." In 2016 and again in 2020, the EPA indeed classified glyphosate as "not likely to be carcinogenic to humans" following agency assessments. However, in 2022, the 9th US Circuit Court of Appeals voided this assessment, finding that the agency applied “inconsistent reasoning” in its review of the science. Among the justifications for the ruling were that the EPA relied heavily on unpublished, non-peer-reviewed studies submitted to regulators by Monsanto and other companies that manufacture glyphosate. The agency also largely disregarded findings from animal studies included by the IARC, which showed a strong link between glyphosate and cancer. "The World Health Organization has recognized glyphosate as a probable carcinogen while the EPA continues to twist itself into pretzels to come to the opposite conclusion," Lori Ann Burd, a staff attorney and director of the Center for Biological Diversity's environmental health program, told Common Dreams. Notably, Health and Human Services Secretary Robert F. Kennedy Jr. built his national profile campaigning against the dangers of pesticides and railing against regulatory capture by big business. Kennedy served as an attorney for Dewayne Johnson, the first plaintiff to win damages against Monsanto in 2018, where a jury determined that Roundup had contributed to his cancer. "If my life were a Superman comic, Monsanto would be my Lex Luthor," Kennedy said in a 2020 Facebook post. "I've seen this company as the enemy of every admirable American value." During Kennedy's 2024 presidential run, he pledged to "ban the worst agricultural chemicals already banned in other countries." But after he was sworn in as President Donald Trump's HHS Secretary, he began to sing a different tune. As Investigate Midwest noted, his "Make America Healthy Again" commission's introductory report made no mention of glyphosate. Meanwhile, he reassured the pesticide industry that it had nothing to worry about: "There’s a million farmers who rely on glyphosate. 100% of corn in this country relies on glyphosate. We are not going to do anything to jeopardize that business model," he said during a Senate Appropriations Committee hearing. The Trump EPA has deregulated toxic chemicals across the board over the past year. It rolled back protections against per- and polyfluoroalkyl substances (PFAS), often referred to as "forever chemicals," in drinking water, which have many documented health risks. It has also declined to ban the widely used insecticide chlorpyrifos, which has been linked to neurodevelopmental disorders in children. Elizabeth Kucinich, the former director of policy at the Center for Food Safety, described the US Department of Justice's effort to shield Bayer as another "betrayal of MAHA health promises." Her husband, the two-time Democratic presidential candidate Dennis Kucinich, worked as the campaign manager for RFK Jr.'s 2024 presidential bid. “This is regulatory capture, not public protection,” she said. “This action shields chemical manufacturers from accountability by elevating a captured federal regulatory process over the lived harm of real people. That is anti-life, and it is exactly what millions of MAHA voters believed they were voting against.” Food & Water Watch staff attorney Dani Replogle said the DOJ filing "encourages the Supreme Court to slam judiciary doors in the faces of cancer patients across the country." "No political posturing can undo the clear message this brief sends to sick Americans harmed by toxic pesticides," she continued. "Trump has Bayer’s back, not theirs." The Trump administration is pushing for the US Supreme Court to shield the manufacturer of Roundup from thousands of state lawsuits alleging that its widely used herbicide product causes cancer. On Monday, US Solicitor General D. John Sauer recommended that the high court agree to hear a challenge to a Missouri jury's verdict in 2023 that awarded $1.25 million to a man named John Durnell, who claimed that the product caused him to develop non-Hodgkin lymphoma. Bayer, the agribusiness giant that purchased the manufacturer of Roundup, the agribusiness giant Monsanto, in 2018, immediately challenged the verdict. In 2015, the World Health Organization's International Agency for Research on Cancer (IARC) classified glyphosate, the active ingredient in Roundup, as "probably carcinogenic to humans" based on "limited evidence." That evidence became less limited in 2019, when a prominent meta-analysis by a team of environmental health researchers found that people exposed to glyphosate at the highest levels had a 41% higher risk of developing non-Hodgkin lymphoma than those who weren't. There are nearly 4,500 Roundup claims currently pending in federal court, and at least 24 cases have gone to trial since October 2023. They make up just a fraction of the more than 170,000 claims filed. According to Bloomberg, Bayer has already been forced to pay out more than $10 billion in verdicts and settlements over the product, which has caused a massive drain on the company's stock price. In what it said was an effort to “manage litigation risk and not because of any safety concerns,” Bayer removed glyphosate-based herbicides from the residential market in 2023, switching to formulas that “rely on alternative active ingredients.” That didn't stop the lawsuits from coming. Durnell's victory was the first successful case brought against Bayer outside California, the only state that labels the product as carcinogenic. That in Missouri opened the floodgates in other states, and plaintiffs subsequently won sizable payouts in Georgia and Pennsylvania. But now the Trump administration is trying to help the company skirt further accountability. Sauer, who is tasked with arguing for the government in nearly every Supreme Court case, filed a 24-page brief stating that there is a lack of clarity on whether states have the authority to determine whether Bayer and Monsanto violated the law by failing to warn customers about potential cancer risks from Roundup. Bayer argues that these cases are preempted by the Federal Insecticide, Fungicide, and Rodenticide Act (FIFRA), which forbids states from enacting labeling requirements more stringent than those recommended by the federal government. Sauer agreed with Bayer, stating in the brief that the US Environmental Protection Agency "has repeatedly determined that glyphosate is not likely to be carcinogenic in humans, and the agency has repeatedly approved Roundup labels that did not contain cancer warnings." In 2016 and again in 2020, the EPA indeed classified glyphosate as "not likely to be carcinogenic to humans" following agency assessments. However, in 2022, the 9th US Circuit Court of Appeals voided this assessment, finding that the agency applied “inconsistent reasoning” in its review of the science. Among the justifications for the ruling were that the EPA relied heavily on unpublished, non-peer-reviewed studies submitted to regulators by Monsanto and other companies that manufacture glyphosate. The agency also largely disregarded findings from animal studies included by the IARC, which showed a strong link between glyphosate and cancer. "The World Health Organization has recognized glyphosate as a probable carcinogen while the EPA continues to twist itself into pretzels to come to the opposite conclusion," Lori Ann Burd, a staff attorney and director of the Center for Biological Diversity's environmental health program, told Common Dreams. Notably, Health and Human Services Secretary Robert F. Kennedy Jr. built his national profile campaigning against the dangers of pesticides and railing against regulatory capture by big business. Kennedy served as an attorney for Dewayne Johnson, the first plaintiff to win damages against Monsanto in 2018, where a jury determined that Roundup had contributed to his cancer. "If my life were a Superman comic, Monsanto would be my Lex Luthor," Kennedy said in a 2020 Facebook post. "I've seen this company as the enemy of every admirable American value." During Kennedy's 2024 presidential run, he pledged to "ban the worst agricultural chemicals already banned in other countries." But after he was sworn in as President Donald Trump's HHS Secretary, he began to sing a different tune. As Investigate Midwest noted, his "Make America Healthy Again" commission's introductory report made no mention of glyphosate. Meanwhile, he reassured the pesticide industry that it had nothing to worry about: "There’s a million farmers who rely on glyphosate. 100% of corn in this country relies on glyphosate. We are not going to do anything to jeopardize that business model," he said during a Senate Appropriations Committee hearing. The Trump EPA has deregulated toxic chemicals across the board over the past year. It rolled back protections against per- and polyfluoroalkyl substances (PFAS), often referred to as "forever chemicals," in drinking water, which have many documented health risks. It has also declined to ban the widely used insecticide chlorpyrifos, which has been linked to neurodevelopmental disorders in children. Elizabeth Kucinich, the former director of policy at the Center for Food Safety, described the US Department of Justice's effort to shield Bayer as another "betrayal of MAHA health promises." Her husband, the two-time Democratic presidential candidate Dennis Kucinich, worked as the campaign manager for RFK Jr.'s 2024 presidential bid. “This is regulatory capture, not public protection,” she said. “This action shields chemical manufacturers from accountability by elevating a captured federal regulatory process over the lived harm of real people. That is anti-life, and it is exactly what millions of MAHA voters believed they were voting against.” Food & Water Watch staff attorney Dani Replogle said the DOJ filing "encourages the Supreme Court to slam judiciary doors in the faces of cancer patients across the country." "No political posturing can undo the clear message this brief sends to sick Americans harmed by toxic pesticides," she continued. "Trump has Bayer’s back, not theirs."
--------------------------------------------------

Title: How Micron Stock Could Be an Even Bigger Winner Than GOOGL from a Google-Meta Deal
URL: https://www.barchart.com/story/news/36416399/how-micron-stock-could-be-an-even-bigger-winner-than-googl-from-a-google-meta-deal
Time Published: 2025-12-02T19:23:02Z
Description: Micron's shares look poised to boom over the longer term as the AI revolution continues.
--------------------------------------------------

Title: Dan Ives Is Betting Big on CoreWeave Stock as an AI Winner. Should You Buy CRWV Too?
URL: https://www.barchart.com/story/news/36414423/dan-ives-is-betting-big-on-coreweave-stock-as-an-ai-winner-should-you-buy-crwv-too
Time Published: 2025-12-02T17:24:08Z
Description: CoreWeave’s record backlog, accelerating hyperscaler demand, and rising analyst optimism keep the stock in focus as a top-tier AI infrastructure play heading...
--------------------------------------------------

Title: NVIDIA’s $2B Power Play: Securing the Future of Chip Design
URL: https://www.marketbeat.com/originals/nvidias-2b-power-play-securing-the-future-of-chip-design/?utm_source=yahoofinance&amp;utm_medium=yahoofinance
Time Published: 2025-12-02T17:12:00Z
Description: NVIDIA secures the future of chip design by investing in Synopsys and moving critical engineering simulations to its own powerful accelerated platform.
--------------------------------------------------

Title: Govt's 'Big Brother' app under fire; Meesho IPO faces investor heat
URL: https://economictimes.indiatimes.com/tech/newsletters/tech-top-5/govts-big-brother-app-under-fire-meesho-ipo-faces-investor-heat/articleshow/125719822.cms
Time Published: 2025-12-02T13:22:27Z
Full Content:
Want this newsletter delivered to your inbox? Updated On Dec 02, 2025, 07:53 PM IST Want this newsletter delivered to your inbox? Thank you for subscribing to Daily Top 5We'll soon meet in your inbox. Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Definitions Top Commodities Top Prime Articles Top Slideshow Top Story Listing Top Market Pages Latest News Follow us on:
--------------------------------------------------

Title: Centre's 'Big Brother' app faces pushback; Wakefit fixes IPO band
URL: https://economictimes.indiatimes.com/tech/newsletters/tech-top-5/centres-big-brother-app-faces-pushback-wakefit-fixes-ipo-band/articleshow/125719822.cms
Time Published: 2025-12-02T13:22:27Z
Full Content:
Want this newsletter delivered to your inbox? Updated On Dec 02, 2025, 07:53 PM IST Want this newsletter delivered to your inbox? Thank you for subscribing to Daily Top 5We'll soon meet in your inbox. Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Definitions Top Commodities Top Prime Articles Top Slideshow Top Story Listing Top Market Pages Latest News Follow us on:
--------------------------------------------------

Title: Credo Technologies Posted a Blowout Quarter—Here's What's Next
URL: https://www.marketbeat.com/originals/credo-technologies-ai-bubble-is-far-from-bursting/?utm_source=yahoofinance&amp;utm_medium=yahoofinance
Time Published: 2025-12-02T12:39:00Z
Description: Credo Technologies is a critical cog in the AI ecosystem, and its business reflects it. Analysts are lifting targets and leading this market higher.
--------------------------------------------------

Title: This Under-$100 Growth Stock Is a Smart Buy With 80% Upside Potential
URL: https://www.barchart.com/story/news/36405490/this-under-100-growth-stock-is-a-smart-buy-with-80-upside-potential
Time Published: 2025-12-02T12:30:02Z
Description: A 134% revenue surge and a $55.6 billion backlog show CoreWeave’s AI cloud is booked solid for years.
--------------------------------------------------

Title: Audio language model startup Gradium raises $70M to create more realistic voice AI systems
URL: https://siliconangle.com/2025/12/02/audio-language-model-startup-gradium-raises-70m-create-realistic-voice-ai-systems/
Time Published: 2025-12-02T12:00:09Z
Full Content:
UPDATED 07:00 EST / DECEMBER 02 2025 by Mike Wheatley Audio artificial intelligence startup Gradium is launching today after closing on an impressive $70 million seed funding round, just three months after it was founded. The startup is backed by investors that include FirstMark Capital and Eurazeo, which led the funding round, as well as DST Global Partners, Korelya Capital and Amplify Partners, and high-profile angels such as former Google LLC Chief Executive Eric Schmidt. Gradium’s mission is to commercialize audio language models, which are specialized AI systems that are designed to process, understand and generate natural language using audio-text data. Natural language is leveraged as a “supervision signal,” allowing ALMs to perform tasks such as audio classification and speech synthesis more effectively than general-purpose large language models. The startup says ALMs are the “audio-native counterpart” to LLMs and are meant to support more natural and expressive voice interactions with dramatically lower latency, making conversations with AI feel more realistic. The concept was first developed by Gradium’s founders during their time at Kyutai, a nonprofit AI research lab. ALMs are trained on datasets that pair audio with descriptive text, enabling them to learn the complex relationships between sound and language. The natural language supervision technique replaces traditional labeling, using natural speech as a guiding signal to teach them how to understand and say specific words. Co-founder and Chief Executive Neil Zeghidour explained that his company wants to help ALMs lock the true potential of “voice AI,” which is still reliant on what he says are subpar systems. “Existing systems are brittle, costly and unable to deliver truly natural interactions,” he said. “Our goal is to make voice the primary interface between humans and machines.” According to Zeghidour, ALMs can outperform LLMs in any kind of voice AI task, including areas such as speech recognition, where spoken language is transformed into written text, as well as audio generation, such as creating original speech, and audio classification, which refers to identifying and categorizing different audio signals. Ultimately, Gradium wants to transform the capabilities of AI assistants and agents, making conversational interactions between them and humans feel more natural and realistic. “To achieve this, we’re eliminating the longstanding tradeoff between quality and scalability: combining ultra-realistic expressivity, accurate transcription and ultra-low-latency interactions at a price point that finally makes high-quality voice ubiquitous,” Zeghidour said. Zeghidour has assembled a talented team to make good on this promise, comprised of researchers and engineers who previously worked at Google’s DeepMind, Meta Platforms Inc.’s FAIR research team and Jane Street Capital LLC. He said the company possesses one of the industry’s highest concentrations of generative audio expertise assembled so far, and it has already developed a number of production-ready systems that are being used by early adopters and generating revenue. Those early adopters include companies in gaming, customer care, language learning, healthcare and AI agents. Gradium is launching its platform and enabling access to its first models today, with support for English, French, German, Spanish and Portuguese. It says it offers flexible plans catering to the smallest developer teams all the way up to the largest enterprises. The startup said it will continue its ongoing collaboration with Kyutai, ensuring it has access to the latest frontier research in generative audio so it can remain at the forefront of the latest innovations in ALMs. Support our mission to keep content open and free by engaging with theCUBE community. Join theCUBE’s Alumni Trust Network, where technology leaders connect, share intelligence and create opportunities. Founded by tech visionaries John Furrier and Dave Vellante, SiliconANGLE Media has built a dynamic ecosystem of industry-leading digital media brands that reach 15+ million elite tech professionals. Our new proprietary theCUBE AI Video Cloud is breaking ground in audience interaction, leveraging theCUBEai.com neural network to help technology companies make data-driven decisions and stay at the forefront of industry conversations. AWS rolls out Security Agent and strengthens GuardDuty and Security Hub at re:Invent 2025 Exclusive: AWS CEO Matt Garman declares a new era: Agents are the new cloud AWS brings sovereign AI on-prem with new AI Factories alongside Trainium3 and Nvidia GB300 launches AWS puts AI agents to work on truly autonomous software development AWS expands Nova foundation models, adds multimodal support Amazon rolls out Nova Act for AI browser agents, combined with 1Password credential security AWS rolls out Security Agent and strengthens GuardDuty and Security Hub at re:Invent 2025 SECURITY - BY DUNCAN RILEY . 13 MINS AGO Exclusive: AWS CEO Matt Garman declares a new era: Agents are the new cloud AI - BY JOHN FURRIER . 14 MINS AGO AWS brings sovereign AI on-prem with new AI Factories alongside Trainium3 and Nvidia GB300 launches AI - BY DUNCAN RILEY . 14 MINS AGO AWS puts AI agents to work on truly autonomous software development AI - BY MIKE WHEATLEY . 14 MINS AGO AWS expands Nova foundation models, adds multimodal support AI - BY PAUL GILLIN . 14 MINS AGO Amazon rolls out Nova Act for AI browser agents, combined with 1Password credential security AI - BY KYT DOTSON . 14 MINS AGO
--------------------------------------------------

Title: AI stock rally may be driven by fear of missing out, but strategists say hold tight
URL: https://www.cnbc.com/2025/12/02/fear-of-missing-out-may-be-fueling-ai-rally-says-ecb.html
Time Published: 2025-12-02T07:04:22Z
Description: The European Central Bank on Wednesday warned of high valuations and increased concentration of global stocks.
--------------------------------------------------

Title: Build Efficient Financial Data Workflows with AI Model Distillation
URL: https://developer.nvidia.com/blog/build-efficient-financial-data-workflows-with-ai-model-distillation/
Time Published: 2025-12-01T22:00:39Z
Full Content:
Use the NVIDIA Data Flywheel Blueprint to generate compact, high-accuracy financial models.
--------------------------------------------------

Title: Competition Is Heating Up, But Bank of America Still Thinks AMD Stock Is a Buy Here
URL: https://www.barchart.com/story/news/36394508/competition-is-heating-up-but-bank-of-america-still-thinks-amd-stock-is-a-buy-here
Time Published: 2025-12-01T21:19:33Z
Description: While competition in the AI chip race accelerates, Bank of America remains faithful in AMD’s future.
--------------------------------------------------