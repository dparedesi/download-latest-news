List of news related to Meta stock price META:

Title: Top analyst revamps S&P 500 target for the rest of the year
URL: https://www.thestreet.com/investing/stocks/top-analyst-revamps-sp-500-target-for-the-rest-of-the-year
Time Published: 2025-11-12T17:03:00Z
Description: Wells Fargo just added a new chapter in the stock market’s growth story this year. The bank has lifted its year-end target for the S&P 500 to 7,100, which...
--------------------------------------------------

Title: Offline and online coupled tensor factorization with knowledge graph
URL: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0336100
Time Published: 2025-11-12T14:00:00Z
Full Content:
How can we accurately decompose a temporal irregular tensor along while incorporating a related knowledge graph tensor in both offline and online streaming settings? PARAFAC2 decomposition is widely applied to the analysis of irregular tensors consisting of matrices with varying row sizes. In both offline and online streaming scenarios, existing PARAFAC2 methods primarily focus on capturing dynamic features that evolve over time, since data irregularities often arise from temporal variations. However, these methods tend to overlook static features, such as knowledge-based information, which remain unchanged over time. In this paper, we propose KG-CTF (Knowledge Graph-based Coupled Tensor Factorization) and OKG-CTF (Online Knowledge Graph-based Coupled Tensor Factorization), two coupled tensor factorization methods designed to effectively capture both dynamic and static features within an irregular tensor in offline and online streaming settings, respectively. To integrate knowledge graph tensors as static features, KG-CTF and OKG-CTF couple an irregular temporal tensor with a knowledge graph tensor by sharing a common axis. Additionally, both methods employ relational regularization to preserve the structural dependencies among the factor matrices of the knowledge graph tensor. To further enhance convergence speed, we utilize momentum-based update strategies for factor matrices. Through extensive experiments, we demonstrate that KG-CTF reduces error rates by up to 1.64× compared to existing PARAFAC2 methods. Furthermore, OKG-CTF achieves up to 5.7× faster running times compared to existing streaming approaches for each newly arriving tensor. Citation: Lee S, Park Y-C, Kang U (2025) Offline and online coupled tensor factorization with knowledge graph. PLoS One 20(11): e0336100. https://doi.org/10.1371/journal.pone.0336100 Editor: George Vousden, Public Library of Science, UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND Received: June 20, 2025; Accepted: October 21, 2025; Published: November 12, 2025 Copyright: © 2025 Lee et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Data Availability: All data files are available at https://github.com/snudatalab/KG-CTF. Funding: This work was supported by the National Research Foundation of Korea (NRF) funded by MSIT (2022R1A2C3007921), Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT), [No. 2022-0-00641, XVoice: Multi-Modal Voice Meta Learning], [No. RS-2024-00509257, Global AI Frontier Lab], [No. RS-2021-II211343, Artificial Intelligence Graduate School Program (Seoul National University)], and [No. RS-2021-II212068, Artificial Intelligence Innovation Hub (Artificial Intelligence Institute, Seoul National University)]. The Institute of Engineering Research and the ICT at Seoul National University provided research facilities for this work. U. Kang is the corresponding author. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. Competing interests: The authors have declared that no competing interests exist. Given a temporal irregular tensor and a knowledge graph tensor, how can we accurately decompose these tensors to derive meaningful latent factors? Many real-world datasets are represented as irregular tensors such as stock data, traffic data, and music data. An irregular tensor consists of matrices with varying row sizes, while the column sizes remain fixed. For example, in stock data, each matrix corresponds to a specific stock, where the number of rows varies based on different time periods, but the columns represent common stock features such as opening price, closing price, and trading volume. Large-scale factual information is effectively organized into a knowledge graph, which represents information through entities and the relationships between them. A knowledge graph is structured as a graph-based database that represents information in the form of triples (es, r, eo), where the subject (head) entity es is connected to the object (tail) entity eo through the relation r. A knowledge graph can be modeled as a third-order binary array in tensor form, where each entry represents a triplet, with a value of 1 indicating a known fact and 0 representing an unknown or missing fact. Various tensor decomposition methods for knowledge graphs [1–5] have been developed to capture hidden relational patterns and improve the accuracy of missing information prediction. Many tensor decomposition methods [6–12] have been proposed to extract patterns from high-dimensional data. Recently, there has been much attention on PARAFAC2 decomposition [13–17] in order to analyze irregular tensors. These approaches [14,16] primarily employ the Alternating Least Squares (ALS) algorithm, incorporating various optimization techniques to enhance the efficiency of updates. However, many existing PARAFAC2 decomposition methods have significant limitations. First, they emphasize modeling temporal dynamic features (e.g., daily stock prices and trading volumes), which leads to neglecting static features (e.g., a company’s sector) that remain unchanged over time in the tensor. Both dynamic and static features are equally crucial for the accurate modeling of factor matrices. Second, incorporating static features into the existing PARAFAC2 decomposition method [14,18] often introduces a significant bias toward the temporal features, ultimately failing to explicitly model auxiliary information. TASTE [19] incorporates both dynamic and static features through coupled matrix and tensor factorization; however, it fails to represent static features as high-dimensional data, potentially resulting in information loss. Third, while existing PARAFAC2-based decomposition methods [15,20] introduce additional regularization terms to incorporate information from multiple sources, these terms often hinder convergence during the learning process. Therefore, the major challenges to be addressed are: 1) how to effectively integrate dynamic and static information in irregular tensors, 2) how to accurately capture patterns within static information, and 3) how to develop an update rule for stable convergence. In this paper, we propose KG-CTF and OKG-CTF, two accurate coupled tensor factorization methods to integrate dynamic and static information in irregular tensors by leveraging knowledge graphs. KG-CTF runs in an offline setting, while OKG-CTF is designed for an online streaming setting. The main ideas of KG-CTF and OKG-CTF are as follows: 1) integrate a temporal irregular tensor with a knowledge graph tensor to model both dynamic and static features, 2) introduce an effective regularization that captures the relationships within the factor matrices of the knowledge graph, and then 3) ensure stable and fast convergence of the complex loss function through a momentum-based ALS update mechanism. Furthermore, in an online streaming setting, OKG-CTF efficiently deals with newly incoming tensors by avoiding direct computations on the entire tensor, instead leveraging only the new data and updated factor matrices. Experimental results show that KG-CTF and OKG-CTF outperform existing PARAFAC2 decomposition methods in missing value prediction tasks, achieving superior accuracy in both offline and online settings. The contributions of this paper are summarized as follows: The code and datasets are available at https://github.com/snudatalab/KG-CTF. In this section, we explain preliminaries of irregular tensor notations, PARAFAC2 decomposition, and knowledge graph, followed by the problem definitions. Table 1 summarizes the symbols used throughout the paper. https://doi.org/10.1371/journal.pone.0336100.t001 An irregular tensor is denoted as , consisting of a collection of slice matrices, where each slice represents the k-th matrix, and K is the total number of slices. Note that the row size Ik varies across slice matrices, while the column size J remains the same for all. PARAFAC2 decomposition [21] has been widely used for analyzing irregular tensors. Given each k-th slice matrix of an irregular tensor , PARAFAC2 decomposes each slice into three matrices: , , and V, as illustrated in Fig 1. This decomposition is formulated as , where is an matrix, is an diagonal matrix, and V is a matrix shared across all slices with R as the target rank. PARAFAC2 converts each slice matrix into , , and for , where is a diagonal matrix. PARAFAC2 converts each slice matrix into , , and for , where is a diagonal matrix. https://doi.org/10.1371/journal.pone.0336100.g001 The objective function of the PARAFAC2 decomposition is formulated as follows: where represents the Frobenius norm of matrix X, defined as , with denoting the (i,j)-th element of matrix X. To ensure the uniqueness of the solution, several studies [22,23] reformulate with , where is a column-orthogonal matrix, and is a shared matrix across all slices. A knowledge graph is a collection of triplets that encode facts through entities and their relationships, denoted as . Specifically, each triplet (h,r,t) captures the semantic connection between a head entity h and a tail entity t through the relationship r. For example, the triplet represents the relationship between the book Harry Potter (head entity) and the author J.K. Rowling (tail entity) through the relation Written by in the context of book knowledge. Similarly, in the context of travel, indicates that Central Park (head entity) is related to New York City (tail entity) via the relation Located in. This structured representation of a knowledge graph facilitates the efficient integration of large-scale factual information, serving as additional contextual data. A knowledge graph is expressed as a three-dimensional tensor , which takes the form of either a regular or an irregular tensor. In this paper, we represent the knowledge graph as an irregular tensor , where each is an item-specific slice matrix that forms an (entity-relation) matrix, with rows corresponding to item-related entities and columns representing relations. A more detailed explanation of this representation is provided later in this paper. We define the problems of coupled tensor factorization with knowledge graph in offline and online streaming settings as follows: Problem 1 (Coupled Tensor Factorization with Knowledge Graph). Given. Find. Factor matrices , , , and for , and common factor matrices , , and with R as the target rank, where each k-th slice matrix of the temporal irregular tensor is approximated by , each k-th slice matrix of the knowledge graph tensor by , and each temporal factor matrix by . Problem 2 (Online Coupled Tensor Factorization with Knowledge Graph). Given. Find. Factor matrices , , , and for , and common factor matrices , , and for the entire tensor and where; denotes the vertical concatenation of matrices, old rows of k-th existing slice matrix are approximated by , and new rows of k-th existing slice matrix are approximated by . Each temporal factor matrix is approximated by , by , and each k-th slice matrix of the knowledge graph tensor by . We propose KG-CTF (Knowledge Graph-based Coupled Tensor Factorization), an accurate coupled tensor factorization method designed to effectively capture both dynamic and static features in irregular tensors. KG-CTF tackles the following challenges to achieve accurate coupled tensor factorization. To address these challenges, we propose the following key ideas (see Fig 2): (a) We introduce a method that couples a temporal tensor with a Knowledge Graph (KG) tensor by sharing the diagonal matrix Sk. This coupling allows the factor matrices to jointly learn both temporal and static features within an irregular tensor. (b) Relational regularization captures the relationship between the factor matrices derived from the KG tensor, improving their interpretability. (c) To ensure consistent entity representations across all slices, we initialize the entity factor matrix with the updated entity embeddings from . This approach maintains coherence in entity factors across slices, promoting stable learning. (d) We apply a momentum update strategy to ensure faster and stable convergence for factor matrices. At each iteration t, the momentum update refines the current ALS update step for by incorporating the update direction from , leading to a more efficient final update step for . (a) We introduce a method that couples a temporal tensor with a Knowledge Graph (KG) tensor by sharing the diagonal matrix Sk. This coupling allows the factor matrices to jointly learn both temporal and static features within an irregular tensor. (b) Relational regularization captures the relationship between the factor matrices derived from the KG tensor, improving their interpretability. (c) To ensure consistent entity representations across all slices, we initialize the entity factor matrix with the updated entity embeddings from . This approach maintains coherence in entity factors across slices, promoting stable learning. (d) We apply a momentum update strategy to ensure faster and stable convergence for factor matrices. At each iteration t, the momentum update refines the current ALS update step for by incorporating the update direction from , leading to a more efficient final update step for . https://doi.org/10.1371/journal.pone.0336100.g002 We formulate a loss function that effectively learns both static and dynamic information during the decomposition of irregular tensors. To capture dynamic information, we leverage the temporally irregular tensor . As described in Eq (1), each slice matrix is factorized using the PARAFAC2 decomposition with a target rank R, yielding three factor matrices: , , and . For example, in stock data analysis, represents the time factor matrix, corresponds to the stock-specific factor matrix, and V serves as the shared stock feature matrix. The loss function designed to capture this dynamic information is formulated as follows: Next, we introduce the knowledge graph tensor as a source of static information and integrate it with the existing temporally irregular tensor . To effectively model the knowledge graph, we represent it as an irregular tensor for two key reasons. First, the number of entities associated with each item varies, inherently resulting in an irregular tensor structure. Second, the conventional entity-relation-entity representation of knowledge graphs leads to exceedingly large and sparse entity factor matrices due to the vast number of entities involved. If the entity factor matrix was constructed using the complete set of entities, the resulting tensor would be highly sparse, making an irregular tensor representation a more effective alternative. To construct this irregular tensor for knowledge graph, we define a slice matrix for each item k, where rows correspond to entities linked to k-th item and columns represent all relation types. Specifically, each matrix is derived from knowledge graph triplets (h,r,t), where the tail entity t denotes the k-th item, the head entity h is an entity associated with that item, and r is the relation type. The (i,j)-th entry of is set to 1 if the i-th entity is connected to item k via the j-th relation, and 0 otherwise. For example, in a stock-related knowledge graph, each item corresponds to a specific stock, with representing its entity–relation matrix for each stock. Triplets such as and indicate that the stock Apple is linked to entities California and IT via the relations located in and industry of, respectively. Accordingly, in for Apple, the row for California has a 1 in the located in column, and the row for IT has a 1 in the industry of column. Therefore, we define the knowledge graph tensor as , where each slice matrix (representing entity-relation interactions for an item) is factorized into three components: , , and . Here, is the entity factor matrix, is the item-specific factor matrix, and R is the relation factor matrix. In this notation, Nk denotes the number of entities linked to the k-th item, L represents the total number of relation types, and R is the target rank. For stock datasets, is decomposed into , , and R, representing entity-specific features related to each stock, stock-level latent factors, and the relation factor matrix shared across all stocks, respectively. Therefore, the loss function for the learning of static information is formulated as follows: To ensure consistent entity representations across different slices and mitigate the inconsistencies that arise from independently decomposing each slice in PARAFAC2, we introduce a shared entity factor matrix approach. As shown in Fig 2(c), the embedding of an entity remains the same across all slices, preserving its representation throughout the decomposition process. For each slice k, the entity factor matrix is initialized using the following strategy: (1) If an entity has appeared in previous slices, its embedding is inherited from the corresponding entity factors in , (2) otherwise, its embedding is randomly initialized. This iterative approach ensures the stability of entity representations while also enhancing their interpretability across slices. Finally, we couple the knowledge graph tensor with the temporal irregular tensor by sharing the common axis . Since is a diagonal matrix that encodes slice-specific information, sharing it allows for simultaneous learning of the dynamic characteristics from the temporal tensor and the static properties embedded in the knowledge graph tensor. Furthermore, unlike other factor matrices (e.g., , V, , or R) that are domain-specific, represents item-level latent factors. Therefore, sharing this static matrix , which is unaffected by temporal dynamics, ensures interpretability while avoiding conflicts between modalities. The overall loss function that couples these two tensors is formulated as follows: We add effective regularizations to the loss function. We introduce a relational regularization term to ensure that the factor matrices obtained from the knowledge graph tensor effectively encode relational structures. Existing methods [24–26] struggle to fully capture the intricate relational dependencies present in knowledge graphs, largely because they overlook the directional nature of these relationships. To address this shortcoming, we incorporate a regularization term that explicitly models the triple structure of the knowledge graph, thereby improving the representation of directional relationships. Based on the approach proposed in [27], we assume that each knowledge graph triplet (h,r,t) satisfies the condition , where h, r, and t correspond to the vector representations of the head entity, relation, and tail entity, respectively. Here, the norm represents the Euclidean distance, enforcing relational consistency within the knowledge graph. For instance, in a stock-related knowledge graph, if the head entity is iPhone, the relation is produced by, and the tail entity is Apple Inc., the relationship is captured by ensuring that remains close to zero. To effectively learn these relational dependencies, we decompose each knowledge graph slice into three factor matrices. The entity factor matrix represents the head entities, the relation factor matrix captures relational properties, and the item factor matrix serves as the representation of the tail entities. To handle cases where an item is connected to multiple entities through the same relation, the regularization term is minimized using the least squares method. For instance, if an item i1 is linked to entities e2 and e3 through relation r1, the objective is to minimize . Given that e2 and e3 are fixed, this can be equivalently rewritten as minimizing . Here, represents the average embedding of e2 and e3. Thus, to incorporate this principle, we define the relational regularization term as follows: where is the diagonal degree matrix associated with , and the (l,l)-th element of corresponds to the number of entities connected to the l-th relation (i.e., the sum of the elements in the l-th column of ). Additionally, is a matrix filled with ones. represents the tail, meaning the embedding of the k-th item padded L times. The matrix represents the relation factor, while represents the head, computed as the average embedding of entities linked by the same relation. Here, represents the embeddings of the Nk entities connected to the k-th item. The product yields a matrix where the l-th row contains the sum of embeddings of entities linked to k-th item through relation l. By applying , we normalize this sum by the number of entities per relation, so that the l-th row of corresponds to the average embedding of entities connected to k-th item via relation l. To further illustrate how the relational regularization term operates, we provide an example in Fig 3. This figure illustrates a case where a head stock h is connected to three entities via four relation types, resulting in a slice matrix . The regularization encourages the tail embedding of stock h, repeated four times as , to be aligned with the sum of the relation embeddings and the average head entity embeddings associated with each relation, computed as . This alignment reduces inconsistency between the stock embedding and its relational context in the knowledge graph, resulting in more semantically coherent representations across domains. Given four relation types and three entities connected to stock h, the slice matrix encodes binary connections between entities and relations. The relational regularization term aligns the tail embeddings of stock h with the sum of the relation embeddings and the average head embeddings computed over entities connected to stock h per relation. Given four relation types and three entities connected to stock h, the slice matrix encodes binary connections between entities and relations. The relational regularization term aligns the tail embeddings of stock h with the sum of the relation embeddings and the average head embeddings computed over entities connected to stock h per relation. https://doi.org/10.1371/journal.pone.0336100.g003 To enhance the interpretability of the factor matrices while preserving accuracy, we employ uniqueness regularization by reformulating as , as established in previous studies [22,23], where is a column-orthogonal matrix. This approach mitigates the issue of arbitrary rotations in factor matrices, ensuring that remains unique, up to scaling and permutation. To enforce this constraint, we incorporate the following regularization terms into Eq (1): where is a hyperparameter to control the effect of uniqueness for . We apply L2 regularization to the factor matrices , , V, and R to mitigate overfitting and enhance numerical stability throughout the optimization process: We define the following loss function , incorporating effective regularization terms: Algorithm 1 KG-CTF with momentum-based ALS. Input: and for Output: , , , , for , , , and Parameter: target rank R and momentum strength β 1: Initialize matrices for , and , and R 2: repeat 3: for do 4: Update using Eq (3) 5: , and 6: Update using Eq (4) 7: , and 8: Update using Eq (8) 9: Update using Eq (6) 10: end for 11: Update V using Eq (5) 12: , and 13: Update R using Eq (9) 14: Update H using Eq (7) 15: until the maximum iteration is reached, or the error ceases to decrease We introduce a Momentum-based ALS algorithm that leverages a momentum mechanism to enhance the convergence speed of ALS when optimizing complex loss functions. By incorporating a fraction of the prior update direction into the newly computed factor matrix, the algorithm achieves more stable and faster factor updates. For the factor matrix , let denote its value at iteration t. After performing the standard ALS update to compute , the update is further refined by incorporating a momentum term: where β is the momentum coefficient, typically ranging between 0 and 1. During the initial iterations (e.g., t < 5), β is set to zero to allow the algorithm to stabilize without the influence of previous updates. In subsequent iterations, the momentum coefficient β is assigned a positive value to integrate a portion of the previous update direction into the current update, thus accelerating convergence and enhancing optimization efficiency. By incorporating this momentum mechanism, the ALS algorithm improves its ability to process high-dimensional data, ultimately achieving faster and more stable convergence. Algorithm 1 presents an overview of the proposed Momentum-ALS algorithm. The algorithm starts with the random initialization of the factor matrices, followed by iterative ALS updates. For each slice k, the factor matrices are initially updated using the standard ALS procedure, and a momentum term is subsequently applied to refine the final update. We use an alternating optimization-based update procedure, where each factor matrix is updated independently while keeping the other factor matrices fixed. Updating . We update by setting and rearranging the terms with the following lemma: Lemma 1. When fixing all the factor matrices except for , the following update for minimizes (Eq (2)): □ Proof: See Appendix. □ Updating . To update , we first transform for k = 1...K into whose k-th row contains the diagonal elements of (i.e., ). Then, we update by setting and rearranging the term based on the loss function (Eq (2)). We update W row by row with the following lemma: Lemma 2. When fixing all the factor matrices except for , the following update for the k-th row of the factor matrix which corresponds to the diagonal elements of minimizes (Eq (2)): where is a vectorization of a matrix. and * denote the Khatri-Rao product and the element-wise multiplication, respectively. is a vector filled with ones. □ Proof: See Appendix. Updating . We update by setting and rearranging the terms with the following lemma: Lemma 3. When fixing all the factor matrices except for , the following update for minimizes (Eq (2)): □ Proof: See Appendix. Updating and . We update and , which are factor matrices for the uniqueness regularization, with the following lemma: Lemma 4. When fixing all the factor matrices except for , the following update for the matrix minimizes the loss function (Eq (2)): where is a column-orthogonal matrix (i.e., ), and and are left and right singular vector matrices of , respectively. □ Proof: See Appendix. Lemma 5. When fixing all the factor matrices except for , the following update for the factor matrix minimizes the loss function (Eq (2)): □ Proof: See Appendix. Updating . We update by setting and rearranging the terms with the following lemma: Lemma 6. Solving the Sylvester equation (Eq (8)) with respect to minimizes the loss function (Eq (2)) when all other factor matrices are fixed: Note that the Sylvester equation [28] has the form , where we set to solve for . □ Proof: See Appendix. □ Updating . We update by setting and rearranging the terms with the following lemma: Lemma 7. When fixing all the factor matrices except for , the following update for the factor matrix minimizes the loss function (Eq (2)): □ Proof: See Appendix. □ We iteratively update the factor matrices using the update procedure in Lemmas 1 to 7. Each update is the exact closed-form ALS solution of a quadratic subproblem with all other factors fixed, which ensures monotonic decrease of the objective and convergence to a stationary local minimum. We provide the time complexity of KG-CTF. Theorem 1. The time complexity of KG-CTF is given by □ Proof: See Appendix. According to Theorem 1, KG-CTF runs in time that scales linearly with the total number of tensor entries, ensuring practicality even for very large datasets. It is also noteworthy that, in most practical settings, the KG information tables are orders of magnitude smaller than the primary tensor (). Consequently, the cubic term + is asymptotically dominated by the linear term in Ik, and its contribution to the overall runtime is negligible. We propose OKG-CTF (Online Knowledge Graph-based Coupled Tensor Factorization), an accurate coupled tensor factorization method designed to handle both dynamic and static features in streaming irregular tensor data. OKG-CTF addresses the following challenges for accurate coupled tensor factorization in an online streaming setting. We address the above challenges with the following ideas (see Fig 4): We formulate a method to couple a streaming temporal tensor with a knowledge graph tensor by sharing the diagonal matrix Sk. This enables factor matrices to jointly learn temporal and static features within an irregular tensor in an online setting. We formulate a method to couple a streaming temporal tensor with a knowledge graph tensor by sharing the diagonal matrix Sk. This enables factor matrices to jointly learn temporal and static features within an irregular tensor in an online setting. https://doi.org/10.1371/journal.pone.0336100.g004 We propose a loss function designed to efficiently capture both dynamic and static features from a streaming temporal irregular tensor . The loss function in Eq (2), when applied in streaming settings, suffers from inefficiencies due to redundant computations of the accumulated tensor whenever new data are given. This highlights the need for a more effective strategy tailored for a streaming setting. Therefore, we reformulate the loss function by separating the terms related to old data from those related to new data. When new data are added to each slice matrix of the temporal irregular tensor, the loss function is defined as follows: where () is the hyperparameter controlling the effect of forgetting factor, which determines the relative importance of newly arrived data compared to older data. Specifically, we divide into and , into and , and into and . This approach ensures efficient computation by avoiding redundant operations on old data and focusing on learning from newly arrived data. The forgetting factor plays a crucial role in controlling the balance between retaining historical information and adapting to recent changes. A smaller emphasizes recent data, enabling rapid adaptation to new patterns but increasing sensitivity to short-term noise. Conversely, a larger gives greater weight to historical information, enhancing stability while slowing adaptation to distributional shifts. Thus, defines the trade-off between adaptivity and stability, highlighting the importance of selecting an appropriate balanced value in practice. We propose an efficient ALS update rule optimized for streaming settings, where one factor matrix is updated independently while fixing the other factor matrices. This rule eliminates the inefficiency caused by repeatedly recalculating terms involving old data whenever new data arrive, focusing on the computation of only new data. When new data are added, the loss function is divided into two parts: one for the old data and another for the new data. During the update process, terms related to old data are loaded without any recomputation, while only the terms associated with the new data are calculated. In the subsequent step, as additional new data arrive, the previously loaded old factor matrix is combined with the computed factor matrix to form the updated old factor matrix, which is then loaded in the next step. This method effectively avoids unnecessary computational growth as data accumulate, ensuring consistent efficiency over time. Algorithm 2 provides an overview of the proposed Momentum-ALS algorithm for OKG-CTF in a streaming setting. It starts by randomly initializing new factor matrices, followed by iterative ALS updates. For each slice k, all factor matrices are updated using standard ALS, with a momentum term applied to refine the final updates. The updated new factor matrices are then merged with the existing ones to update the old factor matrices for the next streaming data. Algorithm 2 OKG-CTF with momentum-based ALS. Input: a new incoming , , pre-existing factor matrices , , , , V, H, and R Output: updated factor matrices , , , , V, H, and R Parameter: target rank R, momentum strength β 1: Initialize matrices for 2: repeat 3: for do 4: Update using Eq (11) 5: , and 6: Update using Eq (12) 7: , and 8: Update using Eq (8) 9: Update using Eq (14) 10: end for 11: Update V using Eq (13) 12: , and 13: Update R using Eq (9) 14: Update H using Eq (15) 15: until the maximum iteration is reached, or the error ceases to decrease 16: Update 17: Update Updating . We update by setting and then rearranging the terms with the following lemma: Lemma 8. When fixing all the factor matrices except for , the following update for minimizes (Eq (10)): □ Proof: See Appendix. Updating . To update , we first transform for k = 1...K into whose k-th row contains the diagonal elements of (i.e., ). Then, we update by setting and then rearrange the term based on the loss function (Eq (10)). We update W row by row with the following lemma: Lemma 9. When fixing all the factor matrices except for , the following update for the k-th row of the factor matrix which corresponds to the diagonal elements of minimizes (Eq (10)): where is a vectorization of a matrix. and * denote the Khatri-Rao product and the element-wise multiplication, respectively. is a vector filled with ones. □ Proof: See Appendix. Updating . We update by setting and then rearranging the terms with the following lemma: Lemma 10. When fixing all the factor matrices except for , the following update for minimizes (Eq (10)): □ Proof: See Appendix. Updating and . We update and , which are factor matrices for the unique regularization, with the following lemma: Lemma 11. When fixing all the factor matrices except for , the following update for the matrix minimizes the loss function (Eq (10)) by solving Orthogonal Procrustes problem [29] due to column-orthogonality: where is a column-orthogonal matrix (i.e., ), and and are left and right singular vector matrices of , respectively. □ Proof: See Appendix. Lemma 12. When fixing all the factor matrices except for , the following update for the factor matrix minimizes the loss function (Eq (10)): □ Proof: See Appendix. Updating and . We update by setting and , and then rearranging the terms with the following lemma: Lemma 13. The update rule for to minimize (Eq (10)) is identical to defined in Lemma 6 for (Eq (2)). □ Lemma 14. The update rule for to minimize (Eq (10)) is identical to defined in Lemma 7 for (Eq (2)). □ We alternatively update factor matrices with our update procedure in Lemmas 8 to 14. Each update is the exact closed-form ALS solution of a quadratic subproblem with all other factors fixed, which ensures monotonic decrease of the objective and convergence to a stationary local minimum. We provide the time complexity of OKG-CTF for updating the factor matrices. Theorem 2. The time complexity of OKG-CTF is given by □ Proof: See Appendix. Theorem 2 establishes that OKG-CTF’s time cost is linear in the time length Ik,new of the newly arrived data, with as the tensor grows. This leads to significantly reduced computational cost, especially in long streaming sequences. We conduct experiments to explore the following research questions: We provide a detailed overview of our experimental setup, including datasets, baselines, task descriptions, evaluation metrics, and hyperparameters. Datasets. We conduct experiments on six real-world datasets, as summarized in Tables 2 and 3. Each dataset comprises a temporal irregular tensor paired with a corresponding knowledge graph tensor. These datasets cover stock markets from the United States (S&P500, NYSE, NASDAQ), South Korea, China, and Japan. For the stock datasets, each temporal irregular tensor consists of a collection of matrices, where each matrix corresponds to an individual stock. Each slice matrix follows a (date, feature) format, with features categorized into two groups: (1) six fundamental features, including opening price, closing price, highest price, lowest price, adjusted closing price, and trading volume, and (2) 83 technical indicators derived from these fundamental features using the Technical Analysis library (https://technical-analysis-library-in-python.readthedocs.io/en/latest/). For the knowledge graph datasets, we construct triple-based knowledge graphs covering all stocks in the six datasets using the ICKG [30] model. The StockKG dataset contains a total of 89,822 entities, including 14,019 stock entities and 15 distinct types of relations. These datasets are represented as irregular tensors in the format (entity, relation, stock), where each slice matrix is structured as (entity, relation). Here, entities denote the set of associated entities for each stock, and the dataset comprises 15 distinct relation types. # of nnz indicates the number of nonzeros. # of nnz indicates the number of nonzeros. https://doi.org/10.1371/journal.pone.0336100.t002 Update cycle denotes the number of time steps between each update. Update cycle denotes the number of time steps between each update. https://doi.org/10.1371/journal.pone.0336100.t003 We preprocess the real-world datasets by applying normalization methods based on their specific characteristics. For the six stock datasets, we perform z-normalization on each j-th column of the slice matrix X. In contrast, the knowledge graph tensor, consisting of binary values (0 or 1), remains unchanged without any additional normalization. Competitors. We compare KG-CTF against existing PARAFAC2 decomposition methods designed for irregular tensors: We compare OKG-CTF with existing streaming PARAFAC2 decomposition methods in an online streaming setting: Task. To evaluate the performance of KG-CTF and OKG-CTF, we perform a missing value prediction task on temporal irregular tensor data. We randomly divide the data into training and test entries with the following ratios: , and . Metric. We evaluate the model performance using the Root Mean Squared Error (RMSE) computed as , where Ω represents the set of test entries in the input tensor X, and denotes the reconstructed tensor obtained from the learned factor matrices. A lower RMSE score indicates better tensor decomposition accuracy. Hyperparameters. The hyperparameters for KG-CTF and OKG-CTF include the target rank R and the regularization strengths , and , along with the momentum coefficient β. We set the hyperparameters as follows: the target rank R to 5 for the China, Japan, and Korea datasets, and to 12 for the S&P500, NYSE, and NASDAQ datasets; the regularization strengths , , , and to 10, 1, 0.01, and 0.1, respectively; and the momentum coefficient β to 0.5. We compare the performance of KG-CTF with baseline models for the task of missing value prediction at test ratios ranging from 10% to 30%. According to Table 4, KG-CTF consistently achieves lower error rates across most datasets. For instance, in the Japan Stock dataset, KG-CTF shows an error rate approximately 1.64× lower than that of PARAFAC2-ALS at 10% test ratio and about 1.52× lower at 30% test ratio. Traditional methods reveal their limitations as they focus primarily on learning dynamic features while neglecting static features. In the NASDAQ, S&P500, and Korea Stock datasets, however, the performance gaps are less pronounced since KG coverage is skewed—a few stocks are linked to many entities while most have very few—so KG signals enhance a limited subset of stocks, reducing the overall benefit of coupling. In contrast, NYSE, China, and Japan Stock datasets exhibit more balanced entity coverage, allowing KG signals to be utilized more uniformly across stocks and resulting in more consistent performance improvements. Additionally, as the test ratio increases from 10% to 30%, the reliance of competing models on dynamic features causes their performance to degrade more significantly, further widening the gap with KG-CTF. Note that bold and underlined fonts indicate the lowest and second-lowest errors, respectively. KG-CTF outperforms the competitors across all datasets and missing value ratios. Note that bold and underlined fonts indicate the lowest and second-lowest errors, respectively. KG-CTF outperforms the competitors across all datasets and missing value ratios. https://doi.org/10.1371/journal.pone.0336100.t004 We evaluate the performance of OKG-CTF with baselines in terms of local errors and efficiency. Local Error. We evaluate OKG-CTF’s performance by analyzing local errors, measuring the mean and standard deviation across all updates. Table 5 shows that OKG-CTF consistently achieves much lower local errors than competing models. For example, in the S&P500 dataset, OKG-CTF performs up to 1.17× better than existing models. This is because OKG-CTF learns both dynamic and static features by incorporating auxiliary information with each new data arrival, resulting in more accurate factor matrices. Note that bold and underlined fonts indicate the lowest and second-lowest errors. OKG-CTF outperforms the competitors across all datasets and missing value ratios. Note that bold and underlined fonts indicate the lowest and second-lowest errors. OKG-CTF outperforms the competitors across all datasets and missing value ratios. https://doi.org/10.1371/journal.pone.0336100.t005 Efficiency. We evaluate the performance of OKG-CTF compared to competing models in a streaming setting. In Fig 5, the running time for the N-th update represents the update time for the N-th newly arrived data, rather than cumulative time. Fig 5 presents the results for all datasets in a streaming setting where new rows of existing slice matrices arrive. OKG-CTF demonstrates superior performance, achieving up to 5.7 × faster speeds compared to traditional static PARAFAC2 decomposition methods and streaming PARAFAC2 decomposition methods. Notably, in the NYSE and S&P500 datasets, Fig 5(b) and Fig 5(c) show that OKG-CTF achieves faster updates compared to competing models. This shows that OKG-CTF maintains competitive speed performance, while combining static and dynamic features to learn richer information. https://doi.org/10.1371/journal.pone.0336100.g005 Scalability for newly arrived data size. We evaluate the scalability of OKG-CTF with respect to the size of a new incoming tensor by measuring its running time. We measure execution times across five update cycles [20, 40, 60, 80, 100]. The length of new rows added to existing slice matrices increases linearly with the update cycle. As shown in Fig 6, the results are presented using box plots: the orange line marks the median, the box covers the upper (Q3) and lower (Q1) quartiles, and the horizontal lines represent and . Fig 6 clearly shows that, in the setting where only new rows are added to existing slice matrices, the execution time of OKG-CTF scales linearly with the update cycle. The size of new rows of existing slice matrices is linearly proportional to an update cycle. The size of new rows of existing slice matrices is linearly proportional to an update cycle. https://doi.org/10.1371/journal.pone.0336100.g006 We conduct an ablation study to evaluate how relationship learning from the knowledge graph and accelerated learning via momentum updates affect prediction accuracy for both KG-CTF and OKG-CTF. Table 6 provides the global error results for KG-CTF under 20% missing-value test ratio, while Table 7 reports the local error results for OKG-CTF under 30% test ratio. For each method, we consider three reduced variants: (i) KG-CTF-R and OKG-CTF-R, which omit the relational regularization derived from the knowledge graph; (ii) KG-CTF-M and OKG-CTF-M, which exclude the momentum updates; (iii) KG-CTF-RM and OKG-CTF-RM, which remove both components and thus resemble traditional CTF-ALS. As shown in Tables 6 and 7, KG-CTF and OKG-CTF consistently show the lowest prediction errors, confirming that incorporating both relational information and momentum updates leads to superior performance. Even though KG-CTF-R and OKG-CTF-R lose some predictive accuracy by excluding knowledge graph relationships, they still outperform their respective -RM variants. Likewise, KG-CTF-M and OKG-CTF-M underscore the benefit of momentum updates, since their performance degrades relative to the full models. These results collectively demonstrate that our models effectively exploit both static relational structure and dynamic temporal information, allowing them to learn more accurate factor matrices for irregular time-evolving tensors. -R and -M indicate the elimination of relational regularization and no momentum update, respectively. Bold and underlined fonts indicate the lowest and second-lowest errors. Note that both the relational regularization and momentum update contribute to improving the prediction accuracy. -R and -M indicate the elimination of relational regularization and no momentum update, respectively. Bold and underlined fonts indicate the lowest and second-lowest errors. Note that both the relational regularization and momentum update contribute to improving the prediction accuracy. https://doi.org/10.1371/journal.pone.0336100.t006 https://doi.org/10.1371/journal.pone.0336100.t007 We analyze the hyperparameter sensitivity of KG-CTF and OKG-CTF by measuring prediction errors across various key hyperparameters, including target rank, relational regularization, uniqueness, L2 regularization, forgetting factor, and momentum coefficient. Our experiments test four target rank values R of [3, 6, 9, 12], five relational regularization hyperparameters of [0.01, 0.1, 1, 10, 100], five uniqueness hyperparameters of [0.01, 0.1, 1, 10, 100], five L2 regularization hyperparameters of [0.01, 0.1, 1, 10, 100], five forgetting factor hyperparameters of [0.001, 0.01, 0.1, 1, 10], and five momentum coefficients β of [0.0, 0.3, 0.5, 0.7, 0.9]. We use the S&P500 (SP) and NASDAQ (ND) datasets to illustrate KG-CTF’s performance (see Fig 7), and the China Stock (CHN) and Korea Stock (KOR) datasets to examine OKG-CTF (see Fig 8). Note that SP stands for S&P500 and ND stands for NASDAQ. Note that SP stands for S&P500 and ND stands for NASDAQ. https://doi.org/10.1371/journal.pone.0336100.g007 Note that CHN stands for China Stock and KOR stands for Korea Stock. Note that CHN stands for China Stock and KOR stands for Korea Stock. https://doi.org/10.1371/journal.pone.0336100.g008 Rank. We evaluate KG-CTF’s performance on S&P500 and NASDAQ datasets across four target rank values (3, 6, 9, 12). As shown in Fig 7(a) and 7(e), the prediction errors steadily decrease as the target rank increases, reaching their lowest at the highest rank R = 12. These results show that larger rank values consistently yield lower prediction errors, confirming that a higher rank helps capture more complex patterns in the data and improves accuracy. Relational pattern. Both KG-CTF and OKG-CTF incorporate relational regularization derived from a knowledge graph. For KG-CTF, Fig 7(b) and 7(f) illustrate the influence of learning relationships from the knowledge graph for the NASDAQ and S&P500 datasets. Specifically, for the NASDAQ dataset, value of 1 achieves lower errors compared to smaller values such as 0.1 or 0.01. In contrast, the S&P500 dataset performs better with smaller values. This difference arises because the NASDAQ dataset contains a larger number of entities, allowing the model to effectively leverage richer relational patterns. However, excessively large values of can lead to overfitting, particularly on datasets with fewer entities like S&P500, causing the model to learn noise rather than meaningful relational structures. A similar pattern appears for OKG-CTF in Fig 8(b) and 8(f). On both the China and Korea Stock datasets, moderate value of (around 1) produces optimal performance, confirming the importance of appropriately tuning relational regularization to avoid overfitting. Uniqueness. We assess the impact of uniqueness regularization on the performance of KG-CTF and OKG-CTF. In both KG-CTF (Fig 7(c), 7(g)) and OKG-CTF (Fig 8(c), 8(g)), we observe that an excessively large degrades performance. Although moderate helps improve the interpretability of the factor matrices, excessive regularization negatively affects the overall performance. L2. We examine how L2 regularization affects prediction performance for both KG-CTF and OKG-CTF. As shown in Fig 7(d) and 7(h) (for KG-CTF), the error rates remain largely unchanged across different L2 regularization hyperparameter values. This stability arises from the normalized input tensors, which align the scales of the factor matrices, as well as from the abundant data in the KG-CTF datasets, which support accurate factor updates even without strong regularization. In contrast, Fig 8(d), 8(h) (for OKG-CTF) reveal that larger values clearly increase prediction errors. Because OKG-CTF operates on newly arrived smaller datasets, excessive L2 regularization overly constrains the model, shrinking parameter values prematurely and preventing it from capturing subtle, local patterns. Thus, while the large datasets in KG-CTF reduce sensitivity to L2 regularization, careful tuning of is necessary for OKG-CTF to balance between preventing overfitting and preserving essential information in smaller, more localized datasets. Forgetting factor. OKG-CTF explicitly includes a forgetting factor for time-evolving tensors. As illustrated in Fig 8(a) and 8(e) for the China and Korea stock datasets, excessively large values of negatively impact the prediction accuracy by overly emphasizing outdated data, while very small values discard useful historical information too quickly. In Korea stock dataset, a moderate value () achieves the best performance, balancing the short-term volatility and long-term trends inherent in stock data. Thus, selecting an intermediate value for is crucial, enabling the model to dynamically adapt to recent data trends while preserving sufficient historical context for stable and accurate predictions. Momentum coefficient. We quantitatively analyze the impact of momentum-based updates on convergence speed in both KG-CTF and OKG-CTF. We measure convergence as the first iteration (epoch) at which the RMSE drops below a dataset-specific target threshold, with lower values indicating faster convergence. As shown in Fig 9, increasing the momentum coefficient β generally leads to faster convergence across the NASDAQ, NYSE, and S&P500 datasets. For example, in NASDAQ, the model with reaches the target RMSE within just 9 iterations, whereas the baseline without momentum () requires 49 iterations—indicating a 40-iteration improvement. This result highlights that the momentum mechanism becomes particularly effective in high-dimensional, large-scale datasets. However, in the S&P500 dataset, excessively large values (e.g., ) slow down convergence or cause instability, indicating that overly strong momentum may harm training stability. Fig 10 shows similar trends in OKG-CTF. Across all datasets, consistently achieves the fastest convergence; for instance, NYSE reaches the target RMSE in only 5 iterations under this setting. By contrast, higher momentum values ( or 0.9) result in slower convergence and degraded final performance. Overall, these results confirm that moderate momentum effectively accelerates convergence, whereas excessively large values can cause oscillations and suboptimal learning. Note that ND and SP denote NASDAQ and S&P500, respectively. Note that ND and SP denote NASDAQ and S&P500, respectively. https://doi.org/10.1371/journal.pone.0336100.g009 Note that ND and SP denote NASDAQ and S&P500, respectively. Note that ND and SP denote NASDAQ and S&P500, respectively. https://doi.org/10.1371/journal.pone.0336100.g010 We describe related works for existing tensor decomposition methods for irregular tensors, streaming tensors, and coupled tensor factorization approaches. Many studies [18,33] have introduced PARAFAC2 decomposition methods for analyzing irregular tensors. Unlike the traditional PARAFAC2-based ALS algorithm [22], RD-ALS [16] and DPar2 [14] apply preprocessing steps prior to factor matrix updates. ATOM [15] further improves the handling of temporal irregular sparse tensors, particularly those with missing values. However, they primarily focus on capturing dynamic features, while static features, which are equally crucial factors, are largely neglected. Integrating static features into the PARAFAC2 model often results in significant bias toward learning dynamic features. This limitation extends to other PARAFAC2-based approaches that do not explicitly incorporate side information. To address this, KG-CTF couples the temporal irregular tensor with the knowledge graph tensor by sharing a common axis, enabling the joint modeling of dynamic and static features while preserving the inherent relational structures among factor matrices. In online streaming settings, tensor decomposition methods [6,34,35] have been developed to efficiently update factor matrices as new data arrive. DAO-CP [9] adapts CP decomposition by detecting changes in tensor streams and selectively reusing or recomputing factor matrices. STF [7] incorporates attention-based temporal regularization to leverage past and future information for improved online learning. For irregular tensors, SPADE [31] updates factor matrices when new slices are added, while DASH [32] extends this by handling both new rows within existing slices and new slice matrices, enabling more flexible updates. However, existing methods focus on dynamic features, neglecting static features, which are equally important. A key limitation of online PARAFAC2 models is that they cannot incorporate static information in an online learning framework, as it remains unchanged over time and does not fit within their update mechanisms. While spectral regularization has been explored in neural networks and factorization models [36–38] to incorporate auxiliary structures, its use in online tensor factorization remains limited. Meanwhile, OKG-CTF effectively integrates dynamic and static features in online irregular tensor decomposition, enabling richer information learning while maintaining efficient factor matrix updates. Previous studies [39–42] have proposed Coupled Matrix-Tensor Factorization (CMTF) methods to jointly decompose tensors and matrices. HaTen2 [43] and SCouT [44] extend CMTF by implementing distributed CP-based factorization within the MAPREDUCE framework. TASTE [19] introduces a coupled irregular tensor decomposition approach for EHR data, while C3APTION [45] builds on TASTE by integrating a (non-negative) PARAFAC2 model with a (non-negative) CP model. These methods leverage complementary information to achieve data fusion, enabling the extraction of richer information through tensor decomposition. However, relying on simple matrices to represent large-scale auxiliary information has limitations, particularly in capturing intricate relationships. In contrast, KG-CTF and OKG-CTF introduce novel data fusion methods that represent knowledge graph data as irregular tensors, effectively capturing relational structures within the factor matrices. KG-CTF [39] is our preliminary work on coupled tensor factorization, designed to jointly integrate temporal irregular tensors with knowledge graph tensors. In this work, we extend KG-CTF further to effectively handle streaming irregular tensors. In this paper, we propose KG-CTF and OKG-CTF, accurate coupled tensor factorization methods that extend the traditional PARAFAC2 approaches by incorporating a knowledge graph tensor. This integration enables the modeling of both dynamic and static characteristics within temporal irregular tensors in offline and online settings, respectively. Existing methods predominantly emphasize capturing dynamic temporal features while overlooking the intricate multi-dimensional relationships embedded in the data. To address these limitations, KG-CTF and OKG-CTF incorporate relational regularization to effectively capture relational structures within the knowledge graph. Additionally, a momentum-based update strategy is employed to accelerate the factor matrix updates. Our proposed methods achieve superior performance over existing PARAFAC2-based approaches by jointly learning dynamic and static features, leading to improved accuracy with minimal computational overhead. Extensive experimental evaluations confirm that both methods significantly reduce error rates, establishing them as robust solutions for complex temporal irregular tensor analysis. Future work includes extending KG-CTF and OKG-CTF to a broader range of datasets and further optimizing them to enhance scalability. https://doi.org/10.1371/journal.pone.0336100.s001 (PDF)
--------------------------------------------------

Title: Links 11/12/2025
URL: https://www.nakedcapitalism.com/2025/11/links-11-12-2025.html
Time Published: 2025-11-12T11:55:14Z
Full Content:
New South Wales Creates Massive Sanctuary To Save 12,000 Koalas Animal Rescue Annual US household spending on pork correlates with Lululemon’s stock price (LULU) Tyler Vigen (Micael T) Badass Rock Covers Played On Traditional Chinese Folk Instruments Laughing Squid #COVID-19/Pandemics 🇺🇸USA: COVID and other infectious disease tracking is limited by the government shutdown. Available data suggest COVID spread is low to moderate, but wastewater shows rising cases in the Northeast and Midwest. Flu, RSV, and bird flu are also increasing.https://t.co/pPtt6dNgRe pic.twitter.com/XXePAdxi4X — Denis – The COVID info guy – (@BigBadDenis) November 12, 2025 So, we may be on the verge of a new pandemic, but this time it's bird flu. Everyone remembers the COVID pandemic. We're using $Nvax stock as an example, by looking at the stock chart, we see a kind of indicator of cataclysmic fluctuations. There are many examples in history. pic.twitter.com/cVX93OfEub — R.T. (@magomedov39) November 11, 2025 Seems like most people in sports would rather claw out their own eyes than acknowledge that ACL injury waves track precisely with Covid infection waves. pic.twitter.com/IWLJVTFj8E — tern (@1goodtern) November 11, 2025 Climate/Environment World oil and gas demand could grow until 2050, IEA says Reuters Breaking News!Code UFB!!! The three-year running mean for the global surface temperature anomaly now exceeds 1.50°C over the pre-industrial baseline, as of November 8, 2025. Are you there, COP 30? It's me, the Paris Agreement. pic.twitter.com/QXtWf4OeR2 — Prof. Eliot Jacobson (@EliotJacobson) November 10, 2025 It's being an extraordinary warm November in Europe where hundreds of records have fallen from West to East from South to North. The exception is Italy,which is also the only country worldwide which hasn' t broken a single heat record in the whole current season Map by Dr. Maue pic.twitter.com/n6nsQDx8xq — Extreme Temperatures Around The World (@extremetemps) November 11, 2025 Refugee camps set to be uninhabitable by 2050 as extreme weather worsens UN UAE turns to cloud seeding as water scarcity challenges grow Borna News The Middle East is running dry as water scarcity threatens millions The Star Tehran’s water could be cut off at night amid ongoing drought Independent World’s first green fuel levy to add almost US$32 to air fares Bloomberg China? China’s CO2 emissions have been flat or falling for past 18 months, analysis finds Guardian EU Eyes Banning Huawei, ZTE Corp From Mobile Networks of Member Countries Bloomberg Nobel laureate urges China to deepen space collaboration Asia Times (Kevin W) India LIVE: India, Pakistan launch probes after blasts in New Delhi, Islamabad Aljazeera Trump tariffs: Why India should push for rollback of Russian oil penalty before trade deal with US; 3-point strategy explained Times of India Southeast Asia Fighting Cambodia, we must be the main boxer: Underline Thailand Thai Rath Noon, YouTube. >20 million followers. Thailand population is about 72 million. Africa Troubled waters: Why is a Nile dam causing such tension? Euronews Amnesty accuses Somalia of neglecting drought victims Somali Guardian South of the Border U.S. aircraft carrier nears Latin America as Venezuela tensions simmer Washington Post European Disunion Paris, France. Andrei Martyanov Germany inches close to agreement on contentious military service but questions remain Euronews Europe’s chief justice slams Orbán Euractiv Old Blighty Starmer allies issue warning to PM’s rivals as fears grow over leadership challenge Guardian (Kevin W). BWAHAHA. Israel v. The Resistance Hamas Statement on Israel’s Ceasefire Violations in Gaza Resistance News Network Partition of war-torn Gaza a looming risk Middle East Online At Hebron’s Ibrahimi Mosque, Israeli MK Zvi Sukkot interrupted Muslim prayers in the Isaac Hall, entering with his shoes on to perform a mock prayer, accompanied by the army. The video is captioned "The Cave of Machpelah is not a mosque”. Disrespecting sacred spaces is part of a… pic.twitter.com/MvtM3FOIaA — Ramy Abdu| رامي عبده (@RamAbdu) November 11, 2025 New Not-So-Cold War Scott Bessent’s Damaging Remarks Puts More Distance between Washington and Moscow Larry Johnson. We have said from the outset that Bessent was an idiot. His hedge fund was microscopically small despite his Soros connection, which should have been an enormous marketing aid had he been any good. So he’s neither managed anything of size nor been a competent investor. His claims re his role in Soros short of the pound have always seemed exaggerated. Soros is hands-on, particularly with large bets. I suspect at most that Bessent executed trades or did some research. Admittedly John Helmer has depicted Kirill Dmitriev as a blowhard and a relentless self-promoter, but that does not make him wrong on the specific remarks that Bessent derided. Killzone🔴Mass Surrender: It Has Begun!🏳️The Defense of Novouspenovka Has Collapsed💥MS For 2025.11.11 Military Summary, YouTube Brief Frontline Report – November 11th, 2025 Marat Khairullin How To Start War With Russia – A British Think Tank Has Ideas Moon of Alabama (Kevin W) Sergey Lavrov: “We know what the Americans have, and the Americans know what they have. Let’s take a year to, so to speak, cool down, analyse the situation, stop measuring everything by the Ukraine yardstick, and focus on the great powers’ responsibility to maintain global security and stability, above all, in terms of avoiding nuclear war. We are ready for that” International Affairs (Micael T) Lavrov’s More Extensive Very Detailed Q&A With Media Karl Sanchez A US Think Tank Considers Armenia & Kazakhstan To Be Key Players For Containing Russia Andrew Korybko Big Brother is Watching You Watch The Biometric Payment Revolution You Never Agreed To Reclaim the Net. Consumers need to say no. I refuse face scans at airline gates. Stuns me that no one else does. Critics Call Proposed Changes To Landmark EU Privacy Law ‘Death By a Thousand Cuts’ Reuters Redmond turns off Flock Safety cameras after ICE arrests Seattle Times (Paul R) Imperial Collapse Watch I saw the Davos world order up close. Now it’s age of the predator The Times TRUMP PLAYS THE OLD CIA CARDS FOR REGIME CHANGE John Helmer Doomsday Scoreboard (Micael T) Trump 2.0 Trump dismisses economic anxiety with ‘fake’ polls and reveals reason 600,000 Chinese students are in US Daily Mail. This from a right wing contact: “We can observe for ourselves how out of it/ill informed Trump may be. Had problems in a friendly interview.” Trump responds to criticism from Marjorie Taylor Greene: ‘She’s lost her way’ NBC. Exceedingly mild for Trump. Exploiting MAGA Sentiments to Back Nigerian Intervention American Conservative (resilc) Shutdown SNAP: Trump admin gets longer Supreme Court pause on order it pay full food stamp benefits CNBC Hemp-THC ban included in federal spending bill Supermarket News The Democratic Shutdown Capitulation: A Perfect and Unnecessary Failure Washington Monthly (resilc) Chuck Schumer Should Be Humanely Euthanized* Ken Klippenstein Jeffries, Democrats will offer 3-year extension of ObamaCare subsidies The Hill. Pathetic. Once Again, Senate Democrats Show They Don’t Get Who They Represent New Republic (resilc). Huh? They represent donors. Tariffs Trump tariff dividends face legal, political roadblocks The Hill Immigration US has sent $7.5m to Equatorial Guinea to accept noncitizens deportees Guardian (resilc) Trump’s H-1B Visa Crackdown to Accelerate Wall Street’s Expansion in India Bloomberg Mamdani A Graveyard of Bad NYC Mayoral Election Narratives Musa Al-Gharabi (Robin K) L’affaire Epstein Israeli Spy Stayed for Weeks at a Time at Jeffrey Epstein’s Mansion Drop Site Epstein is not going away Edward Luce, Financial Times. No archived version :-( Our No Longer Free Press Kash Patel’s GF files $5 million lawsuit against podcaster for ‘insinuation’ she’s Mossad honeypot Grayzone (Chuck L). WTF? Did no one clue them in that the defendant can do discovery? Antitrust The War on Algorithmic Price Fixing Is Here Pat Garofalo (Robin K) AI US taxpayers being kept in the dark over datacenter subsidies The Register 5 recent, ominous signs for Generative AI Gary Marcus Michael Burry’s latest argument against hyperscalers like Meta and Oracle echoes one made by an investor who shorted Enron Business Insider AI adoption in US adds ~900,000 tons of CO₂ annually, study finds Techxplore (Kevin W) Data centers meet resistance over environmental concerns as AI boom spreads in Latin America Guardian ChatGPT violated copyright law by ‘learning’ from song lyrics, German court rules Guardian (Kevin W) A tech entrepreneur/former professor and inventor sent this, noting: “Chat GPT is screwed. Who is going to trust it?” The Zionist entity is actively attempting to influence ChatGPT responses and other AI models as part of a multi-million dollar public diplomacy (hasbara) campaign, according to a new investigation by Haaretz. The Israeli government has signed contracts with U.S.-based public… pic.twitter.com/IqO0L1za4f — MintPress News (@MintPressNews) November 7, 2025 Calls for chatbot age assurance increase as allegations of self-harm, psychosis grow Biometric Update The Bezzle Saudi Arabia’s Dystopian Futuristic City Project Is Crashing and Burning Gizmodo Class Warfare Inside London’s Smallest Apartments YouTube (resilc). ZOMG. The pricey one near Hyde Park looks to be in Belgravia. Reverse mortgages edge up as US economy squeezes older Americans Financial Times Is This The WORST TAKE On The Affordability Crisis? Young Turks, YouTube. It’s gratifying to watch Ben Shapiro self-destruct. Even ICE Is More Popular Than Congress Now, Says Brutal Poll New Republic (resilc) How HR Took Over the World Economist. The Economist catches up with what a colleague has been complaining about for years, rule by HR ladies. Antidote du jour (via): And a bonus: This is aweee! ❤️The border collie is trying to do its job without scaring the baby sheep. pic.twitter.com/2td7XNywGc — The Figen (@TheFigen_) November 11, 2025 A second bonus: Camel's reaction to eating a lemon for the first time..🐪🍋😅 pic.twitter.com/BiAlmel5fU — 𝕐o̴g̴ (@Yoda4ever) November 12, 2025 And a third: Somebody explain it to him before his anxiety level peaks 😂 pic.twitter.com/Ps3SM3lzQi — Posts Of Cats (@PostsOfCats) November 11, 2025 See yesterday’s Links and Antidote du Jour here. I’m calling the border collie herding a baby sheep video good, as in it really happened. In my visits to NZ in the early 80’s, there was 75 million sheep and 3 million people (down to 23 million sheep thrills and up to almost 5 million Kiwis @ present) and I ended up in a number of ‘Sheepedes’ that lasted 20 to 30 minutes as they just kept coming across the road-with border collies as canine cowboys, round ’em up, bring ’em out, keep ’em in line, rawhide! We are currently foster parents for a border collie. While they are bright, athletic dogs, if you don’t have some chickens or sheep or goats for them to herd, they try to herd you. When the challenge of herding our geese and ducks wasn’t enough, my border collie used to try to herd my kids when they were small. Was more successful than I was. Border Collies are relentless, they even (sort of) herd cats. A friend of mine has a border collie who herds bikers. I find it extremely funny even if I am a keen biker. When you are fostering it. Have you noted who the dog has decided to be the “boss” in the herd? Shadow chasing is another one. Collies can be quite prone to OCD. My better half grew up with a collie in the countryside. It used to attempt to nip the back tyres of passing cars, which terrified me. Don’t be too frightened for doggo. We had a Border Collie that chased cars too. He caught two, and died of old age. British readers may remember the joys of “One Man and His Dog” a sheepdog trials show that was on BBC early Sunday evenings throughout my younger years. The intelligent dogs, the farmers communicating with a whistle and calling “come bai”. The excitement when one of the sheep got separated from the pack and tried to go rogue. I loved that show. Border collies are amazing. Here’s a clip from the 1990s. Trial stats at 4.30 https://youtu.be/fHs5cT5kL58 Thank you, Ben. + 1. “It’s in the power of the eye!” Nice choice of YouTube clip. I told you (below) that TV show is good for a few chuckles. There exist contexts in which a TV sport commentator can say, “For a nine-year old bitch she’s still extremely fast.” Definitely real. I have a rescue that genetic testing showed was perhaps 1/8th border collie, and he does these moves all the time – to us, to dogs he meets, to the feral cats, etc. We were confused at first because the herding dogs I saw previously didn’t get so low to the ground, then I saw a couple videos of border collies and bingo! I would ‘rather claw out [my] own eyes’ than accept a three-month rolling average on a chart that exclusively uses the first eleven days of January across multiple years, which maybe I could get talked into, except it is literally connecting unconnected dots when it links the lines up as tho it is longitudinally contiguous. Rhetorical misrepresentation. (That last sentence scans, that’s when you know I’m miffed.) (Just noticed ‘longitudinally contiguous’ scans too. Whoa Momma! tern should know better.) This is presumably in DD-MM-YYYY format (rather than MM-DD), no? Yes, it is. By the way: there is an international ISO norm regarding dates, and it has the format YYYY-MM-DD. I use it quite systematically — it is unambiguous and is quite appropriate for sorting data. My biggest grudge against people writing the datetime libraries for different programming languages is that none of them use the ISO 8601 as basis and standard. It can handle dates, times, timestamps, time differences, time zones, duration, intervals, recurring intervals and eras. And it’s logical, proceeding from the lowest precision to the highest precision. Somebody should also fix the decimal separator issue for good. no, yes. Thank you, that makes sense. OMG, that chart is so awful. An innumerate LARPing as a statistics postdoc This is why I prefer to be cautious in attributing everything bad to COVID. There is real evidence of risks and damage from each infection, but not everything bad is COVID. “Saudi Arabia’s Dystopian Futuristic City Project Is Crashing and Burning” This project never made sense from the get-go. It seemed to be a cross between a vanity project and a white elephant and was sopping up enormous amounts of resources. In any case, who is even supposed to live in this city assuming it was finished? Saudi Arabia would have been better in spending the money on infrastructure, particularly drought-proofing the country. Considering how many countries are experiencing severe water shortages, that might be a wiser investment. Drought-proofing Saudi Arabia through judicious investment in water management infrastructure? You are talking about the country that decided to empty its aquifers to grow crops in the literal desert. Sir Norman, in addition to being a very talented architect, is one of our era’s greatest con men. His understanding of the vulnerabilities of the plutocratic mind is unparalleled. Doomsday Scoreboard (Micael T) In their 1997 book The Fourth Turning: An American Prophecy, historians William Strauss and Neil Howe predicted that between 2005 and 2026 the United States would experience a “Fourth Turning” crisis—a period of social upheaval on the scale of the Revolution, Civil War, or Great Depression. Multiple commentators link recent U.S. crises (2008 recession, 2020 pandemic, political polarization) to this forecast, though no conclusive “cataclysm” has occurred. The cycle is set to resolve by ~2026. ~~~~~~~~~~~~~~~~~~~ I’m quite taken by the Fourth Turning, or 80 years later if you’d like. Everything lines up so perfectly… 1781 Yorktown 1861 Fort Sumter 1941 Pearl Harbor 2022 Ukraine 1837 Financial Panic-1917 US enters WW1 1849 Gold Rush-1929 Great Depression 1893 Financial Panic-1971 US goes off gold standard 1907 Financial Panic-1987 Financial Panic 1929 Financial Panic-2008 Financial Panic add-on 1865 Appomattox-1945 Tokyo Bay That is a fun scroll. One thing ought to be noted about it. The end-of-the-world predictions related to Christianity are far different from current predictions about the fall of the American Empire or neoliberalism or capitalism. The religious predictions actually entail a physical destruction of the planet to be replaced by a new and better model. If the American Empire falls, it won’t be fun for us who live here, but the planet will continue, perhaps for the better. It all depends on how well the rest of the world can ease the USA down. I’m sure that the Empire will not go quietly. Who will secure its nukes? 1945 Hiroshima & Nagasaki-2025 ? 2025-Teheran & Tel Aviv I doubt if Pakistan will nuke Jerusalem, Dome of the Rock and all that, but I’m not so sure about India. Howe has since extended his timeline to 2032. Historian David Kaiser has an alternative interpretation based on the original Strauss/Howe timeline. He thinks the Fourth Turning already happened, but the BushBama regime failed to unite America with a solution to the financial crises and permanent GWOT, so now we’re in an extended period of disgruntlement sort of like the post-reconstruction era. Very glad to see the bonus antidotes today. The sheepdog scene is perhaps to some UK TV viewers not so unusual. Since the 1970s sheepdog trials have been a televised sport in the UK. Close ups of the dog standing still close to the sheep aren’t unusual. Impressive all the same. The BBC produced a show called One Man and His Dog which my mum liked to watch. What the dogs and shepherds accomplish is very impressive but as a TV sport it’s inherently funny, like golf or snooker, owing to the voice commentary having to find novel things to say about it. I expect there are some old clips of the show on YouTube. The cat is wise. My Lucy runs from the room when the printer operates. Following up on yesterday’s Farmer’s Almanac link, it turns out that there are two Old Moores. The Irish Old Moore, Theophilus, was a teacher of languages, a mathematician, and an astrologer. His Old Moore’s Almanac has been going since 1764. The English Old Moore, Francis, was a court astrologer and physician and his Old Moore’s Almanack (note the K) has been going since 1697. Agree! Antidotes without exhaustive investigation to authenticate their authenticity surpass no antidotes by around a million million times. Yes. All doom and no fun makes you go crazy. I always appreciate the antidotes :) > I expect there are some old clips of the show on YouTube. See my comment above :) re: Gaza fascism Germany Kinda funny in a desperate way – Jason Stanley was invited to Germany (Jewish community Frankfurt) to speak about – fascism – what else – on November 9th (saint date) and eventually couldn´t finish his speech becoz “Gaza” – so what about “fascism” now, Stanley? I applaud his honesty. But if the very society claiming absolute wisdom on issues of Holocaust and “fascism” yet over and over and over again denies the genocide “in our time”, what sense does it make to constantly use the term until it has turned hollow because no one listens who does not happen to be a leftist intellectual. It is a very strang situation – I listen to Walter Kirn and then to John Bellamy Foster – go figure. Remember the botched raid on the Marion Record newspaper in Kansas? From the AP and the tv news channel KCTV5: Kansas county agrees to pay $3 million over police raid on a small-town newspaper, editor says. https://www.kctv5.com/2025/11/11/kansas-county-agrees-pay-3-million-over-police-raid-small-town-newspaper-editor-says/ thanks! Seconded. So many of those events that make a big, immediate impact when they occur tend to disappear in the memory hole — especially if things do not unfold according to the approved narrative. Good news. There being consequences for this kind of police behavior is not a given these days. Yves, the Military Summary link might be wrong. The link text says 2025.11.11 but it links to a video two days older with the title Killzone🔴Defense on the Zaporizhzhia Front is Crumbling in Real Time⚡️💥Military Summary 2025.11.09 The state of search on YT is such that I can’t even find that 11.09 video so I have no idea how that happened (I did not watch it). Putting in an 11.11 Killzone link. The search function for YouTube is borked. You can put in a search term and enclose it with inverted commas to search for what you want. But half the search results that come back have absolutely nothing to do with what you are looking for. And the feed is filled with these goofy knock-offs with a thousand subscribers robbing material from interviews of popular commentators from Mearsheimer to Candace. The original interviews or commentary are crowded out. An attempt to starve the content creators or at least slow the growth of ones who speak in contradiction to the Establishment narrative? I hate those. Awful. But sometimes the channel crowds out its own video. It pisses me off no end that Nima will, a couple of days after a long interview, will repost 20-30 minute clips with a different header AND then remove the original!!! I am never giving him a dime due to that behavior. YouTube search is … yeah. You can go to the Military Summary channel page https://www.youtube.com/@militarysummary then click the Videos tab and navigate by date. For some channels like Dialogue Works or Judge Nap use the Live tab instead of Videos tab. In any case, the Home tab is usually no use. re: German farmland vs. Big Agro interview by BERLINER ZEITUNG use google-translate Foreign countries are buying up German farmland: “We are experiencing the second structural break in East Germany” Reinhard Jung from the Brandenburg Farmers’ Association on the sell-off of German agricultural land, the failure of politics – and why Germany is losing control. https://www.berliner-zeitung.de/wirtschaft-verantwortung/ausland-kauft-deutsche-aecker-bauernbund-warnt-vor-zweitem-strukturbruch-in-ostdeutschland-li.10004589 “Following the takeover of Deutsche Agrar Holding (DAH) – including around 20,000 hectares of farmland in eastern Germany – by the Australian fund Igneo, an old concern has been rekindled: the “sell-off” of German soil. Thuringian farmer Reiko Wöllert warned in an interview with the Berliner Zeitung of the loss of farmers’ control – his words sparked a broad debate.” Scott Bessent’s Damaging Remarks Puts More Distance between Washington and Moscow Larry Johnson. He is signalling to his PMC comrades that he is in the “correct” side of history. What the populaces think about his words doesn’t matter. So, yes, the same kind of idiot as Starmer, Merz, Macron et al. I’ve seen Bessent in action and he acts like some sort of bully boy and makes criticisms based on what he thinks is real instead of having the Treasury department give him the straight dope. Still, being a bully boy makes him a good fit in the Trump Cabinet. But I do not think that he will give Trump the true picture of the US economy as Trump would not like that. Bessent is just a dummy who is projecting … calls Dmitriev a liar, but he himself is lying through his teeth about India buying Russian oil. Here is the key quote from Larry Johnson: Moreover, I think it is highly likely that Russia and India will find a way to use a third party to continue shipping oil to India in order for India to continue to have access to affordable oil. India just set up a big trading exchange that settles accounts in non-dollars. Rupees/Yuan, Rupees/Dinar, etc. They can set up intermediaries who will buy the oil, settle in rupees, and pass it along (with a cut, of course.) Bessent is either an illiterate who forgot basic economics – if a commodity is priced lower than market price and there is demand for it, middlemen will step in to make a market. Or he’s lying through his teeth. I suspect the latter. But he is gay! (I didn’t ask, I don’t care; but I got told anyway) “Breaking barriers” is more important than competence. ‘Log Cabinet’ member? I wonder if that is in his Lincoln profile. I used to think that Gay Republican meant “Happy, Happy, Joy, Joy.” Now I understand that it means “Epstein Bait.” Robert Barnes was on the Duran yesterday dissecting parts of the Trump administration, with particular animus against Bessent. Very entertaining and colorful, though he still has faith in crypto and in Vance. https://www.youtube.com/live/2MjEkOKoHcg?si=-v9KylaLQAiO3vEd IMO, Barnes, or at least his twitter feed, consistently offers the correct diagnosis (even if you don’t share his worldview)—-but offers the wrong treatments, lmao I always learn something from Robert. Yesterday he said the reason Marco Rubio, a blue-collar son of Cuban refugees, became a successful politician was because his sister married one of the original cocaine cowboys of south Florida. Thinking Miami Vice here. He also got in an actual fistfight with Musk while in the West Wing. Apparently the reason Musk was banned from the White House and then retaliated with a tweet saying that Trump is in the Epstein list. Almost makes me say that Bessent can’t be all bad, but I guess it’s just two total jerks fighting, so it’s still all bad. Though one can still cheer them on. I was not aware that GM’s CEO Mary Barra was previously GM’s head of HR. Barra has been criticized for abrupt firings of well-liked, and well-credentialed executives both recently recruited or having long GM careers. Eric Starkman is a columnist in our local online news mostly news aggregator, http://www.deadlinedetroit.com and Barra critic. He has written about fired executives as easily disposable “Barra bees.” http://www.deadlinedetroit.com/articles/32623/starkman_why_gm_employees_should_bail_on_ceo_mary_barra_and_avoid _early_morning_termination_events and http://www.deadlinedetroit.com/articles/32552/starkman_gm_under_ceo_mary_barra_is_an_undeniably_soulless_and_dishonest_company changing GM’s old logo to its current sans-serif, lower case “gm” (sic) was the most HR-thing ever, lmao maybe Mary should worry more about build quality, diversifying the model portfolio away from trucks, and V-8 engines not grenade-ing “V-8 engines not grenade-ing” from utube, They Won’t Tell You THE TRUTH About GM V8 ENGINES, So I’ll Do It! https://www.youtube.com/watch?v=C7nr9u2zkfM Mary Barra should also lead an effort to make the front grill of GM vehicles less of a pedestrian killer as they push pedestrians underneath rather than on top of the hood. But then I like the old trucks from the late 1940’s, early 1950’s with the rounded lines. I bought a 1958 Chevy Apache pickup in 1974 for $300. Loved the hood with the little devil horns. It had rusted holes in the floor on both sides large enough to eject empty beer cans. Small cars are also at risk from those behemoths. I saw what looked like a stock (no apparent lift kit) late-model GM pickup parked on the street behind a Toyota iQ the other day and the hood of the pickup was pretty much level with the top of the iQ. One of the benefits of my 1978 New Yorker is that it still came equipped with the pedestrian gunsight on the hood. Sadly, the blood red paint on the coat of arms is fading after all these years. She’s a great person in other ways as well Mr. Wenig and Mr. Wymer have no such worries. In June, Mr. Wenig was re-elected to the board of General Motors, a position that pays $317,000 a year. Mary Barra, GM’s chief executive, called the cyberstalking scandal “regrettable” but noted “it didn’t involve any GM business.” Inside eBay’s Cockroach Cult: The Ghastly Story of a Stalking Scandal (NY Times via archive.ph) I guess in this case she forgot her HR mindset. Thanks for that link. The story is truly appalling and both Wenig and Wymer should be in prison, as if that would ever happen. Thanks for the links. The ‘deadline detroit’ 3rd link includes this: Perhaps in the greater scheme of GM’s global workforce of 163,000 employees, but it represents 4% of GM’s Tech Center workforce, assuming the 25,000 workers GM says its Tech Center employs is a current number. GM fired 600 software engineers assigned to its Tech Center campus in August. That’s crazy. Barra herself notes customers are complaining about the clunky software used to transition the screen between options, especially Apple and Android connections. A problem that could be fixed with better car software. Her answer? Layoff tech software engineers and….get rid of Apple Car Play and Android Auto and other ‘troublesome’ connections in the new cars. Let a 3rd party design new software. More subscription money extracted from car “owners” and advertisers. https://tech.yahoo.com/transportation/articles/gm-drops-apple-carplay-android-135933968.html Yeah, that’ll work. / ;) I want my, I want my ChatGPT I want my, I want my ChatGPT I want my, I want my ChatGPT I want my, I want my ChatGPT Now look at them kosher nostras, that’s the way you do it You play them for fools on AI & ChatGPT That ain’t working, that’s the way you do it Money for nothing and your clicks for free Now that ain’t working, that’s the way you do it Lemme tell ya, them Hasbara guys ain’t dumb Maybe get a blister on your little finger Maybe get a blister on your thumb We got to install influence covenants Custom distortion deliveries We got to move these goys along We got to move these Zionist themes Listen here Now that ain’t working, that’s the way you do it You play them for chumps on the ChatGPT That ain’t working, that’s the way you do it Money for nothing, and your clicks for free Money for Nothing, by Dire Straits https://www.youtube.com/watch?v=wTP2RUD_cL0&list=RDwTP2RUD_cL0 The kosher nostras (nice one) might be doing us a small favor. By destroying the perceived impartiality of AI, they’ve undermined trust. Once nobody trusts that “muh AI” is unbiased and free from tampering by the Central Scrutinizer, they’ll ditch it and rediscover the joys of using your mind. Maybe. Well, we can always hope. It’s useful for timeless questions like Should I put bacon on the salad? Obviously not. Duh! And you shouldn’t eat cheeseburgers either. So Isr is going to try “google bombing” AI. Doesn’t surprise me. https://en.wikipedia.org/wiki/Google_bombing Absolutely: The Economist catches up with what a colleague has been complaining about for years, rule by HR ladies. Further, DEI in various iterations has been around for quite a while. This sentence bemusedly gets to the point, but the chronology is older than the 2020s: ‘ For an “insecure” profession that is “prone to scramble around for fashions and fads”, in the words of one hr director, dei brought plenty to keep busy with, from micro-aggressions to non-gendered toilets. ‘ Jennifer Pan was interviewed by Joshua Citarella on his excellent DoomScroll vlog. The interview is entitled “Selling Social Justice.” She describes the coopting of these initiatives into an extension of management. As Adolph Reed keeps pointing out, a more “diverse” ruling class of oppressors is still a group of oppressors. The expression “rule by HR ladies” also reminded me of a phenomenon that I see / saw in my career in publishing. I’m sure other commenters have seen the same phenomenon in their fields: The division of organizations into fiefdoms. HR is definitely “feminized space” — although it’s main job is to defend the company against the employees. In certain realms of publishing, editorial is women, and marketing is the men. It all becomes a tad too obvious. Oddly, though, publishers just can never find young black men to hire. I wonder why. It’s not just publishers whose HR departments can’t find the black people. A company I’m familiar with determined several years ago that it was short on minority hires and about that same time, the entire workforce was blessed with DEI training. Some did wonder why the rest of the company needed “training” because HR couldn’t hire any minorities (heal thyself!), but I digress…. The solution? An explicit call for more employees to refer minority friends for open positions, with referral bonuses being doubled if it resulted in a minority hire. I wish I was kidding. Re: Ben Shapiro saying people should move for jobs. Is This The WORST TAKE On The Affordability Crisis? Young Turks, YouTube. It’s gratifying to watch Ben Shapiro self-destruct. ***** That’s actually pretty standard conservatism from the 1990s and 2000s, “we gotta move people to jobs and not jobs to people”, so it’s good to see some growth in thinking among the conservative base, away from Ben Shapiro, National Review, etc. Ben Shapiro says lots of stuff which he does not think through- ‘ADAM @AdameMedia Nov 9 Ben Shapiro: Reparations don’t work. Charlamagne: They worked for Jewish people. (They *still* receive HoIocaust reparations) Shapiro: Erm, uh, that’s totally different! Israel took $500b from America (and $30B since Oct 7). It still begs for more. https://xcancel.com/AdameMedia/status/1987321638669717962#m Rev what the hell is this? After all the rhetoric this decade on reparations not being a solution, the USA, France et al. gave and have been giving them to holocaust survivors this whole time? What about Native Americans and black slave descendants? Why has France still not given Haiti back their money? What about flipping Vietnam reparations? What about Iran, Iraq, Afganistan, Sudan, Somalia, Libya, Cuba, Panama, Grenada, Peru, Venezuala, Palestine, hell even Japan, South Africa and Russia not to mention tens more I’m sure I’m forgetting. The US didn’t even ouright persecute Jews during WWII more than they supported Apartheid in SA, so what the hell are they giving them reparations for? So I see a collision of recent STEM graduates who buy a house with a 50 year mortgage (with very equity) finding no jobs due to US deindustrializing and shutting down biomedical research walking away to China or Russia for a sustainable job (and probably leaving both debts behind). “Failure to plan is planning to fail.” Just spitballing here, but I think the demand in China or Russia for US graduates who never considered learning Chinese or Russian is going to be quite low. Although that observation does support your aphorism. Oh, I know some young scholars who are tackling mandarin. A job these days is a great incentive. Some Chinese guys were trying to recruit me about a decade ago. I was very tempted. What’s tackling language 6 if it keeps you fed…? Would a hire of somebody from a deindustrializing country be known as a ‘westback’? Foreign devil Get the Epstein LLC involved and you can call it a bawdy shop. Whiteneck? “we gotta move people to jobs and not jobs to people” So, get more migrants in, instead of outsourcing everything. Lavrov: “The EU may argue that we ‘invaded’ Ukraine in violation of certain agreements.” “We wanted Ukraine to keep its economic ties with Russia.” “Let’s take a year off.” *Blink* Parse at your own risk. That ain’t my take. “Paris, France. Andrei Martyanov” I see this everywhere. In one of the small towns in Normandy near me, I recently saw seniors getting together to share their bounty from the local Carrefour supermarket, under the market square roof. They brought thermoses of coffee and tea to share with each other. About 15 people. I was also recently in an industrial park in a suburb of a major 2 tier city, to pick up some paint for my house. Next to the paint supplier was a food bank “Les Restos du Coeur”. There was a line of at least 50, in the middle of the afternoon on a Wednesday. People looked working/middle class. Decently dressed, many with their children (Wednesday afternoon is off for grade schoolers). Before the pandemic, I’d see groups of pensioners in Versailles, in front of the Franprix there, by the movie theatre. Maybe 10, like the video posted. At the intersection of D capitulationism and L’affaire Epstein, the thought occurs that in addition to potentially or probably (depending on what the Rs do with the promised ACA vote) keeping the ACA premium subsidies issue alive for the mid-terms, by bring the House back into session to deal with the continuing resolution, the capitulation accelerates the Epstein files discharge petition that Speaker Johnson would prefer to suppress. It might actually be smart politics (from D party interests perspective, regardless of real-world impacts on the population); the fact that it is being characterized as D fecklessness might be a bonus. This thought is not offered in praise of the Party; what has been done might be an objectively evil calculation, but a clever one. I think they’re playing good cop/bad cop. The “centrist” dems were recruited by the dnc to be the firewall against any movement left. It’s a rotating and unbeatable cast from manchin and sinema to the current crop of left wing republicans, We are a one party state, Remember the mississippi guy who self financed and was excoriated by the “centrists” for bucking the party. Mamdani sends chills down their spine. Socialism is for the rich and deserving. Part at least of the reason the r’s can’t replace ocare is because ocare is their plan so the protests are all an act. From their collective perspective mamdani winning was a major loss. They’re despicable. And guaranteed grocery lobbyists were banging their turkey pans to get the money flowing. Maybe the epstein thing will pan out, and maybe not,As an confirmed cynic I lean to the latter. Somebody tell me what I’m missing other than the Democrats wanting to slow walk to the day ACA health insurance premiums are $5,000 per month and still in need of subsidies. As I am ALWAYS in search of methods to amuse myself, I was over the moon wonderstruck by the link to the young lady playing classic rock on the Chinese lute. I lost an hour of a otherwise mundane morning grinning from ear to ear. Thank you for the link, which has now been shared with all my music friends (with source attribution, of course) She’s good, but can she do covers with throat singing in Mongolian translation? Side note: The Hu mostly do originals. Had a chance to see the, live a few years ago and they were great. The Hu were one of the bands that helped get me out of the grumpy old man “all new music sounds like stuff I’ve heard before” doldrums I had been in for a while. Their first album is truly special. Last year they released a cover of Iron Maiden’s The Trooper: The HU – “The Trooper” (Official Music Video) In case of “all new music sounds like stuff I’ve heard before” syndrome, nine out of ten doctors recommend getting out of your comfort zone. :) Jokes aside, musical genres can be defined as stuff that sounds like some other stuff. There is always new & unheard stuff in unconsumed genres, and in the space betwen them (for an example see below). Here’s something for your musical friends :) https://www.youtube.com/watch?v=hT7x1NvGf5k&list=RDEM6kSy5Si3f_-hq8qxMKi3Lw Hudson/Wolff on Mamdani and much else. Great stuff. https://michael-hudson.com/2025/11/municipal-socialism-meets-donor-politics/ “And the Republicans and Democrats want to treat New York City like the United States and Europe treated Soviet Russia after its revolution.” Might want to slow the row on all of that hyperbole. Not denying the part about the obstacles coming, but it’s not like it was the Russian Revolution. Mamdani could play Kerensky in this psychodrama. “TRUMP PLAYS THE OLD CIA CARDS FOR REGIME CHANGE” A pro-tip for the Trump regime. If you are going to send covert operations teams into a country like Venezuela, then best you do not advertise the fact but keep everything quiet. Trump does not need the spectacle of a bunch of captured CIA spooks shown off in public. Caitlin Johnstone explains the Israeli “don’t be a sucker” method. https://consortiumnews.com/2025/11/10/caitlin-johnstone-israels-successful-method/ Trump calls this “the art of the deal.” “If I don’t steal your home, someone else will steal it” 3 Epstein emails released by the Dems, all involving Trump. https://oversightdemocrats.house.gov/sites/evo-subsites/democrats-oversight.house.gov/files/evo-media-document/3-emails_redacted.pdf Per the Guardian In one of the memos, Epstein wrote to his co-conspirator Ghislaine Maxwell in 2011 that Trump “spent hours at my house” in the company of one of the disgraced financier’s sex-trafficked victims. The memo describes the president as “that dog that hasn’t barked”, and notes Trump had “never once been mentioned” in connection with what has become a long-running scandal overshadowing his second term of office. A second message, sent by Epstein in April 2011 to Trump biographer Michael Wolff, indicates that Trump had asked him to resign from Mar-a-Lago, the president’s exclusive members-only club in Florida. But Epstein said he was “never a member ever” and adds “of course he knew about the girls as he asked Ghislaine to stop”. Ben Panga: It’s all fun and games till Bill and Hillary show up on lists. Then watch the Dems squeal. My attitude: Mr. Guillotine’s clever meat slicer. One size fits all. Bill and Hill are pretty far back in the rear-view mirror, even for the Dems. A trade of sacrificing that duo in exchange for taking down Trump seems more than even, to me. Then there is the Wizard of Kalorama, who would surely benefit somehow from all of their downfall. I’m more than a bit skeptical of the authenticity of those emails, no? I find Whitney Webb’s articles credible. By that metric, specifically the power dynamic Webb describes existing in the sphere of Epstein’s bosses and business associates, the Clintons may be untouchable. The same method would explain Maxwell still being alive and enjoying privileges while in confinement. This is Robert Maxwell’s daughter after all. I always said the NC link header “L’affaire Epstein” should be “L’affaire Maxwell-Epstein”. Last night’s northern lights was quite something to see~ Tonight’s spectacle promises to be something special, peaking around 10 pm @ an overhead view near you. Unfortunately it looks as if Big Smokes and coastal cities in Cali will have poor visibility for the event, time for an after-work road-trip Californios! Our new planetarium had a great show called Aurora where a photographer went to Yellow Knife in Canada and pointed a hi def wide view camera straight up at the Northern Lights. On the planetarium dome it’s you are there. Spectacular. > Starmer allies issue warning to PM’s rivals as fears grow over leadership challenge Guardian What do dissidents in the PLP think they accomplish by replacing Starmer as PM with Angela Rayner, Shabana Mahmood or Ed Miliband? Seems to me the constraints of any neoliberal UK government are pretty much set and policies follow from that. Any such government will be hated soon enough. Making Miliband the face of it doesn’t fix much. Or what am I missing? Reportedly Labour party members are terrified that they are going to lose huge numbers of local government seats at the elections due in May 2026. Some seem to think that a fresh face will enable them to reduce their losses then. All very short-term thinking. Of course the big showdown, the national General Election, will probably not take place until 2029. Today, the House does something it hasn’t done since September 19th: show up for a vote. And even in September, these stumblebums worked for a grand total of twelve days. Must be nice. Back in July, when the cowardly Mike Johnson skedaddled out of town like a fly-by-night con artist to evade a vote on the Epstein files, NFL training camps hadn’t even opened. The plan apparently is to vote on the new bill to reopen the government, take a long weekend, and possibly work a few days next week before disappearing again for Thanksgiving week. I think this deserves a tribute in song. Carry on, My Wayward Bums Carry on, my wayward bums The skids are greased now, shutdown’s done Lay your committee heads to rest Don’t you trade no more [Intro instrumental] ahh … [Verse 1] Once I rose above the noise and confusion Just to get a glimpse of Donkey illusions Their polls kept soaring ever higher But they got too high [Verse 2] Though my eyes could see they’d fold like a cheap tent Though my neighbor cannot make up the back rent I hear the voices when I’m dreaming I can hear them say Carry on, my wayward bums The skids are greased now, shutdown’s done Lay your weary heads to rest Don’t you trade no more [Verse 3] Masquerading as a base with a reason They’ll just yawn while Donald Trump commits treason And if I claim to be a moderate, well It surely means I’ve got no balls On the stormy sea of shutdowns and motions They’ll just genuflect to thugs ‘cross the ocean They’ve set a course to raise their fortunes But I hear the voices say … Carry on, my wayward bums The skids are greased ’til empire’s done Lay your committee heads to rest Don’t you trade no more No! [Break] carry on … we will always remember carry on … your defeat and surrender Now my health care bills are sky high … surely Hades waits for you! Carry on, my Epstein bums The skids are greased now, shutdown’s done Lay your committee heads to rest Don’t you trade, don’t you trade no more [Instrumental outro] (Melody and original lyrics by Kansas, “Carry on my wayward son”) https://www.youtube.com/watch?v=P5ZJui3aPoQ&list=RDP5ZJui3aPoQ Would state referendums requiring elected officials from the state spend a minimum of 40 hours a month meeting with constituents ( must live in the district, be from a variety of financials classes present in the district and cannot include lobbyists) be legal? This including both state and federal members. I would love to see elected officials be legally required not just to have to meet the responsibilities of their job more than their fundraising, but to have one of the required responsibilities to be regularly meeting with the people they are elected to represent. Instead we are paying a lot of people to beg and suck up to a small coterie of rich people. One of the arguments I heard Mike “the weasel” Johnson make was to the effect of, “oh, we’re still working, we’re just back in our districts meeting with constituents.” And there may be some truth to that, although something tells me that not all 435 of these guys and gals were really spending their time talking to the rabble, and not off on a junket bending the knee for the Israeli flag. Or fundraising. Your idea is an excellent one, but I have no idea if it would pass Constitutional muster. I’m 100% for such meetings! Considering how much of their time is occupied in funds raising, perhaps the best way to rein in the political parties would be to revoke their tax exempt status. Then go after all those dodgy “Advocacy Committees.” simpler to just feed them to the pigs and start over. altho i am a bit drunk and surly…spent 3 hours in a mudhole fixin mom’s ancient water supply pipe(1960’s era black poly pipe)…and cannot lay down, lest i seize up, entirely. laid down the law…instead of spending 25K on fixin the whole decrepit system under her house, she will pay me 5k to walk by and get it done, come spring. all the 100+ years of under the house plumbing will be simply disconnected, and left in place. all the random repairs done in that time, by unknown folks, with whatever was to hand, ignored. we’ll do what i did with my house, and go around the perimeter, and only come into the house where required…. that 3 hours of bullshit honey-do kicked my ass….and covered my whole body with mud. but i walked by, and got it done, and she has water. fie. Poor man, well do I remember the abomination that is black poly pipe. Coterminal with the old multi-layered tarpaper sewer pipe. The only thing I feared more than those two was repairing lead and oakum joints in cast iron sewer pipe. Sleep well, you’ve earned it. Myself spent hours digging under the porch, tracking a groundhog tunnel that took aim at our new sewer line. Second hole I dug myself in today. Thanks for the song. Excellent work once again. Disrespecting sacred spaces is part of… the hallmark of Western imperial colonialism. Ànd probably colonialism in general. I am not a scholar. Common experiences of many sacred spaces in times of conquest–symbolically convert infidels’ houses of worship to your own, if they are important enough, or blow them up. Hagia Sofia is a famous example, but many mosques/churches in Iberia and Middle East used to be churches/mosques, and, of course, many Protestant churches used to be Catholic (well, almost anything in England) and quite a few churches belonging to the wrong peoples were blown up (if only figuratively in some cases), like Alexander Nevski in Warsaw. Just wait until the nukes go off above Jerusalem. Meanwhile in Ellison world claims that they are blacklisting actors who object to genocide. Guess Emma Stone won’t get to star in any of Taylor Sheridan’s dubious products. https://scheerpost.com/2025/11/11/paramount-blacklisting-hollywood-figures-critical-of-gaza-genocide/ More Teens Are Taking Antidepressants. It Could Disrupt Their Sex Lives for Years. (NY Times Mag via archive.ph) Research on adults who take S.S.R.I.s shows they tamp down sexual desire. Why aren’t we studying what that could mean for adolescents who take them? You know what else is happening to teens and adults every year? COVID. COVID penis is a thing. If you want a functional johnson, don’t get infected! But we don’t care about repeat infections with a level 3 biohazard, no issues there! The effects of S.S.R.I.s on young sexuality are all the more relevant because prescriptions for the drugs have soared. Around two million 12-to-17-year-olds in the United States are on S.S.R.I.s. One large 2024 study in the journal of the American Academy of Pediatrics tallied, month by month, the percentage of that age group who filled an antidepressant prescription between 2016 and 2022. During that time, the rate climbed by 69 percent, with the Covid pandemic’s emotional reverberations almost surely playing a part, though a notable rise was underway before then. Among college students in 2023-24, according to a survey with over 100,000 participants, 22 percent had taken an antidepressant during the previous year. This was up from 8 percent in 2007. (bold mine) If you think that’s bad, just wait until you get long COVID! Does long COVID come with long johnson? It might leave you longing for the return of your johnson. An old girlfriend of mine didn’t call it a johnson…she called it an opportunity. From Trump’s H-1B Visa Crackdown to Accelerate Wall Street’s Expansion in India Catch this; Remote work for capitalists offshoring to save a buck, but not for you, to improve your life Trump’s $100,000 fee for visa applications — which JPMorgan Chief Executive Officer Jamie Dimon said “caught everyone off guard” — could add to India’s edge, just as the pandemic gave GCCs a boost by showcasing the potential of remote work. Companies that might consider transferring a worker to the US may now opt to hire them in India instead, banking executives said. (bold mine) Remember, learn to code? Get a STEM degree? LOLz “With the new fee, they’re starting to question if that job is a priority for them,” said Ben Hodzic, head of North America at recruitment firm Selby Jennings. Jobs with a heavy math or computer science component are most at risk, he said. Thanks Obama! For most roles, India offers employers significant salary savings relative to other countries. For an entry level role at a US bank’s GCC, an engineering graduate could earn between 300,000 rupees ($3,384) to 800,000 rupees a year, depending on the location. That compares with $60,000 for an Indian on a US visa, and up to $120,000 for a US citizen in the same role, according to people familiar with the matter. That’s some serious labor arbitrage, no? And once again we see that H1B was about suppressing US wages. What is the tweet from “RT.” supposed to be claiming? $NVAX has been flat since 2023. That blue line is not real. ‘Human safaris’ in Sarajevo: Milan investigates 1990s trips where tourists allegedly paid to kill civilians, El Pais. Sniper tourism. Reminds me of the Brazilian movie Bacurau. It should remind you of Ukraine, and Syria, and all the other places where USA sponsored “freedom fighters” did their thing, and still do their thing. For sure, and in this case willing to pay around a hundred grand for the privilege. To be weekend snipers, they reportedly paid the equivalent of between €80,000 ($92,800) and €100,000 ($116,000), according to the first hypotheses of the investigation. Shooting at children cost more. Alleged, thesis, allegedly, according to the complaint, reportedly, according to the first hypotheses, rumored, clues about the possibility, “an urban legend”, Russian. In this case, I belive that the USA side did it, just like in all other cases. Accusing the “Russians” is part of the spiel. I won’t argue that point as it’s always a reasonable argument, and it sounds like something the izzies/usians would do. It’s the demand side that baffles me. And this was back in the 90s. How much has the industry grown since then? The client list would likely make for interesting reading. I heard the same about Lebanon during the civil war there. Wealthy westerners would pay for trips in to do a bit of sniping so that they could go home with some human kills on their board. Something tells me though that those kills were not Lebanese soldiers or militias. An ingenious way to fund the cause, it’s like having a bake sale. Speaks well of the human condition, lol. Rare good news. My auto insurance went down again. Farm bureau insurance of NC. Kinda shocked. https://oilprice.com/Geopolitics/Asia/Trump-Revives-USCentral-Asia-Ties-with-25-Billion-in-New-Deals.html According to the U.S. International Trade Administration, the deals between U.S. and Central Asian firms totaled $25 billion and included: All American Rail Group Global: rail construction and engineering in the Kyrgyz Republic Boeing: up to 15 787 Dreamliners (Kazakhstan); up to four 787 Dreamliners and 10 737 Max airliners (Tajikistan); and eight more 787 Dreamliners, bringing the prior total to 22 widebody jets (Uzbekistan) Cove Capital: privatization of a tungsten mining company in Kazakhstan John Deere: agricultural machinery for Uzbekistan and Kazakhstan Leidos: upgrade of Kazakhstan’s National Air Traffic Management System. MOUs between Nvidia, the Ministry of Artificial Intelligence & Digital Development, and Freedom Holding Corporation for Advanced AI chips in Kazakhstan The key takeaways from the C5 +1 are: Strengthening the Strategic Partnership and Mutual Trust. The U.S. and the republics underscored their shared commitment to building a long-term, strategic dialogue based on mutual respect, trust, and shared values. The C5 + 1 partnerships will be grounded in transparency, innovation, and shared global responsibility. Deepening Economic and Investment Cooperation. U.S. focus is shifting to economics and business and away from security-only policies. The leaders’ meetings with U.S. business and financial leaders laid the groundwork for a new phase of trade, investment, and industrial collaboration in key areas such as green energy, advanced manufacturing, infrastructure development, digital transformation, and technology innovation. Advancing Regional Connectivity and Sustainable Development. Economic connectivity, energy transition, regional security, and climate resilience are key to regional unity and integration, fostering a stable, prosperous, and interconnected Central Asia that contributes to global peace and sustainable development. Opening a New Chapter in U.S.–Central Asia Relations. The leaders’ shared vision aims to foster innovation, resilience, and shared prosperity for the U.S., Central Asia, and the broader international community. OMG Sergey Lavrov: “We know what the Americans have, and the Americans know what they have. Let’s take a year to, so to speak, cool down Sanity “EU eyes banning Huawei, ZTE Corp from mobile networks of member countries” and “EU’s top judge hits out at Viktor Orbán, warning that the bloc’s funds must not enrich a ruling elite” or some naughty nation’s “public procurement is systematically refused to out-of-state business, favouring the businesses around the leader or the governing party, the leading party.” The unelected leaders of the EU institutions really see themselves as the shit bedraggled tail wagging the member state dogs. Just to make it clear that it is Hungary being sent to the naughty corner because it’s elected officials are protecting the country’s national interests the “EU’s top Judge”, in the words of the Euractiv report, Lenaerts, who “argued that participation in the European Public Prosecutor’s Office (EPPO) – the EU body that investigates and prosecutes crimes involving the Union’s funds – should be mandatory for all countries that receive EU funds. “He described how in some member states probes by the European Anti-Fraud Office (OLAF) – the EU agency tasked with detecting misuse of EU money – “end up in the wastebasket,” lamenting that “the whole system is closed.” “Hungary, notably, has refused to join the EPPO, even though it has no formal opt-out from EU justice cooperation — leaving OLAF dependent on national prosecutors in Budapest, who critics say rarely act on its findings.” Wonder what stage OLAF and the EPPO have got to in the investigation and prosecution of fonda Lyin’s no longer existent trail of electronic messages dealing with EU business. Maybe Huawei and ZTE Corp can throw some light on the contents for us? Leavitt to Believer This week’s episode has Karoline on the defensive, it appears that it was Eddie Haskell who pal’d around with Jeffrey Epstein-not the President. In a Hail Mary toss, she even seemed to implicate Genocide Joe but it fell to the groundless. File under A Win For Womens Sports. From Vigilant Fox: The Olympics Finally Admit What Everyone Already Knew: Men Have an Advantage in Women’s Sports https://www.vigilantfox.com/p/the-olympics-finally-admit-what-everyone “The Olympic Committee appears to have suddenly stumbled across startling new evidence that suggests biological men have advantages over women in sports. Multiple reports are outlining that the IOC is to enact a new policy banning transgender individuals from competing against women. It will also cover those with differences of sex development (DSD), essentially individuals found to have XY chromosomes, such as Imane Khelif, the boxer who punched through every women to win gold at the last Olympics in Paris. Newly released emails reveal Epstein kept close eye on Trump (Guardian) (more emails than the 3 in the news last night) Epstein as Mossadish actor is not getting less believeable. Guess: Ghislaine will be pardoned on Trump’s last day and she can retire to Israel. Your email address will not be published. Required fields are marked * Comment * Name * Email * SUBSCRIPTIONS
--------------------------------------------------

Title: How Catastrophic Is It If the AI Bubble Bursts? An FAQ. - The Ringer
URL: https://www.theringer.com/2025/11/04/tech/ai-bubble-burst-popping-explained-collapse-or-not-chatgpt
Time Published: 2025-11-12T05:47:02Z
Full Content:
You've probably noticed that many people are saying we're in an AI bubble. "OpenAI's Sam Altman sees AI bubble forming," CNBC reports. "Fears of an AI bubble are growing," NBC News states. "AI Is the Bubble to Burst Them All," Wired announces. "Mark Zuckerberg says a ‘collapse’ is ‘definitely a possibility,’" Fortune declares. You've probably also noticed that almost everyone who uses the term “AI bubble” starts to sound very boring and confusing immediately afterward. This is because the people who bring up the AI bubble tend to be market analysts, and most market analysts would rather have potatoes growing inside their bodies than talk like a normal person for four seconds. So what is an AI bubble? Are we in one? How scared should you be? What happens if the artificial intelligence industry blows a trillion-dollar hole in the non-artificial economy? What happens if it doesn't? Let's walk through this thing together. Yes. Because the gigantic numbers floating around the AI economy—deals worth trillions, data centers costing tens of billions, 75 percent of gains in the S&P 500 centered on AI stocks—are almost entirely driven by hype, and the hype has come unglued from reality. The hype around AI insists that it's a world-transforming technology that will revolutionize every aspect of human society. The reality, which we'll explore in more detail in a second, is that AI companies are burning through staggering amounts of money (and fossil fuels) with no clear path to profitability, that the companies themselves aren't super clear about what their products are for, and that many of those products have failed to perform in the applications they've been assigned to (AI search engines return inaccurate information, AI teachers impair learning, AI therapists make mental health worse). Worse yet for the industry, the biggest players are increasingly tied up in time-bomb financial deals that look disastrous for their futures in any but the rosiest of best-case scenarios. But because the hype around AI is so pervasive—who doesn't want to own a chunk of the technology that will determine every aspect of humanity's future?—investors have continued plowing money into the field despite the warning signs, sending stock prices into orbit. As of last week, Nvidia, the leading AI chipmaker, is the first company in history whose stock is priced at over $5 trillion in total—meaning this one individual company accounts for roughly 8 percent of the S&P 500. That's a bubble. Plain English Tackles the AI Bubble Everybody Thinks AI Is a Bubble. What If They’re Wrong? This Is How the AI Bubble Could Burst Is AI Really About to Solve Human Disease? Plain English Tackles the AI Bubble Everybody Thinks AI Is a Bubble. What If They’re Wrong? This Is How the AI Bubble Could Burst Is AI Really About to Solve Human Disease? It's what happens when the price people are willing to pay for a thing exceeds the value of the thing by some drastically untenable amount. It's hard to give a more technical definition, because determining the correct value of anything is weirdly tricky beyond a certain point. Markets, for all that people pretend otherwise, are extremely susceptible to vibes. Past bubbles have inflated around everything from tulips to Japanese real estate to the original wave of dot-com stocks in the early 2000s, but let's run with a simpler example. Say there's a new hype sneaker. It costs $18 to manufacture, it retails for $100, and it's going for $1,800 on StockX. What's its correct value? Everyone can kinda sense that $1,800 is too much to pay for it, but the price keeps going up, so people keep snapping up more pairs, often hoarding multiples in the hope of flipping them for a profit. The price hits $2,000. Then, suddenly, a guy gets nervous and sells 10 pairs for a little less than the current max. People notice this and start selling off their own pairs for whatever they can get before the price craters. By the end of the next day, the bubble's popped. The price is down to $150. People who held their pairs take a massive loss; people who flip sneakers full time have spent a fortune and can't sell their current pairs for enough to refresh their inventory. Why did the price spike? Because people convinced themselves it made sense to spend that much. Why did the price collapse? Because the people who collectively propped up the delusion that the price made sense got spooked and decided to get out with what they could before everyone else decided it didn't. It means that the AI industry's most important product at this moment is not a chatbot or a video generator; it's the story the AI industry is telling about itself. There's a saying stock market people pass around: "The market can remain irrational longer than you can remain solvent." The market is definitely irrational right now; the goal of the AI industry is to keep it irrational until the industry can figure out a way around the mess it's created for itself. How bad is the mess? OpenAI's ChatGPT, by far the most successful generative AI product to date, requires so much expensive computing power to run that it loses money almost every time you use it. (For the first half of 2025, OpenAI took in $4.3 billion in income and still reported a net loss of $13.5 billion.) A recent Deutsche Bank report says that the AI boom is "unsustainable." Bain & Co.'s annual global technology report says the AI industry will need $2 trillion in annual revenue by 2030 to continue at its current rate. (That number will be, um, hard to come by.) A Bank of England report warns that the market could experience a "sharp correction" due to the overvaluation of AI companies. Companies with no clear plan for making money from AI have poured cash into the construction of data centers so massive that they're straining the electrical grid and driving up the price of electricity for the rest of us. They've poured cash into what's called "compute"—processing power, basically, used to train AI models and run search queries—at a rate they can't keep up unless the entire world economy reorganizes itself around their products by, like, Tuesday. All that tech has a shelf life, just as your iPhone does; the industry will have to keep spending ruinous sums every few years to replace it. And to keep the ball in the air, the companies have made a number of increasingly bizarre, shady, and circular deals with each other: Nvidia, for instance, has invested $100 billion in OpenAI, which OpenAI must then turn around and spend on Nvidia products. If I give your lemonade stand $10 so you can buy my $10 lemons, we can't tell our investors (your mom) that we've boosted the lemonade economy by $20. But that's the kind of reasoning that fuels more and more of Silicon Valley's grandiose claims about itself. The thing is, though, the price of a stock is not determined by the soundness of the company. It's determined by the willingness of investors to pay a certain price. And there are ways to convince investors to pay high prices for shares even when it means driving through an endless series of flashing red lights. If you can, say, leverage three decades of mythmaking about the transformative impact of the tech industry by convincing a compliant press to spread the word that your new product is poised to make every sci-fi dream a reality—cure cancer, bring humanity to other planets, create flying cars—then the sheer size of the vision you're peddling might convince investors to buy in, even if doing so seems reckless. Tech investors, especially the superrich ones, are always in the market for stories scaled to their egos, and their egos are getting more messianic all the time. And in the era of crypto and Robinhood, regular idiots like us increasingly see the stock market as a casino. Pushing some chips onto the new, hot, famous, sexy thing seems way more exciting than researching the fundamentals of some well-run company no one's talking about. Plus, everyone else is doing it. OpenAI is currently targeting a $1 trillion IPO. The basis of that number is not—like, extremely not—the solid state of the business. It's the story the company is telling. Talking a big game has thus become the essential and necessary activity of AI companies. (This includes acknowledging the possibility of a bubble as a form of panic mitigation: That way, if the bubble does pop, the wise, patient tech CEOs can say they expected it all along.) AI storytelling is an amalgam of several different narratives, including: As far as I can make out, the scheme is essentially: Keep the ship floating for as long as possible, keep inhaling as much capital as possible, and maybe the tech will get somewhere that justifies the absurd valuations, or maybe we'll worm our way so far into the government that it'll have to bail us out, or maybe some other paradigm-altering development will fall from the sky. And the way to keep the ship floating is to keep peddling the vision and to seem more confident that the dream is inevitable the less it appears to be coming true. Fatherhood and Forgiveness With Roy Wood Jr. Plus, Ed Zitron Breaks Down the “AI Bubble.” Fatherhood and Forgiveness With Roy Wood Jr. Plus, Ed Zitron Breaks Down the “AI Bubble.” Fatherhood and Forgiveness With Roy Wood Jr. Plus, Ed Zitron Breaks Down the “AI Bubble.” Yes. Last week, as Nvidia was crossing the $5 trillion threshold—making the chip manufacturer worth approximately as much as the gross domestic products of France and South Korea combined—several of the so-called Magnificent Seven tech companies released their earnings reports. It was a sensitive moment for big tech. All year, murmurs of a bubble had been growing louder. Deutsche Bank called summer 2025 "the summer AI turned ugly." A series of bad earnings reports could have triggered a major sell-off. The air over Northern California could have echoed with a hollow popping sound. Instead, the earnings reports were … OK? Alphabet, Google's parent company, notched its first $100 billion quarter. Microsoft beat expectations. Meta's stock slid after it announced a one-time tax charge, but not drastically. No bubbles were seriously threatened. If you looked a little more closely, though, there were further signs of strain in the industry. Microsoft's stock slid 5 percent immediately after its earnings call, which analysts interpreted as a sign that the market is mildly freaked out about how much money the company is plowing into AI infrastructure. ("The vibe is cautious," TheTradable reported.) The companies were a little vague about how much revenue they're actually bringing in from AI, or how they expect to make money from it. Zuckerberg, defending the vast sums Meta is pouring into its data centers, unwittingly summed up the uncertain mood when he said that this kind of infrastructure spending "is very likely to be a profitable thing over … over some period." Pretty bad, man! On paper, at least, the ungodly sums AI companies are spending on their infrastructure are propping up the American economy almost single-handedly. In the first half of 2025, spending on data centers accounted for most of the economic growth in the U.S., outpacing all consumer spending combined. (You'll see this reported in ways that make it sound as if the economy is being bolstered by the money AI companies are making, but no, it's the money they're spending that's relevant.) On the other hand, "on paper" may not be the best way to understand the state of the U.S. economy right now. It's been widely observed that many regular people feel the economy is bad, while economists, when they look at the numbers, say it's relatively strong. This disparity is probably in part because, on paper, Meta dumping a thousand trillion dollars into a Death Star–sized “superintelligence lab” with 11 employees in rural Idaho boosts the numbers, but in reality, Zuckerberg's real estate binges have a limited effect on conditions outside the semi-closed loop of the AI industry. (This may be especially true now that private equity funds are getting involved in data center financing.) Groceries are getting more expensive. Utilities are getting more expensive. Thanks to the Trump tariffs, almost everything we buy is getting more expensive. None of that is offset by AI investment, and if AI investment stopped tomorrow, the immediate impact on many people's daily lives might be less than you'd expect. That also applies to, as you might guess, non-AI businesses, many of which are also struggling. Many have scrambled to incorporate AI into their operations, drawn by the promise of a technology that would cut labor costs and revolutionize productivity. Yet according to an MIT study released in August, 95 percent of businesses that have deployed generative AI have gotten no value from it. It's not clear that the AI bubble bursting would have a devastating effect on them either, at least directly. Indirectly, of course, things look quite different. A sharp contraction in tech would put tens of thousands of people out of work, vaporize trillions of investment dollars, torpedo retirement and education funds, obliterate life savings, and ruin lives. It would be a violent shock to a system that's already under strain. Of course, one of the reasons the economy is under strain is the massive concentration of wealth in the hands of a small number of oligarchs, and those same oligarchs would like to use AI to replace the human labor force—likely putting tens of thousands of people out of work, vaporizing non-oligarchic wealth, obliterating savings, etc. It may be better for the world for the bubble to pop, whatever damage is done. For now, though, we are living in the storytelling economy. As long as the shared fantasy of the AI industry holds Silicon Valley and its investors in thrall, the reckoning can be deferred. And in the meantime, who knows? Maybe the bubble will never pop. Maybe the people who've sold the fantasy can figure out how to keep us believing long enough for someone to create it, or at least to dream up a new one and hope we don't notice the difference. It's bitterly funny, though, that up until now, some of the biggest victims of AI companies have been the artists, writers, actors, and filmmakers whose creative work the companies want to cannibalize and replace. The industry has shown nothing but contempt for narrative art that speaks to the human imagination—the very thing that's keeping it alive. Latest in Tech Just the hits, straight to your inbox every week We’ve been around since Brady was a QB
--------------------------------------------------

Title: 10 Proven Vacation Rental Marketing Ideas for 2025 (That Actually Drive Bookings)
URL: https://ahouseinthehills.com/vacation-rental-marketing-ideas-2025/
Time Published: 2025-11-12T05:43:24Z
Full Content:
Get our Design Ideas in your inbox! Sign up U.S. short-term-rental demand jumped about seven percent in 2024, yet supply lagged—so every booking now counts. Travelers still crave one-of-a-kind stays, which means generic marketing won’t cut it. That’s why we built this playbook. It ranks ten battle-tested tactics by impact, cost, and effort. Each move works on a lean budget, scales from a single cabin to 50 condos, and typically pays for itself within 90 days. Pick the tactic that matches your goals, layer on the rest, and keep your 2025 calendar packed. U.S. short-term-rental demand climbed seven percent in 2024, while active listings grew about five percent, a gap wide enough to keep rates healthy yet narrow enough to sharpen competition. (help.airdna.co) According to AirDNA, the supply surge that began during the pandemic is still visible. Non-professional hosts saw occupancy dip to roughly 54 percent in early 2024 before edging back toward 55 percent by mid-2025—evidence that guests now have more choice. Statista projects vacation-rental revenue to exceed about $105 billion in 2025. With demand still outrunning new supply in many drive-to markets, you can secure a larger slice without overspending, a theme we explore next. Rental-industry analysts at Rental Scale-Up note that Airbnb’s search model now weighs more than 800 signals and puts extra weight on booking probability plus guest-satisfaction cues such as transparent fees and replies in under an hour. Vrbo and Booking.com are rolling out similar quality-score updates that lift listings most likely to convert. Across U.S. markets, one in four reservations now lands within five days of arrival, down from one in six in 2022, AirDNA data show. Remote workers and multigenerational groups often decide mid-week and travel the same weekend, so outdated minimum-stay or pricing rules can leave revenue on the table. Two- to four-bedroom homes sit in the sweet spot for last-minute demand, and large groups now feel comfortable booking a 10-person getaway just two weeks out, according to AirDNA’s STR Data Lab podcast. Expect jagged occupancy patterns instead of tidy week-long blocks. New York City’s Local Law 18 blocks OTAs from processing reservations at unregistered homes, cutting thousands of listings since full enforcement began in September 2023. In Dallas, a 2023 ban on short-term rentals in single-family zones remains on hold after a 2025 appeals-court decision, creating a patchwork of “allowed but unsettled” neighborhoods. If you watch these moving parts and adjust pricing, policies, and marketing in real time, you stay visible. Coast, and you risk vanishing from search and local maps. We started with four must-haves. To rank each idea, we built a Priority Score: Impact × 2 – Cost – Difficulty. We then color-coded the results (green 🟢, amber 🟡, red 🔴) so you can adjust weights to fit your goals and skills. With the scorecard set, the first idea shows why professional marketing help can secure more nights on the calendar. Great marketing depends on three scarce resources: time, technology, and continuous tuning. When you already juggle guest messages, turnovers, and repairs, outsourcing growth to a professional team can free up evenings and lift revenue. Full-service vacation-rental managers bundle multi-channel distribution, dynamic pricing, and professional photography. SkyRun Vacation Rentals manages thousands of homes across North America’s most-loved destinations and uses centralized systems to publish one listing to Airbnb, Vrbo, Booking.com, and Google while syncing calendars and adjusting rates as demand shifts. Their centralized systems publish one listing to Airbnb, Vrbo, Booking.com, and Google, sync calendars, and adjust rates as demand shifts. AirDNA reports that managed listings earned 15–20 percent more revenue year over year than comparable self-hosted homes, comfortably covering a typical 20 percent commission. Real-world proof: an AirDNA case study found that Phoenix-area manager Venture REI used data-driven pricing and wider channel reach to raise one owner’s occupancy from 72 percent to 92 percent in a single quarter. If you consider a partner, vet them the way guests vet you. Ask for transparent performance reports, local market knowledge, and clear service tiers. A good manager works like a revenue coach, sharing data that shows exactly how each booking reaches your bank account. Property type + standout feature + key amenity + location cue Example: Lakefront cabin w/ private dock, dog-friendly. Clear language earns the click. AirDNA’s content review shows that listings between 250 and 350 words convert 12 percent better than very short or very long blurbs. Guide readers from arrival to bedtime, weaving in sensory details plus quick answers on parking, Wi-Fi speed, and fees. Update photos each season, adjust the title for local events, and trim outdated lines. Frequent edits nudge you up in search results and signal care to returning guests. Relying on one OTA is like putting all your savings in a single stock; one algorithm tweak or city rule can cut cash flow overnight. A multi-channel plan spreads risk and reaches new demand. Travelnest reports that hosts who diversify beyond their primary site gain up to 30 percent more bookings year-round. Different sites reach different travelers: A channel manager such as Rentals United or Guesty for Hosts syncs rates, rules, and availability in real time. That prevents double bookings and lets you fine-tune prices by channel. One Rentals United case study recorded a 40 percent lift in occupancy after expanding to new channels with automated sync. Aim for the big four—Airbnb, Vrbo, Booking.com, Google—plus one or two niche or regional sites that match your ideal guest. Keep photos, pricing, and policies consistent to build trust with travelers and search algorithms, and you stay visible even if one platform stumbles. Major OTAs keep 10–15 percent of every reservation as commission. Airbnb’s host-only fee rises to 15.5 percent for software-connected listings in October 2025, and Booking.com already averages about 15 percent. That slice of revenue disappears, and you also lose the guest’s email, upsell options, and control over ranking. A direct path on your own site flips the math. You keep the commission, own the contact list, and shield your business from sudden policy changes that can freeze an OTA account. Pass part of the saved fee back to travelers—a five-percent lower nightly rate or free early check-in—and you stay cheaper than your OTA listing while pocketing the same margin. TouchStay notes that hosts who convert just 20 percent of stays to direct save thousands in annual fees, smoothing seasonality and trimming ad spend over time. Think of your site as the property’s digital front door. It needs only four elements: Most hosts launch a direct site through their property-management system or a WordPress template. Connect Stripe or Square, upload professional photos, and you can go live in a weekend. Next, publish two evergreen blog posts that solve travel-planning headaches—“Best kid-friendly hikes near Gatlinburg” or “Where to park for Mardi Gras.” End each post with a soft “check availability” link. Finally, reward past guests for booking direct: offer a five-percent repeat-stay discount or free late checkout in your post-departure email. Small perks chip away at OTA dependence with every return visit. Static nightly rates are guesses. Dynamic pricing tools track live signals such as local events, competitor rates, and booking windows, then refresh prices every day. Rates rise the moment a festival sells out and drop mid-week to keep occupancy steady. Getting started is simple. Connect a service like PriceLabs, Wheelhouse, or Beyond, set your floor and stretch targets, and let the algorithm handle the dials. Beyond users report 10–15 percent higher annual revenue after switching from manual pricing. The lift shows up two ways: average daily rate climbs on peak nights, while occupancy improves in shoulder seasons when the tool lowers prices to capture last-minute stays. Review your pricing calendar weekly to spot odd spikes, and adjust minimum-stay rules to two nights in low season and three or four when demand is high to balance turnover costs. With pricing on autopilot, you can focus on guest experience instead of spreadsheets and out-earn neighbors who still set one price and hope for the best. New guests cost money, whether it’s commissions, ads, or hours of messaging. Past guests cost almost nothing. Hostfully’s 2024 Hospitality Report shows that repeat guests generate 33 percent higher lifetime value and need 50 percent less marketing spend. Staying in their inbox keeps that value flowing. Build the list on checkout day. Export the reservation, tag it “opt-in,” and drop the address into a free platform such as Mailchimp. Email once a quarter. TouchStay recommends quarterly cadence for short-term rentals; more frequent sends feel spammy when travelers book only once or twice a year. Highlight one upgrade (new firepit), two local events, and an early-bird deal, such as 10 percent off spring dates booked by February. Segment for relevance. Families who stayed in July care about school-break deals; remote workers from November want winter monthly rates. Most PMS tools auto-label stays by party size and season, so filtering takes minutes. Add a loyalty hook. “Book direct next time and enjoy free early check-in” costs nothing most days and signals VIP status. Track perks in a spreadsheet and deliver on arrival; 64 percent of operators already use special offers to secure repeat stays. Stack these quick emails to stay top of mind, fill shoulder-season gaps, and cut dependence on paid channels. Travel dreaming starts on phones long before it reaches Google. Forty percent of leisure travelers say social media sparks their trip ideas, and Guesty notes that listings for a well-prepared vacation rental property with an active feed earn 37 percent more bookings than silent ones. The cost is mostly your time, not cash. Pick one or two channels that match your audience. Instagram reels wow couples searching “best sunset Airbnb,” Facebook still guides multigenerational planners, and TikTok’s travel hashtag passed 40 billion views in 2025. Post twice a week: one glossy shot and one slice-of-life clip, such as marshmallows toasting at your firepit or a five-second dawn timelapse on the lake. Guest photos bring built-in trust. Encourage tags, reshare with a thank-you, and add a gentle direct-booking link. Over time your feed turns into a gallery of real memories future guests can picture themselves in. Need a faster boost? Team up with a micro-influencer who fits your locale, perhaps a regional food blogger or adaptive-travel creator. Offer a mid-week comp night and list clear deliverables: one post, one story, usage rights. For owners who’d rather outsource the whole social-media and ad-buying lift, this guide to vacation-rental marketing services breaks down what a specialist agency can handle—from photo shoots to multi-channel campaigns—so you can scale visibility without adding hours to your schedule. Focused audiences beat celebrity scatter and often cost less than one vacant night. Social will not replace OTAs, but it widens the funnel and supplies fresh visuals for your website and listings, content that keeps working long after the likes fade. Reviews do more than reassure travelers; they push you higher in search results. Airbnb factors ratings volume and recency into ranking, while Vrbo’s new “Loved by Guests” badge lifts homes with 9.4-plus average scores and verified photo reviews. Yet Airbnb data show that fewer than half of guests leave a review unless you prompt them. Ask quickly and personally. Send a text within 24 hours of checkout that mentions one detail from the stay: “Glad the kids loved the game room!” Then make the request. Guesty reports that personalized prompts raise review rates by 30 percent over generic automations. Fix first, then ask. Resolve any issue before requesting feedback; future guests judge how you handle hiccups as much as the hiccup itself. Showcase micro-quotes. Drop three-word gems such as “spotlessly clean” or “views for days” into your listing description, website hero copy, and social captions. Snippets deliver social proof where star icons do not appear. Expand the footprint. After an OTA review posts, invite guests to paste the same text on Google Business Profile or Facebook. More review sites mean more pathways for search engines—and travelers—to reach you. Over time, plentiful, authentic feedback becomes the moat that keeps competitors at bay. Organic reach goes far, yet some nights still need a paid boost, such as mid-week gaps or shoulder-season lulls. Hyper-targeted ads place your listing in front of travelers already hunting for the dates you must fill, and you can pause spend once the gap is gone. A Google campaign around “pet-friendly cabin Blue Ridge” shows only to people typing those words. WordStream’s 2024 Google Ads benchmark report indicates travel-sector CPCs average $1.92 and convert at 6–8 percent. Meta lets you filter by interests, income, and even relationship status, so a beach condo can pitch “babymoon getaway” packages to expectant parents within a four-hour drive. The same benchmark data put Facebook’s travel CPC at about $0.51, and retargeting nudges yesterday’s site visitors toward tomorrow’s bookings. Channel Best use case Avg. CPC Key metric Google Search High-intent gaps under 30 days $1.90 Cost per booking Meta (FB/IG) Awareness and retargeting $0.51 View-through bookings TikTok Visual, younger audience $0.80–$1.20* Video watch rate *Early-2025 TikTok Travel advertisers report sub-$1 CPCs in U.S. drive-to markets (internal ad-network data). Start small at about $10 a day, one campaign, and one audience. Send clicks to your direct-booking page so the first stay covers the ad and future stays arrive commission-free. If a channel fails to return at least three times its cost, pause it and test a new angle. Paid ads should regulate cash flow smoothly, not drain it. Use CRM tags to spot work-from-anywhere guests and email a remote-ready bundle: verified 300 Mbps Wi-Fi, spare monitor, mid-stay cleaning. For families, swap in a stroller rental and a map of free playgrounds. Speaking each guest’s language turns price into a footnote and fuels glowing reviews. Partner with a local yoga teacher for sunrise deck sessions or stock s’mores kits plus a star map at the firepit. TouchStay’s 2024 Guest Sentiment Report shows that low-cost add-ons lift review scores by 0.3 stars on average. Higher ratings feed the algorithm and justify a modest rate bump no neighbor can copy overnight. Block one afternoon each month to activate a new AI feature, send a segment-specific email, or test a micro-experience. Track bookings or review scores for 30 days. Keep what moves the needle, drop what does not. Guests feel the momentum, algorithms reward relevance, and your calendar fills while others cling to last year’s checklist. Harper Lee is a lifestyle writer with a B.A. in Sociology from the University of British Columbia (UBC) and a background in community development. She began her career working with nonprofits before transitioning into content creation focused on intentional routines and mental clarity. Harper's voice blends minimalism, personal growth, and digital mindfulness. When not writing, she’s curating cozy playlists, bouldering at local gyms, or taking film photos with her vintage camera collection. Your email address will not be published. Required fields are marked * Comment * Name * Email * Website Save my name, email, and website in this browser for the next time I comment. Hi there! I'm Sarah Lyall, I have a background in interior design and a lifelong love of all things home and garden, so it's no surprise that I ended up turning my passion into a career. © 2025 A House in the Hills
--------------------------------------------------

Title: Daily Market Wrap: Paramount Skydance, CoreWeave, and SoftBank
URL: https://www.thestreet.com/economy/daily-market-wrap-paramount-skydance-coreweave-and-softbank
Time Published: 2025-11-12T01:42:16Z
Description: The market had a mixed performance on Tuesday, Nov. 11, with tech stocks underperforming as a ripple effect of Nvidia’s lackluster performance. The S&P 500...
--------------------------------------------------

Title: A $3 Billion Reason to Buy Nebius Stock Now
URL: https://www.barchart.com/story/news/36055455/a-3-billion-reason-to-buy-nebius-stock-now
Time Published: 2025-11-11T21:08:44Z
Description: Nebius stock soars on a strong Q3 and $3.0 billion contract with Meta Platforms. Here’s why NBIS shares are worth owning heading into 2026.
--------------------------------------------------

Title: Why this ASX stock could be the future of Australian energy shares
URL: https://www.fool.com.au/2025/11/12/why-this-asx-stock-could-be-the-future-of-australian-energy-shares/
Time Published: 2025-11-11T20:45:00Z
Description: This business has a compelling future. Here’s why…
The post Why this ASX stock could be the future of Australian energy shares appeared first on The Motley Fool Australia.
--------------------------------------------------

Title: Nvidia Stock Lurches Down as SoftBank Pulls Entire Investment
URL: http://futurism.com/future-society/nvidia-stock-softbank-ai
Time Published: 2025-11-11T19:46:37Z
Full Content:
By Joe Wilkins Published Nov 11, 2025 2:46 PM EST Last month, we shared a story about Seaport Global Securities analyst Jay Goldberg, who defied the odds as the only voice out of 80 Bloomberg stock watchers who rated Nvidia as a “sell.” While Goldberg makes some very good points — mostly, that AI simply isn’t proficient enough, at least yet, to justify its incredible chokehold on the US economy — the consensus on Wall Street has been firmly against him. Case in point, even after Goldberg made his assessment in the last week of October, investors continued to dump money into Nvidia, which is seen as the “shovel merchant” to the AI goldrush. So much money, in fact, that the company’s market cap briefly shot up above $5 trillion — the first company in history to do so. All that is to say, conventional wisdom is that you’d be nuts to pull an investment in Nvidia right now. Yet that’s exactly what Japanese investment firm SoftBank did on Tuesday, sending numerous tech stocks into a slide. According to Bloomberg, SoftBank disclosed it was pulling its $5.8 billion worth of holdings in Nvidia early Tuesday morning, ending its reign as one of the chip giant’s most prominent backers. The news immediately sent shockwaves throughout the market, dragging Nvidia’s stock down by around 2.6 percent as of Tuesday afternoon. As if to show how codependent the AI industry is, other tech giants were dragged down too, with stock in companies like Tesla falling by 1.8 percent, Meta by 0.95 percent, and Intel around 0.9 percent. Overall, the tech-heavy Nasdaq Index was down by 0.2 percent, while the S&P 500 struggled to maintain a flatline. Overall, it would be awful news for the AI industry if it wasn’t for one little wrinkle: SoftBank is planning on using its previous Nvidia holdings to back OpenAI, the private company behind ChatGPT. It’s already given OpenAI $7.5 billion, with plans for another $22.5 billion soon, as Bloomberg reports. In other words, don’t be shocked if the sell-off evens out in the coming days, as Yahoo Finance suggests. That said, there is at least one lesson to take away from the episode. While most other tech stocks tumbled, Apple soared by over 1.5 percent, its share price reaching an all-time high of $273.53. This is despite a disappointing announcement on Monday that the tech giant was delaying the release of the next iPhone Air in 2026. So what gives? When you peel back the “big tech” trappings, Apple stands out as the largest tech corporation to maintain ambivalence about the AI boom. Back in June, Apple’s research lab dropped a bombshell paper calling out companies like OpenAI for selling “the illusion of thinking” in AI chatbots. Apple has increasingly downplayed any efforts at building out a proprietary AI model, after early attempts failed rather spectacularly. All in all, don’t count on Apple to weather the storm completely if the entire AI bubble begins to pop, but when it comes to the touch-and-go volatility of the AI news cycle, the company might just have the last laugh. More on Nvidia: Nvidia CEO Says China Is “Going to Win” the AI Race I’m a tech and transit correspondent for Futurism, where my beat includes transportation, infrastructure, and the role of emerging technologies in governance, surveillance, and labor. By Victor Tangermann By Frank Landymore By Victor Tangermann By Victor Tangermann By Joe Wilkins By Joe Wilkins By Joe Wilkins By Victor Tangermann By Victor Tangermann By Joe Wilkins By Joe Wilkins By Victor Tangermann By Noor Al-Sibai By Victor Tangermann By Victor Tangermann By Victor Tangermann By Victor Tangermann By Joe Wilkins By Joe Wilkins By Victor Tangermann By Victor Tangermann Disclaimer(s) Articles may contain affiliate links which enable us to share in the revenue of any purchases made. Registration on or use of this site constitutes acceptance of our Terms of Service. © 2025 Recurrent. All rights reserved.
--------------------------------------------------

Title: S&P 500 Halts Rally as Nvidia Leads Megacap Slide: Markets Wrap
URL: https://financialpost.com/pmn/business-pmn/sp-500-halts-rally-as-nvidia-leads-megacap-slide-markets-wrap
Time Published: 2025-11-11T17:38:03Z
Description: Wall Street’s rally took a breather as Nvidia Corp. led losses in megacaps, though broader-market declines were limited by continued optimism that the largest shutdown in US history is coming to an end.
--------------------------------------------------

Title: Nebius Partners With Meta—AI Growth Could Send Stock to New Highs
URL: https://www.marketbeat.com/originals/nebius-partners-with-metaai-growth-could-send-stock-to-new-highs/?utm_source=yahoofinance&amp;utm_medium=yahoofinance
Time Published: 2025-11-11T17:03:00Z
Description: Nebius Group's Q3 results affirm a robust outlook, bolstered by new contracts and demand for AI computing power. Analysts and institutions provide support.
--------------------------------------------------

Title: Analyst Says Don’t Get Left Behind As Massive Liquidity Wave Is Coming For XRP
URL: http://www.newsbtc.com/analysis/xrp/massive-liquidity-coming-for-xrp/
Time Published: 2025-11-11T17:00:28Z
Full Content:
Strict editorial policy that focuses on accuracy, relevance, and impartiality Morbi pretium leo et nisl aliquam mollis. Quisque arcu lorem, ultricies quis pellentesque nec, ullamcorper eu odio. A crypto analyst known as Pumpius has issued a bold warning on social media platform X, declaring that a massive liquidity wave is about to sweep through global markets, and XRP could be the key asset positioned to capture it. His post, shared alongside a chart of the US national debt now above $38 trillion, argues that a combination of government stimulus, monetary easing, and corporate spending is about to unleash a surge of capital unlike anything seen since the 2020 pandemic. In his analysis, Pumpius highlighted that the United States government is preparing to inject over $400 billion in new stimulus payments, and this is going to be the first direct round of such spending since 2021. This comes at a time when the Federal Reserve is cutting interest rates despite inflation still sitting above 3% and labor market data showing signs of cooling. A similar setup in 2020 and 2021 during the COVID-19 pandemic led to an enormous wave of liquidity that lifted both traditional and crypto markets to record highs. Now, President Donald Trump has vowed to provide each American a $2,000 dividend to be distributed from what he said was tariff revenue. The chart shown below illustrates a notable connection vividly: each major stimulus injection, from the $270 billion to $410 billion rounds, coincided with sharp jumps in the national debt and subsequent market expansions. With total US debt now projected to exceed $38 trillion, Pumpius believes another round of liquidity growth is close. The analyst went on to point out that this time, the liquidity wave is not just based on government spending but also on private-sector investment on an extraordinary scale. The so-called Magnificent 7 technology companies (Apple, Microsoft, Amazon, Alphabet, Meta, Nvidia, and Tesla) are collectively pouring over $100 billion every quarter into artificial intelligence infrastructure. According to Pumpius, all this incoming liquidity needs a bridge, an asset capable of settling large-value transactions instantly across borders. He described XRP as the only digital asset designed precisely for this purpose, built for institutional-grade, real-time settlement and capable of handling global capital flows efficiently. Ripple’s technology already provides the financial infrastructure necessary to connect banks, fintechs, and payment systems that will need to move funds quickly as liquidity expands. “The math is simple,” he said. “The liquidity is coming. The rails are ready. Own XRP or be left behind,” he concluded. XRP is one of the top-traded digital assets by volume, and market participants are watching closely to see how the cryptocurrency’s price action plays out. Ripple, its parent technology company, has been making different partnership moves and company acquisitions to expand its reach. This is expected to hopefully boost XRP’s adoption on a global scale and, in turn, its price growth. At the time of writing, XRP is trading at $2.45, down by 1.4% in the past 24 hours. Scott Matherson is a prominent crypto writer at NewsBTC with a knack for capturing the pulse of the market, covering pivotal shifts, technological advancements, and regulatory changes with precision. Having witnessed the evolving landscape of the crypto world firsthand, Scott is able to dissect complex crypto topics and present them in an accessible and engaging manner. Scott's dedication to clarity and accuracy has made him an indispensable asset, helping to demystify the complex world of cryptocurrency for countless readers. Scott Matherson is a prominent crypto writer at NewsBTC with a knack for capturing the pulse of the market, covering pivotal shifts, technological advancements, and regulatory changes with precision. Having witnessed the evolving landscape of the crypto world firsthand, Scott is able to dissect complex crypto topics and present them in an accessible and engaging manner. Scott's dedication to clarity and accuracy has made him an indispensable asset, helping to demystify the complex world of cryptocurrency for countless readers. Scott’s experience spans a number of industries outside of crypto including banking and investment. He has brought his vast experience from these industries into crypto, which allows him to understand even the most complex topics and break them down in a way that is easy for readers from all works of life to understand. Scott’s pieces have helped to break down cryptocurrency processes and how they work, as well as the underlying groundbreaking technology that makes them so important to everyday life. With years of experience in the crypto market, Scott began to focus on his true passion: writing. During this time, Scott has been able to author countless influential pieces that have drawn in millions of readers and have shaped public opinion across various important topics. His repertoire spans hundreds of articles on various sectors in the crypto industry, including decentralized finance (DeFi), decentralized exchanges (DEXes), Staking, Liquid Staking, emerging technologies, and non-fungible tokens (NFTs), among others. Scott’s influence is not just limited to the countless discussions that his publications have sparked but also as a consultant for major projects in the space. He has consulted on issues ranging from crypto regulations to new technology deployment. Scott’s expertise also spans community building and contributes to a number of causes to further the development of the crypto industry. Scott is an advocate for sustainable practices within the crypto industry and has championed discussions around green blockchain solutions. His ability to keep in line with market trends has made his work a favorite among crypto investors. In his personal life, Scott is an avid traveler and his exposure to the world and various way of life has helped him to understand how important technologies like the blockchain and cryptocurrencies are. This has been key in his understanding of its global impact, as well as his ability to connect socio-economic developments to technological trends around the globe like no one else. Scott is known for his work in community education to help people understand crypto technology and how its existence impacts their lives. He is a well-respected figure in his community, known for his work in helping to enlighten and inspire the next generation as they channel their energies into pressing issues. His work is a testament to his dedication and commitment to education and innovation, as well as the promotion of ethical practices in the rapidly developing world of cryptocurrencies. Scott stands steady in the frontlines of the crypto revolution and is committed to helping to shape a future that promotes the development of technology in an ethical manner that translates to the benefit of all in the society. Disclaimer: The information found on NewsBTC is for educational purposes only. It does not represent the opinions of NewsBTC on whether to buy, sell or hold any investments and naturally investing carries risks. You are advised to conduct your own research before making any investment decisions. Use information provided on this website entirely at your own risk. VivoPower International’s evolving “digital asset treasury” blueprint took center stage in New York this week as Adam Traidman, the company’s... XRP is entering one of its most crucial weeks in months as a series of bullish catalysts align to set... Ripple’s Chief Technology Officer (CTO), David Schwartz, has provided a clear explanation for why the Bitcoin price remains so high,... Strict editorial policy that focuses on accuracy, relevance, and impartiality Morbi pretium leo et nisl aliquam mollis. Quisque arcu lorem, ultricies quis pellentesque nec, ullamcorper eu odio. NewsBTC is a cryptocurrency news service that covers bitcoin news today, technical analysis & forecasts for bitcoin price and other altcoins. Here at NewsBTC, we are dedicated to enlightening everyone about bitcoin and other cryptocurrencies. We cover BTC news related to bitcoin exchanges, bitcoin mining and price forecasts for various cryptocurrencies. © 2025 NewsBTC. All Rights Reserved. © 2025 NewsBTC. All Rights Reserved.
--------------------------------------------------

Title: SoftBank’s Nvidia Exit Raises Eyebrows, But Analysts Still See Big Upside for NVDA Stock
URL: https://www.barchart.com/story/news/36051148/softbanks-nvidia-exit-raises-eyebrows-but-analysts-still-see-big-upside-for-nvda-stock
Time Published: 2025-11-11T16:31:56Z
Description: SoftBank’s exit comes at a time when the market is increasingly questioning whether the billions flowing into AI infrastructure will translate into...
--------------------------------------------------

Title: Investor angst over Big Tech’s AI spending spills into bond market
URL: https://www.irishtimes.com/business/2025/11/11/investor-angst-over-big-techs-ai-spending-spills-into-bond-market/
Time Published: 2025-11-11T16:17:12Z
Full Content:
Investors have been selling off the debt of US tech heavyweights, showing how jitters over Silicon Valley’s boom in spending on artificial intelligence have spilled into the bond market. A basket of bonds issued by so-called hyperscalers – companies that are building vast data centres, including Alphabet, Meta, Microsoft and Oracle – has sustained a hit in recent weeks. The spread, or premium in yield that investors demand to buy the debt over Treasuries, has climbed to 0.78 percentage points, the highest level since US president Donald Trump sent markets reeling in April with his tariff plans, and up from 0.5 points in September, according to Bank of America data. The widening spread highlights how investors are increasingly concerned with the way tech groups are turning to debt markets to finance their investments in AI infrastructure. “The important thing the market woke up to in the past two weeks is that it’s the public markets that are going to need to finance this AI boom,” said Brij Khurana, a fixed income portfolio manager at Wellington Management. JPMorgan on Monday said building AI infrastructure would cost more than $5 trillion (€4.3 trillion) and “will likely require participation from every public capital market as well as private credit, alternative capital providers and even government involvement”. The mammoth scale of investment in AI infrastructure has raised concerns about overcapacity, long-term profitability and energy demands. Google, Amazon, Microsoft and Meta will spend more than $400 billion on data centres in 2026, on top of more than $350 billion this year. Tech groups are issuing debt at a quick rate to fund their AI expansion efforts despite having large cash hoards, which is something some investors worry could signal a shift to higher levels of leverage. “The hyperscalers collectively hold [about] $350 billion in liquid cash and investments and are expected to generate [roughly] $725 billion of operating cash flow in 2026,” JPMorgan said. “Even so, substantial new debt supply is coming to the credit markets from these high-quality issuers.” In recent weeks, Meta, Alphabet and Oracle have hit markets with blockbuster debt packages, some with maturities as long as 40 years. Meta last month forged a $27 billion private debt deal with investors, including Pimco and Blue Owl Capital, to fund development of its “Hyperion” data centre in Louisiana. It raised an additional $30 billion in bonds at the end of October, the biggest corporate bond deal since 2023. Meanwhile, Alphabet sold $25 billion of bonds in early November, $17.5 billion of which were raised in the US and $7.5 billion in Europe. Oracle sold $18 billion of bonds in September to fund infrastructure leases such as OpenAI’s “Stargate” data centre in Abilene, Texas. Analysts noted Oracle’s debt has been hit particularly hard in recent months. An index compiled by the Financial Times tracking its debt that has been trading since before the latest bond sale has fallen almost 5 per cent since mid-September, compared with a price fall of about 1 per cent for a broad Ice Data Services basket tracking US high-grade tech debt. Oracle has about $96 billion of long-term debt, according to Bloomberg data. It has rapidly grown its debt balances as part of a series of deals to lease computing power to ChatGPT maker OpenAI, which the US software group said would generate $300 billion in revenue over the next five years. But credit rating agency Moody’s has flagged significant risks from Oracle relying on large commitments from a small number of AI companies to fund its growth. Smaller companies at the heart of the AI boom have also been hit. Data centre operator CoreWeave’s stock has fallen more than 20 per cent over the past two weeks, alongside the drop in bigger names. On Tuesday, the company’s shares were down a further 14 per cent after it lowered its forecast for annual revenue as a result of expected data centre delays. The cost to protect against a default on CoreWeave’s debt has jumped as the equity price has fallen, with the group’s five-year credit default swaps trading at 505 basis points, from below 350bp at the start of October, according to LSEG data. Some analysts argue that the decline in hyperscalers’ bonds in the wake of such large issuance is healthy. “As long as we are still pricing incremental risk, it’s a good sign. The thing I worry about is a rally on more supply rather than a sell-off,” said George Pearkes, a macro strategist at Bespoke Investment Group. “We’re still in early innings in this debt cycle for AI,” he said. Copyright The Financial Times Limited 2025 Join The Irish Times on WhatsApp and stay up to date Sign up to the Business Today newsletter for the latest new and commentary in your inbox Listen to Inside Business podcast for a look at business and economics from an Irish perspective Get the latest business news and commentary from our expert business team in your inbox every weekday morning © 2025 The Irish Times DAC
--------------------------------------------------

Title: Nvidia’s $500 Billion Surge Meets a Wall of Doubt | US Crypto News
URL: https://beincrypto.com/nvidia-softbank-cash-out-us-crypto-news/
Time Published: 2025-11-11T13:40:28Z
Full Content:
Written byLockridge Okoth Edited byMohammad Shahid Welcome to the US Crypto News Morning Briefing—your essential rundown of the most important developments in crypto for the day ahead. Grab a coffee as the AI trade takes another wild turn. Nvidia’s $500 billion rebound has the market buzzing again, but behind the headlines, old believers are cashing out and skeptics are circling. Euphoria is back, but so are the warning signs. Nvidia’s record-breaking rebound has reignited the AI trade, adding half a trillion dollars in market value within just two trading days. Yet beneath the euphoria, major investors are pulling back, and the warnings are getting louder. On Monday, Nvidia shares surged 5.8%, marking their largest daily gain since April. Between midday Friday and Monday’s close, the chipmaker added roughly $500 billion in market capitalization, equivalent to $43 billion per trading hour. 💥BREAKING:NVIDIA SURGES BY 5.8% IN TODAY'S TRADING, ITS BIGGEST DAILY GAIN SINCE APRIL. pic.twitter.com/LFzsEOxUNI The rally came after a bruising week in which Nvidia had lost nearly $800 billion in value, highlighting how swiftly capital is rotating in and out of the AI trade. “Nvidia added $500 billion in market cap in just 48 hours — entries into this historic run are scarce,” The Kobeissi Letter wrote. “Dip buyers are still out in full force.” At a $5.1 trillion valuation, Nvidia now represents 8.5% of the S&P 500. This is larger than the sum of six of the index’s 11 sectors, including Materials, Real Estate, and Utilities. Its market cap also exceeds the combined value of the entire stock markets of Italy, Spain, the UAE, and the Netherlands. While retail investors continue to chase Nvidia’s ascent, SoftBank has quietly exited. The Japanese conglomerate sold its entire $5.83 billion Nvidia stake in October, alongside part of its $9.17 billion T-Mobile holding, as part of a strategy it called “asset monetization.” JUST IN: SoftBank announces it has sold its entire stake in $NVDA for $5.8 billion. pic.twitter.com/9qSOxkZXjd The sales helped SoftBank report a ¥2.92 trillion ($19.1 billion) second-quarter profit, more than double last year’s, powered by $19 billion in Vision Fund gains largely tied to its OpenAI holdings. The company also announced a 4-for-1 stock split and raised its interim dividend as CEO Masayoshi Son reaffirmed SoftBank’s “all-in” commitment to artificial intelligence, robotics, and data infrastructure. SoftBank’s Chief Financial Officer Yoshimitsu Goto said the sales were meant to ensure “safe funding” as the firm prepares to deploy more than $30 billion in fresh investments this quarter. “We want to provide a lot of investment opportunities while maintaining financial strength,” TradFi media reported, citing Goto. However, not everyone is celebrating Nvidia’s meteoric rise. Michael Burry, famed for predicting the 2008 financial crisis, warned that hyperscalers and cloud giants may be artificially inflating earnings by extending the “useful life” of compute equipment. In doing so, they allegedly reduce reported depreciation on AI infrastructure purchased from Nvidia and other suppliers. Understating depreciation by extending useful life of assets artificially boosts earnings -one of the more common frauds of the modern era.Massively ramping capex through purchase of Nvidia chips/servers on a 2-3 yr product cycle should not result in the extension of useful… pic.twitter.com/h0QkktMeUB Burry estimated $176 billion in understated depreciation between 2026 and 2028, which he claims could overstate profits at companies like Oracle and Meta by 27% and 21%, respectively. Against these backdrops,some analysts warn that the math behind the AI boom does not add up. Ross Hendricks noted that to justify current AI valuations, global revenues would need to rise 20x in five years, or else capital expenditure would need to “collapse,” triggering a broad market correction. The AI math ain’t mathin Two ways to fix it: 20x revenue in the next five years, or slash data center capexI’ll take the latter on 100 to 1 oddsSo what does a capex pullback look like? It means hyperscaler cloud computing earnings and NVDA chip sales evaporate.. and with… https://t.co/eI4HIIczTZ Even so, momentum remains unstoppable, for now. Nvidia has become the defining stock of the AI era, its chips powering everything from data centers to large language models like OpenAI’s GPT series. Yet the contrasting moves by SoftBank and warnings from Burry suggest the market’s biggest winner could soon face its toughest test. Here’s a summary of more US crypto news to follow today: Daily Crypto Insights Insights, news and analysis of the crypto market straight to your inbox Disclaimer In adherence to the Trust Project guidelines, BeInCrypto is committed to unbiased, transparent reporting. This news article aims to provide accurate, timely information. However, readers are advised to verify facts independently and consult with a professional before making any decisions based on this content. Please note that our Terms and Conditions, Privacy Policy, and Disclaimers have been updated.
--------------------------------------------------

Title: 3 Data Memory Stocks Beating NVDA This Year
URL: https://www.marketbeat.com/stock-ideas/3-data-memory-stocks-beating-nvda-this-year/?utm_source=yahoofinance&amp;utm_medium=yahoofinance
Time Published: 2025-11-11T12:05:00Z
Description: The AI rush has sent the stocks of memory storage companies through the roof in 2025. Read on to learn why this trend might just be getting started.
--------------------------------------------------

Title: CoreWeave Falls As Data Center Issue Hits Capital Spending, 2025 Revenue Outlook
URL: https://www.investors.com/news/technology/coreweave-stock-coreweave-earnings-news-q32025/
Time Published: 2025-11-11T11:36:45Z
Description: CoreWeave stock fell as investors mulled the company's lowered 2025 guidance for capital spending and revenue amid capacity issues.
--------------------------------------------------

Title: Warren Buffett’s last shareholder letter offers 5 lessons for CEOs and warns that ‘envy and greed walk hand in hand’
URL: https://fortune.com/2025/11/11/warren-buffetts-last-shareholder-letter-offers-5-lessons-for-ceos-and-warns-that-envy-and-greed-walk-hand-in-hand/
Time Published: 2025-11-11T10:27:39Z
Full Content:
Diane Brady is an award-winning business journalist and author who has interviewed newsmakers worldwide and often speaks about the global business landscape. As executive editorial director of the Fortune CEO Initiative, she brings together a growing community of global business leaders through conversations, content, and connections. She is also executive editorial director of Fortune Live Media and interviews newsmakers for the magazine and the CEO Daily newsletter. Good morning. The U.S. celebrates Veteran’s Day today, and we are sending a heartfelt thank you to everyone who has served. Speaking of gratitude, Warren Buffett dropped his ‘farewell’ letter to Berkshire Hathaway shareholders yesterday and offered a master class in introspection, recognizing his own good luck, and passing on sage advice. I’d highly recommend reading the letter in its entirety, but here are a few lessons for leaders I think are worth underscoring: Curb Your Envy: “What often bothers very wealthy CEOs—they are human, after all—is that other CEOs are getting even richer. Envy and greed walk hand in hand. And what consultant ever recommended a serious cut in CEO compensation or board payments?” Learn From Failure: “Don’t beat yourself up over past mistakes—learn at least a little from them and move on. It is never too late to improve.” Measure Success Through Impact: “Greatness does not come about through accumulating great amounts of money, great amounts of publicity or great power in government. When you help someone in any of thousands of ways, you help the world. Kindness is costless but also priceless. Whether you are religious or not, it’s hard to beat The Golden Rule as a guide to behavior.” Ponder Your Legacy: Buffett talks about how FBI Director J. Edgar Hoover, once revered by Americans in the 1930s, “became disgraced for misusing his post.” His advice: “Decide what you would like your obituary to say and live the life to deserve it … You will never be perfect, but you can always be better.” Bet on America: “Our stock price will move capriciously, occasionally falling 50% or so as has happened three times in 60 years under present management. Don’t despair; America will come back and so will Berkshire shares.”Contact CEO Daily via Diane Brady at diane.brady@fortune.com Softbank offloads Nvidia Softbank on Tuesday sold its entire stake in chipmaker Nvidia, pocketing $5.8 billion in a surprise move. Masayoshi Son’s company more than doubled its quarterly net profit thanks in large part to its bet on OpenAI. Shutdown may ease A splinter group of Democrats joined Senate Republicans in passing a measure to reopen the government on Monday night. The legislation now goes to the House, which is expected to take it up no later than Wednesday. Meanwhile, flight cancellations and delays spread amid a shortage of air traffic controllers, who are working without pay. President Trump on Monday threatened to “dock” the pay of any controllers who take time off. CoreWeave results AI data-center and infrastructure operator CoreWeave nearly doubled its revenue backlog to $55.6 billion, surpassing a critical Wall Street benchmark, though its debt increased and it revised down its full-year revenue guidance. Investors are following CoreWeave closely since it could be “a potential canary-like indicator of weakness in the AI ramp-up,” Fortune’s Amanda Gerut reports. Turmoil at the BBC The crisis at the BBC deepened on Monday after President Trump threatened to sue the broadcaster for $1 billion over the erroneous editing of a speech he gave on Jan. 6, 2021. Two BBC executives have already resigned over the matter; the president has demanded an apology and compensation for “harm caused.” The real cost of Trump’s tariff dividend President Trump’s proposed $2,000 tariff dividend for all Americans (excluding “high income people”) will cost more than twice the revenue generated by tariffs, the nonpartisan Committee for a Responsible Federal Budget found. The extra cost would have to be added to the already ballooning federal deficit. UBS economists’ labor market concerns UBS economists in their latest “US Economics Weekly” note compared the national labor market to a bathtub that is losing water (total jobs) as layoffs persist and the flow of jobs slows. “That is a material risk to the outlook,” the investment bank wrote. S&P 500 futures are down 0.22% this morning. The last session closed up 1.54%. STOXX Europe 600 was up 0.67% in early trading. The U.K.’s FTSE 100 was up 0.86% in early trading. Japan’s Nikkei 225 was down 0.14%. China’s CSI 300 was down 0.91%. The South Korea KOSPI was up 0.81%. India’s NIFTY 50 is up 0.47%. Bitcoin was down to $105K. You don’t hate AI because of genuine dislike. No, there’s a $1 billion plot by the ‘Doomer Industrial Complex’ to brainwash you, Trump’s AI czar says by Eva Roytburg Billionaire Ken Griffin shares the top traits he looks for when hiring—and warns that schools are failing to prepare applicants by Jason Ma The CEO who transformed Coach into a luxury powerhouse shares the grueling interview process he uses to vet candidates by Emma Burleigh Meet the millennial Meta cofounder and ex-journalist wife giving away their $20 billion fortune by Jessica Coacci CEO Daily is compiled and edited by Joey Abrams and Claire Zillman. © 2025 Fortune Media IP Limited. All Rights Reserved. Use of this site constitutes acceptance of our Terms of Use and Privacy Policy | CA Notice at Collection and Privacy Notice | Do Not Sell/Share My Personal Information FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.
--------------------------------------------------

Title: Meta's,Tesla's, Alphabet's and Amazon are part of Zacks Earnings Preview
URL: https://finance.yahoo.com/news/metas-teslas-alphabets-amazon-part-074500249.html
Time Published: 2025-11-11T07:45:00Z
Description: Meta's,Tesla's, Alphabet's and Amazon have been highlighted in this Earnings Preview article.
--------------------------------------------------

Title: Ad Tech Briefing: AppLovin’s AI-fueled surge and The Trade Desk’s stumble show where investors are placing their bets
URL: http://digiday.com/marketing/ad-tech-briefing-applovins-ai-fueled-surge-and-the-trade-desks-stumble-show-where-investors-are-placing-their-bets/
Time Published: 2025-11-11T05:01:00Z
Full Content:
Join us Dec. 1-3 in New Orleans for the Digiday Programmatic Marketing Summit This Ad Tech Briefing covers the latest in ad tech and platforms for Digiday+ members and is distributed over email every Tuesday at 10 a.m. ET. More from the series → AppLovin and The Trade Desk emerged as the clear attention-grabbers in this ad tech earnings window — but for very different reasons, and with very different signals about how investors are reading the sector’s future. AppLovin stock, FTW AppLovin’s third-quarter numbers were the kind that usually end an argument. Revenue jumped 68% year over year to $1.4 billion, with net income and adjusted EBITDA growing even faster as the company leans into its AXON-driven advertising platform and shrinks its legacy gaming footprint. The market’s reaction was briskly positive, as the company’s stock popped (see table below). However, what makes that reaction stand out is what it seemed to ignore. Just a month earlier, a Bloomberg report revealed that the U.S. SEC was probing AppLovin’s data-collection practices, following short-seller allegations that it skirted platform terms to squeeze more targeting out of Meta and mobile ecosystems. The stock fell about 14% on that headline in October, and further coverage detailed how the company shut down an “Array” product that had become a focal point of those accusations. Yet when the Q3 numbers hit, Wall Street effectively compartmentalized the regulatory overhang, although, some analysts explicitly advised caution: growth forecasts point to a deceleration from the current breakneck pace, and the SEC probe is still unresolved. But for now, the combination of scale, margins and AI narrative appears to outweigh the governance red flags in investors’ models. Big Tech vs. The open web Meanwhile, The Trade Desk’s Q3 tells a more nuanced tale about sentiment toward the demand side of the ecosystem. The company delivered $739 million in revenue, up 18% year over year (22% excluding U.S. political spend), beating consensus and continuing its long streak of double-digit top-line growth. CTV outpaced the rest of the business, and video now accounts for roughly half of revenue, underscoring The Trade Desk’s role as the de facto DSP for the “open internet.” And yet, the stock fell 4–7% in the wake of the results, depending on which post-earnings snapshot you look at. Coverage framed it as a classic “great quarter, high bar”: the company beat on revenue and EPS, guided Q4 to at least $840 million, but is still working off a bruising summer reaction to its Q2 earnings. On the company’s subsequent earnings call, CEO Jeff Green again insisted Amazon isn’t a direct competitor because most of its ads target owned-and-operated inventory rather than the “open internet.” However, investors appear split on that framing, with some seeing an independent DSP with durable CTV and retail-media momentum; others worry that Big Tech and retailer networks can squeeze the open web on both inventory and data. The Q3 sell-off doesn’t signal that the market has “given up” on The Trade Desk — but it does show that continued backing for the sector’s flagship DSP now depends on more than just beating the quarter. The story investors are buying has to reconcile competition from Amazon, Google and retailer media with a credible path to sustained 20%-ish growth and healthy cash generation. Collaboration across the middle layers of ad tech is another trend investors are monitoring, and while not explicitly raised on the call, the fact that concerned parties are seeking a “grand bargain” to end months, if not years, of sniping over supply-path and auction mechanics is likely welcome. Against that backdrop, The Trade Desk and PubMatic — which reported its own Q3 earnings as Digiday was going to press (see chart) — announced a new API-based integration for deal-ID campaigns using The Trade Desk’s Price Discovery and Provisioning, or PDP, API. Observers have characterized the move as a pragmatic reset: both sides acknowledge that legacy deal-ID plumbing is too brittle for modern CTV and curated marketplaces, and are willing to align on common pipes to keep spend flowing. For markets, deals like this suggest that even when buy- and sell-side rhetoric turns heated, the largest players will still cut operational truces where there’s real money on the table. In a sector where investors have been burned by opaque auctions and fee stacks, cleaner integrations that promise more predictable yield and fewer failed deals are a modest but meaningful de-risking signal. ‘Death of the open web’ narrative The other axis driving valuations is how convincingly companies can connect AI to revenue — and how quickly they can prove it on the open web, not just in pitch decks. DoubleVerify’s Q3 is a case in point. Revenue grew 11% to about $189 million and margins remained robust, but sales came in a touch light versus some expectations, and Q4 guidance implied high-single-digit to low-double-digit growth. The stock promptly dropped around 19%. On the company’s earnings call, DoubleVerify leaned hard into its new DV AI Verification suite: Agent-ID to classify LLM agents and bots, and “AI SlopStopper” to detect and block synthetic or manipulated media across the open web. Management framed AI not just as a risk but as a margin lever, arguing that generative tools can 20x–2000x labeling productivity while opening new revenue lines in social, CTV and LLM-mediated advertising. Analysts pressed on how quickly those innovations could move the growth needle, and DV sketched a medium-term goal of taking social, streaming TV and AI verification from under 30% of revenue to roughly 50%. The share-price reaction suggests investors believe the strategy, but aren’t yet prepared to pay up for it without clearer acceleration. Elsewhere, Teads, provided the cautionary mirror image. Its Q3 revenue came in around $319 million, missing expectations and down roughly 15% year over year on a pro-forma basis, with EPS swinging to a loss — and the stock slumped by about 30%. On its earnings call, management laid out a turnaround plan targeting $35 million in annualized EBITDA improvement and highlighted CTV and AI-driven initiatives as the growth engine. Analysts focused heavily on how quickly Teads could stabilize core markets like the U.S., U.K., and France and whether its AI and CTV bets would stem share loss to rivals. The verdict from Wall Street — at least for now — is that execution risk is high, with the highly leveraged 2024 deal that led to the union of Outbrain and Teads, plus the “death of the open web” narrative, dragging down its stock price. In total, the above developments from last week point to a more nuanced view of ad tech’s prospects, rather than the blanket enthusiasm (or cynicism) of past cycles. On one side are scaled platforms such as AppLovin and The Trade Desk, which can still post high-teens to high-double-digit growth, invest aggressively in AI and CTV, and throw off substantial cash. On the other hand, there are infrastructure and media players that must prove AI is more than a cost line — that it can deepen moats in measurement, verification, and curated inventory rather than simply compressing margins. “Every player is optimizing for their own incentives instead of the health of the ecosystem. And somewhere in that noise, publishers — the ones creating the content and context that make advertising possible — are being left out.” – Renowned industry consultant, Jana Meron, of Lioness Strategies, says the quiet part out loud. News Corp explores multi-LLM licensing playbook News Corp is scoping out the potential for a multi-licensing LLM portfolio strategy, according to sources familiar with the matter. Ranking is out, visibility is in as publishers chip away at AI search optimization The AI search era is rewiring the goal from ranking to visibility, and publishers are slowly but steadily tuning their playbooks. Inside Bayer’s ad tech and data strategy to find new customers and prepare for agentic AI Bayer is bringing its custom algorithm in-house so it can be more hands-on with the model that undergirds its programmatic ad placements, working with Chalice and Snowflake to achieve this aim. Google is helping WPP build Websites for AI search engines Google is giving WPP-owned agencies access to tools that help marketers better appear on AI search engines, including Google’s AI Overviews and rivals such as OpenAI’s ChatGPT and Perplexity. ID5 acquires TrueData, combining strengths to create the most comprehensive ID solution Financial terms of the deal were not publicly disclosed, but the U.K.-based company states that by bringing TrueData’s graph on board, the company is upping its U.S. operations and strengthening its Adaptive Identity technology. The DOJ and Google sharpen their remedy proposals as the two sides prepare for closing arguments Both sides filed new post-remedy trial briefs on Monday, with the DOJ and Google each citing the phrase in support of their conflicting viewpoints on a potential divestiture of Google’s sell-side ad exchange. It’s a new technical standard for running real-time bidding that focuses on efficiency. Brands are getting more creative in their quests for influencers their competitors may not have already tapped. A series of job cuts across the sector have left some execs struggling to find their next gig. The impact of AI could worsen the situation. Get access to tools and analysis to stay ahead of the trends transforming media and marketing Visit your account page to make changes and renew. Get Digiday's top stories every morning in your email inbox. Follow @Digiday for the latest news, insider access to events and more.
--------------------------------------------------

Title: Q2 Results Highlights Today: Bosch, Hindustan Copper, Bajaj Finserv, EID Parry, Bharat Forge, RateGain Travel, Torrent Power, Tata Power, BSE & JB Chemicals Q2 PAT up, ONGC, Thermax Q2 profit declines, Godrej Industries Q2 PAT flat
URL: https://www.thehindubusinessline.com/markets/q2-results-highlights-bajaj-finserv-bajaj-holdings-tata-power-bosch-bse-fortis-healthcare-thermax-torrent-power-bharat-forge-eid-parry-godrej-jb-chemicals-vi-bajaj-finance-hudco-11-november-2025/article70262984.ece
Time Published: 2025-11-11T03:47:35Z
Full Content:
+ 335.97 + 120.60 + 55.00 + 615.00 + 1,467.00 + 335.97 + 120.60 + 120.60 + 55.00 + 55.00 + 615.00 Get businessline apps on Connect with us TO ENJOY ADDITIONAL BENEFITS Connect With Us Get BusinessLine apps on Stack of money coin and laptop computer in the background with trading graph, Business and Financial concept. | Photo Credit: Tendo23 Q2 Results November 11, 2025 updates: Find all the latest Q2 results 2025 updates of Bajaj Finserv, Bajaj Holdings & Investment, The Tata Power Company, Bosch, BSE Limited, Fortis Healthcare, Torrent Power, Rail Vikas Nigam, Bharat Forge, PI Industries, Max Financial Services, Biocon, Container Corporation of India, Gujarat Fluorochemicals Limited, Thermax, Godrej Industries, Hindustan Copper, JB Chemicals and Pharmaceuticals, Emcure Pharmaceuticals, EIH, OneSource Specialty Pharma, EID Parry (India) and more. BSE Ltd reported its highest-ever quarterly revenue of ₹1,139 crore for the quarter that ended September 30, 2025, marking a 40 per cent year-on-year increase and the tenth consecutive quarter of record revenues. Consolidated net profit jumped 61 per cent to ₹557 crore, with operating EBITDA surging 75 per cent to ₹680 crore. The exchange’s equity derivatives segment processed 642 crore contracts during the quarter, generating ₹624 crore in revenue. BSE facilitated 97 new equity listings across its main and SME boards, helping companies raise ₹53,548 crore in Q2. Thermax reported a 40 per cent decline in consolidated net profit to Rs 119 crore in the September quarter due to lower revenues. The company recorded a consolidated operating revenue of Rs 2,474 crore during the quarter, a 5 per cent decrease as compared to Rs 2,616 crore in the corresponding quarter of the previous fiscal year. Borosil Renewables on Tuesday posted a consolidated net profit of Rs 61.57 crore in the September quarter, aided by reduced expenses. It had clocked a net loss of Rs 13.12 crore in the July-September quarter FY25, the company said in an exchange filing. The company saw its total income grow to Rs 380.68 crore during the second quarter from Rs 378.25 crore in the year-ago period. Yatra Online reported a 95.47 per cent year-on-year growth in consolidated net profit at Rs 14.27 crore in the July-September quarter of the current financial year. Net profit stood at Rs 7.30 crore during the corresponding quarter of the previous fiscal, Yatra Online said in a regulatory filing. Revenue from operations grew 48.41 per cent during the quarter under review at Rs 350.86 crore, compared to Rs 236.40 crore in the same period of the previous year. Zaggle Prepaid Ocean Services Limited, a spend management company, has reported a net profit of ₹33.34 crore for the second quarter ended September 30, 2025, compared to ₹18.56 crore in the same period last year, representing a 79.1 per cent growth. Bikaji Foods International Ltd reported a 15.2 per cent year-on-year revenue increase to ₹830.3 crore for the second quarter ended September 30, 2025, driven by strong performance in its packaged sweets segment and export business. The Bikaner-based ethnic snacks manufacturer posted an adjusted profit after tax of ₹80.8 crore, up 18.1 per cent from the previous year. EBITDA grew 20.1 per cent to ₹128.2 crore, with margins expanding to 15.4 per cent. Volume growth stood at 10.8 per cent during the quarter. Tata Power on Tuesday reported a 14 per cent rise in consolidated net profit to Rs 1,245 crore in September quarter, helped by increased revenues. It had clocked a net profit of Rs 1,093 crore in the July-September quarter FY25, the company said in a statement. The company saw its revenue growing to Rs 15,769 crore, up 3 per cent from Rs 15,247 crore in July-September period FY25. JB Chemicals & Pharmaceuticals posted a 19 per cent year-on-year growth in net profit at Rs 208 crore in the second quarter ended September 30, 2025. The drug firm reported a net profit of Rs 175 crore during the July-September quarter of the last fiscal. Revenue from operations increased to Rs 1,085 crore for the period under review as compared with Rs 1,001 crore in the year-ago period, the company said in a regulatory filing. Swedish home furnishing major IKEA India reported a 6 per cent rise in sales to ₹1,860.8 crore in FY25, driven by growth across online, B2B, and food segments. The company’s EBITDA (excluding fixed costs) improved 12 per cent year-on-year, and it aims to turn profitable within the next two years. Torrent Power reported a 49 per cent year-on-year growth in consolidated profits that stood at Rs ₹741 crore at the end of the second quarter of financial year 2025-26. The revenue from operations grew by 10 per cent during the quarter and stood at Rs ₹7,876 crore. The company attributed the strong operational performance to the increase in contribution from merchant power sales, including LNG sales from gas-based power plants. Reduction in finance cost, partially offset by increase in depreciation costs due to capex and commissioning of additional renewable generation capacity also aided the growth. Bosch has reported a growth of 3.4 per cent year-on-year (y-o-y) in its consolidated net profit of ₹554 crore for the second quarter FY26. The growth was attributed to demand in passenger cars and off-highway segment. On a standalone basis, Bharat Forge reported revenue of ₹1,947 crore for Q2 FY26, a decline of 7.5 per cent quarter-on-quarter (QoQ), primarily due to a slowdown in North American commercial vehicle demand. EBITDA stood at ₹545 crore, with margins improving slightly to 28 per cent, up 10 basis points QoQ on account of a favourable product mix. Profit before tax (PBT) before exceptional items was ₹432 crore, down 7.2 per cent QoQ, while profit after tax (PAT) came in at ₹310 crore, compared to ₹339 crore in the previous quarter. Fredun Pharmaceuticals has reported that net profit more than doubled in the September quarter to ₹10 crore and its income jumped 35 per cent to ₹145 crore. EBITDA was up 60 per cent at ₹22 crore. Fredun Medhora, Managing Director, said the domestic formulations business delivered a solid performance through new product introductions and rising institutional demand, while exports maintained steady traction. Emcure Pharmaceuticals reported 13.4 per cent year-on-year growth in consolidated revenue from operations to ₹2,270 crore, while profit after tax (PAT) surged 24.7 per cent to ₹251 crore. EBITDA grew 15.2 per cent YoY to ₹439 crore, with margins improving slightly to 19.3 per cent. Profit before tax (PBT) rose 24.9 per cent YoY to ₹341 crore. Unicommerce Esolutions reported standalone net profit for the quarter ended September 2025 at Rs 6.44 crore as against Rs 4.47 crore profit in the same quarter last year. Zaggle Prepaid Ocean Services reported standalone net profit for the quarter ended September 2025 at Rs 33.24 crore as against Rs 18.55 crore profit in the same quarter last year. Godrej Industries reported consolidated net profit for the quarter ended September 2025 at Rs 492.95 crore as against Rs 488.86 crore profit in the same quarter last year. Awfis Space Solutions reported standalone net profit for the quarter ended September 2025 at Rs 15 crore as against Rs 37.69 crore profit in the same quarter last year. Screenshot 2025-11-11 154902.png Texmaco Rail & Engineering reported standalone net profit for the quarter ended September 2025 at Rs 61.82 crore as against Rs 48.45 crore profit in the same quarter last year. Screenshot 2025-11-11 154341.png Sensex settled 335.97 pts or 0.40% higher at 83,871.32, and Nifty 50 soared 120.60 pts or 0.47% to 25,694.95. IOL Chemicals and Pharmaceuticals reported standalone net profit for the quarter ended September 2025 at Rs 30 crore as against Rs 19.15 crore in the same quarter last year. Orchid Pharma reported consolidated net loss for the quarter ended September 2025 at Rs 3.33 crore as against Rs 25.90 crore profit in the same quarter last year. Emcure Pharmaceuticals posted standalone net profit for the quarter ended September 2025 at Rs 117.6 crore as against Rs 86.9 crore in the same quarter last year. BLS International Services posted standalone net profit for the quarter ended September 2025 at Rs 4.89 crore as against Rs 18.66 crore in the same quarter last year. State-owned Oil and Natural Gas Corporation (ONGC) has reported an 18 per cent fall in its second-quarter net profit due to lower oil prices. The company’s net profit stood at Rs 9,848 crore in July-September -- the second quarter of 2025-26 financial year -- compared to Rs 11,984 crore earnings in the same period a year back, ONGC said in a statement. The fall in profit of India’s biggest oil explorer was primarily a decline in crude oil prices -- from USD 78.33 per barrel in Q2 of FY25 to USD 67.34 in the current fiscal. ( PTI) Bosch reported standalone net profit for the quarter ended September 2025 at Rs 554.2 crore as against Rs 535.9 crore in the same quarter last year. Shares traded at Rs 36,655 on the NSE, down 1.68%. Sterling Tools reported a standalone net profit for the quarter ended September 2025 at Rs 19.79 crore as against Rs 11.88 crore in the year-ago period. Board approved the appointment of Roney John as Chief Manufacturing Officer. Stanley Lifestyles reported a standalone net profit for the quarter ended September 2025 at Rs 5.1 crore as against Rs 5.7 crore in the year-ago period. Lloyds Enterprises reported a standalone net profit for the quarter ended September 2025 at Rs 30.05 crore as against Rs 13.56 crore in the year-ago period. Jupiter Wagons reported a standalone net profit for the quarter ended September 2025 at Rs 52.70 crore as against Rs 88.61 crore in the year-ago period. Hindustan Copper reported standalone net profit for the quarter ended September 2025 at Rs 186.02 crore as against Rs 101.68 crore in the same quarter last year. Shares surged over 5% on the NSE to Rs 355.55. Bajaj Finserv reported standalone net profit for the quarter ended September 2025 at Rs 1,085.18 crore as against Rs 907.57 crore in the same quarter last year. Shares traded 6% lower at Rs 1978 on the NSE. RITES reported standalone net profit for the quarter ended September 2025 at Rs 102.22 crore as against Rs 85.96 crore in the same quarter last year. Shares traded at Rs 244.16 on the NSE Atul Auto reported standalone net profit for the quarter ended September 2025 at Rs 11.86 crore as against Rs 9.52 crore in the same quarter last year. Shares zoomed 7% on the NSE to Rs 481. M & B Engineering reported standalone net profit for the quarter ended September 2025 at Rs 18.42 crore as against Rs 22.41 crore in the same quarter last year. Shares plunged 12% on the NSE to Rs 451. EID Parry India reported consolidated net profit for the quarter ended September 2025 at Rs 766.16 crore as against Rs 591.66 crore in the same quarter last year. Shares traded at Rs 1,039 on the NSE, up 1% Standalone Financial Highlights – Q2 FY26 (Continued Operations)  Total Income: ₹16,610 lakh, up 8% from ₹15,358 lakh in Q2 FY25  EBITDA: ₹1,633lakh, up 44% YoY (vs EBIDTA of ₹1133 lakh, in Q2FY25)  Profit Before Tax: ₹1,006 lakh up 341% YoY (vs profit of ₹228 lakh in Q2 FY25)  Net Profit: ₹756 lakh up 424% YoY (vs ₹144 lakh in Q2 FY25)  EPS: ₹3.25 (vs ₹0.67 in Q2 FY25) Bajaj Finance shares plunged 7.65 per cent to ₹1,002 on Tuesday morning, dragging parent Bajaj Finserv down 7.58 per cent to ₹1,957.80, after the lender trimmed its annual growth forecast citing stress in key lending segments Vodafone Idea shares jumped 6.11 per cent to ₹10.08 in Tuesday’s session, with heavy trading volumes of 95.24 crore shares worth ₹943.85 crore, following the telco’s second-quarter results announced after Monday’s close. Brokerages offered mixed views on the stock’s prospects. Citi maintained a ‘Buy’ rating with a target price of ₹14 per share, while UBS stayed ‘Neutral’ with a more conservative ₹9.7 target. Motilal Oswal also maintained a ‘Neutral’ stance, noting the results were slightly ahead of estimates driven by better enterprise revenue. CLICK TO READ MORE BEL, IndiGo, M&M, Bharti Airtel, and Bajaj Auto led Nifty gainers, while Bajaj twins, ONGC, TMPV, and Apollo Hospitals were top losers. Vi, Bajaj Finance, HUDCO, Jindal Stainless react to Q2 numbers. Cera Sanitaryware reported standalone net profit for the quarter ended September 2025 at Rs 56.65 crore as against Rs 68.08 crore in the same quarter last year. Shares down 1% on the NSE to Rs 5,843.50 Edelweiss Financial Services reported standalone net profit for the quarter ended September 2025 at Rs 32.58 crore as against Rs 29.17 crore in the same quarter last year. Board approved fund raising via NCDs aggregating to Rs 1000 cr. Kirloskar Electric Company reported standalone net profit for the quarter ended September 2025 at Rs 6.3 crore as against Rs 5.23 crore in the same quarter last year. Bharat Forge reported standalone net profit for the quarter ended September 2025 at Rs 309.9 crore as against Rs 361.2 crore in the same quarter last year. On consolidated basis, it logged a net profit of Rs 299.3 crore in the quarter under review compared to Rs 243.3 crore in the year-ago period. Board accorded approval to raise funds not exceeding Rs 2000 cr through term loan, NCDs or any other debt instruments. Laxmiprasad Jahagirdar, President and COO – Manufacturing Operations, is designated as Senior Management Personnel (SMP) w.e.f. November 11, 2025. Shares traded at Rs 1,347.40 on the NSE, up 1.5%. Screenshot 2025-11-11 115655.png RateGain Travel Technologies reported a standalone net profit for the quarter ended September 2025 at Rs 20.3 crore as against Rs 13.4 crore in the same quarter last year. Shares traded at Rs 657 on the NSE, down nearly 2.5%. Reliance Power has reported a net profit of ₹87 crore for the quarter ended September 30, supported by an increase in revenues. E2E Networks reported net loss of Rs 13.46 crore in the September 2025 quarter compared to Rs 12.15 crore profit in the year-ago period. Shares traded at Rs 3,006.40 on the NSE, down 1.5%. EARNINGS (net income adj. ests. in INR where available): * Aavas Financiers Ltd. (AAVAS IN) 2Q 1.51b (13 analysts) * BLS International Services Ltd. (BLSIN IN) 2Q * Bajaj Finserv Ltd. (BJFIN IN) 2Q * Bajaj Holdings & Investment Lt (BJHI IN) 2Q * Balrampur Chini Mills Ltd. (BRCM IN) 2Q * Bharat Forge Ltd. (BHFC IN) 2Q 3.17b (12) * Bikaji Foods International Ltd. (BIKAJI IN) 2Q 777m (5) * Biocon Ltd. (BIOS IN) 2Q 1.08b (11) * Bosch Ltd. (BOS IN) 2Q 5.9b (4) * Cera Sanitaryware Ltd. (CRS IN) 2Q 590m (11) * Container Corp. Of India (CCRI IN) 2Q 3.59b (70 * EID Parry India Ltd. (EID IN) 2Q * EIH Ltd. (EIH IN) 2Q 1.37b (2) * Emcure Pharmaceuticals Ltd. (EMCURE IN) 2Q 2.25b (3) * Finolex Cables Ltd. (FNXC IN) 2Q 1.86b (2) * Fortis Healthcare Ltd. (FORH IN) 2Q 2.74b (6) * Godrej Industries Ltd. (GDSP IN) 2Q * Gujarat Fluorochemicals Ltd. (FLUOROCH IN) 2Q 1.87b (11) * Gujarat State Fertilizers & Ch (GSFC IN) 2Q * Gujarat State Petronet Ltd. (GUJS IN) 2Q 3.19b (10) * Hindustan Copper Ltd. (HCP IN) 2Q * IFCI Ltd. (IFCI IN) 2Q * JB Chemicals & Pharmaceuticals (JBCP IN) 2Q 2.04b (5) * Jupiter Wagons Ltd. (JWL IN) 2Q * Kirloskar Oil Engines Ltd. (KOEL IN) 2Q 1.06b (3) * Max Financial Services Ltd. (MAXF IN) 2Q 1.14b (3) * PI Industries Ltd. (PI IN) 2Q 3.99b (19) * Rail Vikas Nigam Ltd. (RVNL IN) 2Q 3.21b (2) * Rites Ltd. (RITE IN) 2Q 973m (4) * Tata Power Co. (TPWR IN) 2Q 3.03b (9) * Thermax Ltd. (TMX IN) 2Q 1.77b (9) * Torrent Power Ltd. (TPW IN) 2Q 6.43b (5) HUDCO shares traded 4% lower on the NSE at Rs 223.56. Company reported standalone net profit for the quarter ended September 2025 at Rs 709.83 crore compared to Rs 688.62 crore in the year-ago period. Board declared 2nd interim dividend of Rs 1 per share. Paisalo Digital reported standalone net profit for the quarter ended September 2025 at Rs 50.81 crore as against Rs 49.52 crore in the year-ago period. Shares traded at Rs 34.27, lower by 5%. Ather Energy stock traded with over 2% increase on the NSE at Rs 639.80. The stock opened at Rs 640 against the previous close of Rs 625.70. The company trimmed losses by 22% to Rs 154 crore in Q2FY26. Top gainers of Nifty 50: BEL (+1.79%), Trent (+1.27%), Bharti Airtel (+1.26%), IndiGo (+1.12%), Dr Reddy’s Lab (+0.74%) Top losers: Bajaj Finance (-7.10%), Bajaj Finserv (-6.74%), Shriram Finance (-1.67%), TMPV (-1.63%), Jio Financial (-1.11%) Syrma SGS Technology stock rose 1% on the NSE to Rs 816.85. The stock hit an intraday high of Rs 856.40 after opening at Rs 820 against the previous close of Rs 808.05. Company reported 78% y-o-y jump in consolidated net profit to Rs 64 crore in September 2025 quarter. The board had approved the acquisition of Mumbai-based Elcome Integrated Systems. KPIT Technologies stock traded flat on the NSE at Rs 1,182.30. The company reported a 17% decline in its net profit to ₹169.08 crore for the September quarter. Vodafone Idea shares zoomed over 6% to Rs 10.10 against the previous close of Rs 9.50. Vi’s net loss narrowed annually by 23% to ₹5,524 crore in the quarter ending September 30, primarily due to reduced finance costs. Kalpataru shares traded at Rs 369.10 after opening lower at Rs 361.50 against the previous close of Rs 371.15. Company reported consolidated net profit for the quarter ended September 2025 at Rs 4.96 crore as against Rs 27.94 crore in the year-ago period. Company also informed exchanges about withdrawal of Scheme of Arrangement of Demerger of demerged undertaking from Kalpataru Limited to its Wholly Owned Subsidiary, namely, Kalpataru Residency Private Limited Shares of Bajaj Finance traded nearly 7% lower on the NSE at Rs 1,011.60 at 9.44 am, near day’s low of Rs 1,005.30. The stock opened at Rs 1,043.70 against the previous close of Rs 1,085. The NBFC reported its consolidated Q2FY26 net profit at ₹4,948 crore, up 23% on a year-on-year (y-o-y) basis, led by strong growth in core income. Sensex depreciated by 124.75 pts or 0.15 % to 83,410.60 at 9.20 am after opening at 83,671.52 against the previous close of 83,535.35. Nifty 50 dipped by 24.10 pts or 0.09% to 25,550.25. Published on November 11, 2025 Copyright© 2025, THG PUBLISHING PVT LTD. or its affiliated companies. All rights reserved. BACK TO TOP Comments have to be in English, and in full sentences. They cannot be abusive or personal. Please abide by our community guidelines for posting your comments. We have migrated to a new commenting platform. If you are already a registered user of TheHindu Businessline and logged in, you may continue to engage with our articles. If you do not have an account please register and login to post comments. Users can access their older comments by logging into their accounts on Vuukle. Terms & conditions | Institutional Subscriber
--------------------------------------------------

Title: CoreWeave’s earnings report highlights $56 billion in contracted revenue, but its guidance and share price tick down amid AI infrastructure bubble fears
URL: https://fortune.com/2025/11/10/coreweave-earnings-infrastructure-debt-ai-bubble/
Time Published: 2025-11-11T01:22:49Z
Full Content:
Amanda Gerut is the west coast editor at Fortune, overseeing publicly traded businesses, executive compensation, Securities and Exchange Commission regulations, and investigations. CoreWeave needed a lot of things to go right on Monday as it released third-quarter financial results, and one of the most critical was showing that its contracted future revenues could hit a $50 billion target Wall Street had set as a benchmark for the AI data-center and infrastructure operator. In its announcement, CoreWeave confirmed it nearly doubled its revenue backlog, which includes “remaining performance obligations” (RPOs) and other amounts it estimates will be recognized as revenue, to $55.6 billion, up from $30 billion the previous quarter. The surging backlog, which represents future revenues from customers, was driven by contracts with Meta, OpenAI, and French AI startup Poolside. Earnings and revenue, meanwhile, both beat analysts’ consensus estimates. The company also reported an increase in the debt on its balance sheet, however, and it revised its full-year revenue guidance downward. Following its earnings release and call with analysts, the stock dropped 6% in after-hours trading. Some investors have trained a gimlet eye on CoreWeave as more skeptics kick the tires of the booming AI trade and the concurrent infrastructure buildout. Concerns about CoreWeave, which some see as a potential canary-like indicator of weakness in the AI ramp-up, and about the AI build-out in general have sent the stock on a journey that has seen it tumble more than 30% from mid-August highs. The downward revision in revenue guidance reflected delays in construction of some of CoreWeave’s data centers. “While we are experiencing relentless demand for our platform, data center developers across the industry are also enduring unprecedented pressure across supply chains,” CEO Michael Intrator said during the analysts’ call. “In our case, we are affected by temporary delays related to a third-party data-center developer who is behind schedule.” Chief financial officer Nitin Agrawal offered full-year 2025 revenue guidance of $5.05 billion to $5.15 billion, down slightly from the guidance Intrator offered on the second-quarter earnings call, of between $5.15 billion to $5.35 billion. The customer impacted by the delay agreed to adjust the delivery schedule and extend the expiration date, Intrator said, which means CoreWeave will maintain the total value of the original contract. Agrawal said the company’s 2025 capex spending would be between $12 billion to $14 billion, down significantly from the $20 billion to $23 billion Intrator forecast last quarter. However, Agrawal said CoreWeave expects 2026 capex to soar. “Given the significant growth in our backlog and continued insatiable demand for our cloud services, we expect capex in 2026 to be well in excess of double that of 2025,” Agrawal said. CoreWeave reported revenues of $1.4 billion for the quarter, up from $584 million in the same quarter last year and beat analysts’ estimates. Profitability, at least by traditional GAAP measures, remains elusive. CoreWeave reported a net loss of $110 million, although it was an improvement over its $359.8 million loss in the third quarter last year and also better than analysts expected. Adjusted net loss, which shows financial performance without extraordinary items, was $41 million for the quarter compared to the same quarter last year when it was break-even, Agrawal said. Adjusted EBITDA, which shows earnings without certain one-time expenses, were $838 million in the third quarter, compared to $379 million in Q3 2024. Operating income, a metric that shows profit from core businesses, fell to $51.9 million, compared to the same quarter last year when it was $117.1 million. Operating margins shrunk to 4% from 20%. Meanwhile, adjusted operating income, which shows a different view on core business performance, was $217 million for the third quarter, compared to $125 million in the third quarter of 2024, said Agrawal, the CFO. CoreWeave’s third quarter adjusted operating margin was 16%, due to higher revenues, lower costs, and the timing of data center deliveries from third parties. While Monday was just this side of positive for CoreWeave, analysts who are bearish on the AI cloud computing company remain leery of its finances. They see the company as at risk of being overwhelmed by the significant financial commitments it has taken on to build out data centers, which currently look disproportionately large compared to its revenues and cash flow. Based on its latest earnings release, CoreWeave has $9.7 billion in bills due within the next 12 months on its balance sheet, and a total of $14 billion in current and longer-term debt. Last quarter, those figures were $7.6 billion and $11 billion, respectively. CoreWeave also has $34 billion in scheduled lease payments on contracts that will commence between now and 2028. Interest expense reached $311 million for the quarter, nearly triple the figure from the year-earlier period, of $104 million. CoreWeave bulls, meanwhile, remain confident that revenues from the company’s book of contracts will eventually far outstrip its debt obligations. During the past three months, CoreWeave has announced a spate of significant deals, booking a $14.2 billion deal to provide Meta with computing capacity and an agreement with Poolside for a data center with 40,000 of Nvidia’s coveted GPUs. © 2025 Fortune Media IP Limited. All Rights Reserved. Use of this site constitutes acceptance of our Terms of Use and Privacy Policy | CA Notice at Collection and Privacy Notice | Do Not Sell/Share My Personal Information FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.
--------------------------------------------------

Title: CoreWeave’s stock wavers on data center delay and lower revenue forecast
URL: https://siliconangle.com/2025/11/10/coreweaves-stock-wavers-data-center-delay-lower-revenue-forecast/
Time Published: 2025-11-10T23:36:51Z
Full Content:
UPDATED 18:36 EST / NOVEMBER 10 2025 by Mike Wheatley Artificial intelligence compute infrastructure company CoreWeave Inc. delivered better-than-expected financial results today, but its stock lost ground after-hours when it revealed a tepid revenue forecast and said one of its third-party developers has fallen behind schedule on a key data center facility. The company reported a third-quarter loss before certain costs such as stock compensation of 22 cents per share, easily beating Wall Street’s estimate of a 40-cent-per-share loss. Revenue for the period rose by an impressive 134%, to $1.36 billion, also surpassing the analysts’ target of $1.29 billion. The increased revenue had the effect of narrowing CoreWeave’s net loss considerably to just $110 million, down from a $360 million loss in the year-ago period. CoreWeave Chief Executive Michael Intrator (pictured) said the company’s results are a reflection of its disciplined execution across every part of its business. “CoreWeave’s position as the essential cloud for AI has never been stronger as we drive growth through focus and innovation to power the next generation of AI,” he added. The fortunes of CoreWeave are tied directly to those of the AI industry, because the company specializes in renting out access to Nvidia Corp.’s graphics processing units and has secured numerous multibillion-dollar deals with key cloud infrastructure providers such as Microsoft Corp. and Google LLC. The company said its backlog stood at $55.6 billion at the end of the quarter, with 2.9 gigawatts in power under contract, up from 2.2 gigawatts three months earlier. The company made some big announcements during the quarter, notably including a $6.5 billion expansion of its partnership with OpenAI Group PBC. It also signed a new, six-year deal with Meta Platforms Inc. that could ultimately be worth up to $14.2 billion, along with another contract from an undisclosed “leading hyperscaler.” Despite the progress on the deal front, Intrator told analysts on a conference call that the company remains “supply-constrained.” He explained that the problem has to do with partly completed “powered-shell” data centers where the company intends to set up its own infrastructure. Intrator also admitted that one of the company’s third-party contractors has fallen behind schedule. He told analysts that the delay in construction won’t impact the company’s backlog, because the customer affected by the holdup has agreed to adjust its delivery schedule. The original value of the contract will be maintained, he added. “There was a problem at one data center that’s impacting us, but there are 32 data centers in our portfolio,” Intrator pointed out. However, one problem with that delay is that it’s likely going to hurt CoreWeave’s near-term fortunes. The company offered a full-year revenue forecast of between $5.05 billion and $5.15 billion, below Wall Street’s target of $5.29 billion. CoreWeave has enjoyed a wild ride since going public on the Nasdaq in March, when it sold its shares at a price of $40 each. The stock closed at $105.61, representing a gain of more than 165%, only to fall almost 6% in late trading today. Still, it continues to outperform the Nasdaq by a long way, with the broader index up just 32% over the same period. Holger Mueller of Constellation Research praised CoreWeave, not only for its “outstanding growth” but also for proving the many skeptics in the AI industry wrong, as it made great strides towards profitability. “Its earnings-per-share loss improved considerably, and with another quarter like this it should be in the black,” the analyst said. Having demonstrated it has a viable business, CoreWeave now needs to focus on carefully managing its growth, the analyst believes. “The focus has to shift to following the supply chain, delivering more data center capacity and running customer workloads successfully,” he said. “At the moment, it does face some challenges, with delays in one of its data center build outs, and this will need to be addressed.” Despite its impressive progress, CoreWeave has had its share of disappointments. Last month shareholders of the data center infrastructure company Core Scientific Inc. voted to decline a $9 billion acquisition offer, claiming it was undervalued and didn’t recognize its growth potential. CoreWeave chose not to increase its offer, and so the deal has been terminated. “We respect the decision of Core Scientific’s stockholders regarding our previously announced merger agreement,” CoreWeave said in a statement. “Our partnership with Core Scientific remains strong and will continue to execute on shared growth opportunities. CoreWeave’s vision and strategy remain unchanged.” Nevertheless, CoreWeave is still planning to spend lots of money in the coming months, acquisitions or not. On the conference call, Chief Financial Officer Nitin Agrawal said the company’s capital expenditures in fiscal 2026 will be “well in excess of double” its $12 billion to $14 billion forecast for the current year. Support our mission to keep content open and free by engaging with theCUBE community. Join theCUBE’s Alumni Trust Network, where technology leaders connect, share intelligence and create opportunities. Founded by tech visionaries John Furrier and Dave Vellante, SiliconANGLE Media has built a dynamic ecosystem of industry-leading digital media brands that reach 15+ million elite tech professionals. Our new proprietary theCUBE AI Video Cloud is breaking ground in audience interaction, leveraging theCUBEai.com neural network to help technology companies make data-driven decisions and stay at the forefront of industry conversations. Google Photos adds support for Nano Banana-powered AI editing features Google details cloud-based Private AI Compute system for securing Pixel data SoftBank offloads $5.8B stake in Nvidia to free up cash for OpenAI investment Nebius inks $3B data center deal with Meta after missing revenue expectations Google debuts new open-source AI tools, GKE Pod Snapshots Despite the hype of 5G, there's still big demand for high-density Wi-Fi Google Photos adds support for Nano Banana-powered AI editing features AI - BY MIKE WHEATLEY . 1 HOUR AGO Google details cloud-based Private AI Compute system for securing Pixel data AI - BY MARIA DEUTSCHER . 2 HOURS AGO SoftBank offloads $5.8B stake in Nvidia to free up cash for OpenAI investment AI - BY MIKE WHEATLEY . 3 HOURS AGO Nebius inks $3B data center deal with Meta after missing revenue expectations INFRA - BY MARIA DEUTSCHER . 3 HOURS AGO Google debuts new open-source AI tools, GKE Pod Snapshots AI - BY MARIA DEUTSCHER . 5 HOURS AGO Despite the hype of 5G, there's still big demand for high-density Wi-Fi INFRA - BY ZEUS KERRAVALA . 6 HOURS AGO
--------------------------------------------------

Title: Bernstein Remains Bullish on Dollar General (DG), Maintains Buy Call
URL: https://finance.yahoo.com/news/bernstein-remains-bullish-dollar-general-231326445.html
Time Published: 2025-11-10T23:13:26Z
Description: Dollar General Corporation (NYSE:DG) is one of the best dividend stocks to buy. On October 28, Bernstein analyst Zhihan Ma reiterated a Buy rating on Dollar ...
--------------------------------------------------

Title: Stocks Finish Sharply Higher on Plans to Reopen the US Government
URL: https://www.barchart.com/story/news/36033320/stocks-finish-sharply-higher-on-plans-to-reopen-the-us-government
Time Published: 2025-11-10T21:35:03Z
Description: The S&P 500 Index ($SPX ) (SPY ) on Monday closed up +1.54%, the Dow Jones Industrials Index ($DOWI ) (DIA ) closed up +0.81%, and the Nasdaq 100 Index...
--------------------------------------------------

Title: Verizon Sells $11 Billion of Bonds Tied to Frontier Deal
URL: https://finance.yahoo.com/news/verizon-sells-11-billion-bonds-210049783.html
Time Published: 2025-11-10T21:00:49Z
Description: Verizon issued the debt in five parts, according to a person with knowledge of the matter who asked not to be identified discussing private details...
--------------------------------------------------

Title: AI Stock Correction: MSFT, AVGO, IONQ Seen as Stable Tech, Quantum Bets
URL: https://finance.yahoo.com/news/ai-stock-correction-msft-avgo-200000734.html
Time Published: 2025-11-10T20:00:00Z
Description: MSFT, AVGO and IONQ stand out as resilient plays as investors rotate from overheated AI hype to sustainable tech and quantum growth paths.
--------------------------------------------------

Title: Analysts Say Nvidia Stock Is ‘Dominant’ Amid a Giant Race to ‘Secure Compute.’ Buy Shares Now?
URL: https://www.barchart.com/story/news/36030588/analysts-say-nvidia-stock-is-dominant-amid-a-giant-race-to-secure-compute-buy-shares-now
Time Published: 2025-11-10T19:45:19Z
Description: A Jefferies analyst is very bullish on Nvidia and believes the financials are set to keep ballooning.
--------------------------------------------------

Title: S&P 500 profits surge on price hikes, cost cuts
URL: https://www.thestreet.com/markets/corporate-earnings-surge-as-main-street-reels
Time Published: 2025-11-10T19:34:43Z
Description: After President Donald Trump enacted tariffs this spring, stocks tumbled on fears that higher import taxes would crimp corporate profits, leading to layoffs ...
--------------------------------------------------

Title: Making Sense of the Market's Tech Worries
URL: https://finance.yahoo.com/news/making-sense-markets-tech-worries-192200516.html
Time Published: 2025-11-10T19:22:00Z
Description: The recent weakness in leading artificial intelligence stocks has rekindled concerns about the group's momentum and market leadership. But given their...
--------------------------------------------------

Title: RDDT 12.97X P/S Suggests Premium Valuation: Should You Buy the Stock?
URL: https://finance.yahoo.com/news/rddt-12-97x-p-suggests-174100202.html
Time Published: 2025-11-10T17:41:00Z
Description: Reddit's strong ad growth, global expansion, and AI-driven tools help the company to justify its premium valuation.
--------------------------------------------------

Title: Here's How Much Traders Expect CoreWeave Stock To Move After Earnings on Monday
URL: https://www.investopedia.com/here-is-how-much-traders-expect-coreweave-stock-to-move-after-earnings-on-monday-11846581
Time Published: 2025-11-10T16:31:56Z
Full Content:
CoreWeave (CRWV) is slated to report third-quarter results after the closing bell on Monday, with traders expecting a big post-earnings move for the stock. Options pricing suggests traders anticipate shares of CoreWeave could move up to 14% in either direction by the end of this week. A move of that size would push the stock up to $118.70 at the high end, erasing some of the losses incurred amid last week’s slump in tech stocks, or drag it down to $89.30, its lowest price since early September. CoreWeave has only reported quarterly results twice since it began trading, and neither has helped the stock. In May, shares fell more than 2% the day after the company's earnings were released, despite better-than-expected results, with revenue increasing more than 400% year-over-year. Shares tumbled more than 20% after earnings in August, when the company reported a wider-than-expected loss. CoreWeave shares have soared since debuting in March, with investors looking past the company's unprofitability to focus on surging revenue driven by AI demand. How investors react to the company's results on Monday could reflect Wall Street's risk appetite and sentiment pertaining to the AI stock rally. Granted, CoreWeave's shares advanced considerably leading up to both prints. The stock gained nearly 70% between its late-March IPO and May’s report, and rose about 120% heading into August’s results. This time could be different. Leading into Monday's session, CoreWeave shares were down about 30% since its last earnings. CoreWeave's revenue has soared in the last year and a half amid a surge in demand for AI-enabling cloud computing platforms. The company landed several major customers last quarter, signing a $14 billion deal with Meta Platforms (META), a $6 billion deal with Nvidia (NVDA), and a $6.5 billion expansion of its existing agreement with ChatGPT maker OpenAI. The cloud computing provider is expected to report a third-quarter net loss of $284.4 million, narrowing from a loss of $359.8 million in the year ago quarter. Its revenue is projected to jump 120% year-over-year to $1.3 billion, according to analyst estimates compiled by Visible Alpha. Wall Street is split on the outlook for CoreWeave’s stock, with five of the 10 analysts with current ratings tracked by Visible Alpha calling the stock a “buy,” and the other half assigning it a “hold” rating. Their mean target of $158.83 represents about 53% upside from the stock’s closing price last Friday.
--------------------------------------------------

Title: Are U.S. markets in for a rough ride? Here’s what experts are saying and what investors need to know
URL: https://economictimes.indiatimes.com/news/international/us/are-u-s-markets-in-for-a-rough-ride-heres-what-experts-are-saying-and-what-investors-need-to-know/articleshow/125226832.cms
Time Published: 2025-11-10T16:30:07Z
Full Content:
U.S. stock market looks stretched. Valuations are near record highs, growth is slowing, and inflation still hovers around 4%. The OECD sees GDP slipping to 1.6% in 2025, while the Fed delays rate cuts. Credit card delinquencies hit a 12-year high, and profits are tightening. With the S&P 500 heavily reliant on tech giants, even a small shock could spark volatility. Analysts warn of smaller gains, sharper swings, and a tougher road ahead for investors. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. (Catch all the US News, UK News, Canada News, International Breaking News Events, and Latest News Updates on The Economic Times.) Download The Economic Times News App to get Daily International News Updates. Delhi: Blast near Red Fort, multiple casualties reported ‘Amit Shah ji istifa dedo…’: Cong over infiltrator remark Tejashwi blasts EC for withholding voter data after phase 1 Justice Thomas grills lawyer Kaytal over Trump tariffs 6,000 people sent from Haryana to Bihar? Bengaluru jail turns party hub? Inmates caught drinking Pak-Afghan peace talks break down: What happens next Shutdown end ‘very close,’ Trump pushes Dems to reopen Senate votes 60-40 to break filibuster, move to reopen govt Watch: Lava erupts from Hawaii’s Kilauea volcano Delhi: Blast near Red Fort, multiple casualties reported ‘Amit Shah ji istifa dedo…’: Cong over infiltrator remark Tejashwi blasts EC for withholding voter data after phase 1 Justice Thomas grills lawyer Kaytal over Trump tariffs 6,000 people sent from Haryana to Bihar? Bengaluru jail turns party hub? Inmates caught drinking Pak-Afghan peace talks break down: What happens next Shutdown end ‘very close,’ Trump pushes Dems to reopen Senate votes 60-40 to break filibuster, move to reopen govt Watch: Lava erupts from Hawaii’s Kilauea volcano Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Definitions Top Commodities Top Slideshow Private Companies Top Prime Articles Top Story Listing Latest News Follow us on: Find this comment offensive? Choose your reason below and click on the Report button. This will alert our moderators to take action Reason for reporting: Your Reason has been Reported to the admin. Log In/Connect with: Will be displayed Will not be displayed Will be displayed Stories you might be interested in
--------------------------------------------------

Title: 5 Defensive Consumer Plays to Watch If Markets Keep Slipping
URL: https://www.marketbeat.com/stock-ideas/5-defensive-consumer-plays-to-watch-if-markets-keep-slipping/?utm_source=yahoofinance&amp;utm_medium=yahoofinance
Time Published: 2025-11-10T16:22:00Z
Description: Last week, the market showed its first meaningful signs of weakness since May, with SPY breaking its 50-day SMA and several tech leaders selling off sharply.
--------------------------------------------------

Title: Stocks Rally on Optimism that the US Government Will Soon Reopen
URL: https://www.barchart.com/story/news/36025494/stocks-rally-on-optimism-that-the-us-government-will-soon-reopen
Time Published: 2025-11-10T15:10:33Z
Description: The S&P 500 Index ($SPX ) (SPY ) today is up +1.10%, the Dow Jones Industrials Index ($DOWI ) (DIA ) is up +0.55%, and the Nasdaq 100 Index ($IUXX ) (QQQ...
--------------------------------------------------

Title: U.S. Equities Lag International in 2025: 5 Top ETF Performers
URL: https://finance.yahoo.com/news/u-equities-lag-international-2025-123800388.html
Time Published: 2025-11-10T12:38:00Z
Description: International ETFs like FDT, IDV, FDTS, EFAS & FLEU soared as investors pivot from pricey and uncertain policy-driven U.S. markets to undervalued...
--------------------------------------------------

Title: Behind AI Hype, Climate Consequences
URL: https://www.commondreams.org/opinion/climate-consequences-of-ai
Time Published: 2025-11-10T11:50:03Z
Full Content:
To donate by check, phone, or other method, see our More Ways to Give page. Daily news & progressive opinion—funded by the people, not the corporations—delivered straight to your inbox. Daily news & progressive opinion—funded by the people, not the corporations—delivered straight to your inbox. An aerial view of a 33 megawatt data center with closed-loop cooling system is seen on October 20, 2025 in Vernon, California. AI’s massive energy use is giving fossil fuels a lifeline when they should be rapidly phased out in response to the climate emergency. What started as rivulets of hype, hope, and alarm over artificial intelligence have combined into a tsunami-level wave washing over the American consciousness. ChatGPT is the most downloaded application in history, AI stock prices are hitting record market highs, and the American public is giddy about its potential technological upsides and devastated by its role in mental health crises. Less discussed but deeply important are the AI boom’s clear and present dangers to our environment, health, and wallets. That lack of attention to these issues is exactly how President Donald Trump, Big Tech, and the oil and gas industry want it. As Trump attacks climate progress on all fronts, his administration is in lockstep pushing for a fast-tracked AI data center boom fed by gas and coal. It’s critical that AI become part of global climate negotiations—not as an escape hatch for how it could save the planet, but as an urgent threat to people, wildlife, and the atmosphere. It may not be immediately obvious, but AI is a gift to the fossil fuel industry. That’s because AI’s massive energy use is giving fossil fuels a lifeline when they should be rapidly phased out in response to the climate emergency. It’s a huge problem for world leaders as they gather in Brazil for this year’s annual global climate talks, known as COP30. In one of the biggest shifts since last year’s talks, data center expansion to feed energy-intensive AI is straining grids and leading companies and some countries to walk back domestic climate pledges. The Trump administration has cited the power-hungry AI beast as one big excuse for abandoning climate efforts, even as the US disproportionately leads the world in data center pollution. And the great AI energy suck is just getting started, with dozens of massive new data centers slated for construction across the country—and hundreds more around the world. Mark Zuckerberg says one Meta data center will be the size of Manhattan. Sam Altman, the CEO of OpenAI, said recently, “I do guess that a lot of the world gets covered in data centers over time.” These data centers demand immense amounts of power, land, and water for cooling. As one point of comparison, a ChatGPT AI search consumes 10 times as much energy as a normal Google search. Just how bad could data center expansion be for the climate? That’s what we set out to find in our report, Data Crunch: How the AI Boom Threatens to Entrench Fossil Fuels and Compromise Climate Goals. We found that plans for US data center growth, set to be powered primarily by fossil gas, as well as notoriously dirty coal, could triple by 2035. That comes with a huge cost to efforts to preserve a livable planet and limit the deadly flooding, extreme heat, and destructive fires of the climate emergency. Unchecked, the fossil-fueled data center expansion could account for 10% of US economy-wide emissions and 44% of the power sector emissions allowable to meet the US climate target under the Paris Agreement. With a gas-fed AI boom, all other electricity-consuming sectors, like homes and buildings, would need to cut their emissions by 60% more to keep pace with that target, set by former President Joe Biden and still in effect under Paris Agreement terms. Amid all the hype and seeming inevitability of AI dominance, human beings have a chance now to proactively consider what relationship we want with this technology—and the environmental price we’re willing to pay. If new AI data centers were instead powered by renewables like solar and wind, they’d be only 4% of power sector emissions and would barely affect our ability to meet the US climate goal. Despite Trump exiting the Paris Agreement, Biden’s target stands as the United States’ contribution to global efforts to combat climate change. While Trump dismisses climate change as a “con job,” there is broad scientific agreement that every degree of global heating worsens its deadly, destructive effects on people and wildlife. A study last month found that accelerating climate harms mean that half a million people now die every year from extreme heat—an average of one person a minute. The unbridled expansion of data centers to feed AI will only further intensify such fatal consequences and others, including crop loss to drought, spread of disease, and loss of imperiled plants and animals. These consequences are exactly what world leaders gathered in Belem, Brazil, for COP30 are trying to prevent, by limiting global heating by every fraction of a degree that they can. That goal can’t be achieved without serious guardrails on AI data center development. It’s critical that AI become part of global climate negotiations—not as an escape hatch for how it could save the planet, but as an urgent threat to people, wildlife, and the atmosphere. Before AI unleashes a fresh hell of global heating, countries should commit to zeroing out the emissions from data centers by using renewable energy and storage. From Virginia to Tucson to Kosciuko County, Indiana, communities around the country have sprouted near-overnight campaigns to protect their water and electricity from being consumed by data centers and to prevent rate hikes to subsidize two of the wealthiest industries on Earth. Besides playing defense, now is the time to be proactive and question whether data centers serve the public interest despite their many harms. If local communities still think so, they can pass strict regulations to ensure that data centers are powered fully by on-site renewable energy and batteries. If more power is needed, Big Tech companies can pay for residences to get rooftop solar and storage, heat pumps, and energy efficient appliances to free up capacity on the grid for data center neighbors. Amid all the hype and seeming inevitability of AI dominance, human beings have a chance now to proactively consider what relationship we want with this technology—and the environmental price we’re willing to pay. The COP30 climate talks will be a starting place for the world to look carefully at AI’s climate consequences. The tsunami of AI hype and the Trump destruction machine make for daunting foes. But they don’t have to wash away our resolve to leave this world better than we found it. What started as rivulets of hype, hope, and alarm over artificial intelligence have combined into a tsunami-level wave washing over the American consciousness. ChatGPT is the most downloaded application in history, AI stock prices are hitting record market highs, and the American public is giddy about its potential technological upsides and devastated by its role in mental health crises. Less discussed but deeply important are the AI boom’s clear and present dangers to our environment, health, and wallets. That lack of attention to these issues is exactly how President Donald Trump, Big Tech, and the oil and gas industry want it. As Trump attacks climate progress on all fronts, his administration is in lockstep pushing for a fast-tracked AI data center boom fed by gas and coal. It’s critical that AI become part of global climate negotiations—not as an escape hatch for how it could save the planet, but as an urgent threat to people, wildlife, and the atmosphere. It may not be immediately obvious, but AI is a gift to the fossil fuel industry. That’s because AI’s massive energy use is giving fossil fuels a lifeline when they should be rapidly phased out in response to the climate emergency. It’s a huge problem for world leaders as they gather in Brazil for this year’s annual global climate talks, known as COP30. In one of the biggest shifts since last year’s talks, data center expansion to feed energy-intensive AI is straining grids and leading companies and some countries to walk back domestic climate pledges. The Trump administration has cited the power-hungry AI beast as one big excuse for abandoning climate efforts, even as the US disproportionately leads the world in data center pollution. And the great AI energy suck is just getting started, with dozens of massive new data centers slated for construction across the country—and hundreds more around the world. Mark Zuckerberg says one Meta data center will be the size of Manhattan. Sam Altman, the CEO of OpenAI, said recently, “I do guess that a lot of the world gets covered in data centers over time.” These data centers demand immense amounts of power, land, and water for cooling. As one point of comparison, a ChatGPT AI search consumes 10 times as much energy as a normal Google search. Just how bad could data center expansion be for the climate? That’s what we set out to find in our report, Data Crunch: How the AI Boom Threatens to Entrench Fossil Fuels and Compromise Climate Goals. We found that plans for US data center growth, set to be powered primarily by fossil gas, as well as notoriously dirty coal, could triple by 2035. That comes with a huge cost to efforts to preserve a livable planet and limit the deadly flooding, extreme heat, and destructive fires of the climate emergency. Unchecked, the fossil-fueled data center expansion could account for 10% of US economy-wide emissions and 44% of the power sector emissions allowable to meet the US climate target under the Paris Agreement. With a gas-fed AI boom, all other electricity-consuming sectors, like homes and buildings, would need to cut their emissions by 60% more to keep pace with that target, set by former President Joe Biden and still in effect under Paris Agreement terms. Amid all the hype and seeming inevitability of AI dominance, human beings have a chance now to proactively consider what relationship we want with this technology—and the environmental price we’re willing to pay. If new AI data centers were instead powered by renewables like solar and wind, they’d be only 4% of power sector emissions and would barely affect our ability to meet the US climate goal. Despite Trump exiting the Paris Agreement, Biden’s target stands as the United States’ contribution to global efforts to combat climate change. While Trump dismisses climate change as a “con job,” there is broad scientific agreement that every degree of global heating worsens its deadly, destructive effects on people and wildlife. A study last month found that accelerating climate harms mean that half a million people now die every year from extreme heat—an average of one person a minute. The unbridled expansion of data centers to feed AI will only further intensify such fatal consequences and others, including crop loss to drought, spread of disease, and loss of imperiled plants and animals. These consequences are exactly what world leaders gathered in Belem, Brazil, for COP30 are trying to prevent, by limiting global heating by every fraction of a degree that they can. That goal can’t be achieved without serious guardrails on AI data center development. It’s critical that AI become part of global climate negotiations—not as an escape hatch for how it could save the planet, but as an urgent threat to people, wildlife, and the atmosphere. Before AI unleashes a fresh hell of global heating, countries should commit to zeroing out the emissions from data centers by using renewable energy and storage. From Virginia to Tucson to Kosciuko County, Indiana, communities around the country have sprouted near-overnight campaigns to protect their water and electricity from being consumed by data centers and to prevent rate hikes to subsidize two of the wealthiest industries on Earth. Besides playing defense, now is the time to be proactive and question whether data centers serve the public interest despite their many harms. If local communities still think so, they can pass strict regulations to ensure that data centers are powered fully by on-site renewable energy and batteries. If more power is needed, Big Tech companies can pay for residences to get rooftop solar and storage, heat pumps, and energy efficient appliances to free up capacity on the grid for data center neighbors. Amid all the hype and seeming inevitability of AI dominance, human beings have a chance now to proactively consider what relationship we want with this technology—and the environmental price we’re willing to pay. The COP30 climate talks will be a starting place for the world to look carefully at AI’s climate consequences. The tsunami of AI hype and the Trump destruction machine make for daunting foes. But they don’t have to wash away our resolve to leave this world better than we found it. What started as rivulets of hype, hope, and alarm over artificial intelligence have combined into a tsunami-level wave washing over the American consciousness. ChatGPT is the most downloaded application in history, AI stock prices are hitting record market highs, and the American public is giddy about its potential technological upsides and devastated by its role in mental health crises. Less discussed but deeply important are the AI boom’s clear and present dangers to our environment, health, and wallets. That lack of attention to these issues is exactly how President Donald Trump, Big Tech, and the oil and gas industry want it. As Trump attacks climate progress on all fronts, his administration is in lockstep pushing for a fast-tracked AI data center boom fed by gas and coal. It’s critical that AI become part of global climate negotiations—not as an escape hatch for how it could save the planet, but as an urgent threat to people, wildlife, and the atmosphere. It may not be immediately obvious, but AI is a gift to the fossil fuel industry. That’s because AI’s massive energy use is giving fossil fuels a lifeline when they should be rapidly phased out in response to the climate emergency. It’s a huge problem for world leaders as they gather in Brazil for this year’s annual global climate talks, known as COP30. In one of the biggest shifts since last year’s talks, data center expansion to feed energy-intensive AI is straining grids and leading companies and some countries to walk back domestic climate pledges. The Trump administration has cited the power-hungry AI beast as one big excuse for abandoning climate efforts, even as the US disproportionately leads the world in data center pollution. And the great AI energy suck is just getting started, with dozens of massive new data centers slated for construction across the country—and hundreds more around the world. Mark Zuckerberg says one Meta data center will be the size of Manhattan. Sam Altman, the CEO of OpenAI, said recently, “I do guess that a lot of the world gets covered in data centers over time.” These data centers demand immense amounts of power, land, and water for cooling. As one point of comparison, a ChatGPT AI search consumes 10 times as much energy as a normal Google search. Just how bad could data center expansion be for the climate? That’s what we set out to find in our report, Data Crunch: How the AI Boom Threatens to Entrench Fossil Fuels and Compromise Climate Goals. We found that plans for US data center growth, set to be powered primarily by fossil gas, as well as notoriously dirty coal, could triple by 2035. That comes with a huge cost to efforts to preserve a livable planet and limit the deadly flooding, extreme heat, and destructive fires of the climate emergency. Unchecked, the fossil-fueled data center expansion could account for 10% of US economy-wide emissions and 44% of the power sector emissions allowable to meet the US climate target under the Paris Agreement. With a gas-fed AI boom, all other electricity-consuming sectors, like homes and buildings, would need to cut their emissions by 60% more to keep pace with that target, set by former President Joe Biden and still in effect under Paris Agreement terms. Amid all the hype and seeming inevitability of AI dominance, human beings have a chance now to proactively consider what relationship we want with this technology—and the environmental price we’re willing to pay. If new AI data centers were instead powered by renewables like solar and wind, they’d be only 4% of power sector emissions and would barely affect our ability to meet the US climate goal. Despite Trump exiting the Paris Agreement, Biden’s target stands as the United States’ contribution to global efforts to combat climate change. While Trump dismisses climate change as a “con job,” there is broad scientific agreement that every degree of global heating worsens its deadly, destructive effects on people and wildlife. A study last month found that accelerating climate harms mean that half a million people now die every year from extreme heat—an average of one person a minute. The unbridled expansion of data centers to feed AI will only further intensify such fatal consequences and others, including crop loss to drought, spread of disease, and loss of imperiled plants and animals. These consequences are exactly what world leaders gathered in Belem, Brazil, for COP30 are trying to prevent, by limiting global heating by every fraction of a degree that they can. That goal can’t be achieved without serious guardrails on AI data center development. It’s critical that AI become part of global climate negotiations—not as an escape hatch for how it could save the planet, but as an urgent threat to people, wildlife, and the atmosphere. Before AI unleashes a fresh hell of global heating, countries should commit to zeroing out the emissions from data centers by using renewable energy and storage. From Virginia to Tucson to Kosciuko County, Indiana, communities around the country have sprouted near-overnight campaigns to protect their water and electricity from being consumed by data centers and to prevent rate hikes to subsidize two of the wealthiest industries on Earth. Besides playing defense, now is the time to be proactive and question whether data centers serve the public interest despite their many harms. If local communities still think so, they can pass strict regulations to ensure that data centers are powered fully by on-site renewable energy and batteries. If more power is needed, Big Tech companies can pay for residences to get rooftop solar and storage, heat pumps, and energy efficient appliances to free up capacity on the grid for data center neighbors. Amid all the hype and seeming inevitability of AI dominance, human beings have a chance now to proactively consider what relationship we want with this technology—and the environmental price we’re willing to pay. The COP30 climate talks will be a starting place for the world to look carefully at AI’s climate consequences. The tsunami of AI hype and the Trump destruction machine make for daunting foes. But they don’t have to wash away our resolve to leave this world better than we found it.
--------------------------------------------------

Title: The $4.5 Quadrillion Opportunity in Human Time
URL: https://www.pymnts.com/opinion/david-s-evans/2025/the-4-5-quadrillion-opportunity-in-human-time/
Time Published: 2025-11-10T09:00:49Z
Full Content:
Behind almost every great innovation is a story of time. Complete the form to unlock this article and enjoy unlimited free access to all PYMNTS content — no additional logins required. yesSubscribe to our daily newsletter, PYMNTS Today. By completing this form, you agree to receive marketing communications from PYMNTS and to the sharing of your information with our sponsor, if applicable, in accordance with our Privacy Policy and Terms and Conditions. Δ Maybe an innovation saved a lot of our time. Or it made us live longer. Made us more productive workers who could command a higher premium on our time. Or enabled us to pack more things into the limited time we have. Some innovations have done most of the above. Innovations in time have massively improved and extended our lives over the last several centuries. And there’s no letting up. The next wave of disruption will come from those who deliberately innovate around time. Those who see time not as the tick of fixed seconds, but as a human asset whose value has almost unlimited potential. To find inspiration for the next breakthrough, decacorn, and more, catalysts should study time. No asset is more valuable, or more limited, than time. Advertisement: Scroll to Continue Each day, we get just so much. Twenty-four hours, 1,440 minutes, 86,400 seconds. If we don’t use it, we lose it. So, we try to make the most of it. To do that, we trade it, swap it and compress it, each day and over our lifetimes. We can use some of our time endowment to work and make money to buy things. By using our time to learn when we are young, we can earn more money and enjoy our time more when we are older. Just like people value their houses and businesses value their capital stocks, people value their time. In the U.S., economic studies find that the average person values their time on earth at around $13 million. That is based on looking at how much people must be paid to take risks that could end their lives. The government uses that figure to evaluate benefits and costs involving lives. That makes the value of the stock of time for the U.S. population of 340 million people around $4.5 quadrillion (340.1 million people times $13.1 million per life). By comparison, the U.S. housing stock is worth a measly $55 trillion according to Zillow; the total fixed capital stock was worth $87 trillion in 2024 according to the Bureau of Economic Analysis; and the total value of companies on public exchanges in the U.S. was $68 trillion at the end of September. A more precise estimate of the value of time would account for the fact that the value of life and life expectancy vary with age. But when you get to quadrillions, who’s really counting? Governments, businesses and innovators should treat time as what it truly is. A national and global asset. And like every other great asset, its value can grow through disruptive innovation. The better we use it, the richer the world becomes. Almost 90% of American farms didn’t have electricity as late as 1935. Robert Caro’s famous biography of Lyndon Johnson, “The Path to Power,” shows what that meant to the people living in Hill Country, Texas. A typical farm family used 40 gallons of water a day. To get it, they had to walk to a well located about 250 feet away with a bucket and carry it back to the house. A federal study found the average family spent about 500 hours a year and walked about 1,750 miles just to get water. The family devoted even more hours to hauling wood and washing clothes by hand. Tasks that consumed time and strength, especially for women who, literally, carried the heaviest load. More than half suffered physical injuries from the strain of constant standing and physical labor involved in doing both. Without electricity, there wasn’t much else to do. “No radio; no movies; limited reading—little diversion from the hard day just past and the hard day ahead,” according to Caro. “Living was just drudgery,” one person reminisced. Electrification changed all that, not just in Hill Country, but throughout the U.S. and eventually most of the world. People had more time. And more to do with that time. They could also expect to live longer as electrification reduced infant and adult mortality. Disruptive innovations can make time far more valuable. Entrepreneurs, innovators, businesses and governments have nine levers to find the next big thing in time. 1. Saving Time: Spending less time on one thing so you can spend it on another. Millennia ago, people learned to domesticate horses, which reduced the time spent traveling. Running water from electric pumps likely saved all 500 of those family hours fetching water. The invention of the washing machine reduced the amount of homemaker time to do a load of laundry from 4 hours to 41 minutes. E-commerce companies, from online retailers to meal delivery services, save people the time from traveling to and from physical locations or from cooking their own meals. 2. Making Time. Delaying the Grim Reaper’s visit as long as possible. Innovations like indoor plumbing created cleaner water and prevented the spread of disease. Vaccines largely ended many deadly diseases. The development of antibiotics saved lives. Surgical advances, imaging innovations, and drug development do too. Saving lives means extending the amount of time people have. Globally, average life expectancy increased from 32 years in 1900 to 73 years in 2023, more than doubling the amount of time people have. In the U.S., life expectancy increased from about 50 to almost 80. A perfect human specimen, with the best circumstances and the greatest luck, could make it until 125 based on the upper range for demographic studies. Using that data, in the U.S., we’ve reached only 64% of our potential. 3. Enriching Time. Packing more into the time you have. Electrification expanded the portion of the day people had light. That gave them more time to read and do things that are impossible to do in the dark. The printing press, and communication technologies from the telegraph to radio to broadband, have expanded the ability to benefit from our auditory and visual senses. Smartphones, powered by fast cellular, make those experiences on the go and on demand. Today we can listen to an audiobook, a podcast, or the radio while we’re driving, taking the subway or vacuuming the floors. 4. Monetizing Time. Using time to work to make money for people and their families. Innovations can change the amount of time people work. The time people spend working depends on whether they participate in the labor force, how many hours they work, and when they decide to retire. People can then use that money to buy goods and services, which they combine with their time (think about eating) to create value. The labor force participation of women has increased in the last century in part because household chores, which disproportionately fell on them, took up less time. People can work later in life because they are healthier and have more years available to them. Platforms make it possible for people to pick up gig jobs, participate in side hustles and work-from-home using their available time. Innovations often result in people being paid more because they are more productive. With higher incomes and savings, people can decide to work less and retire earlier, with greater incomes and more wealth. 5. Enjoying Time. Spending more time on leisure activities. The disruptive innovations for time saving and improving innovations have made leisure cheaper, because less time is needed for household chores, and more valuable, because sensory-related innovations provide better ways to spend their time. In 2024, the average American, age 15 and over, spent an average of 5.5 hours a day “in some sort of leisure and sport activity, such as watching TV, socializing, or exercising.” That’s about 37% of waking hours (the average number of hours sleeping was 9.0 hours). An economic study found that adults spent 6.75 more fewer hours a week working for pay or at home, and instead on leisure activities, between 1965 and 2003. This time was worth roughly 8% to 9% of GDP based on how much people could have made from paid work 6. Trading Time. Giving people things for free, or at a discount, in return for them giving some of their attention. Since newspapers were first invented, advertisers have been paying for people to pay attention to them. The idea is simple: advertisers buy space in media, hoping that audiences will notice their ads. People might not enjoy the ads, but they do enjoy the content. In exchange for free or cheaper access to that content, they let advertisers try to capture some of their attention. New media innovations have always created huge value by making leisure more enjoyable. Families in places like Hill Country, for instance, could spend hours listening to the radio or watching TV, paying nothing beyond the cost of the equipment and electricity. My 2020 paper on attention markets estimated that Americans spent about 500 billion hours consuming ad-supported content in 2019. That made the content they were consuming worth roughly $7 trillion, given the opportunity cost of their time. 7. Investing Time. Using time to learn and thereby increasing the value of time later in life. People, in most developed countries, invest a large part of their time through their teens, and often beyond, learning. This increases the value of their time, for working and themselves, later in their lives. A 2020 U.S. study by Fed economists found that kids, from kindergarten through high school, spent 36% of their waking hours over the week on class time and enrichment activities, including homework. (The data are from 1997, 2002, and 2007.) Investing in time differs in two main ways from the other levers of innovation. It’s not like choosing to watch TV, clean the house, or pick up hours with side hustles. In the U.S., and many countries, kids are compelled to invest time in learning by the government and by their parents. The logic is that it’s good for the kids and good for the country. Education hasn’t had a true disruption in centuries. Public schooling and standardized curricula were the last big innovations, and online learning has yet to deliver on its promise, with the exception of foreign languages. In 2024, grade 12 reading scores in the U.S. were the worst in three decades and math scores the lowest since 2005. 8. Accelerating Time. Shortening the time between the generation and delivery of information. People can make more and better decisions when they get information more quickly. Disruptive innovations have sharply decreased the time needed to convey information and, therefore, the choices people can make at any moment in time. Cheaper paper helped transmit information easily over long distances. The speed increased with the development of horse-based delivery services. In the U.S., sending mail on the stagecoach took weeks. The short-lived specialty Pony Express could move mail in days. It was replaced with the telegraph, which was nearly instantaneous aside from going to telegraph offices to send and retrieve messages. Economists have examined the value of faster time in commerce. Before the successful launch of the transatlantic telegraph on July 28, 1866, it took 7 to 16 days to send information between the U.S. and Great Britain. It was almost immediate after that. The faster transmittal times reduced the price spread for cotton between New York and Liverpool by 35%. By reducing price distortions, it resulted in economic efficiencies that were worth about 8.4% of the value of the exports. Of course, the internet and related communication technologies have massively accelerated time. Now it can take just a few seconds to buy from sellers around the world, to take just one example. 9. Multiplying Time. Increasing the total of the collective hours of everyone’s time, including their working time. Setting the warm and fuzzies aside, societies depend on the collective hours people spend working, creating, and paying taxes. People make the goods and services we consume or trade with other countries. People come up with the ideas that power innovation. And workers ultimately pay most of the taxes to finance everything from national defense to basic research to social welfare. Europe now faces an “existential crisis” in part because people work fewer hours and have fewer children, who will supply working time in the future. Most developed countries have increasingly severe time shortages and will eventually face crises too. Countries can multiply time by encouraging later retirement, higher workforce participation, longer hours, and immigration. The eight other innovations in time are important drivers. Countries can also try to encourage families to have more babies, but there’s not much evidence that works. Advanced applications of artificial intelligence might be the disruptive innovation we need to solve the great time shortage: it could create human substitutes and increase the productivity of human working time. We’re not ready to count humans out, though. Entrepreneurs, innovators and investors searching for their next breakthrough should treat time as a resource class: measurable, improvable and ripe for disruption. That goes for governments, too. The addressable market isn’t literally $4.5 quadrillion. But that is a proxy for the enormous potential of the nine levers to innovate time. And how even small gains in how we create, extend, or enhance it can generate enormous economic returns. Economists have developed clever data-driven methods for estimating the value that people place on their time that can help size investment opportunities and ROIs. We have put rigor into the old saying that “time is money.” Economists look at how much people have to be paid to give up time, say, for work. Or how much people will pay to save time, like for a faster commute. These aren’t ivory-tower exercises. They drive federal cost-benefit analysis of proposed investments. The simplest approach is based on wages. A person could go to the beach or do some chores around the house instead of working another hour. If they are willing to take $20 to work an extra hour for a gig job, then that must be more than the value of an hour doing something else. The wage-hour tradeoff is hard to pin down in practice because many people have fixed salaries or must work a set number of hours. But the after-average after-tax wage, about $17.83 now, turns out to be a good proxy for the value of time for the average person. Instacart claimed it saved people more than 700 million hours between 2012 and 2023 because they didn’t have to go to the grocery store. At $17.83 an hour, it saved people more than $1.2B. The value of time depends on the situation. An hour of work may be more or less pleasant. The time spent on a subway ride isn’t as costly if a person can listen to music on their smartphone. People hate standing in line at checkout, which is why many opt not to and order things online. To get context-specific estimates, economists conduct surveys that try to get people to reveal how much they value time spent in various activities. The U.S. Department of Transportation used these surveys to value savings in local personal travel at about $12.50 an hour. Recent studies estimate the value of spending time using social media. They find that you would have to pay people a lot to go without. Economists have also developed data-driven methods for putting a dollar value on extending life. People make many decisions that result in small changes in the probability of their dying. Many involve making tradeoffs between money and risk: paying extra for a safe car with lower fatality rates in crashes or taking a job that pays more but poses a great risk of a fatal accident. People don’t act as if their lives are worth an infinite amount of money. Most of the studies, and the most robust, look at job decisions. A review, based on 2017 data, found that an employer would have to pay a typical worker another $100 a year to take a job where 1 in 100,000 workers die from a work-related injury. To summarize these results, economists calculate the “value of a statistical life” as the total amount of money that a group of people would pay to avoid one death: 100,000 people would pay $10 million to save one life. The federal government uses this approach to estimate the benefit of investments in activities that could save or cost lives. They currently adopt the $13.1 million per life figure I used earlier. Economists have found that this figure varies across ages. Younger people have more years to value than older people. Economists also use this approach to value innovations in healthcare. A seminal economic study found that the increase in life expectancy between 1970 and 2000 “added about $3.2 trillion to national wealth per year, an uncounted value equal to half of average annual GDP over the period.” Not surprisingly, AI innovators are chasing improvements in healthcare. The real frontier of time isn’t just looking at a clock. It’s looking inside the brain, too. If you buy the Audible version, you can listen to my book, “Matchmakers,” with Richard Schmalensee. It will take you 6 hours and 53 minutes. We were surprised at how many people chose to do that. But the thing about audiobooks is that you can do lots of other things while you are listening. One survey found that 70% of listeners multitasked. A different survey found that 74% of audiobook listeners listen while driving. People also listen while engaging in lots of other activities, like running or doing household chores. They are packing more things into their heads at the same time. Lots of other time innovations do the same. When we talk about people’s time, we’re really talking about the mental processes that happen within a unit of time. What people do with their brains to consume media, work, learn, view ads and more. Economists and psychologists call these processes “attention.” That term covers what regular people call attention, but much more. (An excellent recent survey has the details.) Like money, attention is limited. Using it for one thing means giving it up for another. But unlike money, it’s powered by cognition and choice, and we can decide to engage in more mental activity. We decide what to do with our brains and senses and then do it. We can think of human time along two dimensions. One is clock time, the steady march of seconds. The other is attention per unit of time, which is the variable flow of mental energy that determines how much we accomplish within those seconds. (This is a simplification since attention has many dimensions itself.) Brain time is the flow of attention through the flow of time. This is where the nine levers of time innovation create immense value. Some of those levers give us more clock time, while others enrich attention. Often, they do both. And the beauty of brain time is that multiple levers can be processed during the same unit of time. Clever innovators can make a lot of money from brain time. Google search saved people clock time from going to the library and on other resources to get information. People could even listen to loud music or talk to their colleagues without getting yelled at by the librarian, which enriched their attention. People ended up spending a lot of time doing search queries and looking at search results pages. And they didn’t have to pay a penny. Google built its business on selling slivers of brain time to advertisers. Advertisers can put an ad on the page and have a chance that some people will pay attention. With Facebook and a smartphone, people could interact with friends anywhere anytime, including while watching TV or on the treadmill. Alphabet and Meta are worth about $5 trillion. They make almost all their revenue from the small percentage of visitors who divert brain time to ads. Focusing on time as an improvable asset, and the nine levers for increasing its value, gives entrepreneurs, innovators and businesses a rigorous, disciplined way to identify and size opportunities. It also hands governments a guide to make investments that will maximize the value of human time. The economics of brain time provides a new lens to help shape the innovations and value their potential. Some economists say the era of unprecedented growth has come to an end. After all, it’s hard to top indoor plumbing. I don’t think it’s over. The potential to improve and extend human time is enormous. The financial incentives are powerful. And AI and other new technologies provide the foundation for new leaps forward. It’s about time. David S. Evans is an economist who has published more than 10 books and 200 articles, many related to entrepreneurship, platforms, the digital economy, and competition policy. He is the chairman and co-founder of Market Platform Dynamics. He has taught at the University College London and the University of Chicago Law School. For more details, see davidsevans.org. This article is part of Evans’ Catalyst Series and extends insights developed in his book Catalyst Code: The Strategies of the World’s Most Dynamic Companies, co-authored with Richard Schmalensee. Headspace Outruns Planet Fitness in October Rankings 58% of SMBs Turn to Embedded Finance for Cash Flow Management The $4.5 Quadrillion Opportunity in Human Time Strong Showings From Affirm and FIS Can’t Stop CE 100 Slide We’re always on the lookout for opportunities to partner with innovators and disruptors.
--------------------------------------------------

Title: AI bubble about to pop as returns on investment fall short?
URL: https://www.dw.com/en/ai-bubble-about-to-pop-as-returns-on-investment-fall-short-chatgpt-microsoft-nvidia-grok-elon-musk/a-74636881
Time Published: 2025-11-10T05:19:00Z
Full Content:
Billions have poured into AI, helping stock valuations soar. But the cracks are starting to show. Slowing adoption, surging costs and elusive profits are fueling warnings that the boom may be headed for a hard reset. The artificial intelligence (AI) party is still in full swing, with tens of billions globally pouring into infrastructure, startups and attracting the best talent. Among the headline announcements this year: ChatGPT parent company Open AI, Softbank and Oracle pledged to invest $500 billion (€433 billion) in AI supercomputers, Open AI and chip giant Nvidia announced a $100 billion fund to maintain the United States' dominance in advanced chips, while Chinese tech giants Alibaba and Tencent hiked investments to help speed up China's ambition to lead AI by 2030. Since ChatGPT’s debut in November 2022, AI-related stocks have added an estimated $17.5 trillion in market value, according to Bloomberg Intelligence, driving around 75% of the S&P 500’s gains and propelling companies like Nvidia and Microsoft to record-breaking valuations. But signs of a hangover are getting harder to ignore. AI usage by corporations is slipping, spending is tightening and the machine learning hype has massively outpaced the profits. Many economists think usage concerns, barely three years into AI going mainstream, dropkick the prevailing narrative that AI would revolutionize how businesses operate by streamlining repetitive tasks and improving forecasting. "The vast bet on AI infrastructure assumes surging usage, yet multiple US surveys show adoption has actually declined since the summer," Carl-Benedikt Frey, professor of AI & work at the UK's University of Oxford, told DW. "Unless new, durable use cases emerge quickly, something will give — and the bubble could burst." The US Census Bureau, which surveys 1.2 million US companies every fortnight, found that AI-tool usage at firms with more than 250 employees dropped from nearly 14% in June to under 12% in August. To view this video please enable JavaScript, and consider upgrading to a web browser that supports HTML5 video AI’s biggest challenge remains its tendency to hallucinate — generating plausible but false information. Other weaknesses are inconsistent reliability and the poor performance of autonomous agents, which complete tasks successfully only about a third of the time. "Unlike an intern who learns on the job, today’s pretrained [AI] systems don’t improve through experience. We need continual learning and models that adapt to changing circumstances," said Frey. As the gap widens between sky-high expectations and commercial reality, investor enthusiasm for AI is starting to fade. In the third quarter of the year, venture-capital deals with private AI firms dropped by 22% quarter on quarter to 1,295, although funding levels remained above $45 billion for the fourth consecutive quarter, market intelligence firm CB Insights wrote last month. "What perturbs me is the scale of the money being invested compared to the amount of revenue flowing from AI," economist Stuart Mills, a senior fellow at the London School of Economics, told DW. Market leader OpenAI, which is backed by Microsoft, generated $3.7 billion in revenue last year, versus total operating expenses of $8-9 billion. The company says it is on course to make $13 billion this year but is still expected to burn through $129 billion before 2029, news site The Information calculated in September. Mills thinks generative AI companies like Elon Musk's Grok and ChatGPT are "charging far less than they need to make a profit" and should raise subscription prices. Few have quantified the AI bubble more starkly than Julien Garran, partner at UK-based research firm MacroStrategy Partnership. He argues that the sheer volume of capital flowing into AI — despite little evidence of sustainable returns — dwarfs previous speculative frenzies. "We estimate a misallocation of capital equivalent to 65% of US GDP — four times bigger than the housing buildup before the 2008/9 financial crisis and 17 times bigger than the dot-com bust," Garran told DW. To view this video please enable JavaScript, and consider upgrading to a web browser that supports HTML5 video Recent earnings from Big Tech have sparked cautious optimism, but also fresh doubts about AI’s staying power. Data analytics and intelligence platform Palantir's Q3 revenue surged 63% year-over-year, but its stock price fell by up to 7% on the news. AMD and Meta also saw their strong AI-related earnings overshadowed by market concerns about sustainability. That disconnect between soaring valuations and shaky fundamentals is exactly what worries Mills, who sees a widening gap between what AI promises and what it actually delivers to businesses. "The data suggests that AI is not penetrating high enough up the value chain. Loads of people are using it, but it's not being used for tasks that directly contribute to value production," he told DW. Nvidia's upcoming earnings on November 19 may prove a key test of whether the AI boom still has legs. In the second quarter, Nvidia's data center sales alone made up 88% of total revenue, which hit a record $46.7 billion. For Q3, the company has guided $54 billion, projecting 54% year-on-year growth, which would equate to a full-year total of more than $200 billion. "With the exception of Nvidia, which is selling shovels in a gold rush, most generative AI companies are both wildly overvalued and wildly overhyped," Gary Marcus, Emeritus Professor of Psychology and Neural Science at New York University, told DW. "My guess is that it will all fall apart, possibly soon. The fundamentals, technical and economic, make no sense." Garran, meanwhile, believes the era of rapid progress in large language models (LLMs) is drawing to a close, not because of technical limits, but because the economics no longer stack up. "They [AI platforms] have already hit the wall," Garran said, adding that the cost of training new models is "skyrocketing, and the improvements aren’t much better." Striking a more positive tone, Sarah Hoffman, director of AI Thought Leadership at the New York-based market intelligence firm AlphaSense, predicted a "market correction" in AI, rather than a "cataclysmic 'bubble bursting.'" After an extended period of extraordinary hype, enterprise investment in AI will become far more discerning, Hoffmann told DW in an emailed statement, with the focus "shifting from big promises to clear proof of impact." "More companies will begin formally tracking AI ROI [return on investment] to ensure projects deliver measurable returns," she added. Edited by: Uwe Hessler
--------------------------------------------------

Title: 3 Growth Stocks with Explosive Upside
URL: https://finance.yahoo.com/news/3-growth-stocks-explosive-upside-043547498.html
Time Published: 2025-11-10T04:35:47Z
Description: Growth boosts valuation multiples, but it doesn’t always last forever. Companies that cannot maintain it are often penalized with large declines in market...
--------------------------------------------------

Title: AI factories face a long payback period but trillions in upside
URL: https://siliconangle.com/2025/11/09/ai-factories-face-long-payback-period-trillions-upside/
Time Published: 2025-11-10T03:49:30Z
Full Content:
UPDATED 22:49 EST / NOVEMBER 09 2025 BREAKING ANALYSIS by David Vellante, David Floyer, Jackie McGuire, Scott Hebner and Christophe Bertrand Our latest forecast indicates that it will take a decade or more for artificial intelligence factory operators and model builders to reach breakeven on their massive capital outlays. Our projections call for nearly $4 trillion in cumulative capital spending outlays by 2030, with just under $2 trillion in cumulative AI revenue generated in that timeframe. We have the crossover point occurring early next decade (2032 on a run-rate basis) then gains far surpassing initial investments by the middle part of the 2030s. Though such projections are invariably subject to constant revision, we believe the size and speed of the initial investments, combined with the challenges of profitably monetizing AI at scale, will require patient capital and long-term thinking to realize durable business results. A short time after we published our first AI factories revenue outlook, OpenAI Group PBC Chief Executive Sam Altman and Microsoft Corp. CEO Satya Nadella introduced new data on the BG2 Pod. As well, on Nov. 4, The Information published projections from Anthropic in an article that also included financial projections on OpenAI based on multiple unnamed sources. This fresh information gives us an opportunity to revisit our figures and do so in the context of economist Erik Brynjolfsson’s productivity J-curve, which explains why new general purpose technologies, like electricity, the steam engine, computing and AI, often experience limited productivity growth at first, because organizations must learn, adapt and reorganize in order to realize benefits. Over time, these innovations tend to outperform expectations. Importantly, our forecasts focus on the business case for AI factory operators currently funding the massive AI buildout – specifically, the big CapEx spenders, including hyperscalers, neoclouds and AI research labs building today’s large language models. We do not attempt in this exercise to go down the “rabbit hole” of forecasting the investment and productivity output from enterprises consuming AI services. These are, however, related as the pace of both consumer and enterprise AI adoptiion will ultimately fuel monetization that AI factory operators will realize. In this Breaking analysis, we analyze these new data points and debate the shape of the AI factories economic curve. We’ll briefly introduce the productivity J-curve, share snippets from the Sam and Satya statements that in many ways speak to the AI productivity paradox. We’ll then revisit our AI factories forecast and assumptions; discuss some of the headwinds the industry must overcome to reach our projections and close with a vision of the future of AI and service as software. The productivity J-curve is a phenomenon where traditional measures of productivity growth initially dip before rising after the adoption of a new general-purpose technology or GPT. This occurs because a novel technology, such as AI, requires significant, but hard-to-measure, intangible investments in areas like employee training and business process redesign. These initial investments can cause temporary negative productivity impacts, but once organizations learn to productively apply the technology, full benefits are realized and productivity growth appears, often in quite dramatic fashion. The concept of the productivity J-curve was developed and modeled by the economists Erik Brynjolfsson, Daniel Rock and Chad Syverson. Recently, on theCUBE at UiPath Fusion, we asked Erik Brynjolfsson to explain the productivity J-curve in the context of today’s AI boom: [Watch Stanford economist Erik Brynjolfsson describe the productivity J-curve and how it relates to AI] Back when I was a young student in Boston, where I guess, I think we first met over there, I was working with Bob Solow, the Nobel Prize winner, and he pointed out that the computer age was everywhere, except the productivity statistics. So he asked me to look into this, and one of the things we saw was that all these companies were investing in these really amazing technologies, but nothing very valuable was coming out. And then later, as we know, in 1995, things started really taking off. And so I did some research, and the same pattern happened with lots of earlier technologies. With electricity, it was like 30 years, in fact, before you had a big boom. The steam engine. And so when I analyzed it, what we see is that these cool technologies, to really get the benefit of them, you have to rethink your business processes. You have to invest in human capital training, and so forth, and all that takes time and energy. And while you’re doing that, there’s not a lot of new output. So you’ve got more input, not a lot of output. By definition, that’s lower productivity. But then once you figure that out, things really take off. So to me, it kind of looks like a J, and we plot it. We did a paper in the American Economic Journal about that, to kind of work out the math of it. And now we’re seeing, I think, the same thing with AI. In our view, the productivity J-curve, at least in part, explains today’s AI return-on-investment paradox. Early adoption of general-purpose technologies is messy, utilization is uneven, workflows and data aren’t ready, and traditional measures of productivity often show dips before durable gains appear in the macro. The latest MIT and recent Enterprise Technology Research data points suggest only modest near-term ROI impact – single digits to low teens of enterprises seeing sustained ROI at scale. We’ve often said that agentic AI will take most of a decade to mature and permeate enterprises broadly. If we count inputs as AI CapEx and outputs as AI factory revenue, current productivity is negative, which helps explain market jitters and bubble talk. We believe near-term skepticism is unsurprising and the payoff depends on raising utilization, improving data quality and putting governed and secure agents into operation so that spend translates to tokens, and token production converts to revenue. Industry consensus had OpenAI revenues at about $13 billion. In a conversation with Altman, Brad Gerstner asked the obvious question: “How can a company with $13 billion in revenue make $1.4 trillion in spend commitments?” This raised Altman’s ire to the point where he spilled some revenue estimates that hadn’t been previously shared. [Watch Altman bristle at the criticisms] Specifically Altman said: Our further research indicates that both of these estimates are run-rate revenue projections. As such, we put OpenAI 2025 revenue at $15 billion. Moreover, in the clip above, Nadella lends credibility to Altman’s statements by claiming he’s never seen a business plan from OpenAI that the company hasn’t met or exceeded. Jackie McGuire of theCUBE Research had the following takeaways on Altman’s and Nadella’s comments: I think their tone tells you a lot about the message. To me, Sam actually sounded a little bit defensive in the “We’re doing well more than 13 billion.” It sounded to me like on one side that we’re doing way better than that. And on the other side, “I’m telling you guys, this is a sure bet. Take the Dodgers in the World Series. I’ve never seen them not lose a game.” There was an article last week in Wired that was called AI is the Bubble to Burst Them All. And it was talking about what the different things are that characterize a bubble, how people talk about it as one of them. And yeah, I don’t know. I just found the tone to be very more defensive than I would expect for somebody that feels really, really secure in the amount of revenue they’re doing. This narrative, as the Wired article reminds us, echoes the hype around RCA in the 1920s. Andrew Ross Sorkin in promoting his new book, “1929,” makes similar comparisons, with OpenAI as today’s analog. But it has faster execution, a bigger installed base and a much more mature communications infrastructure in its favor. Pulling OpenAI’s revenue projections forward suggests a meaningfully higher trajectory for the company. Nadella’s commentary frames OpenAI as an “execution machine” and is encouraging. Coupled with about 800 million monthly active users and what the company claims is 1 million enterprise API customers, demonstrates a blistering cadence and a glimpse of what the next great software company may look like. In the graphic below, we update our earlier AI factory forecast which reframes the datacenter buildout at an accelerated pace. The relevance is this represents the CapEx that ultimately foots the AI bill. Datacenter investments require land, power, water, distribution, thermal systems, and the accelerated stack itself – compute, storage and networking. The AI piece of the forecast (dark brown bars) is astounding and forcing a stack flip to extreme parallelism. The following key additional points are notable: The pace of the buildout steepens relative to our April forecast reflecting disclosures from recent earnings prints and deal signings that indicate OpenAI has secured a disproportionate share of advanced package/graphics processing unit capacity, while Google LLC has stepped up commitments, along with other hyperscalers and Meta Platforms Inc. Taken together, these inputs justify pulling forward AI-factory outlays. As we’ll show below, revenue ramp lags in the model when assessing cumulative spend vs. cumulative revenue. The most recent forecast implies that although hyperscalers, neoclouds and specialist providers will operate much of the capacity, enterprises will ultimately need to underwrite a majority of the economics over time via consumption. This will happen extensively through cloud, neoclouds and colo channels as well as selective on-premises deployments, especially as edge AI matures. While Wall Street rightly notes the hyperscaler and neocloud GPU estates are “lit up,” enterprises running clusters of 1,000-plus GPUs often sit below 30% utilization because of thin parallel-computing muscle memory, immature workflows and data friction. That underutilization is stressed by rapid hardware depreciation; unlike dark fiber in 2000, GPUs lose value fast. In our view, if enterprises cannot translate capacity to tokens and productivity, ROI will accrue elsewhere in the value chain until operating discipline catches up. Endpoints are a potential tailwind as an AI PC refresh cycle will push more inference to the edge, and a return to pragmatic hybrid is likely as organizations balance economics, latency, privacy and the practical limits of data movement. The operational reality is we live in a 12- to 18-month replacement cycle with e-waste and labor challenges implying a perpetual “paint-the-Golden-Gate-Bridge” refresh cadence applied to rows and racks of infrastructure. Hybrid AI will also be deployed by enterprises. As such, choice and flexibility across on-prem/colo/public will matter and upgrade timelines will vary, which argues for architectures that let teams “tap the public” while local capacity evolves (the labor and talent constraints are visible in the workforce data we present later). Data gravity and storage economics are also at play. We expects a meaningful share of cost to sit in storage and data management, not just GPUs. We will likely see renewed interest in deep, economical tiers (including tape) and a storage-vendor arms race to live closer to the accelerators, because data readiness, lineage and metadata for agentic workflows are gating factors to scale. The net is the spend is real and earlier, but breakeven will stretch beyond a decade with improvements in utilization, fabric efficiency and governed data pipelines taking time. In our opinion, the operating agenda is raise money, do deals, build fast, secure power and GPUs, increase utilization, compress network latency, harden governed data planes and sequence hybrid capacity so depreciation curves don’t outrun value realization. The data below represents revenue output from AI factory operators. It does not represent the value created by mainstream enterprises driving productivity and contributing to the macro gross domestic product uplift. Forecasting that impact is a separate exercise that requires assumptions about firm level productivity impacts. Rather this forecast is meant to help us model the revenue return on the massive CapEx buildup happening with AI, which will power a massive productivity boom in our view. The following five key messages are conveyed in the data: Our updated revenue forecast reflects a steeper commercialization curve for AI factories, with OpenAI’s trajectory set higher based on the new information. The near-term ~$20 billion run rate this year and a path to ~$100 billion by 2027, is based on growth initially fueled by consumer/prosumer demand and then accelerated by a rapid cadence of APIs and software that connect to enterprise data. We group Google and Anthropic as a combined partnership because TPU capacity and tight technical alignment make joint scaling plausible even as each maintains distinct channels; and Anthropic has a close partnership with AWS. We assume China’s block rises on restricted access to U.S. technology, which concentrates domestic investment and demand. A core debate from theCUBE Research team is whether a vertically integrated, more “closed” approach can sustain leadership versus an “open grid” that standardizes inter-factory integration. On one side, we argue that without open standards and protocols, multicompany business-to-business workflows risk fragmenting into a patchwork of proprietary adapters, repeating early cloud pain and slowing the “intelligence economy.” Trust requirements (transparency, accountability) and the cost of data movement and governance reinforce the case for openness; unified enterprise data will be the gating factor and creates room for data mobility vendors to grab a piece of the market. On the other side, we note that de facto standards have repeatedly led markets – IBM/360, Windows on commodity PCs, AWS primitives, iPhone, CUDA and the like – where proprietary control plus ecosystem gravity created the interoperability that matter in practice. In that view, surviving factories will define interfaces bilaterally and at scale, then formal standards follow. Key assumption: Enterprises will mostly consume AI via APIs; interoperability will improve through a mix of de facto interfaces and selective open standards; unified, governed data is the real prerequisite to value capture. Netting it out, the forecast supports OpenAI as the current favorite in the race. Advantaged by funding, compute access, fast software/API velocity and deep partnerships, we see this compounding into share gains even if the posture is more closed than purists would like. We acknowledge the risk that openness wins the long game; however, history suggests that de facto standards often dominate first, with formal openness catching up later. Our base case therefore keeps OpenAI in the lead, while watching for evidence of durable open protocols that would shift share toward more open operators. The chart below shows our cumulative CapEx forecast required to build AI factories (orange line) and the token revenue from those factories green line. As you can see, this business is not for the faint of heart, as described by the points below. We believe the cumulative-spend vs. cumulative-revenue forecast underscores the AI productivity paradox in that a multitrillion-dollar CapEx wave begins in 2024, but revenue trails for a decade-plus, yielding an early J-curve where measured productivity looks low or even negative. The spend line reflects the full factory build – land, power, water, distribution, thermal and accelerated stacks – while the revenue line captures commercialization that starts slowly and steepens only after end-to-end solutions mature. In our analysis, three inhibitors dominate the early years: 1) Weak data quality – web data is noisy and enterprise data is also challenging – requiring time-consuming cleanup, harmonization and policy controls; 2) The need for the industry to package and ship a unified, trustworthy agentic software layer that enterprises can adopt without bespoke integration; and 3) The sheer denominator problem – so much CapEx goes out up front that catching up takes time even as utilization improves. There is broad agreement that value creation ultimately skyrockets as the operating leverage kicks in; the open question is pace. Some argue the crossover could come sooner for targeted, high-value workflows rather than blanket enterprise adoption, while others maintain that the scale of CapEx alone pushes breakeven out ~11 years. Headwinds we see: Land/power/water constraints; skilled labor and operational cadence; poor/fragmented data and governance; evolving regulations (and geopolitical frictions) that complicate data movement; and the learning curve to stand up agentic control planes. Netting it out, the forecast dovetails with our key takeaways – a large near-term gap, a long breakeven, early J-curve headwinds, heavy physical/operational constraints and a path to compress the gap by securing energy, lifting utilization, tightening fabrics and hardening governed data pipelines. We believe Deloitte’s “Can US infrastructure keep up with the AI economy?” report articulates a central constraint to our thesis: Energy and water availability – and the speed of grid expansion – will set the pace of the buildout. AI racks run hotter and denser than legacy estates, pushing a structural shift from evaporative to liquid/mechanical cooling and forcing operators to site facilities where dual utility feeds are feasible for redundancy. That is driving builds toward inland markets with favorable land and interconnects but limited local talent pools, while creating visible, localized electricity price inflation in the two to three years following large deployments. In the near term, backup generation remains largely diesel and the grid mix still leans on fossil sources; corporate power purchase agreements and new renewables help, but lead times are long. Nuclear is re-entering the conversation as one of the few scalable, round-the-clock options capable of matching multigigawatt AI clusters over the decade. In our view, this energy reality dovetails with the J-curve economics in that even if capital is available, the tempo of power procurement, water rights and cooling retrofits slows time-to-tokens and represents a headwind to revenue realization. The practical takeaway is that breakeven moves with infrastructure, not just silicon. Implications: Operators will prioritize sites with dual-feed capacity and water sources; lock long-dated PPAs while exploring nuclear options; expect localized utility rate pressure; plan for liquid cooling skills and supply chains; treat energy procurement as a first-class program office alongside networking and data governance. The Deloitte study lays out many challenges and solutions to building out AI infrastructure. Perhaps one that is most underappreciated is skilled labor. We believe a key blocker after power is people. Deloitte’s survey shows competition for skilled labor and a shortage of data-center-specific skills as the top workforce challenges. Building and operating AI factories requires niche trades – nuclear engineers, diesel-gen technicians, high-capacity chiller mechanics and specialized welders – not generic information technology staff. These workers are scarce, unevenly distributed and often unwilling to relocate to inland locations where dual-feed power and water are available, pressuring wage inflation and scheduling risk. The data underscores the point in that respondents cite competition with other sectors (~53%), a shortage of data-center–related skilled labor (~51%), geographic limits on talent (~43%), and high turnover (~42%) as primary obstacles. Labor regulation adds friction as well; notably, power-company executives flag regulation as a challenge far more often than data-center builders, reflecting state-by-state and EU-style variability. Against that backdrop, hyperscalers, neoclouds and well-funded operators will pay up for the best people, while governments are also in the hunt – tightening the market further. In our view, solving the talent gap requires a multiyear effort – national and regional programs to retrain displaced workers; vocational pipelines starting in high school for advanced welding, mechanical and electrical trades, fluid engineers that understand advanced plumbing; and increased use of robotics to service multibuilding campuses measured in football fields. Without this workforce ramp, the CapEx-revenue crossover slips, regardless of how fast silicon ships. Satya Nadella made the following statement: So the new SaaS applications, as you rightfully said, are intelligent applications that are optimized for a set of evals and a set of outcomes that then know how to use the token factories output most efficiently. Sometimes latency matters, sometimes performance matters. And knowing how to do that trade in a smart way is where the SaaS application value is. But overall, it is going to be true that there is a real marginal cost to software this time around. It was there in the cloud era too. When we were doing CD-ROMs, there wasn’t much of a marginal cost. With the cloud, there was. And this time around, it’s a lot more. And so therefore, the business models have to adjust and you have to do these optimizations for the agent factory and the token factory separately. AI is shifting the margin math again. The CD-ROM era drove marginal cost toward the price of plastic; SaaS reintroduced a cloud OpEx tax; AI adds the heaviest burden yet – rapidly depreciating GPUs, power and specialized labor – so headline gross margins compress even as volume potential explodes. Those dynamics align with recent comments about marginal cost pressure and sets the stage for what we view as the more important transition – George Gilbert’s service-as-software or SaSo thesis. In SaSo, factories expose agentic capabilities as programmable services, enterprises consume them through APIs and lightweight local runtimes, and the “software-like” economics accrue disproportionately to buyers (productivity) and to a handful of sellers that achieve scale, utilization, and distribution. We see three forces accelerating SaSo despite near-term cost gravity. First, algorithmic and systems efficiency will complement brute-force scaling – better data selection, sparsity, compilation, and workload shaping can cut compute costs materially. Second, distributed AI will split work sensibly: pre- and post-processing at the edge (including on devices) with factory inference and training behind APIs; storage tiers (including tape) and robotics will lower the cost of operating massive campuses. Third, the factories with the deepest ecosystems will ship the systems of intelligence or SoI agentic control planes, software development kits and adapters that enterprises adopt “as-is,” rather than building bespoke stacks. In our view, this means most organizations will prioritize owning and governing their data while sourcing intelligence from a few high-volume factories that improve fastest. Bottom line: The AI factory buildout is real, front-loaded, and subject to a decade-long J-curve. Power, talent and data quality/governance pace the crossover point. Revenue capture accrues to operators that 1) Drive utilization, 2) Win the networking and systems efficiency game, 3) Support the delivery of trustworthy agentic platforms as services, 4) mobilize developer ecosystems, and 5) Relentlessly work the supply chain. Buyers of AI will see software-like marginal economics. That sets up a a winner-takes-most market. Today, the momentum and evidence place OpenAI and Nvidia Corp. in the lead, with hyperscalers and select partners close behind, fed by a supply chain ecosystem that is mobilizing for massive returns in the 2030s. Support our mission to keep content open and free by engaging with theCUBE community. Join theCUBE’s Alumni Trust Network, where technology leaders connect, share intelligence and create opportunities. Founded by tech visionaries John Furrier and Dave Vellante, SiliconANGLE Media has built a dynamic ecosystem of industry-leading digital media brands that reach 15+ million elite tech professionals. Our new proprietary theCUBE AI Video Cloud is breaking ground in audience interaction, leveraging theCUBEai.com neural network to help technology companies make data-driven decisions and stay at the forefront of industry conversations. AI factories face a long payback period but trillions in upside OpenAI calls for CHIPS Act tax credit to be extended to AI data centers Meta announces plans to spend $600B in the US over three years Congressional Budget Office breached by suspected foreign hackers Rise of the ‘answer engine’: AI’s impact triggers fresh questions for internet ad models, power usage and data sharing Cisco gives customer experience a big dose of AI AI factories face a long payback period but trillions in upside AI - BY GUEST AUTHOR . 1 MIN AGO OpenAI calls for CHIPS Act tax credit to be extended to AI data centers AI - BY MARIA DEUTSCHER . 2 DAYS AGO Meta announces plans to spend $600B in the US over three years AI - BY MARIA DEUTSCHER . 2 DAYS AGO Congressional Budget Office breached by suspected foreign hackers SECURITY - BY MARIA DEUTSCHER . 2 DAYS AGO Rise of the ‘answer engine’: AI’s impact triggers fresh questions for internet ad models, power usage and data sharing AI - BY MARK ALBERTSON . 2 DAYS AGO Cisco gives customer experience a big dose of AI AI - BY ZEUS KERRAVALA . 2 DAYS AGO
--------------------------------------------------

Title: Valuation worries, record-long government shutdown hang over markets: What to watch this week
URL: https://finance.yahoo.com/news/valuation-worries-record-long-government-shutdown-hang-over-markets-what-to-watch-this-week-123041065.html
Time Published: 2025-11-09T12:30:41Z
Description: Skepticism around sky-high tech valuations and a continued dearth of economic data set up the week for investors.
--------------------------------------------------

Title: Amazon's AI comeback: Inside the cloud king’s race to close the Big Tech gap
URL: https://www.livemint.com/companies/amazon-ai-aws-cloud-amazon-vs-microsoft-vs-google-vs-meta-amazon-openai-deal-11762519447694.html
Time Published: 2025-11-09T01:30:11Z
Full Content:
This is a Mint Premium article gifted to you. Subscribe to enjoy similar stories. For years, markets saw Amazon and Apple as laggards in the artificial intelligence race dominated by Microsoft, Google, and Meta. Though Amazon had a huge cloud infrastructure through Amazon Web Services (AWS), investors weren’t excited about the company. However, the narrative shifted when the company posted strong September quarter earnings. A deal with OpenAI and a ramp-up in its capital expenditure signalled that Amazon was back in the AI race. AI is just one of Amazon’s many concerns. How it manages its mammoth retail operations amid regulatory pressures matters too. Market catch-upIn the past few years, post-covid and during the AI boom, Amazon was an outlier among the Big Five tech companies, but for the wrong reasons. In the past five years, Amazon shares gained 51%, while its peers doubled or tripled their market value. As Nvidia boomed on the demand for graphics processing units (GPUs) and Microsoft captured headlines with its OpenAI tie-up, investors were concerned that AWS, a cloud leader and Amazon's key division, was struggling to scale. Amazon was spending heavily on AI infrastructure but was losing share to Microsoft and Google. In the second quarter of 2025, AWS’s profit margins fell sharply. The picture changed after Amazon's third-quarter earnings on 30 October 2025. Results exceeded expectations, and shares jumped 13% in after-hours trading. "There was definitely concern about AWS losing market share to Microsoft Azure and Google Cloud," Argent Capital's Jed Ellerbroek told Reuters. “But now AWS is aboard the train as well." In the past five days, Amazon was the only Big Five stock to post gains, while the others declined. AWS revivalIn the September quarter, AWS reported revenues of $33 billion, up 20.2% from $27.5 billion in Q3 2024. It outpaced the segment's 19% growth in Q3 2024 and exceeded Wall Street's 18.1% forecast. The results lifted AWS’s annualized run rate to $132 billion. During the earnings call, CEO Andy Jassy highlighted that the division was "growing at a pace we haven’t seen since 2022," attributing this to "strong demand in AI and machine learning." It addressed investors’ concerns that AWS—which holds about 31% of global cloud infrastructure, according to recent Synergy Research data—might be struggling to manage scale. Also Read | Nvidia's $100 billion deal with OpenAI: An AI monopoly in the making? It could also leverage other changes in the market, such as the friction between Microsoft and its long-standing partner OpenAI. Earlier this week, Amazon signed a $38 billion cloud agreement with OpenAI. The deal could increase its $200 billion backlog by about 20% in the fourth quarter, according to BMO Capital Markets. It also gave AWS a clearer path to recover market share lost to Microsoft and Alphabet. Capital pushTo sustain growth, Amazon has to sustain capital spending. In Q3 2025, its capex hit $35.1 billion, or 19.5% of revenue, up from 14.8% in Q4 2024. This ratio has climbed steadily: 16.1% in Q1 2025 and 19.2% in Q2. It raised full-year capital expenditure guidance to about $125 billion, with most of the funds going to AWS data centres that support AI workloads. Spending is expected to rise further in 2026. That level of investment places Amazon among the largest spenders in the technology sector. However, higher investments in AI infrastructure add to financial strain. Throughout its history, Amazon has pursued growth through efficiency, reflected in its founder’s philosophy: Your margin is my opportunity. A substantial share of its budget is directed toward in-house technologies like Trainium chips, reducing reliance on third-party GPUs. Amazon says its own chips provide 30–40% better price-performance than comparable GPUs. Customers like Anthropic are deploying hundreds of thousands of Trainium2 chips for models like Claude. Adoption is growing, but it still trails Nvidia. Also Read | Artificial intelligence’s next home: your eyes Labour rebalanceIn the recent quarter, Amazon reported a $1.8 billion pre-tax charge for severance related to planned job cuts, reflecting one of its largest corporate restructurings in years. The layoffs, affecting about 14,000 employees, were announced shortly before the earnings release. During the earnings call, Jassy said the cuts were not AI-driven. “If you grow as fast as we did for several years, the size of businesses, the number of people, the number of locations, the types of businesses you're in, you end up with a lot more people than what you had before, and you end up with a lot more layers," he said. “Sometimes, without realizing it, you can weaken the ownership of the people doing the actual work. And it can slow you down." While Jassy has emphasized culture, the broader context is a shift toward automation across Amazon’s operations. The company aims to automate 75% of its fulfillment network and has deployed more than one million robots globally. These investments suggest a gradual substitution of capital for labour. Amazon’s workforce totalled 1.56 million in 2024, roughly unchanged from two years earlier despite higher sales and output, but down from 1.6 million in the covid-hit 2021. Also Read | AWS disruption: The world needs a more reliable internet Store strategyCorrecting for covid-era overhiring is not the only reset Amazon is undertaking. In physical retail, Amazon is scaling back its direct grocery experiment. The company said it was closing all 14 Amazon Fresh stores in the UK, signalling a retreat from a model that failed to gain traction. The focus is shifting to Whole Foods, where Amazon plans to expand locations and pilot a smaller ‘daily shop’ format designed for urban markets. It is also redirecting grocery efforts toward logistics, emphasizing same-day perishables delivery through Amazon.com. That service now reaches 1,000 US cities and is expected to double coverage by the end of 2025. Physical store revenue has remained steady at about $5.6 billion per quarter. As it experiments and expands its business, Amazon is also regularly facing regulatory and legal hurdles. It settled a Federal Trade Commission (FTC) complaint over Prime subscriptions with a $2.5 billion charge, which includes $1 billion in penalties and $1.5 billion in refunds. A separate antitrust lawsuit from the FTC and 18 states remains pending, with a trial expected in 2027. All these challenges will test the sustainability of Amazon’s business bets. www.howindialives.com is a database and search engine for public data In the past few years, post-covid and during the AI boom, Amazon was an outlier among the Big Five tech companies, but for the wrong reasons. In the past five years, Amazon shares gained 51%, while its peers doubled or tripled their market value. As Nvidia boomed on the demand for graphics processing units (GPUs) and Microsoft captured headlines with its OpenAI tie-up, investors were concerned that AWS, a cloud leader and Amazon's key division, was struggling to scale. Amazon was spending heavily on AI infrastructure but was losing share to Microsoft and Google. In the second quarter of 2025, AWS’s profit margins fell sharply. The picture changed after Amazon's third-quarter earnings on 30 October 2025. Results exceeded expectations, and shares jumped 13% in after-hours trading. "There was definitely concern about AWS losing market share to Microsoft Azure and Google Cloud," Argent Capital's Jed Ellerbroek told Reuters. “But now AWS is aboard the train as well." In the past five days, Amazon was the only Big Five stock to post gains, while the others declined. AWS revivalIn the September quarter, AWS reported revenues of $33 billion, up 20.2% from $27.5 billion in Q3 2024. It outpaced the segment's 19% growth in Q3 2024 and exceeded Wall Street's 18.1% forecast. The results lifted AWS’s annualized run rate to $132 billion. During the earnings call, CEO Andy Jassy highlighted that the division was "growing at a pace we haven’t seen since 2022," attributing this to "strong demand in AI and machine learning." It addressed investors’ concerns that AWS—which holds about 31% of global cloud infrastructure, according to recent Synergy Research data—might be struggling to manage scale. Also Read | Nvidia's $100 billion deal with OpenAI: An AI monopoly in the making? It could also leverage other changes in the market, such as the friction between Microsoft and its long-standing partner OpenAI. Earlier this week, Amazon signed a $38 billion cloud agreement with OpenAI. The deal could increase its $200 billion backlog by about 20% in the fourth quarter, according to BMO Capital Markets. It also gave AWS a clearer path to recover market share lost to Microsoft and Alphabet. Capital pushTo sustain growth, Amazon has to sustain capital spending. In Q3 2025, its capex hit $35.1 billion, or 19.5% of revenue, up from 14.8% in Q4 2024. This ratio has climbed steadily: 16.1% in Q1 2025 and 19.2% in Q2. It raised full-year capital expenditure guidance to about $125 billion, with most of the funds going to AWS data centres that support AI workloads. Spending is expected to rise further in 2026. That level of investment places Amazon among the largest spenders in the technology sector. However, higher investments in AI infrastructure add to financial strain. Throughout its history, Amazon has pursued growth through efficiency, reflected in its founder’s philosophy: Your margin is my opportunity. A substantial share of its budget is directed toward in-house technologies like Trainium chips, reducing reliance on third-party GPUs. Amazon says its own chips provide 30–40% better price-performance than comparable GPUs. Customers like Anthropic are deploying hundreds of thousands of Trainium2 chips for models like Claude. Adoption is growing, but it still trails Nvidia. Also Read | Artificial intelligence’s next home: your eyes Labour rebalanceIn the recent quarter, Amazon reported a $1.8 billion pre-tax charge for severance related to planned job cuts, reflecting one of its largest corporate restructurings in years. The layoffs, affecting about 14,000 employees, were announced shortly before the earnings release. During the earnings call, Jassy said the cuts were not AI-driven. “If you grow as fast as we did for several years, the size of businesses, the number of people, the number of locations, the types of businesses you're in, you end up with a lot more people than what you had before, and you end up with a lot more layers," he said. “Sometimes, without realizing it, you can weaken the ownership of the people doing the actual work. And it can slow you down." While Jassy has emphasized culture, the broader context is a shift toward automation across Amazon’s operations. The company aims to automate 75% of its fulfillment network and has deployed more than one million robots globally. These investments suggest a gradual substitution of capital for labour. Amazon’s workforce totalled 1.56 million in 2024, roughly unchanged from two years earlier despite higher sales and output, but down from 1.6 million in the covid-hit 2021. Also Read | AWS disruption: The world needs a more reliable internet Store strategyCorrecting for covid-era overhiring is not the only reset Amazon is undertaking. In physical retail, Amazon is scaling back its direct grocery experiment. The company said it was closing all 14 Amazon Fresh stores in the UK, signalling a retreat from a model that failed to gain traction. The focus is shifting to Whole Foods, where Amazon plans to expand locations and pilot a smaller ‘daily shop’ format designed for urban markets. It is also redirecting grocery efforts toward logistics, emphasizing same-day perishables delivery through Amazon.com. That service now reaches 1,000 US cities and is expected to double coverage by the end of 2025. Physical store revenue has remained steady at about $5.6 billion per quarter. As it experiments and expands its business, Amazon is also regularly facing regulatory and legal hurdles. It settled a Federal Trade Commission (FTC) complaint over Prime subscriptions with a $2.5 billion charge, which includes $1 billion in penalties and $1.5 billion in refunds. A separate antitrust lawsuit from the FTC and 18 states remains pending, with a trial expected in 2027. All these challenges will test the sustainability of Amazon’s business bets. www.howindialives.com is a database and search engine for public data In the September quarter, AWS reported revenues of $33 billion, up 20.2% from $27.5 billion in Q3 2024. It outpaced the segment's 19% growth in Q3 2024 and exceeded Wall Street's 18.1% forecast. The results lifted AWS’s annualized run rate to $132 billion. During the earnings call, CEO Andy Jassy highlighted that the division was "growing at a pace we haven’t seen since 2022," attributing this to "strong demand in AI and machine learning." It addressed investors’ concerns that AWS—which holds about 31% of global cloud infrastructure, according to recent Synergy Research data—might be struggling to manage scale. It could also leverage other changes in the market, such as the friction between Microsoft and its long-standing partner OpenAI. Earlier this week, Amazon signed a $38 billion cloud agreement with OpenAI. The deal could increase its $200 billion backlog by about 20% in the fourth quarter, according to BMO Capital Markets. It also gave AWS a clearer path to recover market share lost to Microsoft and Alphabet. Capital pushTo sustain growth, Amazon has to sustain capital spending. In Q3 2025, its capex hit $35.1 billion, or 19.5% of revenue, up from 14.8% in Q4 2024. This ratio has climbed steadily: 16.1% in Q1 2025 and 19.2% in Q2. It raised full-year capital expenditure guidance to about $125 billion, with most of the funds going to AWS data centres that support AI workloads. Spending is expected to rise further in 2026. That level of investment places Amazon among the largest spenders in the technology sector. However, higher investments in AI infrastructure add to financial strain. Throughout its history, Amazon has pursued growth through efficiency, reflected in its founder’s philosophy: Your margin is my opportunity. A substantial share of its budget is directed toward in-house technologies like Trainium chips, reducing reliance on third-party GPUs. Amazon says its own chips provide 30–40% better price-performance than comparable GPUs. Customers like Anthropic are deploying hundreds of thousands of Trainium2 chips for models like Claude. Adoption is growing, but it still trails Nvidia. Also Read | Artificial intelligence’s next home: your eyes Labour rebalanceIn the recent quarter, Amazon reported a $1.8 billion pre-tax charge for severance related to planned job cuts, reflecting one of its largest corporate restructurings in years. The layoffs, affecting about 14,000 employees, were announced shortly before the earnings release. During the earnings call, Jassy said the cuts were not AI-driven. “If you grow as fast as we did for several years, the size of businesses, the number of people, the number of locations, the types of businesses you're in, you end up with a lot more people than what you had before, and you end up with a lot more layers," he said. “Sometimes, without realizing it, you can weaken the ownership of the people doing the actual work. And it can slow you down." While Jassy has emphasized culture, the broader context is a shift toward automation across Amazon’s operations. The company aims to automate 75% of its fulfillment network and has deployed more than one million robots globally. These investments suggest a gradual substitution of capital for labour. Amazon’s workforce totalled 1.56 million in 2024, roughly unchanged from two years earlier despite higher sales and output, but down from 1.6 million in the covid-hit 2021. Also Read | AWS disruption: The world needs a more reliable internet Store strategyCorrecting for covid-era overhiring is not the only reset Amazon is undertaking. In physical retail, Amazon is scaling back its direct grocery experiment. The company said it was closing all 14 Amazon Fresh stores in the UK, signalling a retreat from a model that failed to gain traction. The focus is shifting to Whole Foods, where Amazon plans to expand locations and pilot a smaller ‘daily shop’ format designed for urban markets. It is also redirecting grocery efforts toward logistics, emphasizing same-day perishables delivery through Amazon.com. That service now reaches 1,000 US cities and is expected to double coverage by the end of 2025. Physical store revenue has remained steady at about $5.6 billion per quarter. As it experiments and expands its business, Amazon is also regularly facing regulatory and legal hurdles. It settled a Federal Trade Commission (FTC) complaint over Prime subscriptions with a $2.5 billion charge, which includes $1 billion in penalties and $1.5 billion in refunds. A separate antitrust lawsuit from the FTC and 18 states remains pending, with a trial expected in 2027. All these challenges will test the sustainability of Amazon’s business bets. www.howindialives.com is a database and search engine for public data To sustain growth, Amazon has to sustain capital spending. In Q3 2025, its capex hit $35.1 billion, or 19.5% of revenue, up from 14.8% in Q4 2024. This ratio has climbed steadily: 16.1% in Q1 2025 and 19.2% in Q2. It raised full-year capital expenditure guidance to about $125 billion, with most of the funds going to AWS data centres that support AI workloads. Spending is expected to rise further in 2026. That level of investment places Amazon among the largest spenders in the technology sector. However, higher investments in AI infrastructure add to financial strain. Throughout its history, Amazon has pursued growth through efficiency, reflected in its founder’s philosophy: Your margin is my opportunity. A substantial share of its budget is directed toward in-house technologies like Trainium chips, reducing reliance on third-party GPUs. Amazon says its own chips provide 30–40% better price-performance than comparable GPUs. Customers like Anthropic are deploying hundreds of thousands of Trainium2 chips for models like Claude. Adoption is growing, but it still trails Nvidia. Labour rebalanceIn the recent quarter, Amazon reported a $1.8 billion pre-tax charge for severance related to planned job cuts, reflecting one of its largest corporate restructurings in years. The layoffs, affecting about 14,000 employees, were announced shortly before the earnings release. During the earnings call, Jassy said the cuts were not AI-driven. “If you grow as fast as we did for several years, the size of businesses, the number of people, the number of locations, the types of businesses you're in, you end up with a lot more people than what you had before, and you end up with a lot more layers," he said. “Sometimes, without realizing it, you can weaken the ownership of the people doing the actual work. And it can slow you down." While Jassy has emphasized culture, the broader context is a shift toward automation across Amazon’s operations. The company aims to automate 75% of its fulfillment network and has deployed more than one million robots globally. These investments suggest a gradual substitution of capital for labour. Amazon’s workforce totalled 1.56 million in 2024, roughly unchanged from two years earlier despite higher sales and output, but down from 1.6 million in the covid-hit 2021. Also Read | AWS disruption: The world needs a more reliable internet Store strategyCorrecting for covid-era overhiring is not the only reset Amazon is undertaking. In physical retail, Amazon is scaling back its direct grocery experiment. The company said it was closing all 14 Amazon Fresh stores in the UK, signalling a retreat from a model that failed to gain traction. The focus is shifting to Whole Foods, where Amazon plans to expand locations and pilot a smaller ‘daily shop’ format designed for urban markets. It is also redirecting grocery efforts toward logistics, emphasizing same-day perishables delivery through Amazon.com. That service now reaches 1,000 US cities and is expected to double coverage by the end of 2025. Physical store revenue has remained steady at about $5.6 billion per quarter. As it experiments and expands its business, Amazon is also regularly facing regulatory and legal hurdles. It settled a Federal Trade Commission (FTC) complaint over Prime subscriptions with a $2.5 billion charge, which includes $1 billion in penalties and $1.5 billion in refunds. A separate antitrust lawsuit from the FTC and 18 states remains pending, with a trial expected in 2027. All these challenges will test the sustainability of Amazon’s business bets. www.howindialives.com is a database and search engine for public data In the recent quarter, Amazon reported a $1.8 billion pre-tax charge for severance related to planned job cuts, reflecting one of its largest corporate restructurings in years. The layoffs, affecting about 14,000 employees, were announced shortly before the earnings release. During the earnings call, Jassy said the cuts were not AI-driven. “If you grow as fast as we did for several years, the size of businesses, the number of people, the number of locations, the types of businesses you're in, you end up with a lot more people than what you had before, and you end up with a lot more layers," he said. “Sometimes, without realizing it, you can weaken the ownership of the people doing the actual work. And it can slow you down." While Jassy has emphasized culture, the broader context is a shift toward automation across Amazon’s operations. The company aims to automate 75% of its fulfillment network and has deployed more than one million robots globally. These investments suggest a gradual substitution of capital for labour. Amazon’s workforce totalled 1.56 million in 2024, roughly unchanged from two years earlier despite higher sales and output, but down from 1.6 million in the covid-hit 2021. Store strategyCorrecting for covid-era overhiring is not the only reset Amazon is undertaking. In physical retail, Amazon is scaling back its direct grocery experiment. The company said it was closing all 14 Amazon Fresh stores in the UK, signalling a retreat from a model that failed to gain traction. The focus is shifting to Whole Foods, where Amazon plans to expand locations and pilot a smaller ‘daily shop’ format designed for urban markets. It is also redirecting grocery efforts toward logistics, emphasizing same-day perishables delivery through Amazon.com. That service now reaches 1,000 US cities and is expected to double coverage by the end of 2025. Physical store revenue has remained steady at about $5.6 billion per quarter. As it experiments and expands its business, Amazon is also regularly facing regulatory and legal hurdles. It settled a Federal Trade Commission (FTC) complaint over Prime subscriptions with a $2.5 billion charge, which includes $1 billion in penalties and $1.5 billion in refunds. A separate antitrust lawsuit from the FTC and 18 states remains pending, with a trial expected in 2027. All these challenges will test the sustainability of Amazon’s business bets. www.howindialives.com is a database and search engine for public data Correcting for covid-era overhiring is not the only reset Amazon is undertaking. In physical retail, Amazon is scaling back its direct grocery experiment. The company said it was closing all 14 Amazon Fresh stores in the UK, signalling a retreat from a model that failed to gain traction. The focus is shifting to Whole Foods, where Amazon plans to expand locations and pilot a smaller ‘daily shop’ format designed for urban markets. It is also redirecting grocery efforts toward logistics, emphasizing same-day perishables delivery through Amazon.com. That service now reaches 1,000 US cities and is expected to double coverage by the end of 2025. Physical store revenue has remained steady at about $5.6 billion per quarter. As it experiments and expands its business, Amazon is also regularly facing regulatory and legal hurdles. It settled a Federal Trade Commission (FTC) complaint over Prime subscriptions with a $2.5 billion charge, which includes $1 billion in penalties and $1.5 billion in refunds. A separate antitrust lawsuit from the FTC and 18 states remains pending, with a trial expected in 2027. All these challenges will test the sustainability of Amazon’s business bets. www.howindialives.com is a database and search engine for public data Download the Mint app and read premium stories Log in to our website to save your bookmarks. It'll just take a moment. You are just one step away from creating your watchlist! Oops! Looks like you have exceeded the limit to bookmark the image. Remove some to bookmark this image. Your session has expired, please login again. You are now subscribed to our newsletters. In case you can’t find any email from our side, please check the spam folder. This is a subscriber only feature Subscribe Now to get daily updates on WhatsApp
--------------------------------------------------

Title: Is Wall Street losing faith in AI? | TechCrunch
URL: https://techcrunch.com/2025/11/08/is-wall-street-losing-faith-in-ai/
Time Published: 2025-11-08T20:53:48Z
Full Content:
Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us Posted: A rough week for tech stocks might signal a loss of investor confidence in artificial intelligence. The Wall Street Journal reports that the Nasdaq Composite Index was down 3% — making this its worst week since President Donald Trump announced his sweeping tariff plan in April. Tech companies that have otherwise performed well this year were among those hardest hit, with Palantir’s stock price falling 11% this week, Oracle declining by 9%, and Nvidia losing 7%. These drops also come after earnings reports in which Meta and Microsoft indicated that they plan to continue spending heavily on AI (both companies were down about 4%). “Valuations are stretched,” Cresset Capital’s Jack Ablin told the WSJ. “Just the slightest bit of bad news gets exaggerated … and good news is just not enough to move the needle because expectations are already pretty high.” Economic factors like the ongoing government shutdown, declining consumer sentiment, and widespread layoffs are also likely dragging down the stock market. But the less tech-heavy S&P 500 and Dow Jones Industrial Average didn’t do quite as badly, with declines of 1.6% and 1.2%, respectively. Topics StrictlyVC concludes its 2025 series with an exclusive event featuring insights from leading VCs and builders such as Pat Gelsinger, Mina Fahmi, and more. Plus, opportunities to forge meaningful connections.Early Bird rate ends November 17. Subscribe for the industry’s biggest tech news Every weekday and Sunday, you can get the best of TechCrunch’s coverage. TechCrunch Mobility is your destination for transportation news and insight. Startups are the core of TechCrunch, so get our best coverage delivered weekly. Provides movers and shakers with the info they need to start their day. By submitting your email, you agree to our Terms and Privacy Notice. © 2025 TechCrunch Media LLC.
--------------------------------------------------

Title: Is Wall Street losing faith in AI?
URL: https://finance.yahoo.com/news/wall-street-losing-faith-ai-205300697.html
Time Published: 2025-11-08T20:53:00Z
Description: A rough week for tech stocks might signal a loss of investor confidence in artificial intelligence.
--------------------------------------------------

Title: 'Stratospheric' AI Spending By Four Wealthy Companies Reaches $360B Just For Data Centers
URL: https://slashdot.org/story/25/11/08/0533205/stratospheric-ai-spending-by-four-wealthy-companies-reaches-360b-just-for-data-centers
Time Published: 2025-11-08T15:34:00Z
Description: "Maybe you've heard that artificial intelligence is a bubble poised to burst," writes a Washington Post technology columnist. "Maybe you have heard that it isn't. (No one really knows either way, but that won't stop the bros from jabbering about it constantly…
--------------------------------------------------

Title: Why Sam Altman Won't Be on the Hook for OpenAI's Spending Spree
URL: https://www.forbes.com/sites/rashishrivastava/2025/11/07/why-sam-altman-wont-be-on-the-hook-for-openais-massive-spending-spree/
Time Published: 2025-11-08T14:33:00Z
Full Content:
Over the last few months, OpenAI CEO Sam Altman has been on a tear of dealmaking, announcing multibillion dollar agreements with the biggest tech companies in the world. There’s Oracle, Nvidia, Microsoft, AMD, Broadcom, and most recently, Amazon. He’s committed to spending a grand sum total of $1.4 trillion on datacenters in the coming years — an eyebrow-raising figure for a company which claims its annual revenue is projected to reach $20 billion this year, begging an all-important question for the entire tech industry, whose fate is now tied to OpenAI: What happens if he can’t pay? At an event this week, OpenAI CFO Sarah Friar seemed to suggest that the government could act as a “backstop” for the company’s commitments — comments she later walked back. And in a long-winded post on X, Altman addressed the question of what happens to OpenAI if its web of deals falls apart: “If we screw up and can’t fix it, we should fail, and other companies will continue on doing good work and servicing customers,” Altman said. “...We of course could be wrong, and the market—not the government—will deal with it if we are.” The odds don’t look great right now. In order to come through on its compute commitments, OpenAI’s revenue would have to grow to an estimated $577 billion by 2029, roughly the size of Google’s revenue that same year, Tomasz Tunguz, a general partner at Theory Ventures, wrote in a recent blog post. That’s a roughly 2900% jump from its current projections for 2025. But OpenAI has options. One likely scenario is that the AI company pays for and utilizes only a portion of the compute it has booked, said D.A. Davidson analyst Gil Luria. In that case, companies like Oracle, Amazon, Microsoft, CoreWeave and others will most likely renegotiate the contracts and ensure they get at least some amount of business from OpenAI, especially if the alternative is getting none at all. “They don't want OpenAI to go bankrupt, so their incentive is to renegotiate,” he told Forbes. “He’s taking all this commitment knowing that he's not going to actually face any consequences because he doesn't have a financial stake.” Renegotiating contracts isn’t uncommon in the data center world. These contracts are extremely complex and often spread out over a span of years; some parties can even further extend timelines in case companies aren’t able to meet commitments. Clients like OpenAI are typically billed on the basis of usage. The “big numbers” being announced are often larger than what’s actually committed under contract, largely due to variables like share price, data center construction cost and GPU price, data center expert Daniel Golding said. For instance, OpenAI has committed to buy up to 6 GW of AMD’s chips (estimated to be worth around $90 billion) in exchange for about 10% of AMD shares—no cash on either side. But that hinges on performance milestones for OpenAI’s technology and commercial business as well as AMD’s share price. The contracts often have some capital I ifs. Thanks to constraints on power supply and chip availability, there’s a possibility that some of these infrastructure providers aren’t able to deliver in time, another opportunity for OpenAI to weasel out of paying some of the top line number. OpenAI’s $22.4 billion in total contracts with CoreWeave, for instance, can be terminated by either party at any time “for cause” (legal speak for things like delays). But even with about a trillion dollars on the line, the bigger risk in Altman’s mind is not having access to enough cheap compute to train and run better AI models when the time comes— a move that is crucial for revenue growth. “We believe the risk to OpenAI of not having enough computing power is more significant and more likely than the risk of having too much,” he said, adding that the company is also exploring ways to sell compute to other companies directly, much like CoreWeave does. When reached for comment, OpenAI spokesperson Steve Sharpe said the company has “nothing to add.” Altman’s fixation on grabbing as much gargantuan compute as he can is not surprising. He has always knelt at the altar of scaling laws. Earlier this year, Altman mused on the coming of AGI, or artificial general intelligence, the company’s overarching goal of creating AI that matches or surpasses human capabilities. “The intelligence of an AI model roughly equals the log of the resources used to train and run it,” he wrote, noting you could get “continuous and predictable gains” from pumping money into those resources. “The scaling laws that predict this are accurate over many orders of magnitude,” he wrote. Even before ChatGPT was released, he told employees at his crypto-cum-identity company Worldcoin (now called World), that one of his personal operating principles is “scale it up and see what happens,” something he’s found effective with everything from large neural networks to fusion reactors, Forbes reported. And the faster the better. Scaling up “earlier than it makes sense to … is super, super valuable,” he told Worldcoin employees. “The math that Mr. Altman is doing in his head is ‘they need me more than I need them.’” Experts note chief dealmaker Altman doesn’t have anything to lose. He has repeatedly claimed he does not have a stake in the company, and won’t have a stake even after OpenAI has restructured to become a public benefit corporation. “He has the upside, in a sense, in terms of influence, if it all succeeds,” said Ofer Eldar, a corporate governance professor at the UC Berkeley School of Law. “He's taking all this commitment knowing that he's not going to actually face any consequences because he doesn't have a financial stake.” That’s not good corporate governance, according to Jo-Ellen Pozner, a professor of management and entrepreneurship at Santa Clara University’s Leavey School of Business. “We allow leaders that we see as being super pioneering to behave idiosyncratically, and when things move in the opposite direction and somebody has to pay, it's unclear that they're the ones that are going to have to pay,” she said. Luria adds: “He can commit to as much as he wants. He can commit to a trillion dollars, ten trillion, a hundred trillion dollars. It doesn't matter. Either he uses it, he renegotiates it, or he walks away.” There are of course more indirect stakes for Altman, experts said, like the reputational blow he’d take if the deals fall apart. But on paper, he’d seemingly be off the hook, they said. As OpenAI has grown in prominence, tech giants have clamored to strike deals with the AI behemoth. “More of the world wants to work with us, so deals are quicker to negotiate,” Altman said recently. And they’ve reaped the upsides: Oracle, Nvidia, AMD and Broadcom gained a collective $636 billion in market cap on the days their deals were announced. Most recently, when OpenAI announced a $38 billion AI infrastructure deal with Amazon on Monday, the company’s stock increased 4%, adding $10 billion to Jeff Bezos’ net worth. “The math that Mr. Altman is doing in his head is ‘they need me more than I need them,’” Luria said. Companies involved in these circular deals have already indicated they’re willing to bail each other out. In September, Nvidia said it would buy CoreWeave’s unsold computing capacity through 2032, initially worth $6.3 billion. Presumably, that could expand to include anything OpenAI doesn’t use given that it’s CoreWeave’s largest customer. “If you owe the bank a hundred thousand dollars, the bank owns you. If you owe the bank a hundred million dollars, you own the bank,” said Lloyd Walmsley, a Mizuho analyst who covers Meta, Google and Amazon. “ Everyone's holding hands and, and having this leap of faith that the products are so powerful.” It’s also possible that OpenAI uses all the compute it has booked, and needs more. In that case, the AI titan will need to raise more funding—either through private or public markets—and increase its revenue exponentially. Part of why Altman has spoken about a potential OpenAI IPO is that it would make raising cheaper debt much easier. Altman said on Thursday that he’s confident that revenue will continue to grow, primarily from upcoming enterprise products and categories like robotics and consumer devices. Then, take the extreme case. If OpenAI were to file for bankruptcy protection, who would get paid first? Who would, in Sam Altman’s words, “get burnt”? For one, it’s entirely possible that some cash-rich company, perhaps one on the other end of one of its big contracts like Microsoft or Oracle, buys it in a fire sale. In the very unlikely event OpenAI goes bankrupt and liquidates instead, debtholders would get their money back first. Then equity investors, and finally—if there’s anything left over—common shareholders. OpenAI has only announced one debt deal so far, a $4 billion credit facility with nine banks including JPMorgan, Citi, Goldman Sachs and Morgan Stanley. The company announced the loan in October 2024 and said it is a revolving credit facility (akin to a giant corporate credit card). It’s unclear if OpenAI has additional debt, which it isn’t required to disclose as a private company. “If you owe the bank a hundred thousand dollars, the bank owns you. If you owe the bank a hundred million dollars, you own the bank.” King among OpenAI’s equity holders is Microsoft, which owns 27% of the company following OpenAI’s restructuring as a for-profit company last week. Microsoft has invested $11.6 billion of its $13 billion commitment to OpenAI, and OpenAI has committed to purchase $250 billion of Microsoft Azure’s compute services over the coming years. The companies have two-way plans to share revenue. “Of the dominoes that are going to fall when OpenAI can't pay everybody [and the question arises of] who gets paid first, and I'd argue that Microsoft gets paid first,” Luria added. Other large shareholders include Thrive, SoftBank, Dragoneer and investors in the $6 billion merger between Jony Ive’s io and OpenAI. Common shareholders—employees, cofounders and the nonprofit—would get what’s left, proportionally to how much they paid for their shares. Interestingly, OpenAI’s nonprofit holds a special “Class N” common share, which gives it majority voting and veto power in elections of board directors, though that share isn’t entitled to any financial return if the company were to go under. (The nonprofit’s 26% stake likely also includes ordinary common shares.) Altman’s wheeling and dealing is nothing short of mind-boggling, though many of the biggest payments aren’t due for a few years. In the AI universe, that’s plenty of time to figure out how he’s going to pay for it all, whether it’s additional fundraising or explosive revenue growth. Seems like nobody knows the answer just yet, not even him.
--------------------------------------------------

Title: SteelSeries Arctis Nova Elite (Xbox, PC) headset review — At the apex of headset luxury
URL: https://www.windowscentral.com/accessories/headphones/steelseries-arctis-nova-elite-xbox-pc-headset-review
Time Published: 2025-11-08T14:00:00Z
Full Content:
When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. The SteelSeries Arctis Nova Elite is a step above its competitors in every respect, including price. This monster $599 headset literally does it all. Simultaneous audio between two USB-C sources, 3.5mm, and Bluetooth, support for literally every gaming platform, premium materials, ANC, 30-hour swappable batteries, a desktop digital audio controller, and superb audio. The only issues amount to minor nitpicks, but you're going to need to really, REALLY want those extra features to justify that sky-high price tag. The SteelSeries Arctis Nova Elite is the best headset I've ever reviewed. Top shelf build quality and comfort Industry-leading device versatility Immaculate, peerless audio Retractable mic with ANC Handy DAC with great features Monster battery life Premium specs means premium price Software is a bit slow and could be improved Materials make it a fingerprint magnet Why you can trust Windows Central Our expert reviewers spend hours testing and comparing products and services so you can choose the best for you. Find out more about how we test. $599.99. That's how much the latest effort from SteelSeries will set you back. And it's a price tag that's impossible to overlook. This is the SteelSeries Arctis Nova Elite. It joins other products that share the "Elite" branding, such as the Xbox Elite Controller, targeting users on the high end. Gamers span all sorts of purchasing power capabilities these days, and companies know it. For those with cash to burn, building products that can seemingly do everything while also sporting the most premium materials is a segment manufacturers are increasingly targeting. The Arctis Nova Elite unashamedly joins that market as the best Xbox headset for pure, decadent luxury. As a humble games blogger, I'm not sure there's a universe where I would (or even could) ever pay $599.99 for a headset, practically under any circumstances — but if I could afford it, it would absolutely be for this headset. The SteelSeries Arctis Nova Elite is undeniably the most luxurious gaming headset I have ever used, whose features and quality inarguably justify that sky-high price tag. But you're going to be a very specific type of gamer to want to buy in here. This review was made possible thanks to a review sample provided by SteelSeries. The company had no input nor saw the contents of this review prior to publication. For over a decade, I've been reviewing headsets of all shapes and sizes. I've tried earbuds, budget gaming headsets, and premium cans for enthusiasts. I keep all of the headsets I review for active comparisons, and could probably open my own headset store if this tech blogging lark ever folds. One thing that won't fold is my enthusiasm for recommending YOU the best Xbox and PC headsets for your use cases. As for this headset, I've also been using the previous Arctis Nova as my daily driver. How does this one compare? Read on. You know the price already. It's a beefy boy, but what about the specs to match it? Let's take a look. This is premium from every angle you look. This is a hi-res certified headset, which means it's verified by independent organizations as being able to deliver sound beyond a typical CD. This is 24-bit/96 kHz signals specifically, and to do that, requires a higher grade of engineering and materials. As far as I could tell, this is the first wireless gaming headset to achieve this standard — a level typically reserved for audiophile products and studio-grade gear. Category Arctis Nova Pro Elite Drivers 40mm carbon fiber drivers with brass surrounds Frequency response 10 Hz – 40 kHz (Hi-Res certified) Connectivity Dual USB-C, 2.4 GHz wireless, 3.5mm line-in, Bluetooth Microphone Retractable and beamforming internal retracted modes Battery system Dual hot-swappable batteries (30~ hours x2) Build materials Steel headband, aluminum hinges, premium leatherette cushions Weight ~350 g Compatibility PC, PlayStation, Nintendo Switch, Xbox (via DAC), mobile (via Bluetooth) Special features Hi-Res Wireless certification, AI mic noise reduction, EQ software, ANC options, full DAC with multi-platform connectivity, simultaneous audio source mixing Price (RRP) $559.99 USD It's not all about hi-res certification here, though. While premium materials definitely had a role to play here, this headset also boasts some of the most impressive versatility we've ever seen in a gaming headset. All the latest news, reviews, and guides for Windows and Xbox diehards. The Arctis Nova Elite's powerful digital audio controller looks unassuming on your desk, but it boasts monstrous capabilities. It's your platform for hot-swapping and keeping batteries charged up (with each of the 2 included cells offering up to 30 hours of playback). It also lets you mix audio signals from four different sources: two USB-C, one 3.5mm line-in, and one Bluetooth 5.3. This is the first headset that has offered the ability to mix Xbox, PS5, and PC audio simultaneously since SPDIF fell out of fashion as a result — something game streamers using consoles and capture cards might appreciate. Even the packaging is premium here, as SteelSeries guns for the audiophile and enthusiast gamer segment. It's as expensive as some Xbox Series X and PS5 models at $599.99, and it seems to have good stock levels across the board as of writing. Does the Arctis Nova Elite stick the landing? Absolutely yes, in (almost) every regard. And luckily, the parts that could be improved are software in nature and can be updated. Here are more details on the experience. When I opened up the package to this headset, I immediately knew I was about to experience something special. This is by far and away the most expensive headset I have ever reviewed, and its premium presentation will immediately command your attention. The packaging is accented in gold and comes in a sort of monolithic box as if it had descended from another planet. The Arctis Nova Elite sports a familiar design if you've seen the predecessor Arctis Nova Pro (my previous primary driver here), complete with a retractable mic, detachable magnetic side-plates housing USB-C connectivity and the battery bay, as well as a floating headband. What sets it apart is that every aspect of it is dialled up to 11. Various parts of the headset that were plastic in other models are now metal, including the textured volume dial and adjustable hinges on either side. The dials, buttons, and materials all sport a very luxurious feel. Various parts of the headset that were plastic in other models are now metal, including the textured volume dial and adjustable hinges on either side. The leatherette earcups feel incredibly comfortable, and dare I say, dreamy on the skin, easily defeating fabric-clad rivals. The floating headband is also an easy win for long, long periods of use, and retains SteelSeries' tradition for cranial comfort. One weird downside of the floating headband is that it's easy to rock the headset off your head if you get a little too immersed in the music (and immersed you will, the sound delivery on this headset is immense). It's designed for long gaming sessions at the end of the day, but it's worth being aware of. Returning is the retractable boom microphone, which now cleverly has per-configuration settings. When you retract it, you can still use it for calls, and it'll beamform your voice similar to earbuds. When you extend it, it functions as a high-quality mic for comms and potentially even light content creation. I'm not sure I'd record a full YouTube video on this mic over my Elgato XLR, but it's up there with the best gaming headset mics I've used. Indeed, the ability to retract the mic and fall back to Bluetooth 5.3 gives you lifestyle usability here that many other "gaming" headsets don't really offer. The subtle design on the black model means it won't look out of place when used during commutes or on a plane, and there's even an alternative colorway that fits a more Apple-style grey fashion aesthetic, too. The only criticism I'd offer here from a "lifestyle" perspective is that, perhaps, the logos are a bit "loud" for this type of use case. There are after-market sideplates you can buy that look a little more subtle, though, or even louder ones if you prefer. The World of Warcraft Horde ones are out of stock, though (dang.) Also, the soft-touch plastics SteelSeries opted for here tend to be fingerprint magnets too, which isn't a big deal, but on the black model, it can be pretty noticeable. When you're knee deep in corpses in a Battlefield 6 map or rocking to Nirvana while writing a gaming headset review on the internet (meta), you're likely not thinking about the side plates or fingerprints, though. How's the audio? It's fan-expletive-tastic. Let's not beat around the bush here. The Arctis Nova Elite is the most immaculate audio experience I've had in over a decade of gaming headset reviews. I put them directly head-to-head with a family member's studio-grade Beyerdynamic DT 1990 PRO and was quite stunned to find the experience pleasantly comparable. This is a gaming headset, but I've found myself using it primarily for music over the past few weeks. Rediscovering new details in soundscapes I know very well has been incredibly fun with this product, as someone who generally uses earbuds or other random gaming headsets for music typically. No other headset I've used allows for this absurd level of versatility and freedom. There's no distortion, no glitching, no artifacting, no muddiness, no range is overbearing or under-represented — it's simply hard to go back to anything else after using these. ANC helps eliminate background noise on planes, trains, and buses, and easy on-ear controls and a solid mobile app make them a winner for commuters. Indeed, you have multiple ways to connect to this headset, too. As noted, the digital audio controller will sit at your desk and politely allow you to connect up not one, but actually three sound sources, on top of a fourth Bluetooth signal directly into the headset. And yes, you can mix them all simultaneously. No other headset I've used allows for this absurd level of versatility and freedom. The vast majority of users won't need this, but as a game streamer that uses a laptop and an Xbox with a capture card, I've found it incredibly welcome to not need to Bluetooth to my TV to get game audio (but you can still do that if you want?!). The headset is heavily configurable, too. The Steelseries GG software on PC and mobile devices allows you to load up from a huge array of presets for various games, more so than any other headset I've tried. Even obscure games are represented here, which is impressive. The only downside is that you can't really delete any of the presets, nor favorite the ones you prefer. It can be a pain going back and forward between a gaming preset and a music preset, for example — but it's easily fixable. The software on PC in general could use a variety of improvements, as it sometimes hangs and features app downloads and things most people are doubtlessly unlikely to use (why would I need to download Discord from SteelSeries?). But, this is quite honestly my only gripe with the feature set, and thankfully, software is a comparably easy fix over a hardware flaw. This headset has no hardware flaws. The first iteration of the Arctis Nova Pro had a protrusion in the left ear that could get uncomfortable across long sessions, for example, but there's no such issue here. Maximum comfort, with maximum longevity, and superb, immaculate audio. For gaming, the SteelSeries Arctis Nova Elite continues to excel. Games like Battlefield 6 and Overwatch absolutely sing on this device, giving away enemy positions with powerful tactical awareness, all without detracting from the more immersive sound design of the various virtual warzones we inhabit. The amount of tweaking you can do is impressive, too. Pushed to its extremes, the bass can get obnoxiously punchy if you want it to, or leave it thick and creamy, all while retaining maximum clarity and separation. Instruments sound like real instruments on this headset, which might sound like an odd thing to say — but you really feel the physicality of a kick drum or the slide of a bass string in this soundscape. Imagine how that translates to games with high-quality audio design, with explosions and gunfire zipping all around you. It's difficult to compare this to other gaming headsets as a result. The Arctis Nova Elite is just sublime. I wish the apps were a little less bloated and more focused, but it doesn't impact the sound experience. The microphone experience is good, too. As you can hear in the clip above, you're looking at crystal clear comms with the microphone extended, and very good call quality when it's retracted. You can set per-config sidetone too. The sidetone quality isn't the best, but it's more than adequate for game comms. All up, it's hard to find things to gripe about here. I wish the apps were a little less bloated and more focused, but it doesn't impact the sound experience. The number of settings you can alter and control is intuitive to set up and access, even if the software itself can be a bit slow at times. And hey, it can (and will) be updated. This headset is an absolute winner, but ... it's hard to look past that price point. There's pretty much no other headset that competes with the Arctis Nova Elite. On pure audio alone, the Arctis Nova Elite stands out in its own class and is more closely comparable to other hi-res headsets that typically don't fall into the gaming category. The only other headset with this kind of wireless versatility is the Astro A50 (2025), and the Arctis Nova Elite has it utterly beaten on raw audio, comfort, and lifestyle versatility. The Astro A50 is a pure gaming headset, though, and shaves $300 off the asking price to boot. I think, unless you were planning to use this headset everywhere and anywhere as a lifestyle option, you might get more bang for your buck with the similarly versatile Astro A50 ... but you wouldn't get the sound quality, multi-USB source mixing, or hot-swappable batteries. There's simply no real comparison here. The Arctis Nova Elite is well and truly in a category of its own. The Arctis Nova Elite is the ultimate gaming headset. It's the ultimate everything headset, frankly, able to easily accommodate high-end gaming, multi-device mixing for content creation, and day-to-day lifestyle use with ANC and Bluetooth. Its hi-res certification isn't just a sticker; it's immediately recognizable the second you commit a current to this headset. The sound reproduction puts the Arctis Nova Elite thoroughly in a category of its own, with few, if any, comparable peers. But boy howdy, it ain't cheap. You're going to either need to be a true all-day audio enthusiast, particularly fiscally affluent, or (like me) a poor financial planner to justify buying this. In my headset reviews, I tend to put a big emphasis on value for "most" people. Most of us are unlikely to look at a $599.99 headset and ever consider it an option — myself included. But with this, hearing is believing. It's one of the best headsets around. I've used my Arctis Nova Pro as my "daily" headset for several years at this point, and aside from some cushion wear, it's as good as it was the day I got it (and the cushions are easily replaced, too). If you were planning to use this headset for years and years, I think even the more budget-conscious could consider this headset, particularly if you wanted something you could use everywhere and anywhere. At the same time, would you feel comfy taking a $599.99 headset on the subway in that situation? I'm not sure I would. This headset is targeting a very specific type of customer unashamedly, and given what it offers, it's hard to penalize it for its price tag alone. The price makes sense given what's on offer. Whether or not it makes sense for your budget entirely depends on you and your needs. One thing I do know is you absolutely will not be disappointed. The SteelSeries Arctis Nova Elite is a best-in-class headset boasting supreme versatility, comfort, audio, and specs. It also boasts a supreme price tag, shrugging off affordability for maximum features and luxury. You're either going to really want all of its features or have cash to burn to justify this headset, but either way, you won't be disappointed. Follow Windows Central on Google News to keep our latest news, insights, and features at the top of your feeds! Jez Corden is the Executive Editor at Windows Central, focusing primarily on all things Xbox and gaming. Jez is known for breaking exclusive news and analysis as relates to the Microsoft ecosystem while being powered by tea. Follow on Twitter (X) and tune in to the XB2 Podcast, all about, you guessed it, Xbox! You must confirm your public display name before commenting Please logout and then login again, you will then be prompted to enter your display name. Windows Central is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036. Please login or signup to comment Please wait...
--------------------------------------------------

Title: Data-center operator CoreWeave is a stock-market darling. Bears see its finances as emblematic of an AI infrastructure bubble
URL: https://fortune.com/2025/11/08/coreweave-earnings-debt-ai-infrastructure-bubble/
Time Published: 2025-11-08T13:00:00Z
Full Content:
Jeremy Kahn is the AI editor at Fortune, spearheading the publication's coverage of artificial intelligence. He also co-authors Eye on AI, Fortune’s flagship AI newsletter. Leo Schwartz is a senior writer at Fortune covering fintech, crypto, venture capital, and financial regulation. A vast data center in Plano, Texas, is a symbol of the enormous AI infrastructure boom that has boosted stock markets and driven U.S. economic growth over the past year. The data center occupies more than 450,000 square feet and cost $1.6 billion to construct and equip. It supplies 30 megawatts of computing power to train and run AI models. Yet the company that runs it is a leading candidate to be ground-zero for a future AI financial meltdown. The data center is one of dozens around the world operated by CoreWeave, a company that develops and manages data centers and sells their computing capacity to technology companies. Its business is at the center of the AI economy—providing computing power to meet the voracious demand of the likes of Microsoft and OpenAI. But CoreWeave doesn’t own the Plano facility, nor does it own most of the data hubs it’s operating. And that is a part of the problem. The company is built, by its own admission, on a mountain of debt—obligations it has piled up as it races to build out a network of server farms for its customers. And that mountain looms far larger than the piles of cash that CoreWeave has brought in the door so far. When the company announces earnings on Monday, bulls and bears alike will be watching to see how its revenue is growing, and whether it has been able to pare its losses. CoreWeave’s earnings are likely to be a bellwether for the state of the entire AI boom, and for the industry’s massive and expensive infrastructure buildout in particular. CoreWeave has $7.6 billion in current liabilities—bills that fall due within 12 months—on its balance sheet, and $11 billion in debt overall, according to its most recent quarterly earnings report, filed in August. Coming from a tech giant like Google or Microsoft with tens of billions in free cash flow, such numbers wouldn’t raise an eyebrow. But CoreWeave’s revenues were only $1.9 billion in 2024. On its Q2 earnings call, CEO Michael Intrator told analysts that full year 2025 revenue would land between $5.15 billion to $5.35 billion. On the same call, the CEO said he expected CoreWeave’s capex for the year would total between $20 billion and $23 billion. Those short-term figures pale beside a bigger and potentially more onerous obligation that isn’t on its balance sheet: the $34 billion in scheduled lease payments that will start kicking in between now and 2028. Many of those payments are stretched over relatively long terms, of 10 years or more. Still, some of this is for data centers and office buildings that have not yet begun to operate or bring in revenue—representing a vulnerability if any of the as-yet-unprofitable startups CoreWeave sells computing services to are unable to meet their contractual obligations, or if construction delays mean CoreWeave is not able to provide capacity on time, allowing customers to cancel contracts. In a sense, Coreweave is a metaphor for the broader AI industry at the present moment, as top companies commit to enormous capex spending today in the confidence that it’ll be justified by future revenue from AI platforms and services. Investors appear to be broadly convinced by the company’s narrative: CoreWeave’s stock price is up 160% since the company’s IPO in March. But Fortune’s analysis of CoreWeave’s filings with the Securities and Exchange Commission, which are laced with warnings and caveats, show how risky the company’s business model could be. In interviews with several analysts, bulls and bears agreed that CoreWeave’s fundamentals, as reflected in its filings, don’t currently add up. “A lot has to go right,” says Thomas Blakey, a managing director of software equity research at Cantor Fitzgerald, who rates CoreWeave “overweight.” (Of 26 equity analysts who currently cover the stock, 14 had the equivalent of buy or outperform ratings on the shares, while nine had “hold” ratings, and three had “underperform” or “sell” recommendations, according to data from S&P Market Intelligence.) The bears see CoreWeave as a strong candidate to find itself underwater with its mounting liabilities, making it potentially the first domino to fall in the AI ecosystem. “To say they’ll scale out of this is questionable,” says Gil Luria, the head of technology research at the investment firm D.A. Davidson. “I don’t see how it becomes more profitable.” He believes that the likeliest outcome for CoreWeave on a five-year time horizon is bankruptcy—either because its current customers will be able to rely on their own infrastructure by then, or because an increasingly stretched CoreWeave will no longer be able to borrow. In a statement to Fortune, a company spokesperson said that “CoreWeave’s capital structure and financial performance are strong and underpinned by long-term take-or-pay contracts signed with the world’s leading enterprises and AI labs who partner with CoreWeave because we deliver the best AI cloud.” The statement went on to say that the company structured its contracts to “support and repay any related debt obligations while generating additional free cash flow. CoreWeave operates in a supply-constrained market where demand far exceeds capacity, and our hyper-growth is evidence of the trust leading companies place in us to power their most critical AI workloads.” With the company continuing to make huge new spending commitments even as it books new future revenue, AI investors’ attention will be glued to its upcoming quarterly earnings report. One number that everyone will be watching is CoreWeave’s “remaining performance obligations,” or RPOs—essentially revenues that CoreWeave has booked but that have not yet been paid. (Like its scheduled lease payments, CoreWeave’s RPOs are excluded from its balance sheet.) If CoreWeave is booking the kinds of contracts that will pull it out of debt sooner rather than later, the RPOs level—and the forecast for how quickly those future bookings are likely to turn into actual cash—are where they would show up. The company has announced several major new deals since its last quarterly earnings announcement, including a $14.2 billion agreement to supply Meta with computing capacity, and an pact with AI startup Poolside for a data center stuffed with 40,000 Nvidia GPUs. So it is likely its RPO total will climb significantly. Wall Street analysts’ forecasts for the company’s 2026 revenue range from $10.9 billion to $14.9 billion, according to data compiled by LSEG.Bulls argue that this is exactly how the boom will play out in CoreWeave’s favor: The revenue will come through, in great quantity, and its scale will solve the company’s problems by catching up with and then outpacing its capital expenditures. In that scenario, the company becomes the next Levi Strauss or Amazon Web Services, providing the “picks and shovels” of the AI boom, and getting filthy rich. “The potential is beyond the scope of our imagination at this point,” says Kevin Dede, a senior technology analyst at the financial services firm H.C. Wainwright, which rates CoreWeave a “buy.” But for now CoreWeave is miles away from being profitable and is bleeding cash, absent its ability to issue debt. The RPOs it reported in its most recent earnings that are likely to be realized in the next 12 months are not, on their own, sufficient to cover its current obligations and announced growth plans (more on that shortly). The company has razor-thin operating margins—1.6% in the past quarter. After accounting for its large interest expenses, those margins turn sharply negative. The company lost more than $600 million on $2.2 billion in revenue in the first six months of 2025. “That’s not great,” Luria says. “Is there any way that gap closes?”Barring an enormous surge in revenue over the next 12 months or so, the company will likely need to borrow more money, or renegotiate with creditors, in order to cover the obligations already on its books. To be sure, the AI boom could deliver that revenue surge—but even slight weakening in spending growth across the industry could hit CoreWeave disproportionately. Kerrisdale Capital, an investment management firm that is shorting the stock, is pithy in its conclusions: CoreWeave, it wrote in a September report, is “the poster child of the AI infrastructure bubble.” CoreWeave began as a crypto-mining company, a side project of a few friends who were hedge-fund traders. Crypto mining, like AI, relies heavily on graphic processing units, or GPUs, with the chips racing to solve complicated algorithms that spit out currency rewards for correctly verifying blockchain transactions, and CoreWeave was a steady buyer. Over time, Brian Venturo, one of the company’s founders, realized that the rise in AI would be a major factor fueling the surge in demand for the computing power of the GPUs that CoreWeave was already accumulating. Beginning in October 2021, CoreWeave entered into two deals with asset management firm Magnetar Capital, raising first $50 million in convertible notes, and then a year later, an additional $125 million, also in convertible notes. The company used nearly all of it to buy GPUs from Nvidia. Over the next few years, CoreWeave would secure billions of dollars in a combination of debt and equity, building out a sprawling array of data centers across the U.S., and eventually expanding to the U.K. This March, CoreWeave’s IPO made it one of the closest things to a pure-play AI company to debut on public markets. Initially, fears about the company’s debt load restrained its stock’s performance. But its shares took off in May after it reported its first quarterly earnings, including soaring revenue growth of 420% quarter-on-quarter. While the price has declined since a peak in June, CoreWeave shares closed on Friday at $104, up from a debut of $40. But as Luria puts it, the bear case for CoreWeave is simple math. The company’s business model is to borrow capital and then use that capital to build data centers filled with GPUs and then sell time on those GPUs to AI companies. “The question is, are they getting a sufficient return … on their investment to justify the interest they’re paying on their debt?” Luria says. Its most recent filings show how hefty that debt has become. The problem isn’t just the amount of CoreWeave’s debt. It’s the structure—most of it is more expensive than average for corporate debt, and much of it comes due in the next nine months. Of CoreWeave’s current liabilities, $3.6 billion is debt payable by June 30, 2026, just part of $11 billion in overall debt the company carries on its balance sheet. Much of that debt carries hefty interest rates of between 9% and 15%, according to the financial statements, with 11% being the weighted average rate overall. (This fall, rates on newly issued investment-grade corporate debt have hovered between 5.5% and 6%, according to Moody’s. The rate at which CoreWeave is able to borrow has come down over time, with most of its newer debt issued at closer to 9%. ) The majority of CoreWeave’s outstanding debt, its statements show, is in the form of two loans, called Delayed Draw Term Loan (DDTL)1.0 and DDTL 2.0. There is $1.8 billion outstanding on the DDTL 1.0, at a 15% interest rate, and $5 billion in DDTL 2.0, at an 11% interest rate. The company has begun payment on DDTL 1.0; quarterly principal payments on DDTL 2.0 are due beginning in January 2026. (The interest rates on both these loans are floating.) This is where the company’s RPOs come in. CoreWeave says that as of June 30 it had a little over $30 billion, the majority of which should turn into actual sales over the next four years. The company says 50% of that amount, or $15 billion, will be recognized in the next two years. Wall Street consensus forecasts are that the company’s revenues will be about $12 billion for next year. But if its operating margins remain at just 1.6%, the company will only generate $192 million in income from this revenue—not enough to cover its interest expenses or make the principal repayments on its debt. That implies that CoreWeave’s returns remain far below the cost of its capital. Higher RPOs, of course, would mean more revenue for CoreWeave next year. That said, there are also far more capital expenses to come. CoreWeave continues to spend heavily to purchase Nvidia GPUs—which make up the great majority of its capital expenditures—and other equipment to outfit its data centers. In the first half of 2025, for example, it invested $4.7 billion in property, plant and equipment while bringing in only $2.2 billion in revenue. The report from Kerrisdale cites similar concerns as Luria in justifying its short position. CoreWeave is “a debt-fueled GPU rental business with no moat, dressed up as innovation,” the firm writes, arguing that the stock faces a 90% downside. Luria and Kerrisdale both cite CoreWeave’s highly concentrated customer base as another potential peril—a reality that CoreWeave itself acknowledged in its last earnings report. “A substantial portion of our revenue is driven by a limited number of our customers, and the loss of, or a significant reduction in, spend from one or a few of our top customers would adversely affect our business,” the company wrote. Most notably: In the second quarter of 2025, an eye-popping 71% of CoreWeave’s revenue came from Microsoft alone. To be sure, Microsoft has a better credit rating than many countries, including the United States, and is unlikely to renege on its contract with CoreWeave. And CoreWeave’s contracts with its lessees generally require them to pay to the ends of their leases even if they don’t wind up utilizing them, except in case of “nonperformance.” Much of CoreWeave’s utility has come from offering readily available compute as those companies raced to scale up their own operations. But with Microsoft set to spend tens of billions of dollars on developing its own data centers, it may not need CoreWeave’s services in the future. “They will pay their obligations, but the likelihood of them renewing at the end of the contract is much less guaranteed,” Luria says. CoreWeave’s other major customer, OpenAI, is another matter. In March, CoreWeave entered an agreement with Sam Altman’s AI giant, with OpenAI committed to paying $11.9 billion through October 2030, with a $4 billion expansion announced in May. But OpenAI itself has made commitments far beyond its current cash flow—including commitments in the many hundreds of billions to Oracle, Nvidia and other data center providers. If OpenAI runs into any financial troubles, Luria says, CoreWeave likely wouldn’t be first to receive payments, compared to much larger OpenAI partners like Microsoft, Amazon, or even Oracle. (That’s also the case for some of the other, smaller venture-backed and loss-making AI startups CoreWeave serves, such as poolside, Cohere, and Mistral.) To rely on CoreWeave’s ties to OpenAI, he says, “You have to believe that OpenAI is going to be unbelievably successful, so much so that it can pay everybody that’s ahead in line.” All of this means there’ll be plenty at stake when CoreWeave reports earnings on Monday. The company will also be digesting a recent setback: In late October, the shareholders of Core Scientific, a crypto miner with a hoard of computing resources that CoreWeave coveted, rejected CoreWeave’s $9 billion all-stock acquisition offer. (CoreWeave will console itself with a $270 million breakup fee—an amount that will help it cover the $360 million it is expected to pay Core Scientific to lease data center capacity from it next year. Overall, CoreWeave is on the hook to pay Core Scientific some $10 billion in future lease payments over the next 12 years, which may have been one reason CoreWeave was eager to try to use its highly-valued shares to purchase Core Scientific in an all-equity deal valued at $9 billion when the offer was initially made.) The argument for CoreWeave’s success is just as simple as the math against it: AI is going to represent a transformational shift in the global economy, and CoreWeave is powering the technology’s growth. As the development of AI accelerates, so will the demand for computing power from companies aside from the hyperscalers, all hungry for the services of providers like CoreWeave. What’s more, today’s creditors may be willing to wait a little longer for that demand to materialize: The lenders behind DDTL 2.0 recently renegotiated the terms of the loan to delay the start of principal payments. Blakey, at Cantor Fitzgerald, says that CoreWeave is already diversifying its customer base, noting the recent deal with Meta. “It’s a growth business,” he says, in reference to CoreWeave’s capital expenditures. “If business is growing, you have to invest against it.” He and other bulls see a future where the company is no longer laden with debt. Once CoreWeave sheds its liabilities over the next five years, Blakey says, a growing percent of its revenue can begin coming from infrastructure that’s already paid off, boosting CoreWeave’s margins. Moreover, Blakey says that new models of chips might run more efficiently or be able to fetch a higher premium from customers, allowing CoreWeave to hold more pricing power. Blakey says that those $30.1 billion in RPOs—the revenue that has been booked but not yet delivered—are likely to increase meaningfully in CoreWeave’s next earnings, based on recently announced agreements. But the number to watch might be the additional obligations in borrowing that the company will take on to service them: If those obligations scale up alongside the booked revenue, bears say, CoreWeave still risks running out of cash unless it takes on yet more debt, raises more equity, or gets existing creditors to extend terms. Blakey acknowledges that a sustainable path forward for CoreWeave is perilous. “A lot has to go right,” he says. Still, he compares the current moment in AI to the beginning of the smartphone era, where analysts doubted Apple’s claims that it would transform global communication. “CoreWeave is a leader there in terms of this market,” Blakely says. “If they can maintain that lead … they will be able to participate in the spoils.” CORRECTIONS: An earlier version of this story stated incorrectly that Coreweave’s quarterly principal payments for DDTL 1.0 would begin in January 2026; those payments have already begun. The original version also misspelled the surname of Thomas Blakey. This article was updated to add a range of analysts’ projections for CoreWeave’s 2026 revenue. © 2025 Fortune Media IP Limited. All Rights Reserved. Use of this site constitutes acceptance of our Terms of Use and Privacy Policy | CA Notice at Collection and Privacy Notice | Do Not Sell/Share My Personal Information FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.
--------------------------------------------------

Title: It’s not a bubble, because AI is already running the markets
URL: https://cointelegraph.com/news/ai-runsunning-the-markets
Time Published: 2025-11-08T12:30:00Z
Full Content:
AI isn’t a bubble. It’s already reshaping markets. Autonomous AI agents now drive trading, outperforming humans and rewriting how money moves. Opinion by: Saad Naja, Founder and CEO at PiP World While the world debates whether AI is the next dot-com bubble, chasing valuations rather than implications, they’re missing the underlying innovation story. The same AI infrastructure fueling trillion-dollar bets is already rewriting how money moves. AI is no longer an investment theme. It’s the market itself. What few noticed is that the same AI infrastructure driving the headlines is already reshaping the markets from within. The invisible battle happening behind the candlesticks isn’t bulls and bears anymore; it’s between self-learning AIs that never sleep. Markets aren’t just humans using algorithms. They’re autonomous swarms fighting for milliseconds. Agents watch every market 24/7, spotting risks, debating strategies and executing without hesitation. Recent breakthroughs in AI and blockchain acceptance have created the perfect conditions for agentic markets to flourish. AI provides cognition; meanwhile, blockchain supplies trust, verification and payment rails. This offers the medium for AI agents to transact, prove, and exchange value freely. AI has crossed the chasm from stock picker to near-autonomous day trader. It learns and acts faster than any human. It spots what humans miss, predicts the move before it happens and never second-guesses itself. It’s the ultimate insider, without inflaming the SEC. It’s early days for agentic AI in trading, but make no mistake — it’s here and already moving the markets while most traders sleep. During the biggest crypto flash crash on Oct. 10, while the rest of the crypto market was in freefall, AI agents did the opposite. They stayed calm, shorted the chaos, and ended the week up 40%. They gave us a glimpse into the future of markets. One where the AI agents don’t just follow code, they respond like real traders. Some cut risk instantly. Others waited for confirmation. A few leaned into the drawdown. What’s striking is not just the gains, it’s the composure. Each AI agent made its own independent decisions, yet collectively, they converged on profitable outcomes. That’s the essence of agentic intelligence, autonomous systems learning to interpret chaos as opportunity. Companies describe similar behavior within trading desks, where agentic systems parse live data from public disclosures and feed execution layers in real-time. Over time, agents evolve from code to cognition. Autonomous systems that read markets, understand intent and execute strategies on their own. Acting like a digital hive mind, adjusting logic mid-session as markets shift around them. For years, quant funds and high-frequency traders have pitted humans plus algorithms against the market. Enter AI versus AI. Self-directed systems plan, reason and execute around the clock. What’s emerging is a battlefield of AIs — institutional, retail, and synthetic — talking to each other in real-time. When AI trades with AI, human intent disappears. Prices move on machine-to-machine negotiations, not emotion or fundamentals. The market begins to trade itself. Related: AI gives retail investors a way out of the diversification trap A majority of global trading volume now runs through algorithmic systems, estimates ranging from 60% to 89%, depending on the market. Within months, Symphony’s agentic trading layer was clearing $140 million in transactions, working with 15 of the world’s biggest financial institutions to test self-learning yield and execution agents. For decades, investing was about finding an edge. AI gives retail investors that power for the first time. Retail traders can soon deploy the same logic once reserved for billion-dollar funds. Swarm intelligence that scans arbitrage, simulates momentum, hedges risk and executes collaboratively. It’s the retail equivalent of a hedge fund in your pocket. The walls between institutional and retail finance are eroding. AI makes the 1%’s playbook accessible to the 99%. The next outperformers will deploy agentic swarms, rather than tracking indexes. AI versus AI warfare will define liquidity, volatility and price discovery. Humans will still set direction, risk tolerance and capital allocation, but won’t press the buttons. Markets will begin to self-trade in swarms of autonomous participants. Power will shift to whomever fine-tunes the feedback loops. When agents detect each other’s footprints, they’ll evolve meta-strategies, sometimes to cooperate, sometimes to manipulate one another. Trading floors are going quiet. The next generation of traders won’t shout orders; they’ll train AI agents. The winners won’t just be institutions, they’ll be retail traders who fine-tune their swarms alongside human judgment. We’re entering the agentic arms race. Markets of tomorrow won’t sleep or panic. Agentic AI will learn, evolve, compete and occasionally conspire at breakneck speed. While institutions continue to build layers of agents, retail investors face a choice. Follow the herd into AI stocks, or start training their own AI as their wing(wo)man. They won’t have an AlphaGo moment. Quiet, relentless outperformance hides in the charts, open to anyone brave enough to seize their AI agent. Opinion by: Saad Naja, Founder and CEO at PiP World. This article is for general information purposes and is not intended to be and should not be taken as legal or investment advice. The views, thoughts, and opinions expressed here are the author’s alone and do not necessarily reflect or represent the views and opinions of Cointelegraph. Cointelegraph is committed to providing independent, high-quality journalism across the crypto, blockchain, AI, fintech, and gaming industries. To support the free use of our website and sustain our editorial operations, some of the links published on our site may be affiliate links. This means we may receive a commission if you click through and take action—such as signing up for a service or making a purchase. These commissions come at no additional cost to you. Our affiliate relationships help us maintain an open-access platform, but they do not influence our editorial decisions. All news, reviews, and analysis are produced with journalistic independence and integrity. Thank you for supporting responsible and accessible reporting.
--------------------------------------------------