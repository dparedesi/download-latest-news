List of news related to Uber stock price UBER:

Title: ‘2 Out of 3 Ain’t Bad’ When It Comes to Charting the S&P 500’s Top 3 Stocks
URL: https://www.barchart.com/story/news/35158765/2-out-of-3-aint-bad-when-it-comes-to-charting-the-s-p-500s-top-3-stocks
Time Published: 2025-10-01T12:45:01Z
Description: Here’s a look at the three largest stocks in the S&P 500 Index right now… and why one is a bust.
--------------------------------------------------

Title: Luxury home prices are soaring—and this major US city is doing it right
URL: https://www.realtor.com/news/trends/million-dollar-listing-luxury-homes-more-expensive-demand-booms-supply-dwindles-report-september-2025/?cid=eml__1946:66e221571a4446d4e6969d41:rm202509301030_Marketing_Consumer_Daily_EditorialRSSDynamic
Time Published: 2025-09-30T18:36:26Z
Description: Over the past 10 years, the definition of luxury real estate has shifted dramatically, with the once-lofty $1 million price tag no longer serving as the benchmark of high-end housing.
--------------------------------------------------

Title: Dynamic Discounting: How to Do Dynamic Pricing Right
URL: https://knowledge.wharton.upenn.edu/article/dynamic-discounting-how-to-do-dynamic-pricing-right/
Time Published: 2025-09-30T17:19:02Z
Full Content:
A business journal from the Wharton School of the University of Pennsylvania Dynamic pricing doesn’t have to turn off customers. Wharton’s John Zhang says companies can correct perceptions of unfairness by clearly communicating the value. Z. John Zhang Z. John Zhang The following article was written by Wharton marketing professor Z. John Zhang. Dynamic pricing isn’t new. Airlines, hotels, and ride-hailing companies have long relied on it to balance demand and supply, maximize profitability, and serve different types of customers. But in 2025, dynamic pricing is spreading rapidly across industries — from grocery retail to fast food to fashion e-commerce to tickets for the upcoming FIFA World Cup — powered by artificial intelligence, digital price tags, and real-time demand data. The current tariff uncertainties and inflation concerns are further impetus for firms to flirt with, and even embrace, dynamic pricing. Done right, dynamic pricing can benefit both firms and consumers. Done poorly, it can trigger backlash and erode trust. The economic logic is straightforward: Customer willingness to pay varies. It varies across customers, and for the same customer, across occasions and over time. A family booking a vacation months in advance has a very different willingness to pay than an executive booking a same-day flight, and almost everyone is willing to pay more for roses on Valentine’s Day than on any other day. Dynamic pricing helps companies capitalize on this variation, charging a high-willingness-to-pay customer a high price and a low-willingness-to-pay customer a low price at the right time. In the airline industry, leisure travelers secure affordable tickets by booking early, while business travelers can still find seats at the last minute, albeit at a higher price. Uber’s surge pricing — which is a specific type of dynamic pricing — not only helps match riders to drivers but also attracts more drivers into busy zones, increasing supply when it’s most needed. The principle holds across industries. When prices reflect demand and capacity in real time, resources are allocated more efficiently, and customers often have more choice. Firms, of course, stand to reap more short-term profits by charging more to those who are willing to pay more, while accommodating those who can afford to pay only a low price, thus getting both high margins and high volumes for their products or services. Although consumers often conflate them, dynamic pricing and surge pricing are not the same. Dynamic pricing is the practice of adjusting the price of a good or service up or down over time, with some business objectives in mind. Surge pricing is a specific type of dynamic pricing in which a company raises the price of a product or service, unexpectedly for consumers, when demand exceeds supply. It is not surprising to see that several industries are experimenting with new forms of dynamic pricing: History offers cautionary tales. Coca-Cola’s 1999 experiment with vending machines that raised prices in hot weather drew swift backlash, with critics calling it exploitative. The company shelved the idea in the U.S. Wendy’s recent surge pricing announcement triggered a similar outcry and provided a good lesson on what can go wrong with introducing dynamic pricing. Even FIFA’s announcement about future dynamic pricing did not go unnoticed, drawing a New Yok Post headline, “World Cup’s dynamic-priced tickets will cost an arm and a leg — and ruin the global game.” Wendy’s case is worthy of some special attention. In early 2024, Wendy’s CEO Kirk Tanner announced the company’s intention to invest $20 million on high-tech menu boards that can change prices in real time. This means that a Dave’s burger can cost more during busy times like lunch and dinner. The intention here is not a bad one. By charging higher prices at busy times, Wendy’s can shift some of the demand to less busy times, reducing the peak-load staffing as well as some stress for its workers. In addition, with a smaller lunch or dinner crowd, customers would spend less time waiting for their orders at peak times. However, the prospect of dynamic pricing was immediately interpreted by the media and the public as an Uber type of surge pricing for burgers, and it was taken as another example of a greedy corporation trying to exploit customers. Critics noted that unlike Uber, higher prices don’t magically create more burgers at lunchtime and hungry customers get the short end of the stick. Not surprisingly, significant negative public reaction ensued, with “#BoycottWendys” trending on social media. The lesson: Consumers instinctively do not like dynamic pricing or understand it. They resist when it feels like opportunism and when it is not clear what is in it for them. Even in the airline industry, where customers are long used to price variations, dynamic pricing has fueled perceptions of unfairness, making airlines a perennial symbol of consumer frustration. The fact of the matter is that customers have nothing to fear about dynamic pricing. Basic economics dictates that when all following three conditions are present, it is a non-brainer for a firm in any industry to embrace dynamic pricing. First, customer willingness to pay for your firm’s product or services varies over time. Second, your firm has the capability to identify when a customer is willing to pay a high or low price. Third, your firm finds a good way to communicate and implement dynamic pricing without alienating customers. Your firm can avoid alienating customers if dynamic pricing improves access, availability, or fairness for them. The first condition is generally satisfied when: The second condition is always achievable if a firm is willing to make sufficient investments in information gathering, processing, and displaying technologies. Big data and AI capabilities have certainly motivated many firms to look in the direction of dynamic pricing today. But capability alone isn’t enough. Firms must anticipate customer reaction, communicate transparently, and frame price changes around value creation rather than profit extraction. For this reason, the third condition is critical to the success or failure in implementing dynamic pricing. Coming back to Wendy’s PR disaster, the company clarified later that they had “no plans” to raise prices when demand is high. It wants to use its digital menu boards to offer discounts and other value offers during slower periods, not to charge more during peak times. In other words, Wendy’s never wanted to embrace surge pricing, and it intended to offer what I called “dynamic discounting.” Unfortunately, that intention was lost in communication, partially due to the fact that Wendy’s was not clear about it. With dynamic discounting, a firm starts with a fixed regular price and offers variable discounts. Such a mechanism can generate any price point that dynamic pricing can. For instance, Wendy’s can charge its price for Dave’s burgers dynamically, $6 at 11 a.m. to noon, $8 at noon to 1 p.m., and $7 at 1 p.m. to 3 p.m. However, when framed as dynamic discounting, the regular price for the burger becomes $8, and Wendy’s can offer $2 off at 11 a.m. to noon, and $1 off from 1 p.m. to 3 p.m. Dynamic discounting is then much more palatable to customers because nearly everyone gets a trophy. “Everyone gets a trophy” may not be the smartest idea in competitive sports, but it can help to endear customers to dynamic pricing. Similarly, with dynamic discounting, Coca-Cola could have easily set its regular prices based on hot weather and offered colder weather discounts to avoid consumer backlash. FIFA can use it to shift media and customer focus away from speculating on outlandish prices “for a top-tier seat for the July 19 final at East Rutherford, New Jersey’s MetLife Stadium.” Dynamic pricing is becoming a competitive necessity. The fact of the matter is that customers have nothing to fear about dynamic pricing. If anything, dynamic pricing shifts power to savvy consumers. Those who monitor fluctuations, book at the right time, or shop across platforms can consistently secure lower prices. In a dynamic pricing world, knowledge is power. Stock prices are dynamic. Because of it, savvy investors can buy low and sell high. For goods and services without such cycles, consumers still benefit from dynamic pricing in many ways. For instance, Amtrak tickets between Philadelphia and New York can vary from $10 to $200, and informed buyers can exploit the swings by being vigilant and diligent. Without dynamic pricing, Amtrak would have to charge a much higher everyday price to everyone, its train service would become much less accessible, and trains would run with many more empty seats. Yes, under dynamic pricing, some consumers will inevitably pay higher prices. However, when done right, the consumers who face higher prices will also be the ones who could afford to pay more and get more in return. For instance, business travelers can pay more and will pay more under dynamic pricing. In return for the higher prices, they can get a last-minute ticket or a ticket on a convenient schedule any time business calls for a trip. If you are still not convinced that you will benefit from dynamic pricing as a consumer, you may feel much better hearing that the cumulative profits for the airlines industry since the deregulation in 1978 are zero or slightly negative. This is the industry that pioneered dynamic pricing in modern times and that always stays on the cutting edge of the craft. With all the pricing sophistication the industry can muster, it fails to reap more profits because dynamic pricing has fundamentally changed the game for the industry to the benefits of all consumers. The best analogy I can use to explain the situation is American boxing. The basic rules for American boxing are that you can use only two fists and punch opponents only above the waist. However, in Thai boxing, you are allowed to use your two fists as well as two feet and punch and kick the opponent anywhere. It’s definitely a more competitive and bloodier game, as the opponents have more flexibility and more weapons to hurt each other. Ironically, while dynamic pricing gives an adopting airline the advantage of using more price points (equivalently both fists and two feet) to compete against the opponent staying with conventional pricing (two fists), the advantage disappears when the opponent also adopts dynamic pricing. When all airlines use dynamic pricing, they are playing Thai boxing instead of American boxing — each opponent has more pricing points and flexibility to steal rivals’ customers. Not surprisingly, more sophisticated dynamic pricing may offer an adopting firm some fleeting unilateral advantages, but its collective use will benefit consumers and society at large. Dynamic pricing is becoming a competitive necessity. But the winners won’t just be those with the most sophisticated algorithms. The true winners will be the companies that deploy it responsibly: balancing profitability with fairness with customers in mind, designing transparent systems, and ensuring customers feel served rather than squeezed. Customers will accept volatility if dynamic pricing is rooted in supply-and-demand logic, not in opportunism, and if customers feel they also get more from it. Customers will feel they’re getting more if you frame dynamic pricing as dynamic discounting. Sign up to stay informed about our latest article releases. A business journal from the Wharton School of the University of Pennsylvania ©2025 Knowledge at Wharton. All rights reserved. Knowledge at Wharton is an affiliate of the Wharton School of the University of Pennsylvania.
--------------------------------------------------

Title: Serve Robotics Brings Autonomous Deliveries To Chicago With Uber Eats
URL: https://finance.yahoo.com/news/serve-robotics-brings-autonomous-deliveries-155738790.html
Time Published: 2025-09-30T15:57:38Z
Description: Serve Robotics Inc. (NASDAQ:SERV) announced on Tuesday that it has launched its autonomous sidewalk delivery service in the Chicago metropolitan area...
--------------------------------------------------

Title: CoreWeave initiated, Instacart downgraded: Wall Street's top analyst calls
URL: https://finance.yahoo.com/news/coreweave-initiated-instacart-downgraded-wall-134224243.html
Time Published: 2025-09-30T13:42:24Z
Description: CoreWeave initiated, Instacart downgraded: Wall Street's top analyst calls
--------------------------------------------------

Title: Grab Stock To $4?
URL: https://www.forbes.com/sites/greatspeculations/2025/09/29/grab-stock-to-4/
Time Published: 2025-09-29T12:30:00Z
Full Content:
ByTrefis Team, Contributor. Grab Holdings Ltd. (NASDAQ: GRAB), Southeast Asia’s foremost super-app for ride-hailing, deliveries, and digital payments, has experienced a surge in 2025, rising approximately 30% year-to-date to around $6.25 per share. However, as investors ponder whether the stock could double, there is another equally significant question: could Grab’s upward momentum diminish and the stock dip back down towards $4? Let’s delve into the argument. If you are searching for upside potential with reduced volatility compared to owning an individual stock, consider the High Quality Portfolio. It has significantly outperformed its benchmark—which is a mix of the S&P 500, Russell, and S&P MidCap indexes—and has generated returns surpassing 91% since its launch. In addition, check out – The Roller Coaster Ride Of Opendoor Stock? Grab reported a gross merchandise value (GMV) of $7.9 billion for 2024, with revenues totaling around $2.2 billion—representing a slower rate than during its early growth phase. While ride-hailing is on the mend, food delivery has moderated, and fintech remains a burden on profits. At a price of $6.25 per share, Grab trades at approximately 3.5x forward sales, which is below that of global competitors like Uber. Nonetheless, if revenue growth continues to float in the mid-single digits and margins stay exceedingly thin, investors may apply a stricter discount. A multiple nearer to 2x sales would suggest a share price close to $4, significantly lower than the current price. The essential insight: Grab doesn’t require a collapse to experience a decline. A slight disappointment in growth or profitability might be enough to recalibrate expectations. At $6.25 per share, Grab has staged a commendable rally in 2025, but the risk of a retraction persists. If growth continues to stabilize and fintech losses accumulate, the stock could regress back towards $4. On the other hand, stronger margin improvements and increased digital banking adoption could validate today’s valuation—or potentially elevate it further. For investors, Grab is still a narrative of substantial potential but also considerable execution risk. At $6.25, the stock reflects a recovery. At $4, it would hint at skepticism about the profitability of the super-app model. Its future trajectory will depend on Grab's ability to turn market dominance into sustainable earning strength. Investors should brace for considerable volatility and the chance of significant losses if market conditions worsen or if the company fails to realize its ambitious growth objectives. While the 2x upside potential is mathematically sound based on projected revenues, it necessitates flawless execution within a rapidly shifting and competitive environment. Now, we implement a risk assessment framework while structuring the Trefis High Quality (HQ) Portfolio, which, featuring a selection of 30 stocks, has a strong history of outperforming the S&P 500 over the past 4 years. Why is that? As a collective, HQ Portfolio stocks resulted in better returns with lower risk compared to the benchmark index; a smoother ride, as illustrated by HQ Portfolio performance metrics.
--------------------------------------------------

Title: Why Did Reddit Stock Drop 10%?
URL: https://www.forbes.com/sites/greatspeculations/2025/09/29/why-did-reddit-stock-drop-10/
Time Published: 2025-09-29T10:30:00Z
Full Content:
ByTrefis Team, Contributor. Reddit stock (NYSE:RDDT) dropped nearly 10% in the past week, in contrast to the nearly stable performance of the S&P 500 Index. The fluctuations in Reddit’s stock price are particularly notable when compared to its competitors, including Meta Platforms – which fell about 3% during the week, Snap – gaining around 8%, and Pinterest – which dropped approximately 3%. The decline is indicative of investor worries regarding slower user growth and possible traffic challenges related to updates in Google’s search algorithms and AI-generated responses, which may impact engagement and advertising capacity on the platform. With the current share price hovering around $237, we believe Reddit could experience short-term challenges before stabilizing. Importantly, the stock is still significantly higher compared to its IPO valuation from early 2024 and has increased by 45% since late 2024, as outlined in our analysis of Why Reddit Stock Moved. However, for those looking for growth with less volatility than owning a single stock, the High Quality Portfolio is worth considering. It has significantly outperformed its benchmark, which consists of the S&P 500, Russell, and S&P MidCap indexes, achieving returns of over 91% since its launch. As a whole, the stocks in the HQ Portfolio have generated superior returns with reduced risk compared to the benchmark index; offering less of a tumultuous experience, as shown in HQ Portfolio performance metrics. Additionally, don’t miss – Uber Stock To $200? Some of the increase in Reddit’s stock since its IPO can be attributed to the approximately 30% rise in its revenues from 2022 to 2024. Revenue growth surged in 2023 due to the introduction of new ad products and licensing agreements, and this trend continued into 2024 with ongoing growth in advertising and AI-related data licensing. Nevertheless, growth started to slow somewhat in early 2025 amid worries regarding traffic sources and user engagement patterns. Although Reddit has experienced steady revenue growth, its PS multiple has not broadened significantly. The company's PS multiple rose from around 10x in 2024 to almost 12x by mid-2025. While the company’s PS is currently above historical averages, there may be potential downside when comparing the current multiple to previous peaks – roughly 15x in late 2024 and closer to 9x as recently as early 2023. In its latest quarter, Reddit declared revenue of approximately $240 million, reflecting an increase of more than 20% year-over-year, and recorded its second quarterly profit since its IPO. However, the daily active users count of 100 million was slightly under optimistic forecasts, raising concerns about market saturation and competition. For the full year of 2025, Reddit has projected revenue growth in the mid-20% range, but remarks regarding traffic uncertainty have made investors cautious. If the company can demonstrate resilience in user engagement and continue to enhance its ad products, the stock could potentially regain its upward trajectory. However, in the short term, volatility is expected to remain as investors weigh high valuation multiples against execution risks. The Trefis High Quality (HQ) Portfolio, featuring a selection of 30 stocks, has a history of consistently outperforming its benchmark inclusive of all three – S&P 500, Russell, and S&P midcap — and has generated returns above 91% since its inception. What accounts for this success? As a collective, the stocks in the HQ Portfolio deliver better returns with reduced risk compared to the benchmark index; resulting in less of a tumultuous experience, as shown in HQ Portfolio performance metrics.
--------------------------------------------------

Title: The Case Against Generative AI
URL: https://www.wheresyoured.at/the-case-against-generative-ai/
Time Published: 2025-09-29T00:00:00Z
Full Content:
Soundtrack: Queens of the Stone Age - First It Giveth Before we go any further: This is, for the third time this year, the longest newsletter I've ever written, weighing in somewhere around 18,500 words. I've written it specifically to be read at your leisure — dip in and out where you'd like — but also in one go. This is my comprehensive case that yes, we’re in a bubble, one that will inevitably (and violently) collapse in the near future. I'll also be cutting this into a four-part episode starting tomorrow on my podcast Better Offline. I deeply appreciate your time. If you like this newsletter, please think about subscribing to the premium, which I write weekly. Thanks for reading. Alright, let’s do this one last time. In 2022, a (kind-of) company called OpenAI surprised the world with a website called ChatGPT that could generate text that sort-of sounded like a person using a technology called Large Language Models (LLMs), which can also be used to generate images, video and computer code. Large Language Models require entire clusters of servers connected with high-speed networking, all containing this thing called a GPU — graphics processing units. These are different to the GPUs in your Xbox, or laptop, or gaming PC. They cost much, much more, and they’re good at doing the processes of inference (the creation of the output of any LLM) and training (feeding masses of training data to models, or feeding them information about what a good output might look like, so they can later identify a thing or replicate it). These models showed some immediate promise in their ability to articulate concepts or generate video, visuals, audio, text and code. They also immediately had one glaring, obvious problem: because they’re probabilistic, these models can’t actually be relied upon to do the same thing every single time. So, if you generated a picture of a person that you wanted to, for example, use in a story book, every time you created a new page, using the same prompt to describe the protagonist, that person would look different — and that difference could be minor (something that a reader should shrug off), or it could make that character look like a completely different person. Moreover, the probabilistic nature of generative AI meant that whenever you asked it a question, it would guess as to the answer, not because it knew the answer, but rather because it was guessing on the right word to add in a sentence based on previous training data. As a result, these models would frequently make mistakes — something which we later referred to as “hallucinations.” And that’s not even mentioning the cost of training these models, the cost of running them, the vast amounts of computational power they required, the fact that the legality of using material scraped from books and the web without the owner’s permission was (and remains) legally dubious, or the fact that nobody seemed to know how to use these models to actually create profitable businesses. These problems were overshadowed by something flashy, and new, and something that investors — and the tech media — believed would eventually automate the single thing that’s proven most resistant to automation: namely, knowledge work and the creative economy. This newness and hype and these expectations sent the market into a frenzy, with every hyperscaler immediately creating the most aggressive market for one supplier I’ve ever seen. NVIDIA has sold over $200 billion of GPUs since the beginning of 2023, becoming the largest company on the stock market and trading at over $170 as of writing this sentence only a few years after being worth $19.52 a share. While I’ve talked about some of the propelling factors behind the AI wave — automation and novelty — that’s not a complete picture. A huge reason why everybody decided to “do AI” was because the software industry’s growth was slowing, with SaaS (Software As A Service) company valuations stalling or dropping, resulting in the terrifying prospect of companies having to “under promise and over deliver” and “be efficient.” Things that normal companies — those whose valuations aren’t contingent on ever-increasing, ever-constant growth — don’t have to worry about, because they’re normal companies. Suddenly, there was the promise of a new technology — Large Language Models — that were getting exponentially more powerful, which was mostly a lie but hard to disprove because “powerful” can mean basically anything, and the definition of “powerful” depended entirely on whoever you asked at any given time, and what that person’s motivations were. The media also immediately started tripping on its own feet, mistakenly claiming OpenAI’s GPT-4 model tricked a Taskrabbit into solving a CAPTCHA (it didn’t — this never happened), or saying that “people who don’t know how to code already [used] bots to produce full-fledged games,” and if you’re wondering what “full-fledged” means, it means “pong” and a cobbled-together rolling demo of SkyRoads, a game from 1993. The media (and investors) helped peddle the narrative that AI was always getting better, could do basically anything, and that any problems you saw today would be inevitably solved in a few short months, or years, or, well, at some point I guess. LLMs were touted as a digital panacea, and the companies building them offered traditional software companies the chance to plug these models into their software using an API, thus allowing them to ride the same generative AI wave that every other company was riding. The model companies similarly started going after individual and business customers, offering software and subscriptions that promised the world, though this mostly boiled down to chatbots that could generate stuff, and then doubled down with the promise of “agents” — a marketing term that’s meant to make you think “autonomous digital worker” but really means “broken digital product.” Throughout this era, investors and the media spoke with a sense of inevitability that they never really backed up with data. It was an era based on confidently-asserted “vibes.” Everything was always getting better and more powerful, even though there was never much proof that this was truly disruptive technology, other than in its ability to disrupt apps you were using with AI — making them worse by, for example, suggesting questions on every Facebook post that you could ask Meta AI, but which Meta AI couldn’t answer. “AI” was omnipresent, and it eventually grew to mean everything and nothing. OpenAI would see its every move lorded over like a gifted child, its CEO Sam Altman called the “Oppenheimer of Our Age,” even if it wasn’t really obvious why everyone was impressed. GPT-4 felt like something a bit different, but was it actually meaningful? The thing is, Artificial Intelligence is built and sold on not just faith, but a series of myths that the AI boosters expect us to believe with the same certainty that we treat things like gravity, or the boiling point of water. Can large language models actually replace coders? Not really, no, and I’ll get into why later in the piece. Can Sora — OpenAI’s video creation tool — replace actors or animators? No, not at all, but it still fills the air full of tension because you can immediately see who is pre-registered to replace everyone that works for them. AI is apparently replacing workers, but nobody appears to be able to prove it! But every few weeks a story runs where everybody tries to pretend that AI is replacing workers with some poorly-sourced and incomprehensible study, never actually saying “someone’s job got replaced by AI” because it isn’t happening at scale, and because if you provide real-world examples, people can actually check. To be clear, some people have lost jobs to AI, just not the white collar workers, software engineers, or really any of the career paths that the mainstream media and AI investors would have you believe. Brian Merchant has done excellent work covering how LLMs have devoured the work of translators, using cheap, “almost good” automation to lower already-stagnant wages in a field that was already hurting before the advent of generative AI, with some having to abandon the field, and others pushed into bankruptcy. I’ve heard the same for art directors, SEO experts, and copy editors, and Christopher Mims of the Wall Street Journal covered these last year. These are all fields with something in common: shitty bosses with little regard for their customers who have been eagerly waiting for the opportunity to slash contract labor. To quote Merchant, “the drumbeat, marketing, and pop culture of ‘powerful AI’ encourages and permits management to replace or degrade jobs they might not otherwise have.” Across the board, the people being “replaced” by AI are the victims of lazy, incompetent cost-cutters who don’t care if they ship poorly-translated text. To quote Merchant again, “[AI hype] has created the cover necessary to justify slashing rates and accepting “good enough” automation output for video games and media products.” Yet the jobs crisis facing translators speaks to the larger flaws of the Large Language Model era, and why other careers aren’t seeing this kind of disruption. Generative AI creates outputs, and by extension defines all labor as some kind of output created from a request. In the case of translation, it’s possible for a company to get by with a shitty version, because many customers see translation as “what do these words say,” even though (as one worker told Merchant) translation is about conveying meaning. Nevertheless, “translation” work had already started to condense to a world where humans would at times clean up machine-generated text, and the same worker warned that the same might come for other industries. Yet the problem is that translation is a heavily output-driven industry, one where (idiot) bosses can say “oh yeah that’s fine” because they ran an output back through Google Translate and it seemed fine in their native tongue. The problems of a poor translation are obvious, but the customers of translation are, it seems, often capable of getting by with a shitty product. The problem is that most jobs are not output-driven at all, and what we’re buying from a human being is a person’s ability to think. Every CEO talking about AI replacing workers is an example of the real problem: that most companies are run by people who don’t understand or experience the problems they’re solving, don’t do any real work, don’t face any real problems, and thus can never be trusted to solve them. The Era of the Business Idiot is the result of letting management consultants and neoliberal “free market” sociopaths take over everything, leaving us with companies run by people who don’t know how the companies make money, just that they must always make more. When you’re a big, stupid asshole, every job that you see is condensed to its outputs, and not the stuff that leads up to the output, or the small nuances and conscious decisions that make an output good as opposed to simply acceptable, or even bad. What does a software engineer do? They write code! What does a writer do? They write words! What does a hairdresser do? They cut hair! Yet that’s not actually the case. As I’ll get into later, a software engineer does far more than just code, and when they write code they’re not just saying “what would solve this problem?” with a big smile on their face — they’re taking into account their years of experience, what code does, what code could do, all the things that might break as a result, and all of the things that you can’t really tell from just looking at code, like whether there’s a reason things are made in a particular way. A good coder doesn’t just hammer at the keyboard with the aim of doing a particular task. They factor in questions like: How does this functionality fit into the code that’s already here? Or, if someone has to update this code in the future, how do I make it easy for them to understand what I’ve written and to make changes without breaking a bunch of other stuff? A writer doesn’t just “write words.” They jostle ideas and ideals and emotions and thoughts and facts and feelings into a condensed piece of text, explaining both what’s happening and why it’s happening from their perspective, finding nuanced ways to convey large topics, none of which is the result of a single (or many) prompts but the ever-shifting sand of a writer’s brain. Good writing is a fight between a bunch of different factors: structure, style, intent, audience, and prioritizing the things that you (or your client) care about in the text. It’s often emotive — or at the very least, driven or inspired by a given emotion — which is something that an AI simply can’t replicate in a way that’s authentic and believable. And a hairdresser doesn’t just cut hair, but cuts your hair, which may be wiry, dry, oily, long, short, healthy, unhealthy, on a scalp with particular issues, at a time of year when perhaps you want to change length, at a time that fits you, in “the way you like” which may be impossible to actually write down but they get it just right. And they make conversation, making you feel at ease while they snip and clip away at your tresses, with you having to trust that they’ll get it right. This is the true nature of labor that executives fail to comprehend at scale: that the things we do are not units of work, but extrapolations of experience, emotion, and context that cannot be condensed in written meaning. Business Idiots see our labor as the result of a smart manager saying “do this,” rather than human ingenuity interpreting both a request and the shit the manager didn’t say. What does a CEO do? Uhhh, um, well, a Harvard study says they spend 25% of their time on “people and relationships,” 25% on “functional and business unit reviews,” 16% on “organization and culture,” and 21% on “strategy,” with a few percent here and there for things like “professional development.” That’s who runs the vast majority of companies: people that describe their work predominantly as “looking at stuff,” “talking to people” and “thinking about what we do next.” The most highly-paid jobs in the world are impossible to describe, their labor described in a mish-mash of LinkedInspiraton, yet everybody else’s labor is an output that can be automated. As a result, Large Language Models seem like magic. When you see everything as an outcome — an outcome you may or may not understand, and definitely don’t understand the process behind, let alone care about — you kind of already see your workers as LLMs. You create a stratification of the workforce that goes beyond the normal organizational chart, with senior executives — those closer to the class level of CEO — acting as those who have risen above the doldrums of doing things to the level of “decisionmaking,” a fuzzy term that can mean everything from “making nuanced decisions with input from multiple different subject-matter experts” to, as ServiceNow Bill McDermott did in 2022, “[make] it clear to everybody [in a boardroom of other executives], everything you do: AI, AI, AI, AI, AI.” The same extends to some members of the business and tech media that have, for the most part, gotten by without having to think too hard about the actual things the companies are saying. I realize this sounds a little mean, and I must be clear it doesn’t mean that these people know nothing, just that it’s been possible to scoot through the world without thinking too hard about whether or not something is true. When Salesforce said back in 2024 that its “Einstein Trust Layer” and AI would be “transformational for jobs,” the media dutifully wrote it down and published it without a second thought. It fully trusted Marc Benioff when he said that Agentforce agents would replace human workers, and then again when he said that AI agents are doing “30% to 50% of all the work in Salesforce itself,” even though that’s an unproven and nakedly ridiculous statement. Salesforce’s CFO said earlier this year that AI wouldn’t boost sales growth in 2025. One would think this would change how they’re covered, or how seriously one takes Marc Benioff. It hasn’t, because nobody is paying attention. In fact, nobody seems to be doing their job. This is how the core myths of generative AI were built: by executives saying stuff and the media publishing it without thinking too hard. AI is replacing workers! AI is writing entire computer programs! AI is getting exponentially more-powerful! What does “powerful” mean? That the models are getting better on benchmarks that are rigged in their favor, but because nobody fucking explains it, regular people are regularly told that AI is “powerful.” The only thing “powerful” about generative AI is its mythology. The world’s executives, entirely disconnected from labor and actual production, are doing the only thing they know how to — spend a bunch of money and say vague stuff about “AI being the future.” There are people — journalists, investors, and analysts — that have built entire careers on filling in the gaps for the powerful as they splurge billions of dollars and repeat with increasing desperation that “the future is here” as absolutely nothing happens. You’ve likely seen a few ridiculous headlines recently. One of the most recent, and most absurd, is that that OpenAI will pay Oracle $300 billion over four years, closely followed with the claim that NVIDIA will “invest” “$100 billion” in OpenAI to build 10GW of AI data centers, though the deal is structured in a way that means that OpenAI is paid “progressively as each gigawatt is deployed,” and OpenAI will be leasing the chips (rather than buying them outright). I must be clear that these deals are intentionally made to continue the myth of generative AI, to pump NVIDIA, and to make sure OpenAI insiders can sell $10.3 billion of shares. OpenAI cannot afford the $300 billion, NVIDIA hasn’t sent OpenAI a cent and won’t do so if it can’t build the data centers, which OpenAI most assuredly can’t afford to do. NVIDIA needs this myth to continue, because in truth, all of these data centers are being built for demand that doesn’t exist, or that — if it exists — doesn’t necessarily translate into business customers paying huge amounts for access to OpenAI’s generative AI services. NVIDIA, OpenAI, CoreWeave and other AI-related companies hope that by announcing theoretical billions of dollars (or hundreds of billions of dollars) of these strange, vague and impossible-seeming deals, they can keep pretending that demand is there, because why else would they build all of these data centers, right? That, and the entire stock market rests on NVIDIA’s back. It accounts for 7% to 8% of the value of the S&P 500, and Jensen Huang needs to keep selling GPUs. I intend to explain later on how all of this works, and how brittle it really is. The intention of these deals is simple: to make you think “this much money can’t be wrong.” It can. These people need you to believe this is inevitable, but they are being proven wrong, again and again, and today I’m going to continue doing so. Underpinning these stories about huge amounts of money and endless opportunity lies a dark secret — that none of this is working, and all of this money has been invested in a technology that doesn’t make much revenue and loves to burn millions or billions or hundreds of billions of dollars. Over half a trillion dollars has gone into an entire industry without a single profitable company developing models or products built on top of models. By my estimates, there is around $44 billion of revenue in generative AI this year (when you add in Anthropic and OpenAI’s revenues to the pot, along with the other stragglers) and most of that number has been gathered through reporting from outlets like The Information, because none of these companies share their revenues, all of them lose shit tons of money, and their actual revenues are really, really small. Only one member of the Magnificent Seven (outside of NVIDIA) has ever disclosed its AI revenue — Microsoft, which stopped reporting in January 2025, when it reported “$13 billion in annualized revenue,” so around $1.083 billion a month. Microsoft is a sales MACHINE. It is built specifically to create or exploit software markets, suffocating competitors by using its scale to drive down prices, and to leverage the ecosystem that it’s created over the past few decades. $1 billion a month in revenue is chump change for an organization that makes over $27 billion a quarter in PROFITS. Don’t worry Satya, I’ll come back to you later. “But Ed, the early days!” Worry not — I’ve got that covered. This is nothing like any other era of tech. There has never been this kind of cash-rush, even in the fiber boom. Over a decade, Amazon spent about one-tenth of the capex that the Magnificent Seven spent in two years on generative AI building AWS — something that now powers a vast chunk of the web, and has long been Amazon’s most profitable business unit. Generative AI is nothing like Uber, with OpenAI and Anthropic’s true costs coming in at about $159 billion in the past two years, approaching five times Uber’s $30 billion all-time burn. And that’s before the bullshit with NVIDIA and Oracle. Microsoft last reported AI revenue in January. It’s October this week. Why did it stop reporting this number, you think? Is it because the numbers are so good it couldn’t possibly let people know? As a general rule, publicly traded companies — especially those where the leadership are compensated primarily in equity — tend to brag about their successes, in part because said bragging boosts the value of the thing that the leadership gets paid in. There’s no benefit to being shy. Oracle literally made a regulatory filing to boast it had a $30 billion customer, which turned out to be OpenAI, who eventually agreed (publicly) to spend $300 billion in compute over five years. Which is to say that Microsoft clearly doesn’t have any good news to share, and as I’ll reveal later, they can’t even get 3% of their 440 million Microsoft 365 subscribers to pay for Microsoft 365 Copilot. If Microsoft can’t sell this shit, nobody can. Anyway, I’m nearly done, sorry, you see, I’m writing this whole thing as if you’re brand new and walking up to this relatively unprepared, so I need to introduce another company. In 2020, a splinter group jumped off of OpenAI, funded by Amazon and Google to do much the same thing as OpenAI but pretend to be nicer about it until they have to raise from the Middle East. Anthropic has always been better at coding for some reason, and people really like its Claude models. Both OpenAI and Anthropic have become the only two companies in generative AI to make any real progress, either in terms of recognition or in sheer commercial terms, accounting for the majority of the revenue in the AI industry. In a very real sense, the AI industry’s revenue is OpenAI and Anthropic. In the year where Microsoft recorded $13bn in AI revenues, $10 billion came from OpenAI’s spending on Microsoft Azure. Anthropic burned $5.3 billion last year — with the vast majority of that going towards compute. Outside of these two companies, there’s barely enough revenue to justify a single data center. Where we sit today is a time of immense tension. Mark Zuckerberg says we’re in a bubble, Sam Altman says we’re in a bubble, Alibaba Chairman and billionaire Joe Tsai says we’re in a bubble, Apollo says we’re in a bubble, nobody is making money and nobody knows why they’re actually doing this anymore, just that they must do it immediately. And they have yet to make the case that generative AI warranted any of these expenditures. That was undoubtedly the longest introduction to a newsletter I’ve ever written, and the reason why I took my time was because this post demands a level of foreshadowing and exposition, and because I want to make it make sense to anyone who reads it — whether they’ve read my newsletter for years, or whether they’re only just now investigating their suspicions that generative AI may not be all it’s cracked up to be. Today I will make the case that generative AI’s fundamental growth story is flawed, and explain why we’re in the midst of an egregious bubble. This industry is sold by keeping things vague, and knowing that most people don’t dig much deeper than a headline, a problem I simply do not have. This industry is effectively in service of two companies — OpenAI and NVIDIA — who pump headlines out through endless contracts between them and subsidiaries or investments to give the illusion of activity. OpenAI is now, at this point, on the hook for over a trillion dollars, an egregious sum for a company that already forecast billions in losses, with no clear explanation as to how it’ll afford any of this beyond “we need more money” and the vague hope that there’s another Softbank or Microsoft waiting in the wings to swoop in and save the day. I’m going to walk you through where I see this industry today, and why I see no future for it beyond a fiery apocalypse. While everybody (reasonably!) harps on about hallucinations — which, to remind you, is when a model authoritatively states something that isn’t true — but the truth is far more complex, and far worse than it seems. You cannot rely on a large language model to do what you want. Even the most highly-tuned models on the most expensive and intricate platform can’t actually be relied upon to do exactly what you want. A “hallucination” isn’t just when these models say something that isn’t true. It’s when they decide to do something wrong because it seems the most likely thing to do, or when a coding model decides to go on a wild goose chase, failing the user and burning a ton of money in the process. The advent of “reasoning” models — those engineered to ‘think’ through problems in a way reminiscent of a human — and the expansion of what people are (trying) to use LLMs for demands that the definition of an AI hallucination be widened, not merely referring to factual errors, but fundamental errors in understanding the user’s request or intent, or what constitutes a task, in part because these models cannot think and do not know anything. However successful a model might be in generating something good *once*, it will also often generate something bad, or it’ll generate the right thing but in an inefficient and over-verbose fashion. You do not know what you’re going to get each time, and hallucinations multiply with the complexity of the thing you’re asking for, or whether a task contains multiple steps (which is a fatal blow to the idea of “agents.” You can add as many levels of intrigue and “reasoning” as you want, but Large Language Models cannot be trusted to do something correctly, or even consistently, every time. Model companies have successfully convinced everybody that the issue is that users are prompting the models wrong, and that people need to be “trained to use AI,” but what they’re doing is training people to explain away the inconsistencies of Large Language Models, and to assume individual responsibility for what is an innate flaw in how large language models work. Large Language Models are also uniquely expensive. Many mistakenly try and claim this is like the dot com boom or Uber, but the basic unit economics of generative AI are insane. Providers must purchase tens or hundreds of thousands of GPUs each costing $50,000 a piece, and hundreds of millions or billions of dollars of infrastructure for large clusters. And that’s without mentioning things like staffing, construction, power, or water. Then you turn them on and start losing money. Despite hundreds of billions of GPUs sold, nobody seems to make any money, other than NVIDIA, the company that makes them, and resellers like Dell and Supermicro who buy the GPUs, put them in servers, and sell them to other people. This arrangement works out great for Jensen Huang, and terribly for everybody else. I am going to explain the insanity of the situation we find ourselves in, and why I continue to do this work undeterred. The bubble has entered its most pornographic, aggressive and destructive stage, where the more obvious it becomes that they’re cooked, the more ridiculous the generative AI industry will act — a dark juxtaposition against every new study that says “generative AI does not work” or new story about ChatGPT’s uncanny ability to activate mental illness in people. So, let’s start simple: NVIDIA is a hardware company that sells GPUs, including the consumer GPUs that you’d see in a modern gaming PC, but when you read someone say “GPU” within the context of AI, they mean enterprise-focused GPUs like the A100, H100, H200, and more modern GPUs like the Blackwell-series B200 and GB200 (which combines two GPUs with an NVIDIA CPU). These GPUs cost anywhere from $30,000 to $50,000 (or as high as $70,000 for the newer Blackwell GPUs), and require tens of thousands of dollars more of infrastructure — networking to “cluster” server racks of GPUs together to provide compute, and massive cooling systems to deal with the massive amounts of heat they produce, as well as the servers themselves that they run on, which typically use top-of-the-line data center CPUs, and contain vast quantities of high-speed memory and storage. While the GPU itself is likely the most expensive single item within an AI server, the other costs — and I’m not even factoring in the actual physical building that the server lives in, or the water or electricity that it uses — add up. I’ve mentioned NVIDIA because it has a virtual monopoly in this space. Generative AI effectively requires NVIDIA GPUs, in part because it’s the only company really making the kinds of high-powered cards that generative AI demands, and because NVIDIA created something called CUDA — a collection of software tools that lets programmers write software that runs on GPUs, which were traditionally used primarily for rendering graphics in games. While there are open-source alternatives, as well as alternatives from Intel (with its ARC GPUs) and AMD (Nvidia’s main rival in the consumer space), these aren’t nearly as mature or feature-rich. Due to the complexities of AI models, one cannot just stand up a few of these things either — you need clusters of thousands, tens of thousands, or hundreds of thousands of them for it to be worthwhile, making any investment in GPUs in the hundreds of millions or billions of dollars, especially considering they require completely different data center architecture to make them run. A common request — like asking a generative AI model to parse through thousands of lines of code and make a change or an addition — may use multiple of these $50,000 GPUs at the same time, and so if you aspire to serve thousands, or millions of concurrent users, you need to spend big. Really big. It’s these factors — the vendor lock-in, the ecosystem, and the fact that generative AI only works when you’re buying GPUs at scale — that underpin the rise of Nvidia. But beyond the economic and technical factors, there are human ones, too. To understand the AI bubble is to understand why CEOs do the things they do. Because an executive’s job is so vague, they can telegraph the value of their “labor” by spending money on initiatives and making partnerships. AI gave hyperscalers the excuse to spend hundreds of billions of dollars on data centers and buy a bunch of GPUs to go in them, because that, to the markets, looks like they’re doing something. By virtue of spending a lot of money in a frighteningly short amount of time, Satya Nadella received multiple glossy profiles, all without having to prove that AI can really do anything, be it a job or make Microsoft money. Nevertheless, AI allowed CEOs to look busy, and once the markets and journalists had agreed on the consensus opinion that “AI would be big,” all that these executives had to do was buy GPUs and “do AI.” We are in the midst of one of the darkest forms of software in history, described by many as an unwanted guest invading their products, their social media feeds, their bosses’ empty minds, and resting in the hands of monsters. Every story of its success feels bereft of any real triumph, with every literal description of its abilities involving multiple caveats about the mistakes it makes or the incredible costs of running it. Generative AI exists for two reasons: to cost money, and to make executives look busy. It was meant to be the new enterprise software and the new iPhone and the new Netflix all at once, a panacea where software guys pay one hardware guy for GPUs to unlock the incredible value creation of the future. Generative AI was always set up to fail, because it was meant to be everything, was talked about like it was everything, is still sold like it’s everything, yet for all the fucking hype, it all comes down to two companies: OpenAI, and, of course, NVIDIA. NVIDIA was, for a while, living high on the hog. All CEO Jensen Huang had to do every three months was saying “check out these numbers” and the markets and business journalists would squeal with glee, even as he said stuff like “the more you buy the more you save,” in part tipping his head to the (very real and sensible) idea of accelerated computing, but framed within the context of the cash inferno that’s generative AI, seems ludicrous. Huang’s showmanship worked really well for NVIDIA for a while, because for a while the growth was easy. Everybody was buying GPUs. Meta, Microsoft, Amazon, Google (and to a lesser extent Apple and Tesla) make up 42% of NVIDIA’s revenue, creating, at least for the first four, a degree of shared mania where everybody justified buying tens of billions of dollars of GPUs a year by saying “the other guy is doing it!” This is one of the major reasons the AI bubble is happening, because people conflated NVIDIA’s incredible sales with “interest in AI,” rather than everybody buying GPUs. Don’t worry, I’ll explain the revenue side a little bit later. We’re here for the long haul. Anyway, NVIDIA is facing a problem — that the only thing that grows forever is cancer. On September 9 2025, the Wall Street Journal said that NVIDIA’s “wow” factor was fading, going from beating analyst estimates in by nearly 21% in its Fiscal Year Q2 2024 earnings to scraping by with a mere 1.52% beat in its most-recent earnings — something that for any other company, would be a good thing, but framed against the delusional expectations that generative AI has inspired, is a figure that looks nothing short of ominous. Per the Wall Street Journal: In any other scenario, 56% year-over-year growth would lead to an abundance of Dom Perignon and Huang signing hundreds of boobs, but this is NVIDIA, and that’s just not good enough. Back in February 2024, NVIDIA was booking 265% year-over-year growth, but in its February 2025 earnings, NVIDIA only grew by a measly 78% year-over-year. It isn’t so much that NVIDIA isn’t growing, but that to grow year-over-year at the rates that people expect is insane. Life was a lot easier when NVIDIA went from $6.05 billion in revenue in Q4 FY2023 to $22 billion in revenue in Q4 FY2024, but for it to grow even 55% year-over-year from Q2 FY2026 ($46.7 billion) to Q2 2027 would require it to make $72.385 billion in revenue in the space of three months, mostly from selling GPUs (which make up around 88% of its revenue). This would put Nvidia in the ballpark of Microsoft ($76 billion in the last quarter) and within the neighborhood of Apple ($94 billion in the last quarter), predominantly making money in an industry that a year-and-a-half ago barely made the company $6 billion in a quarter. And the market needs NVIDIA to perform, as the company makes up 8% of the value of the S&P 500. It’s not enough for it to be wildly profitable, or have a monopsony on selling GPUs, or for it to have effectively 10x’d their stock in a few years. It must continue to grow at the fastest rate of anything ever, making more and more money selling these GPUs to a small group of companies that immediately start losing money once they plug them in. While a few members of the Magnificent Seven could be depended on to funnel tens of billions of dollars into a furnace each quarter, there were limits, even for companies like Microsoft, which had bought over 485,000 GPUs in 2024 alone. To take a step back, companies like Microsoft, Google and Amazon make their money by either selling access to Large Language Models that people incorporate into their products, or by renting out servers full of GPUs to run inference (as said previously, the process to generate an output by a model or series of models) or train AI models for companies that develop and market models themselves, namely Anthropic and OpenAI. The latter revenue stream of which is where Jensen Huang found a solution to that eternal growth problem: the neocloud, namely CoreWeave, Lambda and Nebius. These businesses are fairly straightforward. They own (or lease) data centers that they then fill full of servers that are full of NVIDIA GPUs, which they then rent on an hourly basis to customers, either on a per-GPU basis or in large batches for larger customers, who guarantee they'll use a certain amount of compute and sign up to long-term (i.e. more than an hour at a time) commitments. A neocloud is a specialist cloud compute company that exists only to provide access to GPUs for AI, unlike Amazon Web Services, Microsoft Azure and Google Cloud, all of which have healthy businesses selling other kinds of compute, with AI (as I’ll get into later) failing to provide much of a return on investment. It’s not just the fact that these companies are more specialized than, say, Amazon’s AWS or Microsoft Azure. As you’ve gathered from the name, these are new, young, and in almost all cases, incredibly precarious businesses — each with financial circumstances that would make a Greek finance minister blush. That’s because setting up a neocloud is expensive. Even if the company in question already has data centers — as CoreWeave did with its cryptocurrency mining operation — AI requires completely new data center infrastructure to house and cool the GPUs, and those GPUs also need paying for, and then there’s the other stuff I mentioned earlier, like power, water, and the other bits of the computer (the CPU, the motherboard, the memory and storage, and the housing). As a result, these neoclouds are forced to raise billions of dollars in debt, which they collateralize using the GPUs they already have, along with contracts from customers, which they use to buy more GPUs. CoreWeave, for example, has $25 billion in debt on estimated revenues of $5.35 billion, losing hundreds of millions of dollars a quarter. You know who also invests in these neoclouds? NVIDIA! NVIDIA is also one of CoreWeave’s largest customers (accounting for 15% of its revenue in 2024), and just signed a deal to buy $6.3 billion of any capacity that CoreWeave can’t otherwise sell to someone else through 2032, an extension of a $1.3 billion 2023 deal reported by the Information. It was the anchor investor ($250 million) in CoreWeave’s IPO, too. NVIDIA is currently doing the same thing with Lambda, another neocloud that NVIDIA invested in, which also plans to go public next year. NVIDIA is also one of Lambda’s largest customers, signing a deal with it this summer to rent 10,000 GPUs for $1.3 billion over four years. In the UK, NVIDIA has just invested $700 million in Nscale, a former crypto miner that has never built an AI data center, and that has, despite having no experience, committed $1 billion (and/or 100,000 GPUs) to an OpenAI data center in Norway. On Thursday, September 25, Nscale announced it had closed another funding round, with NVIDIA listed as a main backer — although it’s unclear how much money it put in. It would be safe to assume it’s another few hundred million. NVIDIA also invested in Nebius, an outgrowth of Russian conglomerate Yandex, and Nebius provides, through a partnership with NVIDIA, tens of thousands of dollars’ worth of compute credits to companies in NVIDIA’s Inception startup program. NVIDIA’s plan is simple: fund these neoclouds, let these neoclouds load themselves up with debt, at which point they buy GPUs from NVIDIA, which can then be used as collateral for loans, along with contracts from customers, allowing the neoclouds to buy even more GPUs. It’s like that Robinhood infinite money glitch… …except, that is, for one small problem. There don’t appear to be that many customers. As I went into recently on my premium newsletter, NVIDIA funds and sustains Neoclouds as a way of funnelling revenue to itself, as well as partners like Supermicro and Dell, resellers that take NVIDIA GPUs and put them in servers to sell pre-built to customers. These two companies made up 39% of NVIDIA’s revenues last quarter. Yet when you remove hyperscaler revenue — Microsoft, Amazon, Google, OpenAI and NVIDIA — from the revenues of these neoclouds, there’s barely $1 billion in revenue combined, across CoreWeave, Nebius and Lambda. CoreWeave’s $5.35 billion revenue is predominantly made up of its contracts with NVIDIA, Microsoft (offering compute for OpenAI), Google (hiring CoreWeave to offer compute for OpenAI), and OpenAI itself, which has promised CoreWeave $22.4 billion in business over the next few years. This is all a lot of stuff, so I’ll make it really simple: there is no real money in offering AI compute, but that isn’t Jensen Huang’s problem, so he will simply force NVIDIA to hand money to these companies so that they have contracts to point to when they raise debt to buy more NVIDIA GPUs. Neoclouds are effectively giant private equity vehicles that exist to raise money to buy GPUs from NVIDIA, or for hyperscalers to move money around so that they don’t increase their capital expenditures and can, as Microsoft did earlier in the year, simply walk away from deals they don’t like. Nebius’ “$17.4 billion deal” with Microsoft even included a clause in its 6-K filing that Microsoft can terminate the deal in the event the capacity isn’t built by the delivery dates, and Nebius has already used the contract to raise $3 billion to… build the data center to provide compute for the contract. Here, let me break down the numbers: From my analysis, it appears that CoreWeave, despite expectations to make that $5.35 billion this year, has only around $500 million of non-Magnificent Seven or OpenAI AI revenue in 2025, with Lambda estimated to have around $100 million in AI revenue, and Nebius around $250 million without Microsoft’s share, and that’s being generous. In simpler terms, the Magnificent Seven is the AI bubble, and the AI bubble exists to buy more GPUs, because (as I’ll show) there’s no real money or growth coming out of this, other than in the amount that private credit is investing — “$50 billion a quarter, for the low end, for the past three quarters.” I dunno man, let’s start simple: $50 billion a quarter of data center funding is going into an industry that has less revenue than Genshin Impact. That feels pretty bad. Who’s gonna use these data centers? How are they going to even make money on them? Private equity firms don’t typically hold onto assets, they sell them or take them public. Doesn’t seem great to me! Anyway, if AI was truly the next big growth vehicle, neoclouds would be swimming in diverse global revenue streams. Instead, they’re heavily-centralized around the same few names, one of which (NVIDIA) directly benefits from their existence not as a company doing business, but as an entity that can accrue debt and spend money on GPUs. These Neoclouds are entirely dependent on a continual flow of private credit from firms like Goldman Sachs (Nebius, CoreWeave, Lambda for its IPO), JPMorgan (Lambda, Crusoe, CoreWeave), and Blackstone (Lambda, CoreWeave), who have in a very real sense created an entire debt-based infrastructure to feed billions of dollars directly to NVIDIA, all in the name of an AI revolution that's yet to arrive. The fact that the rest of the neocloud revenue stream is effectively either a hyperscaler or OpenAI is also concerning. Hyperscalers are, at this point, the majority of data center capital expenditures, and have yet to prove any kind of success from building out this capacity, outside, of course, Microsoft’s investment in OpenAI, which has succeeded in generating revenue while burning billions of dollars. Hyperscaler revenue is also capricious, but even if it isn’t, why are there no other major customers? Why, across all of these companies, does there not seem to be one major customer who isn’t OpenAI? The answer is obvious: nobody that wants it can afford it, and those who can afford it don’t need it. It’s also unclear what exactly hyperscalers are doing with this compute, because it sure isn’t “making money.” While Microsoft makes $10 billion in revenue from renting compute to OpenAI via Microsoft Azure, it does so at-cost, and was charging OpenAI $1.30-per-hour for each A100GPU it rents, a loss of $2.2 an hour per GPU, meaning that it is likely losing money on this compute, especially as SemiAnalysis has the total cost per hour per GPU at around $1.46 with the cost of capital and debt associated for a hyperscaler, though it’s unclear if that’s for an H100 or A100 GPU. In any case, how do these neoclouds pay for their debt if the hyperscalers give up, or NVIDIA doesn’t send them money, or, more likely, private credit begins to notice that there’s no real revenue growth outside of circular compute deals with neoclouds’ largest supplier, investor and customer? They don’t! In fact, I have serious concerns that they can’t even build the capacity necessary to fulfil these deals, but nobody seems to worry about that. No, really! It appears to be taking Oracle and Crusoe around 2.5 years per gigawatt of compute capacity. How exactly are any of these neoclouds (or Oracle itself) able to expand to actually capture this revenue? Who knows! But I assume somebody is going to say “OpenAI!” Here’s an insane statistic for you: OpenAI will account for — in both its own revenue (projected $13 billion) and in its own compute costs ($16 billion, according to The Information, although that figure is likely out of date, and seemingly only includes the compute it’ll use, and not that it has committed to build, and thus has spent money on) — about 50% of all AI revenues in 2025. That figure takes into account the $400m ARR for ServiceNow, Adobe, and Salesforce; the $35bn in revenue for the Magnificent Seven from AI (not profit, and based on figures from the previous year); revenue from neoclouds like CoreWeave, Nebius, and Lambda; and the estimated revenue from the entire generative AI industry (including Anthropic and other smaller players, like Perplexity and Anysphere) for a total of $55bn.OpenAI is the generative AI industry — and it’s a dog of a company. As a reminder, OpenAI has leaked that it’ll burn $115 billion in the next four years, and based on my estimates, it needs to raise more than $290 billion in the next four years based on its $300 billion deal with Oracle alone. That alone is a very, very bad sign, especially as we’re three years and $500 billion or more into this hype cycle with few signs of life outside of, well, OpenAI promising people money. Credit to Anthony Restaino for this horrifying graphic: This is not what a healthy, stable industry looks like. Alright, well, things can’t be that bad on the software side. Right? Right? As I covered on my premium newsletter a few weeks ago, everybody is losing money on generative AI, in part because the cost of running AI models is increasing, and in part because the software itself doesn’t do enough to warrant the costs associated with running them, which are already subsidized and unprofitable for the model providers. Outside of OpenAI (and to a lesser extent Anthropic), nobody seems to be making much revenue, with the most “successful” company being Anysphere, makers of AI coding tool Cursor, which hit $500 million ‘annualized” (so $41.6 million in one month) a few months ago, just before Anthropic and OpenAI jacked up the prices for “priority processing” on enterprise queries, raising its operating costs as a result. In any case, that’s some piss-poor revenue for an industry that’s meant to be the future of software. Smartwatches are projected to make $32 billion this year, and as mentioned, the Magnificent Seven expects to make $35 billion or so in revenue from AI this year. Even Anthropic and OpenAI seem a little lethargic, both burning billions of dollars while making, by my estimates, no more than $2 billion and $6.26 billion in 2025 so far, despite projections of $5 billion and $13 billion respectively. Outside of these two, AI startups are floundering, struggling to stay alive and raising money in several-hundred million dollar bursts as their negative-gross-margin businesses flounder. As I dug into a few months ago, I could find only 12 AI-powered companies making more than $8.3 million a month, with two of them slightly improving their revenues, specifically AI search company Perplexity (which has now hit $150 million ARR, or $12.5 million in a month) and AI coding startup Replit (which also hit $150 million ARR in September). Both of these companies burn ridiculous amounts of money. Perplexity burned 164% of its revenue on Amazon Web Services, OpenAI and Anthropic last year, and while Replit hasn’t leaked its costs, The Information reports its gross margins in July were 23%, which doesn’t include the costs of its free users, which you simply have to do with LLMs as free users are capable of costing you a hell of a lot of money. Problematically, your paid users can also cost you more than they bring in as well. In fact, every user loses you money in generative AI, because it’s impossible to do cost control in a consistent manner. A few months ago, I did a piece about Anthropic losing money on every single Claude Code subscriber, and I’ll walk you through it in a very simplified fashion: Anthropic is, to be clear, the second-largest model developer, and has some of the best AI talent in the industry. It has a better handle on its infrastructure than anyone outside of big tech and OpenAI. It still cannot seem to fix this problem, even with weekly rate limits. While one could assume that Anthropic is simply letting people run wild, my theory is far simpler: even the model developers have no real way of limiting user activity, likely due to the architecture of generative AI. I know it sounds insane, but at the most advanced level, model providers are still prompting their models, and whatever rate limits may be in place appear to, at times, get completely ignored, and there doesn’t seem to be anything they can do to stop it. No, really. Anthropic counts amongst its capitalist apex predators one lone Chinese man who spent $50,000 of their compute in the space of a month fucking around with Claude Code. Even if Anthropic was profitable — it isn’t, and will burn billions this year — a customer paying $200-a-month running up $50,000 in costs immediately devours the margin of any user running the service that day, if not that week or month. Even if Anthropic’s costs are half the published rates, one guy amounted to 125 users’ monthly revenue. That’s not a real business! That’s a bad business with out-of-control costs, and it doesn’t appear anybody has these costs under control. A few weeks ago, Replit — an unprofitable AI coding company — released a product called “Agent 3.” which promised to be “10x more autonomous” and offer “infinitely more possibilities,” “[testing] and [fixing] its code, constantly improving your application behind the scenes in a reflection loop.” In reality, this means you’d go and tell the model to build something and it would “go do it,” and you’ll be shocked to hear that these models can’t be relied upon to “go and do” anything. Please note that this was launched a few months after Replit raised its prices, shifting to obfuscated “effort-based” pricing that would charge “the full scope of the agent’s work.” Agent 3 has been a disaster. Users found tasks that previously cost a few dollars were spiralling into the hundreds of dollars, with The Register reporting one customer found themselves with a $1000 bill after a week: Another user complained that “costs skyrocketed, without any concrete results”: As I previously reported, in late May/early June, both OpenAI and Anthropic cranked up the pricing on their enterprise customers, leading to Replit and Cursor both shifting their prices. This abuse has now trickled down to their customers. Replit has now released an update that lets you choose how autonomous you want Agent 3 to be, which is a tacit admission that you can’t trust coding LLMs to build software. Replit’s users are still pissed off, complaining that Replit is charging them for activity when the agent doesn’t do anything, a consistent problem across its Reddit. While Reddit is not the full summation of all users across every company, it’s a fairly good barometer of user sentiment, and man, are users pissy. Traditionally, Silicon Valley startups have relied upon the same model of “grow really fast and burn a bunch of money, then “turn the profit lever.” AI does not have a “profit lever,” because the raw costs of providing access to AI models are so high (and they’re only increasing) that the basic economics of how the tech industry sells software don’t make sense. I’ll reiterate something I wrote a few weeks ago: In simpler terms, it is very, very difficult to imagine what one user — free or otherwise — might cost, and thus it’s hard to charge them on a monthly basis, or tell them what a service might cost them on average. This is a huge problem with AI coding environments. According to The Information, Claude Code was driving “nearly $400 million in annualized revenue, roughly doubling from a few weeks ago” on July 31 2025. That annualized revenue works out to about $33 million a month in revenue for a company that predicts it will make at least $416 million a month by the end of the year, and for a product that has become the most-popular coding environment in the world, from the second-largest and best-funded AI company in the world. …is that it? Is that all that’s happening here? $33 million dollars, all of it unprofitable, after it felt, at least based on social media chatter and discussing with multiple different software engineers, that Claude Code had become ubiquitous with anything to do with LLMs. To be clear, Anthropic’s Sonnet and Opus models are consistently some of the most popular for programming on Openrouter, an aggregator of LLM usage, and Anthropic has been consistently-named as “the best at coding.” Some bright spark out there is going to say that Microsoft’s Github Copilot has 1.8 million paying subscribers, and guess what, that’s true, and in fact, I reported it! Here’s another fun fact: the Wall Street Journal reported that Microsoft loses “on average more than $20-a-month-per-user,” with “...some users [costing] the company as much as $80.” And that’s for the most-popular product! If you believe the New York Times or other outlets that simply copy and paste whatever Dario Amodei says, you’d think that the reason that software engineers are having trouble finding work is because their jobs are being replaced by AI. This grotesque, abusive, manipulative and offensive lie has been propagated throughout the entire business and tech media without anybody sitting down and asking whether it’s true, or even getting a good understanding of what it is that LLMs can actually do with code. Members of the media, I am begging you, stop doing this. I get it, every asshole is willing to give a quote saying that “coding is dead,” and that every executive is willing to burp out some nonsense about replacing all of their engineers, but I am fucking begging you to either use these things yourself, or speak to people that do. I am not a coder. I cannot write or read code. Nevertheless, I am capable of learning, and have spoken to numerous software engineers in the last few months, and basically reached a consensus of “this is kind of useful, sometimes.” However, one very silly man once said that I don’t speak to people who use these tools, so I went and spoke to three notable, experienced software engineers, and asked them to give me the straight truth about what coding LLMs can do. In simple terms, LLMs are capable of writing code, but can’t do software engineering, because software engineering is the process of understanding, maintaining and executing code to produce functional software, and LLMs do not “learn,” cannot “adapt,” and (to paraphrase Brown), break down the more of your code and variables you ask them to look at at once. It’s very easy to believe that software engineering is just writing code, but the reality is that software engineers maintain software, which includes writing and analyzing code among a vast array of different personalities and programs and problems. Good software engineering harkens back to Brian Merchant’s interviews with translators — while some may believe that translators simply tell you what words mean, true translation is communicating the meaning of a sentence, which is cultural, contextual, regional, and personal, and often requires the exercise of creativity and novel thinking. My editor, Matthew Hughes, gave an example of this in his newsletter: Similarly, coding is not just “a series of text that programs a computer,” but a series of interconnected characters that refers to other software in other places that must also function now and explain, on some level, to someone who has never, ever seen the code before, why it was done this way. This is, by the way, why we are still yet to get any tangible proof that AI is replacing software engineers…because it can’t. Of all the fields supposedly at risk from “AI disruption,” coding feels (or felt) the most tangible, if only because the answer to “can you write code with LLMs” wasn’t an immediate, unilateral no. The media has also been quick to say that AI “writes software,” which is true in the same way that ChatGPT “writes novels”. In reality, LLMs can generate code, and do some software engineering-adjacent tasks, but, like all Large Language Models, break down and go totally insane, hallucinating more as the tasks get more complex. And, as I pointed out earlier, software engineering is not just coding. It involves thinking about problems, finding solutions to novel challenges, designing stuff in a way that can be read and maintained by others, and that’s (ideally) scalable and secure. The whole fucking point of an “AI” is that you hand shit off to it! That’s what they’ve been selling it as! That’s why Jensen Huang told kids to stop learning to code, as with AI, there’s no point. And it was all a lie. Generative AI can’t do the job of a software engineer, and it fails while also costing abominable amounts of money. Coding LLMs seem like magic at first, because they (to quote a conversation with Carl Brown) make the easy things easier, but they also make the harder things harder. They don’t even speed up engineers — they actually make them slower! Yet coding is basically the only obvious use case for LLMs. I’m sure you’re gonna say “but I bet the enterprise is doing well!” and you are so very, very wrong. Before I go any further, let’s establish some facts: All of this is to say that Microsoft has one of the largest commercial software empires in history, thousands (if not tens of thousands) of salespeople, and thousands of companies that literally sell Microsoft services for a living. And it can’t sell AI. A source that has seen materials related to sales has confirmed that, as of August 2025, Microsoft has around eight million active licensed users of Microsoft 365 Copilot, amounting to a 1.81% conversion rate across the 440 million Microsoft 365 subscribers. This would amount to, if each of these users paid annually at the full rate of $30-a-month, to about $2.88 billion in annual revenue for a product category that makes $33 billion a fucking quarter. And I must be clear, I am 100% sure these users aren’t all paying $30 a month. The Information reported a few weeks ago that Microsoft has been “reducing the software’s price with more generous discounts on the AI features, according to customers and salespeople,” heavily suggesting discounts had already been happening. Enterprise software is traditionally sold at a discount anyway — or, put a different way, with bulk pricing for those who sign up a bunch of users at once. In fact, I’ve found evidence that it’s been doing this a while, with a 15% discount on annual Microsoft 365 Copilot subscriptions for orders of 10-to-300 seats mentioned by an IT consultant back in late 2024, and another that’s currently running through September 30, 2025 through Microsoft’s Cloud Solution Provider program, with up to 2400 licenses discounted if you pay upfront for the year. Microsoft seems to do this a lot, as I found another example of an offer that ran from January 1 2025 through March 31 2025. An “active” user is someone who has taken one action on Copilot in any Microsoft 365 app in the space of 28 days. Now, I know. That word, active. Maybe you’re thinking “Ed, this is like the gym model! There are unpaid licenses that Microsoft is getting paid for!” Fine! Let’s assume that Microsoft also has, based on research that suggests this is the case for all software companies, another 50% — four million — of paid Copilot licenses that aren’t being used. That still makes this 12 million users, which is still a putrid 2.72% conversion rate. So, why aren’t people paying for Copilot? Let’s hear from someone who talked to The Information: Microsoft 365 Copilot has been such a disaster that Microsoft will now integrate Anthropic’s models in an attempt and make them better. Oh, one other thing: sources also confirm GPU utilization for Microsoft 365’s enterprise Copilot is barely scratching 60%. I’m also hearing that less than SharePoint — another popular enterprise app from Microsoft with 250 million users — had less than 300,000 weekly active users of its AI copilot features in August. So, The Information reported a few months ago that Microsoft’s projected AI revenues would be $13 billion, with $10 billion of that from OpenAI, leaving about $3 billion of total revenue across Microsoft 365 Copilot and any other foreseeable feature that Microsoft sells with “AI” on it. This heavily suggests that Microsoft is making somewhere between $1.5 billion and $2 billion on Azure or Microsoft 365 Copilot, though I suppose there are other places it could be making AI revenue too. Right? I guess. In any case, Microsoft’s net income (read: profit) in its last quarterly earnings was $27.2 billion. Pathetic. One of the comfortable lies that people tell themselves is that the AI bubble is similar to the fiber boom, or the dot com bubble, or Uber, or that we’re in the “growth stage,” or that “this is what software companies do, they spend a bunch of money then “pull the profit lever.” This is nothing like anything you’ve seen before, because this is the dumbest shit that the tech industry has ever done. AI data centers are nothing like fiber, because there are very few actual use cases for these GPUs outside of AI, and none of them are remotely hyperscale revenue drivers. As I discussed a month or so ago, data center development accounted for more of America’s GDP growth than all consumer spending combined, and there really isn’t any demand for AI in general, let alone at the scale that these hundreds of billions of dollars are being sunk into. The conservative estimate of capital expenditures related to data centers is around $400 billion, but given the $50 billion a quarter in private credit, I’m going to guess it breaks $500 billion, all to build capacity for an industry yet to prove itself. And this NVIDIA-OpenAI “$100 billion funding” news should only fill you full of dread, but also it isn’t fucking finalized, stop reporting it as if it’s done, I swear to god- Anyway, according to CNBC, “the initial $10 billion tranche is locked in at a $500 billion valuation and expected to close within a month or so once the transaction has been finalized,” with “successive $10 billion rounds are planned, each to be priced at the company’s then-current valuation as new capacity comes online.” At no point is anyone asking how, exactly, OpenAI builds data centers to fill full of these GPUs. In fact, I am genuinely shocked (and a little disgusted!) by how poorly this story has been told. Let’s go point by point: To be clear, when I say OpenAI needs at least $300 billion over the next four years, that’s if you believe its projections, which you shouldn’t. Let’s walk through its (alleged) numbers, while plagiarizing myself: According to The Information, here's the breakdown (these are projections): OpenAI's current reported burn is $116 billion through 2030, which means there is no way that these projections include $300 billion in compute costs, even when you factor in revenue. There is simply no space in these projections to absorb that $300 billion, and from what I can tell, by 2029, OpenAI will have actually burned more than $290 billion, assuming that it survives that long, which I do not believe it will. Don’t worry, though. OpenAI is about to make some crazy money. Here are the projections that CFO Sarah Friar signed off on: Just so we are clear, OpenAI intends to 10x its revenue in the space of four years, selling software and access to models in an industry with about $60 billion of revenue in 2025. How will it do this? It doesn’t say. I don’t know OpenAI CFO Sarah Friar, but I do know that signing off on these numbers is, at the very least, ethically questionable. Putting aside the ridiculousness of OpenAI’s deals, or its funding requirements, Friar has willfully allowed Sam Altman and OpenAI to state goals that defy reality or good sense, all to take advantage of investors and public markets that have completely lost the plot. I need to be blunter: OpenAI has signed multiple different deals and contracts for amounts it cannot afford to pay, that it cannot hope to raise the money to pay for, that defy the amounts of venture capital and private credit available, all to sustain a company that will burn $300 billion and has no path to profitability of any kind. So, as I said above, CNBC reported on September 23, 2025 that the NVIDIA deal will be delivered in $10 billion tranches, the first of which is “expected to close within a month,” and the rest delivered “as new capacity comes online.” This is, apparently, all part of a plan to build 10GW of data center capacity with NVIDIA. A few key points: So, let’s start simple: data centers take forever to build. As I said previously, based on current reports, it’s taking Oracle and Crusoe around 2.5 years per gigawatt of data center capacity, and nowhere in these reports does one reporter take a second to say “hey, what data centers are you talking about?” or “hey, didn’t Sam Altman say back in July that he was building 10GW of data center capacity with Oracle?” But wait, now Oracle and OpenAI have done another announcement that says they’re only doing 7GW, but they’re “ahead of schedule” on 10GW? Wait, is NVIDIA’s 10GW the same 10GW as Oracle and OpenAI are working on? Is it different? Nobody seems to know or care! Anyway, I cannot be clear enough how unlikely it is that (as NVIDIA has said) “the first gigawatt of NVIDIA systems will be deployed in the second half of 2026,” and that’s if it has bought the land and got the permits and ordered the construction, none of which has happened yet. But let’s get really specific on costs! Crusoe’s 1.2GW of compute for OpenAI is a $15 billion joint venture, which means a gigawatt of compute runs about $12.5 billion. Abilene’s eight buildings are meant to hold 50,000 NVIDIA GB200 GPUs and their associated networking infrastructure, so let’s say a gigawatt is around 333,333 Blackwell GPUs. Though this math is a little funky due to NVIDIA promising to install its new Rubin GPUs in these theoretical data centers, that means these data centers will require a little under $200 billion worth of GPUs. By my maths that’s $325 billion. I’m so tired of this. A number of you have sent me the following image with some sort of comment about how “this is how it’ll work,” and you are wrong, because this is neither how it works nor how it will work nor accurate on any level. In the current relationship, NVIDIA Is Not Sending OpenAI $100 Billion, nor will it send it that much money, because 90% of OpenAI’s funding is gated behind building 9 or 10 gigawatts of data center capacity. In the current relationship, OpenAI does not have the money to pay Oracle. Also, can Oracle even afford to give that much money to NVIDIA? It had negative free cash flow last quarter, already has $104 billion in debt, and its biggest new customer cannot afford a single fucking thing it’s promised. The only company in this diagram that actually can afford to do any of this shit is NVIDIA, and even then it only has $56 billion cash on hand. In any case, as I went over on Friday, OpenAI has promised about a trillion dollars between compute contracts across Oracle, Microsoft, Google and CoreWeave, 17 Gigawatts of promised data centers in America between NVIDIA and “Stargate,” several more gigawatts of international data centers, custom chips from Broadcom, and their own company operations. How exactly does this get paid for? Nobody seems to ask these questions! Why am I the asshole doing this? Don’t we have tech analysts that are meant to analyse shit? AHhhhh- Every time I sit down to write about this subject the newsletters seem to get longer, because people are so painfully attached to the norms and tropes of the past. This post is, already, 17,500 words — a record for this newsletter — and I’ve still not finished editing and expanding it. What we’re witnessing is one of the most egregious wastes of capital in history, sold by career charlatans with their reputations laundered by a tech and business media afraid to criticize the powerful and analysts that don’t seem to want to tell their investors the truth. There are no historic comparisons here — even Britain’s abominable 1800s railway bubble, which absorbed half of the country’s national income, created valuable infrastructure for trains, a vehicle that can move people to and from places. GPUs are not trains, nor are they cars, or even CPUs. They are not adaptable to many other kinds of work, nor are they “the infrastructure of the future of tech,” because they’re already quite old and with everybody focused on buying them, you’d absolutely see one other use case by now that actually mattered. GPUs are expensive, power-hungry, environmentally destructive and require their own kinds of cooling and server infrastructure, making every GPU data center and environmental and fiscal bubble unto themselves. And, whereas the Victorian train infrastructure still exists in the UK — though it has been upgraded over the years — a GPU has a limited useful lifespan. These are cards that can — and will — break after a period of extended usage, whether that period is five years or later, and they’ll inevitably be superseded by something better and more powerful, meaning that the resale value of that GPU will only go down, with a price depreciation that’s akin to a new car. I am telling you, as I have been telling you for years, again and again and again, that the demand is not there for generative AI, and the demand is never, ever arriving. The only reason anyone humours any of this crap is the endless hoarding of GPUs to build capacity for a revolution that will never arrive. Well, that and OpenAI, a company built and sold on lies about ChatGPT’s capabilities. ChatGPT’s popularity — and OpenAI’s hunger for endless amounts of compute — have created the illusion of demand due to the sheer amount of capacity required to keep their services operational, all so they can burn $8 billion or more in 2025 and, if my estimates are right, nearly a trillion dollars by 2030. This NVIDIA deal is a farce — an obvious attempt by the largest company on the American stock market to prop up the one significant revenue-generator in the entire industry, knowing that time is running out for it to create new avenues for eternal growth. I’d argue that NVIDIA’s deal also shows the complete contempt that these companies have for the media. There are no details about how this deal works beyond the initial $10 billion, there’s no land purchased, no data center construction started, and yet the media slurps it down without a second thought. I am but one man, and I am fucking peculiar. I did not learn financial analysis in school, but I appear to be one of the few people doing even the most basic analysis of these deals, and while I’m having a great time doing so, I am also exceedingly frustrated at how little effort is being put into prying apart these deals. I realize how ridiculous all of this sounds. I get it. There’s so much money being promised to so many people, market rallies built off the back of massive deals, and I get that the assumption is that this much money can’t be wrong, that this many people wouldn’t just say stuff without intending to follow through, or without considering whether their company could afford it. I know it’s hard to conceive that hundreds of billions of dollars could be invested in something for no apparent reason, but it’s happening, right god damn now, in front of your eyes, and I am going to be merciless on anyone who attempts to write a “how could we see this coming?” Generative AI has never been reliable, has always been unprofitable, and has always been unsustainable, and I’ve been saying so since February 2024. The economics have never made sense, something I’ve said repeatedly since April 2024, and when I wrote “How Does OpenAI Survive?” in July 2024, I had multiple people suggest I was being alarmist. Here’s some alarmism for you: the longer it takes for OpenAI to die, the more damage it will cause to the tech industry. On Friday, when I put out my piece on OpenAI needing a trillion dollars, I asked analyst Gil Luria if the capital was there to build the 17 Gigawatts that OpenAI had allegedly planned to build. He said the following: That doesn’t sound good! Anyway, as I discussed earlier, venture capital could run out in six quarters, with investor and researcher Jon Sakoda estimating that there will only be around $164 billion of dry powder (available capital) in US VC firms by the end of 2025. In July, The French Tech Journal reported (using Pitchbook data) that global venture capital deal activity reached its lowest first-half total since 2018, with $139.4 billion in deal value in the first half of 2025, down from $183.4 billion in the first half of 2024, meaning that any further expansion or demands for venture capital from OpenAI will likely sap the dwindling funds available from other startups. Things get worse when you narrow things to US venture capital. In a piece from April, EY reported that VC-backed investment in US companies hit $80 billion in Q1 2025, but “one $40 billion deal” accounted for half of the investment — OpenAI’s $40 billion deal of which only $10 billion has actually closed, and that didn’t happen until fucking June. Without the imaginary money from OpenAI, US venture would have declined by 36%. The longer that OpenAI survives, the longer it will sap the remaining billions from the tech ecosystem, and I expect it to extend its tendrils to private credit too. The $325 billion it needs just to fulfil its NVIDIA contract, albeit over 4 years, is an egregious sum that I believe exceeds the available private capital in the world. Let’s get specific, and check out the top 10 private equity firms’ available capital! Assuming that all of this capital is currently available, the top 10 private equity firms in the world have around $477 billion of available capital. We can, of course, include investment banks — Goldman Sachs had around $520 billion cash in hand available at the end of its last quarter, and JPMorgan over $1.7 trillion, but JP Morgan has only dedicated $50 billion in direct lending commitments as of February 2025, and while Goldman Sachs expanded its direct private credit lending by $15 billion back in June, that appears to be an extension of its “more than $20 billion” direct lending close from mid-2024. Include both of those, and that brings us up to — if we assume that all of these funds are available — $562 billion in capital and about $164 billion in US venture available to spend, and that’s meant to go to more places than just OpenAI. Sure, sure, there’s more than just the top 10 private equity firms and there’s venture money outside of the US, but what could it be? Like, another $150 billion? You see, OpenAI needs to buy those GPUs, and it needs to build those data centers, and it needs to pay its thousands of staff and marketing and sales costs too. While OpenAI likely wouldn’t be the ones raising the money for the data centers — and honestly, I’m not sure who would do it at this point? — somebody is going to need to build TWENTY GIGAWATTS OF DATA CENTERS if we’re to believe both Oracle and NVIDIA You may argue that venture funds and private credit can raise more, and you’re right! But at this point, there have been few meaningful acquisitions of AI companies, and zero exits from the billions of dollars put into data centers. Even OpenAI admits in its own announcement about new Stargate sites that this will be a “$400 billion investment over 3 years.” Where the fuck is that money coming from? Is OpenAI really going to absorb massive chunks of all available private credit and venture capital for the next few years? And no, god, stop saying the US government will bail this out. It will have to bail out hundreds of billions of dollars, there is no scenario where it’s anything less than that, and I’ve already been over this. While the US government has spent equivalent sums in the past to support private business (the total $440 billion dispersed during the Great Recession’s TARP program, where the Treasury bought toxic assets from investment banks to stop them from imploding a la Lehman, springs to mind), it’s hard to imagine any case where OpenAI is seen as vital to the global financial system — and the economic health of the US — as the banking system. Sure, we spent around $1tn — if we’re being specific, $953bn — on the Paycheck Protection Program during the Covid era, but that was to keep people employed at a time when the economy outside of Zoom and Walmart had, for all intents and purposes, ceased to exist. There was an urgency that doesn’t apply here. If OpenAI goes tits up, Softbank loses some money — nothing new there — and Satya Nadella has to explain why he spent tens of billions of dollars on a bunch of data centers filled with $50,000 GPUs that are, at this point, ornamental. And while there will be — and have been — disastrous economic consequences, they won’t be as systemically catastrophic as that of the pandemic, or the global financial crisis. To be clear, it’ll be bad, but not as bad. And there’s also the problem of moral hazard — if the government steps in, what’s to stop big tech chasing its next fruitless rainbow? — and optics. If people resented bailing out the banks after they acted like profligate gamblers and lost, how will they feel bailing out fucking Sam Altman and Jensen Huang? I do apologize for the length of this piece, but the significance of this bubble requires depth. There is little demand, little real money, and little reason to continue, and the sheer lack of responsibility and willingness to kneel before the powerful fills me full of angry bile. I understand many journalists are not in a position where they can just write “this shit sounds stupid,” but we have entered a deeply stupid era, and by continuing to perpetuate the myth of AI, the media guarantees that retail investors and regular people’s 401Ks will suffer. It is now inevitable that this bubble bursts. Deutsche Bank has said the AI boom is unsustainable outside of tech spending “remaining parabolic,” which it says “is highly unlikely,” and Bain Capital has said that $2 trillion in new revenue is needed to fund AI’s scaling, and even that math is completely fucked as it talks about “AI-related savings”: Even when stared in the face by a ridiculous idea — $2 trillion of new revenue in a global software market that’s expected to be around $817 billion in 2025 — Bain still oinks out some nonsense about the “savings from applying AI in sales, marketing, customer support and R&D,” yet another myth perpetuated I assume to placate the fucking morons sinking billions into this. Every single “vibe coding is the future,” “the power of AI,” and “AI job loss” story written perpetuates a myth that will only lead to more regular people getting hurt when the bubble bursts. Every article written about OpenAI or NVIDIA or Oracle that doesn’t explicitly state that the money doesn’t exist, that the revenues are impossible, that one of the companies involved burns billions of dollars and has no path to profitability, is an act of irresponsible make believe and mythos. I am nobody. I am not a financier. I am not anybody special. I just write a lot, and read a lot, and can do the most basic maths in the world. I am not trying to be anything other than myself, nor do I have an agenda, other than the fact that I like doing this and I hate how this story is being told. I never planned for this newsletter to get this big, and now that it has, I’m going to keep doing the same thing every week. I also believe that the way to stop this happening again is to have a thorough and well-sourced explanation of everything as it happens, ripping down the narratives as they’re spun and making it clear who benefits from them and how and why they’re choosing to do so. When things collapse, we need to be clear about how many times people chose to look the other way, or to find good faith ways to interpret bad faith announcements and leak. So, how could we have seen this coming? I don’t know. Did anybody try to fucking look? Subscribe today. It's free. Please. Great! You’ve successfully signed up. Welcome back! You've successfully signed in. You've successfully subscribed to Ed Zitron's Where's Your Ed At. Your link has expired. Success! Check your email for magic link to sign-in. Success! Your billing info has been updated. Your billing was not updated.
--------------------------------------------------

Title: TechCrunch Mobility: Self-driving trucks startup Kodiak goes public and a shake-up at Hyundai’s Supernal | TechCrunch
URL: https://techcrunch.com/2025/09/28/techcrunch-mobility-self-driving-trucks-startup-kodiak-goes-public-and-a-shake-up-at-hyundais-supernal/
Time Published: 2025-09-28T16:02:43Z
Full Content:
Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us Welcome back to TechCrunch Mobility — your central hub for news and insights on the future of transportation. To get this in your inbox, sign up here for free — just click TechCrunch Mobility! The autonomous vehicle industry is years — maybe decades — from maturing. And so there’s still a Wild West quality to the sector, in spite of the steady stream of announcements that do show marked progress. Two such news items from this week illustrate my point of progress, possibility, and even a bit of peril (at least to the ups and downs a public market can provide). First up is Gatik, an AV and logistics startup that is applying its tech to middle-mile trucks. The startup, which I first wrote about in 2019, announced a multi-year and expanded commercial partnership with Canada’s largest retailer, Loblaw. Under the deal, Gatik will deploy 20 autonomous trucks by the end of 2025 to provide driverless delivery to Loblaw’s network of stores in the greater Toronto area. Co-founder and CEO Gautam Narang told me the company will add another 30 autonomous trucks to the fleet by the end of 2026. The deal is notable, and not just because of the fleet size. As Narang explained to me, the trucks will be handling the full regional network for Loblaw. This means these third-generation AV trucks will operate autonomously to pick up products from two distribution centers and make deliveries to over 300 retail stores. “These are multiple brands within the Loblaw umbrella,” he said. In other words, this is not some fixed-route pilot program. It’s commercial, and it’s complex. Next up is Kodiak Robotics, another startup I have reported on since its founding. The company, which is developing self-driving trucks for highway, industrial, and defense uses, began trading on Nasdaq this week under the tickers KDK and KDKRW. The company, which is now called Kodiak AI, went public via a merger with special-purpose acquisition company Ares Acquisition Corporation II, an affiliate of Ares Management. The deal valued the startup at about $2.5 billion. Kodiak raised $275 million in financing. More than $212.5 million came from certain institutional investors, including $145 million in PIPE funding and about $62.9 million in trust cash from Ares. It should be noted that the trust cash is smaller (it was $562 million), as some SPAC investors redeemed their shares. I spoke to founder and CEO Don Burnette the day before Kodiak’s big debut about why he took the company public — let alone via a SPAC. It was a big moment for Burnette, whose family was on hand to watch him ring the bell and mark the milestone. The stock was trading at about $7.70 Friday, down about 10% from its market open. “As you can imagine, building and scaling a transformative autonomous driving company is very capital intensive, and we were looking to access the public markets as a path forward for the company. And when choosing between, you know, traditional IPO or a SPAC, we considered all the options,” he said. “We felt like, from a timing perspective, it was the right decision for the company (to take the SPAC route).” It should be noted that Burnette is also quite bullish on defense. Here’s why: “I think autonomy is the future of ground transportation broadly,” he said, before noting the benefits within defense for logistics and reconnaissance operations for ground vehicles. “One of the key things is defense requires unstructured autonomy, and this is one of the areas where we become specialists.” A few weeks ago, we wrote about some trouble at Hyundai‘s electric air taxi startup Supernal, including that the company had stopped work on its air taxi program and that its CEO and CTO were out. This week, a little bird told us that a wider reorg of Supernal’s C-suite was afoot — something Hyundai Motor Group has now confirmed to us. Chief strategy officer Jaeyong Song and chief safety officer Tracy Lamb are part of a “transition to new leadership,” according to the Korean conglomerate. Song’s departure is particularly notable, as he was once the VP of Hyundai’s Advanced Air Mobility division, which Supernal was spun out of in 2021. Also gone is Lina Yang, who most recently served as chief of staff to the startup’s now-former CEO, but who also served as Supernal’s “Head of Intelligent Systems” before that. Got a tip for us? Email Kirsten Korosec at kirsten.korosec@techcrunch.com or my Signal at kkorosec.07, or email Sean O’Kane at sean.okane@techcrunch.com. Remember Moxion Power, the portable battery startup that raised $110 million before going bankrupt? The founders are back with a new startup called Anode Technology Company, which has designed a mobile battery and inverter that can be used for EV charging and supplying remote power to construction sites and live events. The startup just raised $9 million in seed funding in a round led by Eclipse Ventures; its partner, Jiten Behl, who spearheaded the deal, was previously Rivian’s chief growth officer. Apparently, Behl’s interest was sparked by his experience at Rivian. Side note: Palo Alto-based venture capital firm Eclipse sure has been busy this year. The VC firm led the $105 million round of Also, the micromobility startup that spun out of Rivian, and recently hired longtime T. Rowe Price Group investor Joe Fath as partner and head of growth. The firm doesn’t explicitly focus on transportation, but some of its portfolio companies in this sector include Arc, Bedrock Robotics, Reliable Robotics, Skyryse, and Wayve. Other deals that got my attention … Rapido, a popular ride-hailing platform in India that competes with Uber, doubled its valuation to $2.3 billion following a secondary share sale by food delivery giant Swiggy. The share sale comes just weeks after Rapido began piloting food deliveries, edging into Swiggy’s core territory. Telo, the tiny electric truck developer, raised $20 million in a Series A funding round co-led by designer and Telo co-founder Yves Béhar and Tesla co-founder Marc Tarpenning, who is on Telo’s board. Additional investment came from Salesforce CEO Marc Benioff and early-stage funds like TO VC, E12 Ventures, and Neo. TheTrump administration is seeking up to a 10% stake in Lithium Americas in exchange for renegotiating the repayment period of a $2.26 billion Department of Energy loan. GM is a major investor in the Canadian company, which is developing a lithium mine in Nevada that is expected to be the largest in the Western Hemisphere. Hackers have had quite an active week in the transportation sector. Stellantis confirmed a data breach involving customers’ personal information. The breach is linked to a hack of its Salesforce database. Meanwhile, a hack that began last Friday and targeted check-in systems provided by Collins Aerospace caused delays at Brussels, Berlin, and Dublin airports, as well as London’s Heathrow. The U.K.’s National Crime Agency has arrested a man in connection to the ransomware attack. And finally, Jaguar Land Rover said it will not resume production at its factories for yet another week as it continues to grapple with fallout from a cyberattack. Battery materials startup Sila started operations at its facility in Moses Lake, Washington, a milestone that could pave the way for longer-range, faster-charging EVs. The factory is the first large-scale silicon anode factory in the West and will initially be capable of making enough battery materials for 20,000 to 50,000 EVs. Future expansion could fulfill demand for as many as 2.5 million vehicles. Automakers continue to pull back on EVs and electrified vehicles. Honda is ending U.S. production of its Acura ZDX electric vehicle that was being built by General Motors in Tennessee, CNBC reported. And Stellantis has canceled plans to produce a 4xe plug-in hybrid Jeep Gladiator in North America by the end of 2025. Which EV is next on the chopping block? The National Highway Traffic Safety Administration opened an investigation into Rivian over issues with the seat belts in its electric delivery vans that could introduce additional risk in the event of a crash, Bloomberg reported. Tesla asked the Environmental Protection Agency not to roll back current vehicle emissions standards, breaking from other major automakers that want to see the rules eased. TuneIn, an audio streaming service, is collaborating with the Federal Emergency Management Agency to deliver emergency alerts directly to drivers. Volvo Cars is pledging a commitment to U.S. production. The company said it will continue to invest in its U.S. car plant near Charleston, South Carolina, and announced plans to expand the factory to produce a hybrid vehicle by the end of the decade. Waymo launched “Waymo for Business,” a new service designed for companies to set up accounts so their employees can access robotaxis in cities like Los Angeles, Phoenix, and San Francisco. Zoox has asked federal regulators for an exemption that would allow the Amazon-owned autonomous vehicle company to commercially deploy its custom-built robotaxis, which lack traditional controls like pedals and a steering wheel. Finally, proof of life from Luminar founder Austin Russell. You may remember that Russell was mysteriously and suddenly replaced in May as CEO of the lidar company he created. The company has never truly explained his departure, only that it was the result of a “code of business conduct and ethics inquiry” initiated by the board. Russell has been silent; while he remains on Luminar’s board, he hasn’t signed any of the filings the company has submitted with the U.S. Securities and Exchange Commission since he was replaced. This week, he reappeared as the co-founder of a new company called Russell AI Labs. It’s billed as a “platform that backs and builds transformative AI and frontier technology companies.” It doesn’t seem like his troubles at Luminar have affected his ability to attract high-profile support or make eyebrow-raising deals. Russell’s co-founders are Markus Schäfer, CTO and board member at Mercedes-Benz Group AG, and Murtaza Ahmed, who served as a managing director at Goldman Sachs before joining SoftBank and was a partner in the $100 billion Vision Fund and managing partner of its $5 billion Latin America Fund. As part of Russell AI Lab’s debut, the startup announced it has taken a $300 million stake in agentic AI company Emergence AI. Topics Transportation Editor ONE-WEEK BUNDLE FLASH SALEFounder Bundle Offer: Land your investor and sharpen your pitch. Save 15% when you bring 4-9 founders.Investors Bundle Offer: Discover your next breakout startup. Save 20% when you bring 4-9 investors.Bundle offer ends October 3. AI recruiter Alex raises $17M to automate initial job interviews Vibe-coding startup Anything nabs a $100M valuation after hitting $2M ARR in its first two weeks The AI services transformation may be harder than VCs think Famed roboticist says humanoid robot bubble is doomed to burst Electronic Arts will reportedly be acquired for $50B Spotify to label AI music, filter spam and more in AI policy change It isn’t your imagination: Google Cloud is flooding the zone © 2025 TechCrunch Media LLC.
--------------------------------------------------

Title: TechCrunch Mobility: Self-driving trucks startup Kodiak goes public and a shake-up at Hyundai’s Supernal
URL: https://finance.yahoo.com/news/techcrunch-mobility-self-driving-trucks-160100799.html
Time Published: 2025-09-28T16:01:00Z
Description: Welcome back to TechCrunch Mobility — your central hub for news and insights on the future of transportation.
--------------------------------------------------

Title: The Only Alexa Command List You'll Ever Need: 200+ Voice Commands for Your Echo
URL: https://www.cnet.com/home/smart-home/the-only-alexa-command-list-youll-ever-need-200-voice-commands-for-your-echo/
Time Published: 2025-09-28T10:00:04Z
Full Content:
Our expert, award-winning staff selects the products we cover and rigorously researches and tests our top picks. If you buy through our links, we may get a commission. Reviews ethics statement This is your complete guide to all the Alexa voice commands that make managing your smart home easier than ever. These voice commands can help you unlock Alexa's true potential. If you still think Alexa is just for setting timers and playing music, it's time to catch up. After 11 years, Amazon finally gave its voice assistant a massive brain upgrade with the new, AI-powered Alexa Plus, and it's a total game-changer. This isn't the same Alexa you're used to. The new version is smarter, more conversational, and can actually anticipate your needs. We're talking about an assistant that can manage your entire smart home, juggle your calendar, and follow you from room to room. While privacy is still a valid concern for many, a recent CNET survey found Alexa is the most trusted AI assistant out there. Your Echo device is now capable of so much more, but it's useless if you don't know what to say. Here are the essential Alexa commands you need to know to unlock what your smart speaker can actually do now. Don't miss any of our unbiased tech content and lab-based reviews. Add CNET as a preferred Google source. Amazon recently launched Alexa Plus, a major AI-powered upgrade to its voice assistant. This new version brings significantly improved conversational abilities and smart home control. The upgrade costs $20 monthly but is free for Amazon Prime subscribers. The upgraded system, first demoed in 2023, can handle more complex requests, remember personal details and perform multiple actions through natural conversation. With these spring cleaning and organization features, Alexa Plus aims to make managing your home more intuitive than ever. Notable new commands include: Before that, Amazon had announced new hardware products while also talking up a few new additions to the already vast Alexa commands library, including: By default, Amazon's connected speakers all have the same wake word. To cue up a request, just say, "Alexa." You can change the wake word to something else if, say, your own name is Alexa, or you'd just prefer an alternative. You can also trigger your smart assistant with Amazon, Echo or Computer. To change it, in the Alexa app go to Settings then Device Settings then select the Echo device you'd like to change the wake word on (you have to change each device's settings individually). If you have an Amazon Tap, Dash Wand or the Amazon Fire TV voice remote, you'll need to press a button to wake Alexa. Amazon updated the Tap with a hands-free mode that you must enable in the settings. The only wake word available to the Amazon Tap is Alexa. There's also a feature called Follow-Up Mode that makes it easier and faster to issue multiple commands to Alexa without having to keep repeating the wake word, if you enable it. When you do, Alexa will continue to listen for another command after it's completed your first request. You can keep issuing more commands until you're done or you say, "Stop." Amazon has also built on this a multiple commands feature by allowing you to string two related commands into one. You can say something like, "Alexa, play folk music at volume six," or, "Alexa, add bread, milk and eggs to my shopping list." Your Echo device can be convenient in the kitchen, the living room or anywhere for that matter. While the most obvious or natural way to use Alexa may be through an Echo speaker from Amazon, it's not the only way you can call up Amazon's digital assistant. In fact, there are more and more ways to access Alexa being created all the time, and you don't even need any specialized devices. Here are some of the most prominent ways to use Alexa with the devices you already have: You can enable the mobile apps to listen for Alexa when they're open (this will, however, disable your phone from listening for its native digital assistant's wake word -- i.e. "Hey, Siri" or "Hey, Google" won't work while you have the Alexa app open). Otherwise, you can tap the Alexa icon to call up the assistant. On an updated Windows computer, you can summon Cortana and say, "Open Alexa." After the initial connection is made, saying this will cue up Amazon's assistant through Cortana. Alexa Echo Auto allows you to connect your phone to Alexa in your car. The Echo Auto is capable of carrying out many of the same commands and features as your home device, but with some restrictions (it won't unlock your doors, for example). The list of Alexa commands is expansive and grows with every new service or device it supports. Alexa isn't perfect, but it's pretty great at understanding natural language, so you don't always have to speak the commands exactly as you see them below. Many commands work when worded several different ways or even with words omitted. When you consider the possible third-party commands through Skills -- essentially the apps of Amazon's Alexa -- the list goes on even further. To learn what individual skills are capable of, visit the skill's page from the Amazon Alexa app or alexa.amazon.com. Here are all the native Alexa commands. The Echo Show devices and Echo Spot are the only Echo speakers with touchscreen displays. This means you can tell them to show you things. You can ask your Echo show to show you things using voice commands. You can now use compatible Echo devices (Echo, Echo Dot, Echo Look, Echo Show and Amazon Tap) to control your Fire TV and Fire TV Sticks. Amazon also builds its Fire TV operating system into televisions like the Element EL4KAMZ17 series. All of the commands above work on those too, in addition to a few TV-specific commands below. Alexa commands also work with Fire TV products. You can make calls and leave voicemails to other Echo users, as well as "Drop In" to your own echo devices, either to voice or video chat with whoever's in the room (or just to monitor the space like a security camera). If you have an Android, you can send text messages with Alexa. Control purchases, shopping lists and notifications with your Echo device. To turn on notifications, open the Alexa app and select to Settings, then Notifications, then Shopping Notifications and toggle it on. Your Echo speakers will light up yellow when you have new notifications. Alexa can answer all of your music and movie-related questions. Kids can ask Alexa to play parent-approved music and stories with the Echo Dot Kids Edition. Alexa can integrate with loads of smart home platforms, such as SmartThings, Philips Hue, Wink, Insteon, Lutron, Belkin WeMo and many more. Some require you to enable skills, and some don't. Here is a selection of the commands you can use for controlling your smart home, although there are dozens more. Alexa can integrate with loads of smart home platforms and devices. Skills are third-party applications for Alexa speakers. They allow you to connect third-party software and hardware to your speaker, as well as play games and add different news sources to your Flash Briefing. Originally, they had to be enabled before you could use them, but Amazon has since made that process automatic (just ask for the Skill and it will enable when it's used). Microsoft's Cortana is available as a skill -- but rather than just being a skill, it opens the door to a completely separate digital assistant through your Alexa speakers. Once you've added the skill, enabled permissions and connected your Microsoft and Amazon accounts, just say, "Alexa, open Cortana." When you're speaking to Cortana you can check your emails, ask for the next event on your calendar or add items to your to-do list. For now, the Cortana skill is limited because it's a public preview of what the full integration will be in the future. Ring in the holiday season -- or the spooky season -- using you Echo devices. Alexa comes chock-full of Easter eggs and jokes -- the list is long. We cover the strange world of Alexa Easter eggs here, noting some of the more popular or prominent commands that prompt a snarky or humorous response. For even more, check out this Reddit thread dedicated to Alexa Easter eggs.
--------------------------------------------------