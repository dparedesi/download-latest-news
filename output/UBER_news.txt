List of news related to Uber stock price UBER:

Title: AI #123: Moratorium Moratorium
URL: https://www.lesswrong.com/posts/9bbu9nebdSfXa8cKa/ai-123-moratorium-moratorium
Time Published: 2025-07-03T15:40:03Z
Description: Published on July 3, 2025 3:40 PM GMTThe big AI story this week was the battle over the insane AI regulatory moratorium, which came dangerously close to passing. Ultimately, after Senator Blackburn realized her deal was no good and backed out of it, the dam b‚Ä¶
--------------------------------------------------

Title: Uber Eyes Pony.ai‚Äôs U.S. Unit in Potential Deal Backing Founder Travis Kalanick
URL: https://finance.yahoo.com/news/uber-eyes-pony-ai-u-183155844.html
Time Published: 2025-07-02T18:31:55Z
Description: Uber Technologies, Inc. (NYSE:UBER) ranks among the best FAANG stocks to buy according to hedge funds. Bernstein maintained its $95 price target and...
--------------------------------------------------

Title: Nykaa's early investor to exit; VC funding rebounds in 2025
URL: https://economictimes.indiatimes.com/tech/newsletters/tech-top-5/nykaas-early-investor-to-exit-vc-funding-rebounds-in-2025/articleshow/122207847.cms
Time Published: 2025-07-02T13:58:41Z
Full Content:
Want this newsletter delivered to your inbox? Updated On Jul 02, 2025, 08:02 PM IST Want this newsletter delivered to your inbox? Thank you for subscribing to Daily Top 5We'll soon meet in your inbox. Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Definitions Top Commodities Top Prime Articles Top Slideshow Top Story Listing Top Market Pages Latest News Follow us on:
--------------------------------------------------

Title: Animal Spirits: The Top 10 Risks to the Stock Market
URL: https://awealthofcommonsense.com/2025/07/animal-spirits-the-top-10-risks-to-the-stock-market/
Time Published: 2025-07-02T11:15:45Z
Full Content:
A Wealth of Common Sense Posted July 2, 2025 by Ben Carlson This episode is sponsored by Vanguard. Learn more at: https://vgi.vg/3GbOsYM The dollar is off to its worst start to a year since Bretton Woods ended in 1973 pic.twitter.com/k1G2eVQEv1 ‚Äî Jake (@EconomPic) June 30, 2025 Interesting split: Growth sectors are outperforming in the US, while Value sectors are leading the rest of the world pic.twitter.com/ftgZwFEe1z ‚Äî Mike Zaccardi, CFA, CMT üçñ (@MikeZaccardi) June 25, 2025 Israel $EIS has been the best performing country ETF in our asset class matrix in the second quarter. Up 24.7%. üî• pic.twitter.com/fCuvmrpIvj ‚Äî Bespoke (@bespokeinvest) June 30, 2025 "At year-end 2024, Individual Retirement Accounts (IRAs) and 401(k) plans accounted for 58% of the $44 trillion of total US retirement market assets" ‚Äì GS pic.twitter.com/Tdt42U60hy ‚Äî Sam Ro üìà (@SamRo) June 23, 2025 Counter #'s The average college graduate is now 24 years old, up from 22 in the 1980s and 40%+ of graduates now go on to graduate school, compared to roughly 20 to 25% in the 1980s. Thus, the applicable bucket is 25-29 year olds where unemployment is near a record low. https://t.co/SQ2Wqr3MPK pic.twitter.com/fIZeqaWS3Z ‚Äî Jake (@EconomPic) June 26, 2025 loan underwriters at freddie mac determining if an unemployed teenager has enough fartcoin to secure a mortgage. pic.twitter.com/8tRin6krYU ‚Äî Dip Wheeler (@DipWheeler) June 25, 2025 Just released Q1 2025 NMDB data reveals: ‚Äì 20.7% of mortgaged homes have a rate <3%‚Äì 32.7% have a rate 3.0 ‚Äì 3.99%‚Äì 17.9% have a rate 4.0 ‚Äì 4.99%‚Äì 9.9% have a rate 5.0 ‚Äì 5.99%‚Äì 18.8% have a rate >= 6% 81% of mortgaged homes have a rate below 6%, that's down from the peak of‚Ä¶ pic.twitter.com/3kCJZyL76P ‚Äî Odeta Kushi (@odetakushi) June 30, 2025 Ever wonder if you should be tipping your Uber driver after a ride? Tipping on Uber rides is entirely optional, says CEO Dara Khosrowshahi, who addresses the growing question. While just over 20% of riders currently tip, that number is rising. Khosrowshahi emphasizes it‚Äôs a‚Ä¶ pic.twitter.com/AYE9YKUlu3 ‚Äî CBS Sunday Morning üåû (@CBSSunday) June 27, 2025 'THE SOCIAL NETWORK 2' is officially in the works Aaron Sorkin is returning to write, and also direct (via: Deadline) pic.twitter.com/8ggDWoVQAi ‚Äî ScreenTime (@screentime) June 25, 2025 Follow us on Facebook, Instagram, and YouTube. Check out our t-shirts, coffee mugs, and other swag here. Subscribe here: Nothing in this blog constitutes investment advice, performance data or any recommendation that any particular security, portfolio of securities, transaction or investment strategy is suitable for any specific person. Any mention of a particular security and related performance data is not a recommendation to buy or sell that security. Any opinions expressed herein do not constitute or imply endorsement, sponsorship, or recommendation by Ritholtz Wealth Management or its employees. The Compound, Inc., an affiliate of Ritholtz Wealth Management, received compensation from the sponsor of this advertisement. Inclusion of such advertisements does not constitute or imply endorsement, sponsorship or recommendation thereof, or any affiliation therewith, by the Content Creator or by Ritholtz Wealth Management or any of its employees. Investing in speculative securities involves the risk of loss. Nothing on this website should be construed as, and may not be used in connection with, an offer to sell, or a solicitation of an offer to buy or hold, an interest in any security or investment product This content, which contains security-related opinions and/or information, is provided for informational purposes only and should not be relied upon in any manner as professional advice, or an endorsement of any practices, products or services. There can be no guarantees or assurances that the views expressed here will be applicable for any particular facts or circumstances, and should not be relied upon in any manner. You should consult your own advisers as to legal, business, tax, and other related matters concerning any investment. The commentary in this ‚Äúpost‚Äù (including any related blog, podcasts, videos, and social media) reflects the personal opinions, viewpoints, and analyses of the Ritholtz Wealth Management employees providing such comments, and should not be regarded the views of Ritholtz Wealth Management LLC. or its respective affiliates or as a description of advisory services provided by Ritholtz Wealth Management or performance returns of any Ritholtz Wealth Management Investments client. References to any securities or digital assets, or performance data, are for illustrative purposes only and do not constitute an investment recommendation or offer to provide investment advisory services. Charts and graphs provided within are for informational purposes solely and should not be relied upon when making any investment decision. Past performance is not indicative of future results. The content speaks only as of the date indicated. Any projections, estimates, forecasts, targets, prospects, and/or opinions expressed in these materials are subject to change without notice and may differ or be contrary to opinions expressed by others. The Compound Media, Inc., an affiliate of Ritholtz Wealth Management, receives payment from various entities for advertisements in affiliated podcasts, blogs and emails. Inclusion of such advertisements does not constitute or imply endorsement, sponsorship or recommendation thereof, or any affiliation therewith, by the Content Creator or by Ritholtz Wealth Management or any of its employees. Investments in securities involve the risk of loss. For additional advertisement disclaimers see here: https://www.ritholtzwealth.com/advertising-disclaimers Please see disclosures here. A Wealth of Common Sense is a blog that focuses on wealth management, investments, financial markets and investor psychology. I manage portfolios for institutions and individuals at Ritholtz Wealth Management LLC. More about me here. For disclosure information please see here. Email address: ¬© 2025 A Wealth of Common Sense. Every month you'll receive 3-4 book suggestions--chosen by hand from more than 1,000 books. You'll also receive an extensive curriculum (books, articles, papers, videos) in PDF form right away.
--------------------------------------------------

Title: Ripple CTO Drops Bombshell On Pre-IPO Shares As Linqto Meltdown Explodes
URL: https://bitcoinist.com/ripple-cto-bombshell-pre-ipo-shares-linqto/
Time Published: 2025-07-01T17:30:03Z
Full Content:
Linqto‚Äôs once-celebrated promise to ‚Äúdemocratize‚Äù (Ripple) pre-IPO investing is collapsing under the weight of federal probes, a looming bankruptcy filing and a furious customer base that now numbers roughly 13,000. According to an internal review first detailed by The Wall Street Journal, investigators for the Securities and Exchange Commission and the US Department of Justice are examining allegations that former chief executive William Sarris secretly marked up Ripple shares by more than 60 percent, sold customer stock without permission and promoted deals to thousands of investors who failed to meet accredited-investor standards. New management concedes that client accounts have been frozen since February and warns that a Chapter 11 filing could leave many investors as unsecured creditors. A March 14 press release from the company‚Äôs new leadership confirmed ‚Äúpervasive securities-law violations,‚Äù the pausing of all trading and the dismissal of nearly half the staff while Linqto ‚Äúexplores all options to preserve value,‚Äù including court-supervised restructuring. The same statement insists that the special-purpose vehicles (SPVs) holding customers‚Äô assets remain on issuer cap tables, but concedes that an independent forensic review is under way to verify that claim. Into that vacuum stepped attorney John E. Deaton, who told his X followers that the situation is a ‚Äútotal clusterfuck‚Äù and that roughly 11,500 Linqto users bought units in SPVs that, in turn, were supposed to own Ripple shares. Deaton says as many as 5,000 of those investors are non-accredited, creating ‚Äúa regulatory compliance nightmare‚Äù now squarely on the SEC‚Äôs radar. He plans to host a live session at 3 p.m. EST today to detail what he calls a ‚Äúheavily involved‚Äù enforcement action and to explain why simply refunding principal would strip investors of six- and seven-figure gains booked on private-share price appreciation. Ripple‚Äôs chief technology officer David Schwartz‚Äîbetter known online as ‚ÄúJoelKatz‚Äù‚Äîadded fuel to the blaze by reminding holders that they never owned Ripple equity outright. ‚ÄúYou don‚Äôt own the shares directly,‚Äù Schwartz wrote, ‚Äúbut you own a portion of a legal entity that owns the shares.‚Äù He elaborated, saying: ‚ÄúSo if you ‚Äòbought‚Äô Z shares, you own X fraction of a legal entity with Y shares where X√óY=100. This generally lets you buy ‚Äòshares‚Äô more easily and in smaller quantities, but the equivalent per-share price is usually higher.‚Äù This clarification dismantled a key misconception among many Linqto clients who believed they were holding Ripple stock directly. The implications are now being examined not only by the SEC but also by customers who fear their indirect ownership could be rendered illiquid or encumbered in bankruptcy court. When pressed about whether those SPVs could be affected by Linqto‚Äôs financial collapse, Schwartz responded: ‚ÄúThe legal entity that owns the shares that you own part of should not have exposure to Linqto going bankrupt. So a direct encumbrance on the shares to cover Linqto‚Äôs debts shouldn‚Äôt happen. But the entity may face operational challenges depending on exactly how it‚Äôs structured.‚Äù That operational risk is precisely what has many investors on edge. If trustees, custodians, or record-keepers tied to those SPVs are forced to restructure, change providers, or liquidate assets, investors may find themselves in prolonged legal limbo with no access to their holdings‚Äîeven if the shares remain technically intact on the cap table. Complicating perceptions further, Schwartz addressed a separate thread linking billionaire George Soros to Ripple. He clarified that Soros Fund Management backed PolySign‚Äîanother private company in which many Linqto users invested‚Äîduring its 2022 acquisition of fund administrator MG Stover, but said he was ‚Äúnot aware of any Soros connection to Ripple.‚Äù Initially, Schwartz wrote: ‚ÄúIt wouldn‚Äôt surprise me very much since his funds own bits of almost everything (Salesforce, Amazon, Google, JP Morgan, Goldman, Uber, FedEx, and many more), but I couldn‚Äôt find any actual connection.‚Äù However, after further reflection, he corrected himself: ‚ÄúOh, wait, I remember now. Yes, Soros‚Äô fund did invest in PolySign to help finance the acquisition of MG Stover! No connection to Ripple AFAICT though.‚Äù The deeper regulatory concern is structural. Linqto created more than 500 SPVs, each designed to pool hundreds of retail investors while keeping the underlying issuer‚Äôs shareholder count below the 2,000-owner threshold that triggers public-reporting obligations. Internal emails obtained by investigators show former executives exhorting staff to ‚Äútake no prisoners‚Äù in sales campaigns‚Äîat times buying back Ripple shares from customers at $55 each, only to flip them to Ripple for $61, banking an $8 million spread. If those shares never made it into the SPVs‚Äîas suggested in confidential memos cited by investigators‚Äîquestions of beneficial ownership, tax liability and voting rights could embroil Ripple itself in discovery. What happens next will hinge on three converging clocks: Linqto‚Äôs restructuring timetable, the SEC‚Äôs enforcement calendar and the pace at which SPV trustees can‚Äîor cannot‚Äîdemonstrate clean title to almost half a billion dollars‚Äô worth of private-company shares. Until then, thousands of would-be Ripple shareholders remain locked out of their accounts, watching from the sidelines as a legal and regulatory cyclone decides whether their ‚Äúpre-IPO dream‚Äù survives or is wiped out in a courtroom ledger. At press time, XRP traded at $2.20. For updates and exclusive offers enter your email. Jake Simmons has been a Bitcoin enthusiast since 2016. Ever since he heard about Bitcoin, he has been studying the topic every day and trying to share his knowledge with others. His goal is to contribute to Bitcoin's financial revolution, which will replace the fiat money system. Besides BTC and crypto, Jake studied Business Informatics at a university. After graduation in 2017, he has been working in the blockchain and crypto sector. You can follow Jake on Twitter at @realJakeSimmons. Bitcoin news portal providing breaking news, guides, price analysis about decentralized digital money & blockchain technology. ¬© 2025 Bitcoinist. All Rights Reserved.
--------------------------------------------------

Title: Coffee Break: OpenAI as The Money Pit
URL: https://www.nakedcapitalism.com/2025/06/open-ai-chatgpt-money-pit.html
Time Published: 2025-06-30T18:00:30Z
Full Content:
OpenAI has fatally flawed finances which reveal a company that presents no serious threat to any of the tech incumbents, including Google. In the (excellent) comments to my post last Monday on Google‚Äôs inexplicable-to-me decision to risk their search monopoly by going all-in on LLM AI one from Hickory exposed that I had failed to make a key point: ChatGPT is not a threat to replace Google as the leader in search because OpenAI loses money on every ChatGPT prompt and is trying to make it up in volume. Let‚Äôs put aside the claims about LLMs having reasoning ability for now and focus on the bullish business case for ChatGPT as a killer app that threatens Google search. Cal Newport lays out that case: The application that has‚Ä¶ leaped ahead to become the most exciting and popular use of these tools is smart search. If you have a question, instead of turning to Google you can query a new version of ChatGPT or Claude. These models can search the web to gather information, but unlike a traditional search engine, they can also process the information they find and summarize for you only what you care about. Want the information presented in a particular format, like a spreadsheet or a chart? A high-end model like GPT-4o can do this for you as well, saving even more extra steps. Smart search has become the first killer app of the generative AI era because, like any good killer app, it takes an activity most people already do all the time ‚Äî typing search queries into web sites ‚Äî and provides a substantially, almost magically better experience. This feels similar to electronic spreadsheets conquering paper ledger books or email immediately replacing voice mail and fax. I would estimate that around 90% of the examples I see online right now from people exclaiming over the potential of AI are people conducting smart searches. This behavioral shift is appearing in the data. A recent survey conducted by Future found that 27% of US-based respondents had used AI tools such as ChatGPT instead of a traditional search engine. From an economic perspective, this shift matters. Earlier this month, the stock price for Alphabet, the parent company for Google, fell after an Apple executive revealed that Google searches through the Safari web browser had decreased over the previous two months, likely due to the increased use of AI tools. Keep in mind, web search is a massive business, with Google earning over $175 billion from search ads in 2023 alone. In my opinion, becoming the new Google Search is likely the best bet for a company like OpenAI to achieve profitability‚Ä¶ That‚Äôs a seemingly reasonable claim, but doesn‚Äôt hold up after a look into OpenAI‚Äôs business plans for ChatGPT. Despite their seeming threat to Google search, OpenAI is the kind of self-defeating competition no monopolist should fear, much less destroy its proven business model to compete with. The New York Times put it pretty well last September: pic.twitter.com/As1hKPAqtB ‚Äî Nat Wilson Turner (@natwilsonturner) June 30, 2025 Morningstar summed up the NYT‚Äôs reporting well: Financial documents reviewed by The New York Times reveal a company burning through cash at an alarming rate, raising questions about the sustainability of its current trajectory and the potential risks of prioritizing break-neck expansion over responsible AI development. Let‚Äôs discuss some of the key points from the New York Times report, which was published last week before the funding announcement: ‚Äî OpenAI‚Äôs monthly revenue hit $300 million in August 2024, a 1,700% increase since early 2023. ‚Äî The company expects to generate around $3.7 billion in annual sales this year and anticipates revenue ballooning to $11.6 billion in 2025. ‚Äî Despite rising revenues, OpenAI predicts a loss of about $5 billion. this year due to high operational costs, biggest of which is the cost of computing power it gets through its partnership with Microsoft. ‚Äî OpenAI predicts its revenue will hit $100 billion in 2029. The Times report raises serious questions about OpenAI‚Äôs sustainability and realistic goals. The company‚Äôs monthly revenue growth from early 2023 to August 2024 is nothing short of explosive; however, the long-term projection of $100 billion in revenue by 2029 appears unrealistic. This figure would require sustaining an average annual growth rate of more than 90% for five consecutive years (93.3% to be precise, from an expected $3.7 billion in 2024 to $100 billion in 2029), a feat rarely achieved in the tech industry, especially for a company already operating at such a large scale. While impressive on paper, said projections may be masking underlying financial challenges and setting expectations that could be difficult, if not impossible, to meet. Financial challenges become even more apparent given the current expense structure in relation to projected growth. It‚Äôs crucial to note that, even if it reaches the projected revenue targets, OpenAI is not merely failing to break even in 2024 ‚Äì it‚Äôs losing significantly more money than it‚Äôs generating. This means that before OpenAI can even consider achieving its ambitious growth targets, it must first find a way to become profitable, or at the very least, break even. Bryan McMahon pointed out the massive financial risk posed by the stock market bubble driven by faith in LLMs or as he calls it Generative AI: Venture capital (VC) funds, drunk on a decade of ‚Äúgrowth at all costs,‚Äù have poured about $200 billion into generative AI. Making matters worse, the stock market‚Äôs bull run is deeply dependent on the growth of the Big Tech companies fueling the AI bubble. In 2023, 71 percent of the total gains in the S&P 500 were attributable to the ‚ÄúMagnificent Seven‚Äù‚ÄîApple, Nvidia, Tesla, Alphabet, Meta, Amazon, and Microsoft‚Äîall of which are among the biggest spenders on AI. Just four‚ÄîMicrosoft, Alphabet, Amazon, and Meta‚Äîcombined for $246 billion of capital expenditure in 2024 to support the AI build-out. Goldman Sachs expects Big Tech to spend over $1 trillion on chips and data centers to power AI over the next five years. Yet OpenAI, the current market leader, expects to lose $5 billion this year, and its annual losses to swell to $11 billion by 2026. If the AI bubble bursts, it not only threatens to wipe out VC firms in the Valley but also blow a gaping hole in the public markets and cause an economy-wide meltdown. But wait it gets worse, per Ed Zitron: It seems, from even a cursory glance, that OpenAI‚Äôs costs are increasing dramatically. The Information reported earlier in the year that OpenAI projects to spend $13 billion on compute with Microsoft alone in 2025, nearly tripling what it spent in total on compute in 2024 ($5 billion). This suggests that OpenAI‚Äôs costs are skyrocketing, and that was before the launch of its new image generator which led to multiple complaints from Altman about a lack of available GPUs, leading to OpenAI‚Äôs CEO saying to expect ‚Äústuff to break‚Äù and delays in new products. Nevertheless, even if we assume OpenAI factored in the compute increases into its projections, it still expects to pay Microsoft $13 billion for compute this year. This number, however, doesn‚Äôt include the $12.9 billion five-year-long compute deal signed with CoreWeave, a deal that was a result of Microsoft declining to pick up the option to buy said compute itself. Payments for this deal, according to The Information, start in October 2025, and assuming that it‚Äôs evenly paid (the terms of these contracts are generally secret, even in the case of public companies), this would still amount to roughly $2.38 billion a year. I‚Äôll let the Entertainment Strategy Guy nail the profitability coffin shut: By all accounts, right now, OpenAI is losing money. Like literally billions of dollars. The energy costs of LLMs are enormous. If they‚Äôre pricing their services below market value, trying to gain market share, then we don‚Äôt know if AI can make money for the service it‚Äôs providing right now. Two factors are driving these costs. First, the memory an AI program uses (either the more data it stores as it thinks or the longer it thinks about a problem/answer), the more it costs the AI companies in compute. Second, the AI companies are racing to build next-generation models that will require even more training, which means higher costs. And the salaries for top AI engineers/scientists are also sky-rocketing up. This is why I‚Äôm somewhat skeptical about the sorts of things that OpenAI is promising that AI can do (like become your universal assistant that remembers everything about you); it seems like an absolute memory boondoggle of monumental proportions. How much energy will it take for AI to analyze my whole life if it‚Äôs already too taxing for an LLM to remember how to format links properly? But wait, there‚Äôs even more bad news that just dropped. OpenAI is now in a bidding war for talent with some of the stupidest money out there, Mark Zuckerberg of Meta: ‚Ä¶competition for top AI researchers is heating up in Silicon Valley. Zuckerberg has been particularly aggressive in his approach, offering $100 million signing bonuses to some OpenAI staffers, according to comments Altman made on a podcast with his brother, Jack Altman. Multiple sources at OpenAI with direct knowledge of the offers confirmed the number. The Meta CEO has also been personally reaching out to potential recruits, according to the Wall Street Journal. ‚ÄúOver the past month, Meta has been aggressively building out their new AI effort, and has repeatedly (and mostly unsuccessfully) tried to recruit some of our strongest talent with comp-focused packages,‚Äù Chen wrote on Slack. And speaking of dumb money and OpenAI, Softbank is involved, although maybe not as much as reported: (In April) OpenAI closed ‚Äúthe largest private tech funding round in history,‚Äù where it ‚Äúraised‚Äù an astonishing ‚Äú$40 billion,‚Äù and the reason that I‚Äôve put quotation marks around it is that OpenAI has only raised $10 billion of the $40 billion, with the rest arriving by ‚Äúthe end of the year.‚Äù The remaining $30 billion ‚Äî $20 billion of which will (allegedly) be provided by SoftBank ‚Äî is partially contingent on OpenAI‚Äôs conversion from a non-profit to a for-profit by the end of 2025, and if it fails, SoftBank will only give OpenAI a further $20 billion. The round also valued OpenAI at $300 billion. And things might not be going so well with Softbank because OpenAI is now talking to even dumber, and much more dangerous, money: Saudi Arabia. And if you‚Äôve ever paid attention to the actual words coming out of OpenAI CEO Sam Altman‚Äôs mouth, you‚Äôll realize Altman attracting dumb money is just a case of birds of a feather flocking together. Ed Zitron chronicles some of the stupid in his latest newsletter: Here is but one of the trenchant insights from Sam Altman in his agonizing 37-minute-long podcast conversation with his brother Jack Altman from last week: ‚ÄúI think there will be incredible other products. There will be crazy new social experiences. There will be, like, Google Docs style AI workflows that are just way more productive. You‚Äôll start to see, you‚Äôll have these virtual employees, but the thing that I think will be most impactful on that five to ten year timeframe is AI will actually discover new science.‚Äù When asked why he believes AI will ‚Äúdiscover new science,‚Äù Altman says that ‚ÄúI think we‚Äôve cracked reasoning in the models,‚Äù adding that ‚Äúwe‚Äôve a long way to go,‚Äù and that he ‚Äúthink[s] we know what to do,‚Äù adding that OpenAI‚Äôs o3 model ‚Äúis already pretty smart,‚Äù and that he‚Äôs heard people say ‚Äúwow, this is like a good PHD.‚Äù That‚Äôs the entire answer! It‚Äôs complete nonsense! Sam Altman, the CEO of OpenAI, a company allegedly worth $300 billion to venture capitalists and SoftBank, kind of sounds like a huge idiot! Ed also roasts Alphabet/Google‚Äôs Sundar Pichai: Sundar Pichai, when asked one of Nilay Patel‚Äôs patented 100-word-plus-questions about Jony Ive and Sam Altman‚Äôs new (and likely heavily delayed) hardware startup: I think AI is going to be bigger than the internet. There are going to be companies, products, and categories created that we aren‚Äôt aware of today. I think the future looks exciting. I think there‚Äôs a lot of opportunity to innovate around hardware form factors at this moment with this platform shift. I‚Äôm looking forward to seeing what they do. We are going to be doing a lot as well. I think it‚Äôs an exciting time to be a consumer, it‚Äôs an exciting time to be a developer. I‚Äôm looking forward to it. The fuck are you on about, Sundar? Your answer to a question about whether you anticipate more competition is to say ‚Äúyeah I think people are gonna make shit we haven‚Äôt come up with and uhh, hardware, can‚Äôt wait!‚Äù While I think Pichai is likely a little smarter than Altman, in the same way that Satya Nadella is a little smarter than Pichai, and in the same way that a golden retriever is smarter than a chihuahua. That said, none of these men are superintelligences, nor, when pressed, do they ever seem to have any actual answers. If ChatGPT were such an existential threat to Google‚Äôs search monopoly that Alphabet‚Äôs only option was risking the empire to beat OpenAI in the LLM race, it would be profitable or at least have a plausible path to profitability. Sam Altman being a blithering idiot isn‚Äôt really the disadvantage it should be since he‚Äôs going up against competition like Mark Zuckerberg, Elon Musk, and Sundar Pichai. This isn‚Äôt like Uber vs. the local taxi incumbents in the 2010s where despite Uber‚Äôs never going to be profitable business model they were able to take over in many markets because OpenAI does not have a huge cash advantage over Alphabet and never will. Next week we‚Äôll look at at Meta, the absolute stupidest tech money around ‚Äî a company that put Dana White of the Ultimate Fighting Championship on its board. And because I promised I‚Äôd get around to this, regarding LLMs ability to ‚Äúreason‚Äù it was thoroughly debunked last October by six researchers from Apple in a paper called ‚ÄúGSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models.‚Äù When the paper was released the senior author, Mehrdad Farajtabar, tweeted that, ‚Äú‚Äúwe found no evidence of formal reasoning in language models ‚Ä¶. Their behavior is better explained by sophisticated pattern matching‚Äîso fragile, in fact, that changing names can alter results by ~10%!‚Äù Veteran political operative and corporate media professional. One of the Ed Zitron pieces you cited: https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/ while quite long, goes deep into the details of OpenAI‚Äôs present and future financing and how they expect to meet their financial commitments over the next two or three years. It left me in a funk for several days, not because I care a whit about OpenAI, but because the business press has now apparently become so delusional and dishonest that it‚Äôs hard to believe anything or even see how things can go on. After reading this, I have to conclude that OpenAI/Softbank is definitely, positively going to go out of business in the next two or three years. How much of the rest of the economy they take down with it is perhaps more worrisome. This is the same business press that covered Uber and Lyft breathlessly for 15 years as Uber burnt through money.. because they wanted the businesses to succeed. The will do the same thing with OpenAI until they magically find profit. Kurtismayfield, yea but I don‚Äôt think the overall economy has the runway that Uber had in the 2010s. Gonna be some reality checks sooner rather than later. Yea, the LLM bubble popping might be the end of the ‚ÄúEverything Bubble‚Äù that George Soros wrote a whole book about 20 years ago As a complement to this piece, I recommend this lengthy interview with technology journalist Karen Hao about her recent book ‚ÄúEmpire of AI: Dreams and Nightmares in Sam Altman‚Äôs OpenAI‚Äù. thanks! I will check it out. Agreed. It was excellent. I‚Äôm not so sure that taking over search or even making money are the real goals of these people. We had a story in Links today about LLMs ability to ensnare the lonely or unhappy into ‚Äúrelationships‚Äù that seem quite real to the victims. That could prove a handy tool if you‚Äôre a tech billionaire trying to take over the world or even a government seeking to disable potential dissidents. One emerging dystopia is a world where tech billionaires use AIs to battle each other for world control. The LLMs would be useful for ‚Äúconverting‚Äù people to their cause, while another type of AI could control huge drone swarms that attack opponents‚Äô data centers. Philip K. Dick could make a fun novel out of that possibility. excellent point. I‚Äôm always missing the story because I‚Äôm busy arguing the rational explanation. Like trying to evaluate today‚Äôs stonk market based on business fundamentals or betting on professional wrestling based on the athleticism of the performers. LLM‚Äôs ability to persuade might indeed be the killer app. What dark magick! That is in fact VULCAN‚ÄôS HAMMER from 1959, or damned close to it, IIRC. It‚Äôs almost universally agreed to be Dick‚Äôs worst novel, for completions only. but Dick‚Äôs visionary abilities make even his least essential work of interest. It certainly wasn‚Äôt his mastery of prose. Apologies, I read the post before I saw your comment which I duplicated below. Karen Hao has substantial insights into the broader questions. ‚ÄúSecond, the AI companies are racing to build next-generation models that will require even more training, which means higher costs.‚Äù ‚ÄúTraining‚Äù Data mining that amounts to wealth transfers and even more opportunities for surveillance and control of the flow of information are going to be the main outcome. Yea Gary Marcus is saying surveillance is where OpenAI is headed, I‚Äôll get into that in a future post although even there Palintir is way ahead of them and is infamously using AI widely in Gaza and everywhere else. There is a lot to be said for local inference. ‚ÄúFast‚Äù and ‚Äúeasy‚Äù are not usually among them. I will say that the installation process is slowly getting easier for the suitably equipped general user, month by month. Consider also the possibility of OpenAI or other chatbot providers being a regulatory arbitrage bid with broader ambitions, sort of like Uber. The anti-AI partisans, supplied with scary developments by researchers, are helping create the conditions for the enclosure of local private computation, with the economic and surveillance effects you‚Äôd imagine. The ‚ÄúSingapore Consensus on Global AI Safety Research Priorities‚Äù only hints at this eventuality. It does speak plainly to the general desire for surveillance among the participants, and utters some other uncomfortably guild-like noises. yikes. It‚Äôs easy to dismiss some of the ‚ÄúOMG AI is totes going to take over the world‚Äù crap as the opposite side of the coin of the hype but you‚Äôre right. There are a lot of very scary possibilities being worked toward even as the business idiots defraud believers for billions. Of course that‚Äôs scary too as they‚Äôre risking yet another financial collapse. I love dooming with this community! Everyone here is smarter than me and I‚Äôm learning a ton in these comment sections. Such a pleasant change from the various ridiculous and highly toxic electorates, ‚Äútargets‚Äù and fandoms I‚Äôve been writing for these last 28 years. To see where all this AI stuff may be headed, a viewing of ‚ÄúForbidden Planet‚Äù might be predictive. Their version ruined it‚Äôs creators, the Krell,. I haven‚Äôt seen that since I was a kid and I didn‚Äôt have a clue what it was about. will give it a shot now Seconded. Not only is it a beautiful movie with stunning hand-painted sets, credible spacecraft and a great robot, but also the issues it addresses are more relevant now than when the movie was made. Human hubris and the human subconscious make for a dangerous pairing. Transhumanist dreams become nightmares. And Anne Francis is smokin‚Äô hot. ok then, my friend‚Äôs documentary is going to have to wait As a complete ignoramus in these matters, I have long assumed the most likely financiers of AI are going to to be the US and Chinese militaries. I imagine no self-respecting general is going to want to fight a war of the future without feeling he has the superior AI. Am I missing something? Palintir has certainly used AI as a ‚Äúkiller app‚Äù in Gaza. But I don‚Äôt know much about what type of AI ‚Äî if it‚Äôs machine learning or LLMs or what. I suspect it‚Äôs some of all types. No intelligent general would depend on AI because LLM based AIs are always very convincing but one out of three times they are flat out wrong. These mistakes are sometimes called ‚Äúhallucinations.‚Äù I was not thinking of LLMs, but other forms of AI. Palantir and the IDF don‚Äôt care about hallucinations or wrong data, they don‚Äôt view their targets as human so they don‚Äôt care if they get a few extra victims while they‚Äôre targeting a doctor or journalist‚Äôs family for a synchronized multi-site assassination. for genocidal purposes hallucinations are a feature, not a bug ‚Äúone out of three times they are flat out wrong.‚Äù Seems like better results than those delivered by our present intelligence agencies (the surveillance and control bureaucracies). So we can guarantee about 100% of generals will buy into it. Especially once a the hint of post military career board positions are offered. A young man our family knew when he was a high school student in Ljubljana desperate to come to America and work on AI now, nearly 20 years later, has a Silicon Valley start-up working on voice recognition and mimicry. Wonder who‚Äôs interested in that. all kinds of fun people, I‚Äôm sure. From MI6 to the Sinaloa Cartel‚Ä¶ I think you are right for two reasons: 1. Drones with target matching that can take over in case of broken communication would make one main anti-drone defence on the battlefield in Ukraine much less useful. (Machine learning, not a chatbot) 2. Accountability sink. When the need comes to massacre civilians or POWs, it‚Äôs useful if the machine kills and can be blamed. Also it saves on PTSD treatment for the soldiers. See Gaza. Don‚Äôt know the business aspects, but ISTM that building the models and running the models are two different things. I have a couple of open source Hugging Face-type models here locally that I run in the open source Python environment on NVidia cuda with 6 Gb VRAM, though you need 12 or even 18 Gb to really be productive. As far as online, I‚Äôve found I‚Äôm using Google-AI from their search where I might have used Stack Overflow in the past for simple programming solutions. Don‚Äôt see any monetization opportunities for Google from my usage. On a large open source project I work on, one dev has a MS CoPilot account and runs all the commits through it prior to merging. I don‚Äôt see any earth-shaking insights from it but it does in the main offer useful ideas. You haven‚Äôt seen CoPilot producing hallucinations? Oddly, I‚Äôve found for basic Python, OpenAI‚Äôs Codex and its GitHub integration work surprisingly well. It‚Äôs still clearly a very early product and you can‚Äôt for example independently push to a PR branch and get Codex to update its working branch, but whatever. I was only using it for pretty straightforward personal things. Some of us are so old we can remember twenty five years ago when the web was considered a libertarian alternative to traditional media and the open source movement an ultimate expression of this. I still regard it that way and about half my searches go to information aggregator Wikipedia which is produced by humans if not always trustworthy humans. But whatever it‚Äôs flaws, I‚Äôd say Wiki is a lot more trustworthy than a money making robot run by investor sharks. If AI isn‚Äôt about surveillance then what else could this impractical technology possibly be about? True, from the above, it sounds like it is merely about suckering stock buyers. Balzac said behind every great fortune is a great crime and then W.C. Fields said you can‚Äôt cheat an honest man. Welcome to our world. Wiki (and Reddit) has been heavily manipulated by the worst actors on Earth for decades now. See Who‚Äôs Editing Wikipedia ‚Äì Diebold, the CIA, a Campaign ‚Äî Wired 2007 There‚Äôs also the rumor that Ghislaine Maxwell was a huge moderator on Reddit which has never been confirmed, but this Vice article ‚Äúdebunking‚Äù it has many of the tropes of other ‚Äúdebunkings‚Äù (see Vox.com‚Äôs 2020 covid coverage, the suppression of the NY Post‚Äôs 2020 election eve Hunter Biden laptop story or MSNBC on Russiagate to this day). Use of terms like ‚Äúincoherent and evidence-free conspiracy theory‚Äù, ‚ÄúThe ‚Äòevidence‚Äô shared by conspiracy theorists‚Äù‚Ä¶.sets off alerts in the part of my brain that triggers PTSD when the phrase ‚Äúunprovoked invasion of Ukraine‚Äù is encountered. Counterpoint, the theory was pushed hard by this Utah MAGA Senate candidate who at a glance is walking the anti-Zionist/anti-Semite line a little to closely for my comfort. Like others I don‚Äôt get much out of Reddit. And of course we all know about how Wales is not to be trusted and how Wikipedia is manipulated by the spooks. But also of course there are countless topics on Wikipedia that have nothing to do with the spooks. Everything is manipulated now to some degree but some formats are less susceptible than others. Walter Cronkite once said he picked all the stories for the evening news from that day‚Äôs NY Times. Now the Times is a joke https://www.moonofalabama.org/2025/06/nyt-guessing-about-iran-with-experts-who-lack-knowledge-of-it.html and we webians have to become our own gatekeepers and editors rather than rely on that dubious ‚Äúfirst draft of history‚Äù (which I too once read avidly). Computers are a tool. You control them or they control you. my difficulty is dealing with normies who don‚Äôt become their own gatekeepers. watching the democrats go blue maga in the 2016-2024 era was pretty awful since that was my closest family and friends my GOP family and friends were always at a bit of an arm‚Äôs remove, cousins not siblings I think you‚Äôll find the full-fat version is ‚ÄúVladimir Putin‚Äôs brutal, unprovoked invasion of Ukraine‚Äù. Extra points for later references to Putin‚Äôs Chef, Putin‚Äôs Banker, Putin‚Äôs Thinker and other variations on his imagined menagerie of stock villain characters. Karen Hao, in an interview with Novara Media UK offers substantial information on the AI situation. Silicon Valley Insider Exposes Cult Like AI Companies As Artificial Intelligence begins to fundamentally alter the way normal people live their lives, it‚Äôs often talked about in terms of boom and doom, which makes a nuanced examination difficult. The problem with AI is that the understanding required to scrutinise the technology is rare and even if one does have that understanding, the ability to clearly communicate it is even rarer. This week‚Äôs guest has been both a worker in, and reporter on the tech industry and is uniquely poised to present a nuanced and informed analysis of this rapidly expanding industry. In her new book, ‚ÄòEmpire of AI‚Äô, Karen Hao debunks myths that surround AI and exposes us to the full breadth of this global industry, from it‚Äôs cult-leader like CEOs to the workers that power the technology. She sat down with Aaron to talk about Sam Altman‚Äôs origin story, the traumatising nature of content moderation work and the striking similarities between Open AI and the British East India Company. IMO there is a case for LLMs becoming profitable but it involves injecting ads/propaganda directly into the answers. I‚Äôm sure companies and governments would pay large amounts of money to make sure that a model is biased in a way that directly benefits them. Of course, it requires getting to the point where people don‚Äôt have any alternatives to go back to. This makes Google‚Äôs destruction of the open web make sense on multiple levels The Sam Altman and Sundar Pichai quotes reminded me of this NewsRadio clip from the 90s: https://www.youtube.com/watch?v=lE1bS-Mn2Mk It would be funny if they weren‚Äôt running some of the biggest and most powerful companies in the world. I mean it‚Äôs easy to beat Google search these days because it‚Äôs been completely enshittified. I use Kagi ‚Äì paying $100/year but I will never get a single ad. It‚Äôs like Google when Google was actually good. Well worth it. I‚Äôm doing the same, although on the monthly plan and never switched to annual. Worth noting unlike Neeva, Kagi doesn‚Äôt spider itself and just uses feeds from Google, Microsoft Bing, and a few others I think. Nonetheless, not being the product is worth paying $10 a month for. The specific survival of OpenAI isn‚Äôt of any particular interest to me personally, but DeepThink‚Äôs achievement of a 30x improvement in cost for training an effective model showed that the link between performance improvement and cost for such a new technology is not something that should be projected forward with any confidence. Whether that will save OpenAI itself, again, to me, who cares, but it seems likely to be relevant to the future ubiquity of the technology itself. DeepThink or DeepSeek? DeepSeek! Thank you Just clarifying because they‚Äôre very different animals. Very hard to tell how much of the claims made by DeepSeek are true. There is a true fog of propaganda war over that topic at the moment. It seems likely they did achieve significant efficiencies. It also seems entirely plausible that they did take advantage of OpenAI and others‚Äô training data so it might not be replicable. This was my first thought. Just because chatgpt is unprofitable and expensive to operate now doesn‚Äôt mean that‚Äôs baked in to LLMs or ‚ÄúAI‚Äù. anyone who wants to evaluate whether it is wise for google to adopt LLMs in search needs to look at best-in-class in terms of cost like deepseek. Someone recently said the cost of AI converges to the cost of electricity over time. Deepseek‚Äôs improvements likely will be adopted by google eventually. What does the profitability look like at this point? I agree with many of the points in this article, but pointing out chatgpt‚Äôs unprofitability isn‚Äôt convincing. It‚Äôs very early stages and Chinese firms clearly show there‚Äôs massive room for cost savings. I saw one estimate that deepseek query costs are 3% of Chatgpt‚Äôs, so I think google‚Äôs decision should be judged with that future efficiency rate. also, whether or not chatgpt is a threat to google isn‚Äôt the issue. It‚Äôs whether LLMs and related ai tech is a threat, especially with 97% reduced query costs, and I think the answer is obviously yes. Natural language queries and responses are far more intuitive for most users and use cases than inputting a phrase and browsing links. Compare with asking ‚Äúwhere is the nearest home depot‚Äù and being given the answer. It would be good to be skeptical of the reported cost advantages of Deepseek. I looked at it for my applications, which relate to cyber security for industrial control systems, and I was astounded by its ability to ‚Äúreason.‚Äù (I‚Äôm going to sidestep here why I put quotes around ‚Äúreason,‚Äù except to say the capability is valuable, even if it is not what humans do.) Back in February, my firm expectation was that every other engine would acquire the same reasoning capabilities within weeks or months. The fact that they have come nowhere close is suggestive that the cost advantages of Deepseek are not what they were claimed to be. A chunk of LLM API requests get redirected from places where money is real to OpenAI where the charges are on the order of 1/6 the price. Setting up your own compute to run your own models locally is pretty pricey, so if OpenAI craters it‚Äôs going to cause some pain in certain products currently subsidized by the magic of Silicon Valley. built in lack of resilience to the industry. OpenAI collapsing could be a singularity that pulls a lot of peripheral companies down into a black hole with it. ‚Äúoops not the singularity we promised, does a minsky moment count?‚Äù Great post this and reading it, I can see a future direction that they will go in. That they will want the user to talk to the AI instead of just hammering on keys. That, come to think of it, was featured in the 2013 film ‚ÄúHer‚Äù which had a computer AI- https://en.wikipedia.org/wiki/Her_(2013_film)#Plot They say that they want more training sets to make their AI better but where will those come from? They have ransacked the internet now and slurped it all up. They haven‚Äôt even set up standards for AI yet and we are still in the bananas stage- https://www.theregister.com/2025/06/27/bofh_2025_episode_12/ that‚Äôs one of the reasons Gary Marcus has known all along that the mass compute/big money/big scale approach wouldn‚Äôt work. they‚Äôre out of content to train on and the more the LLM generated content gets mixed in the worse the output gets There is lots of content left to train on. But it isn‚Äôt openly accessible stuff. Think of all the NHS data palantir will now get it‚Äôs hands on. All the data that various governments store. All the data corporations store. Hell even think about all the messages that get sent in Whatsapp and similar every day. All of that data is out that and not currently accesible. But it will be. and private phone conversations! I suspect Palintir, Meta, Alphabet, Amazon and others are grabbing ‚Äútraining data‚Äù that would shock and appall even the most jaded of us Oh, the Dems love ‚Äúlabor,‚Äù because the honchos give them (dues) money to run their campaigns during which they mouth platitudes about ‚Äúworking families.‚Äù But as far as supporting actual rank and file workers, not at all. You see these union politicians like Sean Fain (yes, he is for all intents and purposes a Dem Party neoliberal politician). The Dems co-opted the unions, and deal almost exclusively with high- and medium-level hacks like Fain, who think like they do. Please do not leave off topic comments. The place for this is Links. This is called thread-jacking and is a violation of our written site Policies. And there is this: Potemkin Understanding in Large Language Models As a search engine it‚Äôs OK at best, but in other regards it‚Äôs really not very reliable. this persuading people to believe crazy nonsense might be the killer app I failed to see when I did the initial post. very scary but as someone who‚Äôs spent decades in the ‚Äúget attention > attempt to persuade‚Äù field I can see where that‚Äôs a high margin business provided they can cut way way down on the compute costs and energy burn. but I‚Äôm not sure the lack of need for high quality content relates to any technical cost savings. Anyone know? People already believe crazy nonsense Who needs AI? Well per MIT Technology Review ‚ÄúAI can do a better job of persuading people than we do: OpenAI‚Äôs GPT-4 is much better at getting people to accept its point of view during an argument than humans are‚Äîbut there‚Äôs a catch.‚Äù There is a huge market to be able to control exactly what crazy nonsense specific individuals believe. This could replace advertising completely ‚Äî provided they can dramatically reduce cost and energy use. Big provisions. Re tweet that the behavior of LLMs is best explained as ‚Äúsophisticated pattern matching.‚Äù I agree with that, but I think a better and more incisive way of explaining LLMs is to simply say that they are all about mimicry. They are consummate con artists. They can sound just like a doctor without knowing medicine. They can sound just like a PhD without even knowing how to reason or think. Is that some huge human achievement, that we have developed a computer program that can mimic doctors and PhDs without actually knowing anything? To me, the answer is no. It‚Äôs not much of an achievement at all to develop automated con artists. Why do we need automated con artists that sound convincing but know nothing and have no value other than how convincing they sound? Several years back i overheard a senior enginer explaining to a junior one that ‚Äúthe key to being s consultant isn‚Äôt knowing more than the client, it‚Äôs bullshitting them that you know more‚Äù. Perhaps AI is kust a reflection of where society has already gone. it might be an achievement along the lines of Dr Frankenstein‚Äôs. I don‚Äôt pay any attention to the AI ‚Äúfeatures‚Äù in Google search, though that‚Äôs getting more and more difficult over time, because I don‚Äôt trust it not to make stuff up. I‚Äôm surprised more people aren‚Äôt likewise leery of it. word is getting out but reptition is the most powerful form of persuasion according to some and the whole tech industry is pushing this stuff on us over and over and over and over ‚ÄúThe energy costs of LLMs are enormous.‚Äù Amongst all their BS and hype I can‚Äôt look past the energy aspect. Where will the affordable energy come from to power all of the data centres as they store increasing amounts of data, and the more data AI has to interrogate the more it consumes energy to ‚Äòthink‚Äô (just consumes an increasingly larger amount of energy as it learns and grows)? The more I listen to energy experts discuss energy demand and affordable clean energy (is anything really clean considering the resources we dig up to build solar/wind capture infrastructure) the more I think AI will be limited by (clean/cleanish) energy availability. Based on current trends, humans will be limited by energy availability because AI has priority. Your email address will not be published. Required fields are marked * Comment * Name * Email *
--------------------------------------------------

Title: Google Stock Is a High-Growth Story With Room to Run in 2025
URL: https://www.barchart.com/story/news/33126272/google-stock-is-a-high-growth-story-with-room-to-run-in-2025
Time Published: 2025-06-30T17:29:31Z
Description: This trillion-dollar company is still considered a growth story.
--------------------------------------------------

Title: Make Fun of Them
URL: https://www.wheresyoured.at/make-fun-of-them/
Time Published: 2025-06-30T15:25:03Z
Full Content:
Have you ever heard Sam Altman speak? I‚Äôm serious, have you ever heard this man say words from his mouth? Here is but one of the trenchant insights from Sam Altman in his agonizing 37-minute-long podcast conversation with his brother Jack Altman from last week: When asked why he believes AI will ‚Äúdiscover new science,‚Äù Altman says that ‚ÄúI think we‚Äôve cracked reasoning in the models,‚Äù adding that ‚Äúwe‚Äôve a long way to go,‚Äù and that he ‚Äúthink[s] we know what to do,‚Äù adding that OpenAI‚Äôs o3 model ‚Äúis already pretty smart,‚Äù and that he‚Äôs heard people say ‚Äúwow, this is like a good PHD.‚Äù That‚Äôs the entire answer! It‚Äôs complete nonsense! Sam Altman, the CEO of OpenAI, a company allegedly worth $300 billion to venture capitalists and SoftBank, kind of sounds like a huge idiot! ‚ÄúBut Ed!‚Äù you cry. ‚ÄúYou can‚Äôt just call Sam Altman an idiot! He isn‚Äôt stupid! He runs a big company, and he‚Äôs super successful!‚Äù My counter to that is, first, yes I can, I‚Äôm doing it right now. Second, if Altman didn‚Äôt want to be called stupid, he wouldn‚Äôt say stupid shit with a straight face to a massive global audience. My favourite part of the interview is near the beginning: This is a nonsensical conversation, and both of them sound very, very stupid. ‚ÄúSo, is this going to make new science or make science faster?‚Äù ‚ÄúYeah, I hear scientists are using AI to go faster [CITATION NEEDED], but if a human scientist goes three times faster [CITATION NEEDED] using my model that would be good. Also I heard from a guy that he heard a guy who did biology who said ‚Äòthis helped.‚Äô‚Äù Phenomenal! Give this guy $40 billion or more dollars every year until he creates a superintelligence, that‚Äôll fucking work. Here are some other incredible quotes from the genius mind of Sam Altman: This is gobbledygook, nonsense, bullshit peddled by a guy who has only the most tangential understanding of the technology his company is building. Every single interview with Sam Altman is like this, every single one, ever since he became a prominent tech investor and founder. Without fail. And the sad part is that Altman isn‚Äôt alone in this. Sundar Pichai, when asked one of Nilay Patel‚Äôs patented 100-word-plus-questions about Jony Ive and Sam Altman‚Äôs new (and likely heavily delayed) hardware startup: The fuck are you on about, Sundar? Your answer to a question about whether you anticipate more competition is to say ‚Äúyeah I think people are gonna make shit we haven‚Äôt come up with and uhh, hardware, can‚Äôt wait!‚Äù While I think Pichai is likely a little smarter than Altman, in the same way that Satya Nadella is a little smarter than Pichai, and in the same way that a golden retriever is smarter than a chihuahua. That said, none of these men are superintelligences, nor, when pressed, do they ever seem to have any actual answers. Let‚Äôs see what Satya Nadella of Microsoft answered when asked about how exactly it‚Äôs going to get to (and I paraphrase Dwarkesh Patel‚Äôs mealy-mouthed question) $130 billion in AI revenue ‚Äúthrough AGI‚Äù: This quote has been used as a means of suggesting that Nadella is saying that ‚Äúgenerative AI is generating basically no value,‚Äù which, while somewhat true, obfuscates its true meaning: Satya Nadella isn‚Äôt saying a fucking thing. The question was ‚Äúhow do you get Microsoft to $130 billion in revenue,‚Äù and Satya Nadella‚Äôs answer was to say ‚Äúuhhh, abundance, uhhh, explosion, uhhhhh, GDP! Growth! Industrial revolution! Inflation-adjusted! Percentages! The winners will be the people who do stuff, and then productivity will go up!‚Äù This is fucking nonsense, and it‚Äôs time to stop idolizing these speciously-informed goobers. While kinder souls or Zitron-haters may read this and say ‚Äúahh, actually, what Nadella was saying was‚Ä¶‚Äù stop. I want to stop you there and suggest that perhaps a smart person should be able to speak clearly enough that their intent is obvious. It‚Äôs tempting to believe that there is some sort of intellectual barrier between you and the powerful ‚Äî that the confusing and obtuse way that they speak is the sound of genius, rather than somebody who has learned a lot of smart-sounding words without ever learning what they mean. ‚ÄúBut Ed, they‚Äôre trained to do this!‚Äù As someone who has media trained hundreds of people, there is only so much you can do to steer someone‚Äôs language. You cannot say to Sundar Pichai ‚Äúhey man, can you sound more confusing?‚Äù You can, however, tell them what not to talk about and hope for the best. Sure, you can make them practice, sure, you can give them feedback, but people past a certain stage of power or popularity are going to talk however they want, and if they‚Äôre a big stupid idiot pretending to be smart, they‚Äôre going to sound exactly like this. Why? Because nobody in the media ever asks them to explain themselves. When you‚Äôve spent your entire career being asked friendly-or-friendly-adjacent questions and never having someone say ‚Äúwait, what does that mean?‚Äù you will continue to mutate in a pseudo-communicator that spits out information-adjacent bullshit. I am, to be clear, being very specific about that question. Powerful CEOs and founders never, ever get asked to explain what they‚Äôre saying, even when what they‚Äôre saying barely resembles an actual answer. Pichai, Altman and Nadella have always given this kind of empty-brained intellectual slop in response to questions because the media coddles them. These people are product managers and/or management consultants ‚Äî and in Altman‚Äôs case, a savvy negotiator and manipulator known for ‚Äúan absenteeism that rankled his peers and some of the startups he was supposed to nurture‚Äù as an investor at yCombinator, according to the Washington Post. By ‚Äúcoddle,‚Äù I mean these people are deliberately engaging in a combination of detective work and amnesia, where the reader or the listener is forced to simultaneously try and divine the meaning of their answer, while also not thinking too hard about the question the interviewer asked. Look at most modern business interviews. They involve a journalist asking a question, somebody giving an answer, and the journalist saying ‚Äúokay!‚Äù and moving onto the next question, occasionally saying ‚Äúbut what about this?‚Äù when the appropriate response to many of the answers is to ask them to simplify them so that their meaning is clearer. A common response to all of this is to say that ‚Äúinterviewers can‚Äôt be antagonistic,‚Äù and I don‚Äôt think a lot of people understand what that means. It isn‚Äôt ‚Äúantagonistic‚Äù to ask somebody to clearly articulate what they‚Äôre saying, nor is it ‚Äúantagonistic‚Äù to say that you don‚Äôt understand, or that they didn‚Äôt answer the question you asked. If this is ‚Äúantagonistic‚Äù to you, you are, intellectually-speaking, a giant fucking coward, because what you‚Äôre suggesting is that somebody cannot ask somebody to explain themselves, which is what an interview is. And I imagine nobody really wants to do this, because if you actually put these people on the spot, you‚Äôd realize the dark truth that I spoke of a few weeks ago: that the reason the powerful sound like idiots is because, well, they‚Äôre idiots. They sound like Business Idiots and create products to sell to Business Idiots, because Business Idiots run most companies and buy solutions based on what the last Business Idiot told them. To quote the excellent Nik Suresh: I know some of you might read this and say ‚Äúthese people can‚Äôt be stupid! These people run companies! They make huge deals! They read all these books!‚Äù and my answer is that some of the stupidest people I‚Äôve ever met have read more books than you or I will read in a lifetime. While they might be smart when it comes to corporate chess moves or saying ‚Äúthis product category should do this,‚Äù none of these men ‚Äî not Altman, Pichai or Nadella ‚Äî actually has a hand in the design or creation of any of the things their companies make, and they never, ever have. Regardless, I have a larger point: it‚Äôs time to start mocking these people and tearing down their legends as geniuses of industry. They are not better than us, nor are they responsible for anything that their companies build other than the share price (which is a meaningless figure) and the accumulation of power and resources. These men are neither smart nor intellectually superior, and it‚Äôs time to start treating them as such. These people are powerful because they have names that are protected by the press. They are powerful because it is seen as unseemly to mock them because they are rich and ‚Äúrunning a company,‚Äù a kind of corporate fealty that I find deeply unbecoming of an adult. We are, at most, customers. We do not ‚Äúowe them‚Äù anything. We are long past the point when any of the people running these companies actually invented anything they sell. iIf anything, they owe us something, because they are selling us a product, even if said product is free and monetised by advertising. While reporters ‚Äî as anyone ‚Äî should have some degree of professionalism in interviews or covering subjects, there is no reason to treat these people as special, even if they have managed to raise a lot of money or their product is popular, because if that were the case we‚Äôd have far more coverage of defense contractor Lockheed Martin. It made $1.71 billion in profit last quarter, and hasn‚Äôt had a single quarter under a billion dollars in the last year. I‚Äôm being a little glib, but the logic behind covering OpenAI is, at this point, ‚Äúit makes a lot of money and its product is popular,‚Äù which is also a fitting description of Lockheed Martin. The difference is that OpenAI has a consumer product that loses billions of dollars, and Lockheed Martin has products that makes billions of dollars by removing consumers from the Earth. Both of them are environmentally destructive. Covering OpenAI sure doesn‚Äôt seem to be about the tech, because if you looked at the tech you‚Äôd have to understand the tech, you‚Äôd see that the user numbers weren‚Äôt there outside of the 500 million people using ChatGPT, of which very few are actually paying for the product, and that the term ‚Äúuser‚Äù encompasses everything from the most occasional users who log in out of curiosity, to people who are actually using it as part of their daily lives. If covering OpenAI was about the tech, you‚Äôd read about how the tech itself doesn‚Äôt seem to have a ton of mass-market use cases, and those use cases aren‚Äôt really the kind of things that you‚Äôd pay for. If they did, there‚Äôd be articles that definitively discussed them versus articles in the New York Times about ‚Äúeverybody using AI‚Äù that boil down to ‚ÄúI use ChatGPT as search now‚Äù and ‚ÄúI heard a guy who asked it to teach him about modern art.‚Äù Yet men like Dario Amodei and Sam Altman continue to be elevated because they are ‚Äúbuilding the future,‚Äù even if they don‚Äôt seem to have built it yet, or have the ability to clearly articulate what that future actually looks like. Anthropic has now put out multiple stories suggesting that its generative AI will ‚Äúblackmail‚Äù people as a means of stopping a user from turning off the system, something which is so obviously the company prompting its models to do so. Every member of the media covering this uncritically should feel ashamed of themselves. Sadly, this is all a result of the halo effect of being a Guy Who Raised Money or Guy Who Runs Big Company. We must, as human beings, assume that these people are smart, and that they‚Äôd never mislead us, because if we accept that they aren‚Äôt smart and that they willingly mislead us, we‚Äôd have to accept that the powerful are, well, bad and possibly unremarkable. And if they‚Äôre untrustworthy people that don‚Äôt seem that smart, we have to accept that the world is deeply unfair, and caters to people like them far more than it caters to people like us. We do not owe Satya Nadella any respect because he‚Äôs the CEO of Microsoft. If anything, we should show him outright scorn for the state of Microsoft products. Microsoft Teams is an insulting mess that only sometimes works, leaving workers spending 57% of their time either in Teams Chat, Teams Meetings or sending emails according to a Microsoft study. MSN.com is an abomination read by hundreds of millions of people a month, bloated with intrusive advertisements, attempts to trick you into downloading an app, and quasi-content that may or may not be AI generated. There are few products on the modern internet that show more contempt for the user -- other than, of course, Skype, a product that Microsoft let languish for more than a decade, the product so thoroughly engorged with spam that leaving it unattended for more than a month left you with a hundred unread messages from Eastern European romance scammers. Microsoft finally killed it in May. Products like Word and Excel don‚Äôt need improving, but that doesn‚Äôt stop Microsoft from trying, bloating them with odd user interface choices and forcing users to fight with popups to use an AI-powered Copilot that most of them hate. Why, exactly, are we meant to show these people respect? Because they run a company that provides a continually-disintegrating service? Because that service has such a powerful monopoly that it‚Äôs difficult to leave it if you‚Äôre interacting with other people or businesses? I think it‚Äôs because we live in Hell. The modern tech ecosystem is so utterly vile. Every single day our tech breaks in new and inventive ways, our iPhones resetting at random, random apps not accepting button presses, our Bluetooth disconnecting, our word processors harassing us to ‚Äútry and use AI‚Äù while no longer offering us suggestions for typos, and our useful products replaced with useless shit, like how Google‚Äôs previously-functional assistants were replaced with generative AI that makes them tangibly worse so that Google can claim it has 350 million monthly active Gemini users. Yet the tech and business media acts as if everything is fine. It isn‚Äôt fine! It‚Äôs all really fucked! You can call me a cynic or a pessimist or every name under the sun, but the stakes have never been higher, and the damage never more wide-spread. Everything feels broken, and covering these companies as if it isn‚Äôt is insulting to your readers and your own intelligence. Look at the state of your computer or phone and tell me anything feels congruent or intentional rather than an endless battle of incentives. Look at the notifications on your phone and count the number of them that have absolutely nothing to do with information you actively need. As we speak, I have a notification from Adobe Lightroom, an app I use occasionally to edit photos, that tells me ‚ÄúElevate any scene - now enhance people, sky, water and more with Quick Actions.‚Äù Zerocam, an app that brands itself ‚Äúthe first anti-AI camera app‚Äù where you ‚Äúcapture moments, not megapixels,‚Äù gave me a notification asking if I took a photo today. Amazon notified me that there is a deal picked just for me ‚Äî a battery pack that I bought several months ago. Every single company that sends notifications like these should be mocked, but we have accepted such vile conditions as the norm. Apple should be tarred and feathered for allowing companies to send spam notifications, and yet it isn‚Äôt because, by and large, Apple is less vile and less exploitative than Microsoft, Google or Amazon. If you are reading this as a member of the tech press, seriously, please look at your daily experience with tech. Count the number of times that your day or a task is interrupted by poorly-designed software or hardware (such as the many, many times Zoom or Teams has a problem with Bluetooth, or a website just doesn‚Äôt load, or you type something into your browser and it just doesn‚Äôt do anything), or when the software you use either actively impedes you (hey, did you want to use AI? No? You sure?) or refuses to work in a logical way (see: Google Drive). There are tens of thousands of stories like this every day, and if you talked to people, you‚Äôd see how widespread it is‚Ä¶or maybe, I dunno, see that it‚Äôs happening to you too? There are people responsible, and the tech media writes about them every day. I realize it seems weird to constantly write that a company is releasing broken, convoluted software, but hey, if we can write 300,000 stories about how crime-ridden New York City is, why can‚Äôt we write three of them about how fucked Microsoft Office or Google Search have become? And why can‚Äôt we talk to the people in power about it? Is it because the questions are too hard to ask? Is it because it feels icky to interrupt Satya Nadella as he waffles on about using Copilot all the time by saying ‚Äúhey man, Microsoft Teams is broken, tons of people feel this way, why?‚Äù or ‚Äúwhy have you let MSN.com turn into a hub of AI slop and outright disinformation?‚Äù Oh no! You won‚Äôt get your access! Wahh! Who cares? Write a story about how Microsoft has become so unbelievably profitable as its products get worse, and talk about how weird and bad that is for the world! Ask Nadella those tough questions, or publish that Microsoft‚Äôs PR wouldn‚Äôt let you! These people are neither articulate nor wise, and whatever ‚Äúintelligence‚Äù they may claim to have doesn‚Äôt seem to manifest in good products or intelligent statements. So why treat them like they‚Äôre smart? Why show them deference or pleasantries? These people have crapped up our digital lives at scale, and they deserve contempt, or at the very least a stern fucking reception. I realize I‚Äôm repeating points I‚Äôve made again and again, but why is there such a halo around these fucking bozos? I‚Äôm serious! Why are we so protective of these guys? We‚Äôre more than happy to criticise celebrities, musicians, professional sports players, and politicians (fucking barely), but the business class is somehow protected outside of the occasional willingness to say that Elon Musk might have sort have done something wrong. I‚Äôm not denying there are critics. We have Molly White, Edward Ongweso Jr, Brian Merchant and ‚Äî at a major outlet like CNN, no less! ‚Äî one of the greatest living business writers in Allison Morrow. I believe that tech criticism is a barely-explored and hugely-profitable industry if we treated tech journalism less like the society pages and more like a force to hold the most powerful people in the world accountable as they continually harm billions of people in subtle ways. People are angry, and they aren‚Äôt stupid, and they want to see that anger reflected in the stories they read ‚Äî and the meek deference we show to dumb fucking tech leaders is the opposite of that. As I‚Äôve said before: we live in an era of digital tinnitus, nagged by notifications, warring with software ostensibly built for us that acts as if we‚Äôre the enemy. And if we‚Äôre the enemy, we should treat those building this software as the enemy in return. We are their customers, and they have failed us. The entire approach to business owners, especially in tech, is ridiculous. These people are selling us a product and the product fucking stinks! Put aside however you feel about generative AI for a second and face one very simple point: it doesn‚Äôt do enough, it‚Äôs really not cool at all, and we‚Äôre being forced to use it. I realize that some of you may want them to succeed, or want to be the person who tells everybody that they did so. I get that there are rewards for you ‚Äî promotions, new positions, TV appearances repeating exactly what the powerful did and why they did it, or a plush role as that company‚Äôs head of communications ‚Äî but I am telling you, your readers and viewers are waking up to it, and they feel like you have contempt for them and contempt for the truth. It‚Äôs easy ‚Äî and common! ‚Äî to try and dismiss my work as some sort of hater‚Äôs screed, a ‚Äúcynical‚Äù approach to a tech industry that‚Äôs trying ‚Äúbrave new things‚Äù or whatever. In my opinion, there‚Äôs nothing more cynical than watching billions of people get shipped increasingly-shitty and expensive solutions and then get defensive of the people shipping them, and hostile to the people who are complaining that the products they use suck. I am angry at these companies because they have, at scale, torn down a tech industry that allowed me to be who I am today, and their intentional and disgraceful moves fill me full of disgust. I have watched the tech media move away from covering ‚Äútechnology‚Äù and more toward covering the people behind it, to the point that the actual outputs ‚Äî the software and hardware we use every day ‚Äî have taken a backseat to stories about whether Elon Musk does or doesn‚Äôt use a computer, which is meaningless, empty gossip journalism built to be shared by peers and nothing else. And please, please do not talk about optimism. If you are blindly saying that everything OpenAI does is cool and awesome and interesting, you aren‚Äôt being optimistic ‚Äî you‚Äôre telling other people to be optimistic about a company‚Äôs success. It isn‚Äôt ‚Äúoptimistic‚Äù to believe that a company is going to build powerful AI despite it failing to do so. It‚Äôs propaganda, and yes, this is also the case if you simply don‚Äôt do the research to form a real opinion. I am not a pessimist because I criticize these companies, and framing me as one is cowardly and ignorant. If you are so weak-willed and speciously-informed that you can‚Äôt see somebody criticise a company without outright dismissing them as ‚Äúa hater‚Äù or ‚Äúpessimist,‚Äù you are an insult to journalism or analysis, and you know it in your wretched little heart. My heart sings with a firm belief in the things I think, founded on rigorous structures of knowledge that I‚Äôve gained from reading things and talking to people, because something in me is incapable of being swayed by something just because everybody else is. You are assuming people are right because it is inconvenient and uncomfortable to accept they may not be, because doing so requires you to reckon with a market-wide hysteria founded on desperation and a lack of hyper-growth markets left in the tech industry. Worse still, in engaging with faux-optimism, you are failing to protect your readers and the general public. And if that‚Äôs what you want to do, ask yourself why! Why do you want these companies to win? What is it you want them to win? Do you want them to be rich? Do you want to be the person that told people they would be first? What is the world you want, and what does it look like, and how does doing your job in this way work toward creating that world? This isn‚Äôt optimism ‚Äî it‚Äôs horse-trading, or strategic alignment behind powerful entities. It is choosing a side, because your side isn‚Äôt with the reader or the truth. If it was ‚Äî even if you believed generative AI was powerful and that they simply didn‚Äôt understand ‚Äî your duty would be to educate the reader in a clear-set and obvious way, and if you can‚Äôt find a way to do so, acknowledging that and explaining why. True optimism requires you to have a deep, meaningful understanding of things so that you can engage in real hope ‚Äî a magical feeling, one that can buoy you in the most challenging times. What many claim is ‚Äúoptimism‚Äù is actually blind faith, the likes of which you‚Äôll see at a roulette table. Or, of course, knowingly peddling propaganda. Let‚Äôs even take a different tact: say you actually want these companies to ‚Äúbuild powerful AI,‚Äù and believe they‚Äôre smart enough to do so. Say that, somehow, looking at their decaying finances, the lack of revenue, the lack of growth, and the remarkable lack of use cases, you still come out of it saying ‚Äúsure, I think they‚Äôre going to do this!‚Äù How? Why haven‚Äôt they done it yet? Why, three years in, are we still unable to describe what ChatGPT actually does, and why we need it? Take away how much money OpenAI makes for a second (and, indeed, how much it loses). Does this product actually really inspire anything in you? What is it that‚Äôs magical about this? And, on a business level, what is it I‚Äôm meant to be impressed by, exactly? OpenAI has ‚Äî allegedly ‚Äî hit ‚Äú$10 billion in annualized revenue‚Äù (essentially the biggest month it can find, multiplied by 12), which is‚Ä¶not that much, really, considering it‚Äôs the most prominent company in the software world, with the biggest brand, and with the attention of the entirety of the world‚Äôs media. It has, allegedly, 500 million weekly active users ‚Äî and, by the last count, only 15.5 million paying subscribers, an absolutely putrid conversion rate even before you realize that the actual conversion rate would be monthly active subscribers. That‚Äôs how any real software company actually defines its metrics, by the fucking way. Why is this impressive? Because it grew fast? It literally had more PR and more marketing and more attention and more opportunities to sell to more people than any company has ever had in the history of anything. Every single industry has been told to think about AI for three years, and they‚Äôve been told to do so because of a company called OpenAI. There isn‚Äôt a single god damn product since Google or Facebook that has had this level of media pressure, and both of those companies launched without the massive amount of media (and social media) that we have today. Having literally everybody talking about your product all the time for years is pretty useful! Why isn‚Äôt it making more money? Why are we taking any of these people seriously? Mark Zuckerberg paid $14.3 billion for Scale AI, an AI data company, as a means of hiring its CEO Alexandr Wang to run his ‚Äúsuperintelligence‚Äù team, has been offering random OpenAI employees $100 million to join Meta, thought about buying both AI search company Perplexity and generative video company Runway and even tried to buy OpenAI co-founder Ilya Sutskever‚Äôs pre-product ‚Äú$32bn valuation‚Äù non-company Safe Superintelligence, settling instead on hiring its CEO Daniel Gross and buying his venture fund for some fucking reason. When you put aside the big numbers, these are the actions of a desperate dimwit with a failing product trying to buy his way to making generative AI into a ‚Äúsuperintelligence,‚Äù something that Meta‚Äôs own Chief AI scientist Yan LeCun says isn‚Äôt going to work. By assuming that there is some sort of grand strategy behind these moves beyond ‚Äúif we get enough smart people together something will happen,‚Äù you help boost the powerful‚Äôs messaging and buoy their stock valuations. You are not educating anybody by humouring these goofballs. In fact, the right way to approach this would be to ask why Meta, a multi-trillion dollar market cap company with a near-monopoly over all social media, is spending billions of dollars in what appears to be a totally irresponsible way. Instead, people are suggesting this is Mark Zuckerberg‚Äôs genius at work. Anyway, putting that aside, what exactly is the impressive part of generative AI again? The fucking code? Enough about the code, I‚Äôm tired of hearing about the code, I swear to god you people think that being a software engineer is only coding and that it‚Äôs fine if you ship ‚Äúmediocre code,‚Äù as if bad code can‚Äôt bring down entire organizations. What do you think a software engineer does? Is all they do code? If you think the answer is yes, you are wrong! Human beings may make mistakes in writing code, but they at least know what a mistake looks like, which a generative AI does not, because a generative AI doesn‚Äôt know what anything is, or anything at all, because it is a probabilistic model. Congratulations! You made another way in which software engineers can automate parts of their jobs ‚Äî stop being so fucking excited about the idea that people are going to lose their livelihoods! It‚Äôs nasty, and founded on absolutely nothing other than your adulation for the powerful! These models are dangerous and chaotic, built with little intention or regard for the future, just like the rest of big tech‚Äôs products. ChatGPT would‚Äôve been a much smaller deal if Google had any interest in turning Google Search into a product that truly answered a query (as opposed to generating more of them to show more impressions to advertisers) ‚Äî a nuanced search engine that took a user‚Äôs query and spat out a series of websites that might help answer said question rather than just summarising a few of them for an answer. And if you ever need proof that Google just doesn‚Äôt know how to fucking innovate anymore, look at AI Summaries, a product that both misunderstands search and why people use ChatGPT as a search replacement. While OpenAI may ‚Äúsummarise‚Äù stuff to give an answer, it at the very least gives something approximating a true answer, rather than a summary that feels like an absentee parent trying to get rid of you and then throwing you $20 in the hopes you‚Äôll leave them alone. If Google Search truly evolved, ChatGPT wouldn‚Äôt really matter, because the idea of a machine that can theoretically answer a question is kind of why people used fucking Google in the fucking first place. Again, why are we not describing this company as the business equivalent of a banana republic? It‚Äôs actively making its shit worse to juice growth, and it‚Äôs really obvious how badly it sucks. Why doesn‚Äôt the state of Google dominate tech news, just like how random ketamine-fuelled tweets from Elon Musk do? Why aren‚Äôt we, collectively, repulsed by Google as a company? Why aren‚Äôt we, collectively, repulsed by OpenAI? No matter how big ChatGPT is, the fact that there‚Äôs a product out there with hundreds of millions of users that constantly gets answers wrong is a genuinely worrying thing for society, and that‚Äôs before you get to the environmental damage, the fact it trained its models on millions of people‚Äôs art and writing, and oh, I dunno, the fact it plans to lose over a hundred billions of dollars before becoming profitable? Why are we not more horrified? Why are we not more forlorn that this is where hundreds of billions of dollars are being forced? The most prominent company in the tech industry is an unstable monolith with a vague product that can only make $10 billion a year (revenue, not profit) as the very fabric of its existence is shoved down the throat of every executive in the world at once. Also, if it‚Äôs not fed $20 billion to $40 billion a year, it will die. Give me a fucking break. I don‚Äôt know, I sound pretty ornery, I get accused of being a hater or missing the grand mystery of this bullshit every few minutes by somebody with an AI avatar of a guy who looks like he‚Äôs banned from multiple branches of Best Buy, I understand there‚Äôs things that people do with Large Language Models, I am aware, but none of it matters because the way they‚Äôre being discussed is like we‚Äôre two steps from digitally replacing hundreds of millions of people. The reality is far simpler: we have an industry that has spent nearly half a trillion dollars between its capital expenditures and venture capital funding to create another industry with the combined revenue of the fucking smartwatch industry. What I‚Äôm writing isn‚Äôt inflammatory ‚Äî in fact, it‚Äôs far more deeply rooted in reality than those claiming that OpenAI is building the future. Let‚Äôs do some fucking mathematics! Projected Big Tech Capital Expenditures in 2025 and revenue from AI: That‚Äôs $327 billion this year, with a total revenue of‚Ä¶what, $18 billion of revenue? And that‚Äôs not profit! And that‚Äôs if we include OpenAI‚Äôs spend on Azure. Even if every single one of these companies was making $18 billion in revenue a year from this it wouldn‚Äôt be great, but it‚Äôs more than likely that these chunderfucks can‚Äôt even pull together the projected revenue ($32 billion) of the global smartwatch industry! What a joke! ‚ÄúWuhh, but what about OpenAI?‚Äù What about OpenAI? I‚Äôve written about this so much. So what, OpenAI makes $12.7 billion this year, but loses $14 billion, what does that mean to you, exactly? What‚Äôre you going to say? The cost of inference is coming down? No, the cost that people are being charged is going down, we have no firm data on the actual costs because the companies don‚Äôt want to talk about it, and yes, it will absolutely lower prices to compete with other companies. The Information just reported that OpenAI was doing this to compete with Microsoft last week! Hey, quick question ‚Äî wasn‚Äôt SoftBank meant to spend $3 billion annually on OpenAI‚Äôs software? Did that happen? Anyway, even if we add OpenAI‚Äôs revenue to the pot, we are at $30.7 billion. If we add the supposed $1 billion in revenue from training data startup Surge, $300 million in ‚Äúannualized revenue‚Äù from Turing, optimistically assume that Perplexity will have $100 million (up from $34 million in 2024, where it burned $65 million) in revenue in 2025, and assume that Anysphere‚Äôs (which makes Cursor) $200 million run rate stays consistent through 2025, we are at‚Ä¶$32.3 billion. But I'm not being fair, am I? I didn‚Äôt include many of the names from The Information‚Äôs generative AI database. Prepare yourself, this is gonna be annoying! So let's add some more. We‚Äôve got $3 billion from Anthropic, $870 million from Scale (now part of Meta), another alleged $300 million for Anysphere (The Information claims $500 million in ARR), we consider Neo4j‚Äôs ‚Äú>$200 million ARR‚Äù to mean ‚Äú$200 million,‚Äù Midjourney‚Äôs ‚Äú>$200 million ARR‚Äù to mean $200m, Ironclad‚Äôs ‚Äú>$150 million ARR‚Äù to mean $150 million ARR, Glean‚Äôs $103 million ARR, Together AI‚Äôs $100 million ARR, Moveworks‚Äô $100 million ARR, Abridge‚Äôs $100 million ARR, Synthesia‚Äôs $100 million ARR, WEKA‚Äôs ‚Äú>$100 million ARR‚Äù to mean $100m ARR, Windsurf‚Äôs $100m ARR, Runway‚Äôs $84 million ARR, Elevenlabs‚Äô ‚Äú>$100m ARR‚Äù to mean $100m ARR, Cohere‚Äôs $70m ARR, Jasper‚Äôs ‚Äú>$60m ARR‚Äù to mean $60m, Harvey‚Äôs $50m ARR, Ada‚Äôs ‚Äú>$50m ARR‚Äù to mean $50m, Photoroom‚Äôs $50m ARR‚Ä¶and then assumed the combined ARR of the remainders are somewhere in the region of a very generous $200m, we get‚Ä¶ Less than $39 billion dollars of total revenue in the entire generative AI industry. Jesus fucking christ! According to The Information, generative AI companies have raised more than $18.8 billion in the first quarter of 2025, after investing $21 billion in Q4 2024 and $4 billion in Q3 2024 for a grand total of $43.8 billion, or a total of $370.8 billion of investment and capital expenditures for an industry that, despite being the single-most talked about thing on the planet, cannot even create a tenth of the dollars it requires to make it work. These companies are predominantly unprofitable, perpetually searching for product-market fit, and even when they find it, seem incapable of generating revenue numbers that remotely justify their valuations. If I‚Äôm honest, I think the truly radical position here is the one taken by most tech reporters that would rather take the lazy position of ‚Äúwell Uber lost a lot of money!‚Äù than think for two seconds about whether we‚Äôre all being sold a line of shit. What we‚Äôre watching is a mountain of waste perpetuated by the least-charming failsons of our generation. Nobody should be giving Satya Nadella or Sam Altman a glossy profile ‚Äî they should be asking direct, brutal questions, much like Joanna Stern just did of Apple‚Äôs Craig Federighi, who had absolutely fucking nothing to share because he has never been pushed like this. Put aside the money for a second and be honest: these men are pathetic, unimpressive, uninventive, and dreadfully, dreadfully boring. Anthropic‚Äôs Wario (Sorry, Dario) Amodei and OpenAI‚Äôs Sam Altman have far more in common with televangelist Joel Olstein than they‚Äôll ever have with Steve Jobs or any number of people that have actually invented things, and they got that way because we took them seriously instead of saying ‚Äúwait, what do you mean?‚Äù To a single one of their wrongheaded, oafish and dim-witted hype-burps. It‚Äôs boring! I‚Äôm terribly, horribly bored, and if you‚Äôre interested in this shit I am genuinely curious why, especially if you‚Äôre a reporter, because right now the ‚Äúinnovation‚Äù happening in AI is, at best, further mutations of the Software As A Service business model, providing far less value than previous innovations at a calamitous cost. Reasoning models don‚Äôt even reason, as proven by an Apple paper released a few weeks ago, and agents as a concept are fucked because large language models are inherently unreliable ‚Äî and yes, a study out of fucking Salesforce found that agents began to break down when given multi-step tasks, such as ‚Äúany task you‚Äôd want to have an agent automate.‚Äù So, here‚Äôs my radical suggestion: start making fun of these people. They are not charming. They are not building anything. They have scooted along amassing billions of dollars promising the world and delivering you a hill of dirt. They deserve our derision ‚Äî or, at the very least, our deep, unerring suspicion, if not for what they‚Äôve done, but for what they‚Äôve not done. Sam Altman is nowhere near delivering a functioning agent, let alone anything approaching intelligence, and really only has one skill: making other companies risk a bunch of money on his stupid ideas. No, really! He convinced Oracle to buy $40 billion of NVIDIA chips to put in the Abilene Texas ‚ÄúStargate‚Äù data center, despite the fact that the Stargate organization has yet to be formed (as reported by The Information). SoftBank and Microsoft pay all of OpenAI‚Äôs bills, and the media does his marketing for him. OpenAI is, as I said, quite literally a banana republic. It requires the media and the markets to make up why it has to exist, it requires other companies to pump it full of money and build its infrastructure, and it doesn‚Äôt even make products that matter, with Sam Altman constantly talking about all the exciting shit other people will build. You can keep honking about how ‚Äúit built the API that will power the future,‚Äù but if that‚Äôs the case, where‚Äôs the fucking future, exactly? Where is it? What am I looking at here? Where‚Äôs the economic activity? Where‚Äôs the productivity? The returns suck! The costs are too high! Why am I the radical person for saying this? This entire situation is absolutely god damn ridiculous, an incomparable waste even if it somehow went in the green. For the horrendous amounts of capital invested in generative AI to make sense, the industry would have to have revenue that dwarfed the smartphone and enterprise SaaS market combined, rather than less than half of that of the mobile gaming industry. Satya Nadella, Sam Altman, Wario Amodei, Tim Cook, Andy Jassy ‚Äî they deserve to be laughed at, mocked, or at the very least interrogated vigorously, because their combined might has produced no exciting or interesting products outside of, at best, what will amount to a productivity upgrade for integrated development environments and faster ways to throw out code that may or may not be reliable. These things aren‚Äôt nothing, but they‚Äôre nowhere near the something that we‚Äôre being promised. So I put it to you, dear reader: why are we taking them seriously? What is there to take seriously other than their ability to force stuff on people? And I‚Äôll leave you with a question: how do they manage to keep doing this, exactly? They always seem to find new growth, every single quarter, without fail? Is it because they keep coming up with new ideas? Or is it because they come up with new ideas to get more money, a vastly different choice that involves increasing the prices of products or making them worse so that they can show you more advertisements. My positions are not radical, and if you believe they are, your deference to the powerful disgusts me. In any case, I want to end this with something inspirational, because I believe that things change when regular people feel stronger and more capable. I want you to know that you are fully capable of understanding all of this. I don‚Äôt care if you ‚Äúaren‚Äôt a numbers person‚Äù or ‚Äúdon‚Äôt get business.‚Äô I don‚Äôt have a single iota of economics training, and everything you‚Äôve ever read me write has been something I‚Äôve had to learn. I was a layperson right up until I learned the stuff, then I became a stuff-knower, just like you can be. The tech industry, the finance industry, the entire mechanisms of capitalism want you to believe that everything they do is magical and complex, when it‚Äôs all far more obvious than you‚Äôd believe. You don‚Äôt have to understand the entire fundamentals of finance to know how venture capital works ‚Äî they buy percentages of companies at a valuation that they hope is much lower than the company would be worth in the future. You don‚Äôt need to be technical to know that Large Language Models generate a response based on billions of pieces of training data, and by guessing at what the next bit of text in a line should be based on what it‚Äôs seen previously. These people love to say ‚Äúah, but didn‚Äôt you see-‚Äù and present an anecdote, when no anecdote will ever defeat the basics of ‚Äúyour business doesn‚Äôt make any money, the software doesn‚Äôt do the things you claim it‚Äôs meant to, and you have no path to profitability.‚Äù They can yammer at you all they want about ‚Äúlots of people using ChatGPT,‚Äù but that doesn‚Äôt change the fact that ChatGPT just isn‚Äôt that revolutionary, and their only play here is to make you feel stupid rather than actually showing you why it‚Äôs so fucking revolutionary. This is the argument of a manipulator and a coward, and you are above such things. You don‚Äôt really have to be a specialist in anything to pry this shit apart, which is why so much of my work is either engaging to those who learn something from it or frustrating to those that intentionally deceive others through gobbledygook hype-schpiel. I will sit here and explain every fucking part of this horrid chain of freaks, and break it down into whatever pieces it takes to educate as many people as I have to to make things change. I also must be clear that I am nobody. I started writing this newsletter with 300 subscribers and no reason other than the fact I wanted to, and four years later I have nearly 64,000 subscribers and an award-winning podcast. I have no economics training, no special access, no deep sources, just the ability to look at things that are happening and say stuff. I taught myself everything I know about this industry, and there is nothing stopping you from doing the same. I was convinced I was stupid until around two years ago, though if I‚Äôm honest it might have been last year. I have felt othered the majority of my life, convinced by people that I am incapable or unwelcome, and as I‚Äôve become more articulate and confident in who I am and what I believe in, I have noticed that the only people that seek to degrade or suppress are those of weak minds and weaker wills ‚Äî Business Idiots in different forms and flavors. I have learned to accept who I am ‚Äî that I am not like most people ‚Äî and people conflate my passion and vigor with anger or hate, when what they‚Äôre experiencing is somebody different who deeply resents what the powerful have done to the computer. And while I complain about the state of media, what I‚Äôve seen in the last year is that there are many, many people like me ‚Äî both readers and peers ‚Äî that resent things in the same way. I conflated being different with being alone, and I couldn‚Äôt be more wrong. For those of you that don‚Äôt wish to lick the boots of the people fucking up every tech product, the tent is large, it‚Äôs a big club, and you‚Äôre absolutely in it. A better tech industry is one where the people writing about it hold it accountable, pushing it toward creating the experiences and connectivity that truly change the world rather than repeating and reinforcing the status quo. Don‚Äôt watch the mouth, watch the hands. These companies will tell you that they‚Äôre amazing as many times as they want, but you don‚Äôt need to prove that ‚Äî they do. I don‚Äôt care if you tell a single human soul about my work, but if it helps you understand these people better, use it to teach other people. These people may seem all-powerful, but they‚Äôve built the Rot Economy on a combination of anonymity and a placant press, but pressure against them starts with you and those you know understanding how their businesses work, and trusting that you can understand because you absolutely can. Millions of people understanding how these people run their companies and how poorly they‚Äôve built their software will stop people like Sundar Pichai from being able to quietly burn Google Search to the ground. People like Sam Altman are gambling that you are easily-confused, easily-defeated and incurious, when you could be writing thousands of words on a newsletter that you never, ever edit for brevity. You can understand every fucking part of their business ‚Äî the economics of OpenAI, the flimsy promises of Salesforce, the destruction of Google Search ‚Äî and you can tell everybody you know about it, and suddenly it won‚Äôt be so easy for these wretched creeps to continue thriving. I know it sounds small, and like your role is even smaller, but the reason they‚Äôve grown so rapaciously is driven by the sense that the work they do is some sort of black magic, when it‚Äôs really fucking stupid and boring finance stapled onto a tech industry that‚Äôs run out of ideas. You are more than capable of understanding this entire world ‚Äî including the technology, along with the finances that ultimately decide what technology gets made next. These people have got rich and famous and escaped all blame by casting themselves as somehow above us, when if I‚Äôm honest, I‚Äôve never looked down on somebody quite as much as I do the current gaggle of management consultant fucks that have driven Silicon Valley into the ground. Subscribe today. It's free. Please. Great! You‚Äôve successfully signed up. Welcome back! You've successfully signed in. You've successfully subscribed to Ed Zitron's Where's Your Ed At. Your link has expired. Success! Check your email for magic link to sign-in. Success! Your billing info has been updated. Your billing was not updated.
--------------------------------------------------

Title: FOMO-Driven Call Buying Soars as Traders Chase S&P 500‚Äôs Furious Run
URL: https://financialpost.com/pmn/business-pmn/fomo-driven-call-buying-soars-as-traders-chase-sp-500s-furious-run
Time Published: 2025-06-30T09:54:46Z
Description: Traders keen to seize on further gains after the S&P 500 Index hit its first record since February are betting on stock-market darlings that they expect will surpass the index‚Äôs ascent.
--------------------------------------------------

Title: FOMO-Driven Call Buying Soars as Traders Chase S&P 500‚Äôs Furious Run
URL: https://finance.yahoo.com/news/fomo-driven-call-buying-soars-093000519.html
Time Published: 2025-06-30T09:30:00Z
Description: (Bloomberg) -- Traders keen to seize on further gains after the S&P 500 Index hit its first record since February are betting on stock-market darlings that...
--------------------------------------------------

Title: Analysts rework Uber stock price target on autonomous vehicle expansion
URL: https://www.thestreet.com/automotive/analysts-rework-uber-stock-price-target-on-autonomous-vehicle-expansion
Time Published: 2025-06-29T21:32:00Z
Description: This is what could happen next to Uber stock.
--------------------------------------------------