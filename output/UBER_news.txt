List of news related to Uber stock price UBER:

Title: Worker-bee AGI: Why AWS is betting on practical agents, not ‘messiah AGI’
URL: https://siliconangle.com/2025/12/08/worker-bee-agi-aws-betting-practical-agents-not-messiah-agi/
Time Published: 2025-12-08T17:04:58Z
Full Content:
UPDATED 12:04 EST / DECEMBER 08 2025 BREAKING ANALYSIS by Dave Vellante and George Gilbert At AWS re:Invent 2025, Amazon Web Services Inc. faced a dual mandate: Speak to millions of longstanding cloud customers while countering a persistent narrative that the company is lagging in artificial intelligence. In our view, AWS chose a distinctly pragmatic path. Rather than chasing the holy grail of what we call “messiah AGI,” or artificial general intelligence or even competing head-on with frontier-scale large language model, the company emphasized foundational agentic scaffolding and customizable large and small language models. This approach aligns with our thesis that the real near-term value in AI lies inside the enterprise – what we see as “worker-bee AGI” – not in aspirational, generalized intelligence. Skeptics argue that this worker-bee AGI is little more than RPA 2.0, burdened by familiar data silos. Though that critique rings somewhat true, we not view AWS’ strategy as merely paving the robotic process automation cow path. Rather, we see the company making a deliberate shift from siloed agentic automation toward what we call “service-as-software” – a new model in which business outcomes, not individual applications, become the primary point of control. In this special edition of Breaking Analysis, we break down AWS re:Invent 2025 through the lens of this emerging paradigm. We’ll examine how AWS is repositioning its infrastructure, services and AI roadmap to support a transformation in the operational, business and technology models of virtually every organization and industry. At re:Invent 2025, one theme kept surfacing in our conversations in that we’re watching two fundamentally different AI models collide. On one side, we see what we call the messiah AGI quest – led by Open AI Labs PBC Chief Executive Sam Altman and the frontier labs – pushing ever deeper into the earth in search of more intelligence. On the other side sits the enterprise, represented metaphorically by JPMorgan Chase CEO Jamie Dimon and powered by renewable, sustainable data assets that grow stronger with every additional agent deployed. OpenAI and ChatGPT defined the opening chapter of generative AI by tapping a reservoir of free, high-quality internet data. Through GPT-4 and likely GPT-5, the marginal cost of data was essentially zero. Compute was expensive, but the fuel for the models was essentially free. That era is ending, in our view. As freely available high-quality data is depleted, the labs are turning to human expertise – curated reasoning traces from domain specialists – to maintain their performance advantage. We see this as a dramatically different business model. Credible reporting suggests that by 2029 to 2030, OpenAI could be spending 20% to 25% of its revenue just to acquire proprietary expert data. In our view, this is a classic diminishing-returns scenario where you achieve rising marginal costs for increasingly niche improvements. It’s the image of Altman digging deeper into the ground for shrinking seams of coal. Enterprises, by contrast, operate on renewable energy, as shown on the right hand side of the title slide. Their proprietary data grows as they deploy more agents, build more models and instrument more workflows. Every incremental deployment generates more signals, more context, more labeled outcomes. They’re on an experience curve – one that accelerates as data harmonization improves. JPMorgan Chase is the most obvious example, but it represents a much broader pattern. The more enterprises connect their systems of record with their emerging agent ecosystems, the faster their marginal costs fall. This is why we believe the real economic opportunity lies with worker-bee AGI inside the enterprise, not messiah AGI in the labs. The image of windmills and solar farms on our cover slide symbolizes the renewable nature of enterprise data. In the age of AI, algorithms are increasingly commoditized and developed by specialized labs. But shaping data – aligning it with workflows, policies, context and outcomes – is where competitive advantage resides. This brings us to a critical question: Could OpenAI simply partner with leading enterprises to overcome its data disadvantage? In theory, yes. In practice, we see three barriers: In other words, owning a frontier model isn’t enough. To win in the enterprise, the model must be embedded in the workflow to include policy, security, data lineage, context, orchestration, and deterministic logic. This is software, not science, and thus far frontier labs are not enterprise software companies. (Note: Our colleague David Floyer disputes this premise. He believes research labs such as OpenAI and Anthropic will build great enterprise software on top of their LLMs and simplify the adoption of enterprise AI. We’ll be digging into and debating this topic with him in future Breaking Analysis episodes.) As a result, the disruption won’t manifest in the technology model alone, rather we’ll see it in the operational and business models of emerging AI software companies – including pricing. The seat-based pricing model that has defined enterprise software for decades will not survive the agentic era, in our view. Infrastructure consumption models will evolve as well. We believe the winners will shift toward value-based/outcome-based pricing aligned with real business results. This is the heart of service-as-software. And AWS – whether intentionally or instinctively – is leaning directly into this shift. It is missing some pieces, however, which we’ll discuss in detail. Let’s park the technology model for a moment and examine the coming changes in the operational and business models of enterprises as a result of AI. As we’ve argued in earlier Breaking Analysis episodes, the shift to AI-driven operations requires a wholesale transformation of how organizations function – not just in their technology stacks, but in their operational and business models. When the industry migrated from on-premises software to software as a service, the burden fell largely on information technology departments and software vendors. Mainstream organizations didn’t have to rethink how their companies worked. This time is different in that the entire organization will change. Practitioners often say the hard part of transformation is people and process, not technology. In the agentic era, all three are hard. The operational model, the business model and the technology model must move in concert, and none of them can remain anchored in legacy assumptions. For six decades – despite new devices, new user interfaces and new software delivery models – the industry continued to build in silos. These were essentially craft cells for knowledge work, each optimized locally because that was the only way we knew how to automate. The shift ahead replaces these craft silos with an end-to-end assembly line for knowledge work. That represents a profound process change. The organizational structures built to make machine-like efficiency possible no longer align with end-to-end outcomes. On the business model side, the shift is equally profound. Traditional software economics were built around nonrecurring engineering or NRE costs. Pricing was often seat-based with added maintenance fees, and steadily improving (and predictable) marginal costs as volume grew. Even in the cloud era, despite variable infrastructure costs, vendors benefited from the same model – upfront NRE, light ongoing maintenance and falling marginal costs as scale increased. AI breaks that pattern. In the new model, organizations deliver outcomes, and pricing will be based on value, usage or direct outcome proxies. More important, the foundation of economic advantage shifts from physical capital and depreciating software assets to digital expertise that compounds. Intelligence becomes capital. The more data that flows through the system, the richer the experience base becomes. Cost advantages and differentiation strengthen simultaneously, creating winner-take-most dynamics. This is where tokens enter the equation. Software companies not only face cloud cost-of-goods-sold, they now incur token costs. Though consumers may benefit from improvements in graphics processing unit price-performance, the marginal economics that once accrued to software vendors increasingly accrue to the organizations that climb the AI learning curve fastest. Getting volume and getting there fast becomes critical; once a company builds compounding advantage through expertise, it becomes extremely difficult for others to catch up. This gets back to the difference between models and agents. The model guys are in this “token grind” where through distillation and advances in the frontier of intelligence, their costs are coming down something like 10 to 30 times per year, some obscene number when it’s just the raw model and the application programming interface. But when it’s an agent and there’s a learning loop in there, their prices are much more stable. And so that gets back to what we’re going to talk about, and where AWS is focused, which is the surrounding scaffolding needed to build, manage and govern agents. The bottom line is the economics of software are being rewritten. Depreciating assets are giving way to compounding expertise, and organizations that build these systems early will gain durable structural advantage. In our view, this shift underpins the emerging service-as-software model – and explains why enterprise AI will look nothing like the transitions of the past. The technology shift unfolding now is far more complex than the move to cloud. The cloud era changed the operational model for running the same application silos – breaking monoliths into microservices but leaving the underlying fragmentation intact. Data remained siloed, and even the application logic itself stayed isolated within domain-specific systems. What is happening now is much different. For decades, enterprises converted data into a corporate asset through the rise of relational databases. That was a significant milestone, but it didn’t unify how businesses reason. In the agentic era, humans and agents need a shared understanding of the rules, processes and semantics that govern the enterprise. That requires constructing a true system of intelligence or SoI – a shared asset that expresses how the business runs. This is something the industry has never done before, and it upends 60 years of accumulated investment in application-centric architectures. Developing a migration path for this transformation is extraordinarily challenging, because every existing enterprise today is built on top of layers of deterministic logic that reflect the constraints of siloed automation. The “Tower of Babel” metaphor on the slide above captures the legacy landscape. Each application has its own language, its own worldview, its own schema. They don’t talk to each other. Even when organizations attempt to consolidate through a lakehouse, the silos reappear inside the lakehouse itself – sales, service, logistics and every other domain carries its own schema, definitions and constraints. Asking cross-functional questions – for example, what happened, why it happened, what should happen next – requires stitching these worlds together with extensive data engineering. This is brittle work, and it reinforces the fragmentation that enterprises are now trying to escape. The move from application-centric silos to a unified, data-centric platform is not simply a technology upgrade. It is a rearchitecture of how intelligence is represented inside the enterprise. And it is this shift that will determine whether organizations can deploy agents that truly understand and drive end-to-end business outcomes. The slide above depicts a dead whale being kicked down the beach – an intentionally stark metaphor for the scale of the challenge ahead. The reference traces back to Microsoft Corp. co-founder Bill Gates, who once mocked attempts by Lotus and WordPerfect to bolt graphical interfaces onto DOS-era software. He likened that effort to “kicking dead whales down the beach” – an impossible, grinding task weighed down by accumulated legacy code and technical debt. The situation today is exponentially harder. Instead of a single dead whale, the industry faces a thousand. Sixty years of investment in application-centric silos must now be harmonized into a coherent systems of intelligence. Every layer of legacy logic, schema, workflow and domain-specific constraint has to be reconciled. And at this moment, no one vendor has a complete solution for how to do it. The metaphor captures the reality in that preserving compatibility with decades of siloed systems while attempting to build unified, agent-ready architectures is not only difficult – it borders on impossible without rethinking the foundational architecture of the business. The agentic era demands a level of semantic, procedural and data harmonization that legacy architectures were never designed to support. In this next section, we’ll turn to what the broader transformation means for AWS. A series of announcements at re:Invent – general availability milestones, continued investment in Kiro, enhancements across the software development lifecycle, and significant expansions to Nova and Nova Forge – underscore how AWS is positioning itself for the service-as-software era. But before we do that, let’s revisit how we see the emerging technology stack evolving. The slide above depicts the transition from application-centric silos to a data-centric platform. At the base sits the data platform – the logical data estate aggregating information from operational systems, websites and external sources. Vendors such as Snowflake Inc., Databricks, and AWS with its Redshift have done remarkable work consolidating these assets. But consolidation is not the same as harmonization. The data platform remains neither machine-readable nor agent-readable. Even humans often require a business intelligence layer to interpret it. Functionally, these systems provide high-fidelity snapshots of what happened – two-dimensional views constrained by the schemas of each domain. At best, with feature engineering and narrow machine learning, they can forecast what’s likely to happen within a limited scope. What enterprises need next is a true system of intelligence, represented in green on the slide. We’ve discussed previously the need for a four-dimensional, end-to-end map of the business. This is the layer that gives both humans and agents a shared understanding of processes, rules and dependencies. Some organizations attempt to build this today with platforms such as Palantir, but doing so often requires forward-deployed engineers or FDEs crafting bespoke solutions at great expense (~$1 million annually for each FDE). Each customer effectively rebuilds the system from scratch. Above that sits the system of agency, shown in yellow. This is the agent control framework – important for orchestration, policy and workflow activation, but not itself the source of intelligence. It draws meaning from the system of intelligence beneath it. For agents to make decisions with the same contextual awareness humans use today – understanding, for example, how delaying an order for lack of a part could jeopardize a major contract – they must be anchored in a harmonized representation of the enterprise. Without that harmonization, neither humans nor agents can reliably see across domains or reason about second- and third-order effects. Humans can run isolated what-if analyses, but scaling those insights across the full enterprise is impractical when the underlying maps must be stitched together manually. The key point is that the emerging software stack requires customers to transform their technology model. The data platform alone is not enough. Systems of intelligence and systems of agency must work in tandem to provide the end-to-end visibility, shared meaning and decision-making context that define the agentic era. The next question we want to address is how AWS maps onto this architecture – and where its recent announcements signal its intent to lead. With the benefit of four days of re:Invent behind us, a clearer picture emerged of where AWS is investing and how it aligns to the evolving software stack shown above. When mapped against the model of data platforms, systems of intelligence, and systems of agency, the green layer – the system of intelligence – is still largely incomplete. It doesn’t come out of the box. Enterprises such as JPMorgan Chase, Dell Technologies Inc. and Amazon.com Inc. itself have had to build it themselves, whereas most mainstream enterprises don’t have the capability to do so. Where AWS is strong today is in the layers surrounding that gap. Bedrock has matured considerably. A year ago, reliability issues – struggles even with two and three nines – triggered urgent internal focus. That work appears to have paid off. Bedrock now serves as the abstraction layer above LLMs that AWS has long needed. AgentCore, introduced as a control framework for building multi-agent systems, shows real promise as well. Even more compelling are AWS’ first-party agents. The Kiro autonomous coding agents, along with new DevOps and security agents, formed some of the most interesting narratives of the week. They still have to earn customer trust, but the conceptual story around them is strong. These agentic capabilities, however, highlight the critical dependency on the missing middle layer. Agents are only as effective as the context they draw from. AI is programmed by data, and without a well-structured system of intelligence to feed them, their potential is limited. At the bottom of the stack, the data platform continues to evolve. SageMaker’s lakehouse features – especially S3’s expansion into table formats such as Iceberg – signal S3’s shift from a simple get/put object store into something more structurally aware. Neptune, AWS’ graph database, receives far less public attention, including its knowledge graph capabilities, yet it represents an important ingredient for shaping contextual data. in our view. This is where the divergence between AWS and Microsoft is instructive. Microsoft prefers to articulate where customers should be three to five years out and seed early product iterations – Fabric IQ being a recent example, potentially even designed to counter Palantir Technologies Inc.’s momentum. AWS, by contrast, tends to stay one step ahead of customers’ stated needs, solving problems incrementally rather than prescribing long-horizon architectures. Even so, Neptune already plays a role in bottom-up AI workload development, helping customers structure data for agentic applications. And one can imagine a future where Neptune joins S3 buckets and S3 tables as a more central mechanism for harmonizing data, though that would represent a strategic evolution for AWS. The broader takeaway is that AWS is prioritizing agent-specific tooling. As Swami Sivasubramanian, Amazon’s vice president of agentic AI, put it in his keynote, the company wants to be “the best place to build agents.” On that dimension, progress is evident and deserving of high marks. But the system of intelligence – the contextual substrate agents depend on – is still an open frontier across the industry. Vendors such as Palantir and Celonis SE operate directly to address this space, but no one vendor has yet solved the problem at scale. AWS may lean on Neptune, expand the capabilities of S3, or take a different path altogether. What’s certain in our view is that the green layer – the harmonized representation of data and process knowledge – is the piece that will ultimately determine how far agentic architectures can go. The DevOps agent emerged last week as one of the most consequential pieces of AWS’ agentic strategy. When mapped onto the emerging software stack – systems of intelligence in green and systems of agency in yellow – the DevOps agent sits in the layer that orchestrates digital operations. Understanding why this matters requires looking at the complexity of modern enterprise estates. A DevOps agent must reason across sprawling, heterogeneous environments composed of infrastructure, middleware, application components and thousands of microservices. Unlike a monolithic system such as SAP, where a single vendor created an end-to-end framework with well-understood internals, AWS environments are far more open-ended. The DevOps agent is designed to look across all of digital operations, identify when something breaks, determine the root cause and, when confidence is high enough, execute a remediation plan – potentially without human intervention. This introduces an important concept in that DevOps agents function as training wheels for the broader system of intelligence. They represent a prototype of what an enterprise-wide reasoning layer could become. Digital operations are only one slice of the problem. The full system of intelligence must encompass all business operations, and that requires a 4D map of the enterprise that shows how systems connect, their dependencies and how actions in one domain influence outcomes in another. AWS described this mapping capability as topology – an attempt to learn a representation of how Amazon services and infrastructure components interrelate. Conversations with vendors such as Datadog Inc., Dynatrace Inc., Splunk Inc. and Elasticsearch B.V. revealed that each has deep visibility into its own domain and partial insight into adjacent ones. Dynatrace, for example, places a probe on every host, enabling it to construct a causal graph – a kind of twin of digital operations. The DevOps agent uses these external views when needed. When it identifies a problem but lacks sufficient visibility to diagnose it, it can call out to partners such as Dynatrace and say, in effect: Run the deeper query for me. This bottom-up collaboration hints at how a general system of intelligence may ultimately emerge – not as a single monolithic product but as an aggregation of increasingly broad platforms across an ecosystem. This raises a broader architectural question related to top-down versus bottom-up approaches. A pure bottom-up approach risks “boiling the ocean” – digging two tunnels from multiple directions without a guarantee that the tunnels meet in the middle. A purely top-down approach lacks grounding in operational reality. The workable model appears to be a hybrid where the the outcome is defined top-down, then stitched together with the necessary data bottom-up to support that outcome. In practice, this might look like deploying the DevOps agent for a specific service area and augmenting it with Dynatrace data to achieve end-to-end visibility. Once that outcome works, extend it incrementally to additional services. This creates the scaffolding for a system of intelligence one outcome at a time – a middle-out expansion if you will, anchored by practical workflows. The DevOps agent therefore serves two purposes: 1) It solves a tangible operational problem today; and 2) It lights the path toward an enterprise-wide intelligence layer that will ultimately govern agentic systems. Kiro, first announced at the AWS Summit in New York, took on new significance last week. Anyone who still believes AWS is behind in AI need only look at the cadence and depth of innovations emerging around Kiro and its autonomous coding capabilities. Despite that, the keynote significantly understated its importance, in our view. Developers we spoke with emphasized that Kiro is quickly becoming central to their workflows. And the reason is that Kiro goes beyond the vibe-coding paradigm that has dominated the last year. Developers, by the way, still love Cursor, which continues to sets the standard. For months, the conversation in AI-assisted development has centered on scaffolding – the supporting structures that transform rapidly evolving models into agentic applications. Tools such as GitHub Copilot pioneered “code complete” – hit tab, finish your line. Cursor advanced the state of the art by customizing the integrated development environment so developers could chat with the agent, enabling longer-horizon tasks. Google’s Antigravity, which came from the Windsurf acquisition, followed the same path. These tools are powerful, but they remain forms of vibe coding. The artifact is still the code. You live in the code. You fix the code. The scaffolding evolves as models advance. Kiro breaks from this model and enters new ground. Instead of writing code and letting the agent assist, Kiro starts upstream – with the requirements document. The agent works at the ideation level, partnering with the developer to flesh out specifications, tighten ambiguities, highlight missing details and introduce best practices. The requirements document then feeds into a design document, creating a clear specification. Only then does Kiro generate code. And crucially, the code is disposable. When the software needs to evolve, you don’t traverse through the codebase trying to predict what will break. You update the requirements, adjust the design and regenerate the code from the spec. This reverses decades of software engineering logic. The artifact is no longer the code – it is the specification. Though Cursor can function similarly, it is still code-first out of the box. Even more striking is the potential impact on legacy systems. AWS’ Transform product can reverse-engineer a design document from an existing codebase. AWS believes it can go further and generate the requirements specification itself. That opens the door to something the vibe-coding world has not addressed – brownfield modernization. Instead of writing elaborate migration plans or manually dissecting aging monoliths, enterprises may be able to produce specifications from legacy code and move forward iteratively, regenerating components as needed. This is why Kiro is so significant, in our opinion. It elevates the abstraction from writing code to defining intent. This aligns with the broader shift toward agents, systems of intelligence, and outcome-oriented architectures. When AWS first introduced Kiro, it gave a nod to vibe coding because it was the trend of the moment. But even then, they hinted that Kiro represented something more. The story last week at re:Invent emphasized this is not another flavor of assisted coding. It is a new model for how software gets built, maintained and evolves. AgentCore emerged as one of the most pivotal announcements of the week because it represents the scaffolding required to make agents production-grade. Bedrock has steadily matured into the foundational abstraction layer for model access, but AgentCore sits alongside it as the operational backbone for multi-agent systems. It is the control infrastructure that governs how agents behave, how they coordinate and how they remain within defined boundaries. AgentCore provides the essentials of memory, runtime services, utilities like code interpreter and – critically – observability and policy enforcement. These capabilities matter because agents are not like traditional software components. Governing a data platform is relatively straightforward. Policies answer simple questions like who can access which data, under what conditions? Even column-based or tag-based controls remain manageable within deterministic systems. Agents are different. They take actions. They chain actions. They invoke tools. They do so with varying parameters, in varied contexts, and with probabilistic reasoning. The policy framework must therefore answer far more complex questions such as: Should this agent be allowed to take this action, with these parameters, in this context, in pursuit of this goal? That level of governance is exponentially more sophisticated than anything required in legacy data or application systems. This is why AgentCore is significant. Putting agents into production requires deterministic enterprise scaffolding – strong guardrails, clear boundaries, actionable observability and the ability to enforce policy across dynamic behaviors. This is heavy enterprise software, not something LLM vendors are likely to deliver. Frontier labs focus on models, not operational governance. Enterprises need a control plane that can manage armies of agents reliably, safely and consistently. Again, this is a debate inside theCUBE Research, which we’ll continue to explore. AgentCore begins to fill this gap. It establishes the governance fabric that agents must operate within and provides the layer into which downstream capabilities – systems of intelligence and systems of agency – will ultimately connect. It is the early architecture of agent-native operations, and AWS appears intent on owning this part of the stack. Among all the news coming out of re:Invent, Nova Forge stands out as the most strategically significant. The framework aligns directly with our thesis that enterprises will differentiate by owning their data, customizing their models, and building systems of intelligence that reflect their proprietary workflows. Nova Forge serves as the mechanism that makes this possible. It is the first offering from a major U.S. vendor that delivers open weights and training data, giving customers the ability to adapt the model to their own environments. The availability of training data is a critical distinction. While startups continue to build on lower-cost open-weight models such as DeepSeek, those offerings generally include weights only – not the underlying data. Nova Forge allows enterprises to substitute, augment or extend the training corpus with their own information, creating a model tuned to their specific context and competitive advantage. This introduces several strategic dynamics. Customizing a model through pretraining or reinforcement learning effectively welds an enterprise to that version of the model. When the next, more capable model arrives months later, the tuning process must be repeated. The complexity is not just operational – it can introduce behavioral instability as models shift. This is why some frontier-model providers, particularly those whose businesses depend on API consumption, actively discourage customers from performing deep reinforcement learning. Their pitch is if you avoid the heavy customization, you sacrifice some tight integration but stay aligned with the rapid improvement cycle of frontier models. This perspective underscores a broader debate about how the enterprise AI stack will evolve. One argument holds that frontier-model companies will become the next great software vendors, providing layers of tooling atop their LLMs to simplify enterprise integration. The counterargument is that mainstream enterprises – and the ISVs serving them – will need far more specialization than a handful of frontier models can deliver. Agents are not just RPA 2.0; they represent much more. As these agents proliferate, organizations will require a diverse portfolio of models, many of them small and highly specialized. In that world, frontier models play a role – but as orchestrators, handling complex planning and reasoning. The bulk of enterprise differentiation will come from customized, specialized models trained on proprietary data. Nova Forge is the first major signal that AWS intends to support this path by delivering open weights, open data and the ability for customers to shape the intelligence layer of their enterprise directly. A major subplot at re:Invent was AWS’ forceful claim that it is the best place to run Nvidia Corp. GPUs. That declaration hits with irony, given the persistent narrative that AWS lacks allocation, faces political challenges with Nvidia, and is focused on its own silicon efforts – Trainium in particular. Meanwhile, public commentary from outlets such as CNBC continues to over-index on competition to Nvidia, framing tensor processing units, Trainium and other accelerators as existential threats. The reality is more nuanced. GPUs are expensive, and performance per watt is the defining metric. Volume determines learning curves. And on that dimension, Nvidia remains in the driver’s seat. High volume gives Nvidia cost advantage, supply advantage and architectural advantage. Unless the company stumbles, the position is theirs to lose. Nvidia also locked up the leading process nodes at Taiwan Semiconductor Manufacturing Co. securing massive capacity. It is reminiscent of Apple Inc. 15 years ago: No competitor could match its handset performance because Apple had tied up the most advanced silicon for entire product cycles. No alternative supplier could close the gap. AWS’ historical challenge in securing Nvidia volume traces back to its own infrastructure strategy. The company spent years building Nitro, designing composable data centers, expanding instance types, optimizing storage and networking, and refining hypervisors. That approach made AWS infrastructure-smart – but not the earliest or largest buyer of full-stack Nvidia systems. When the ChatGPT moment hit, Nvidia wanted to sell integrated data center kits, not just racks. Providers that lacked infrastructure sophistication were forced to buy everything, and in return they received the larger allocations. That included Microsoft and the neoclouds, and Oracle as well – though in Oracle’s case, the scale-up design served the needs of its database architecture. Then came a second, largely unspoken issue: failure rates. For the last 12 months, the volume GPU has been the GB200. Multiple sources reported that failure rates were as high as 50%. No one talked about it publicly. The industry was reluctant to make Nvidia look bad and risk a reduction in allocation. But the implications were that supply would continue to be constrained. This was the year hyperscaler capital spending surged, and Wall Street was left wondering where the returns were. Utilization was low for reasons almost nobody understood externally. The shift began in October, when the GB300 surpassed the GB200 in volume. The GB300 installs more smoothly, runs more reliably and appears to deliver meaningfully higher quality. Neocloud providers such as Lambda reported excellent performance from GB300 systems. As GPU specialists willing to buy full stacks, they secured allocations consistent with that model. This dynamic contributed to the broader narrative of the “GPU-rich” and the “GPU-poor.” The GPU-rich could advance model training, inference and agentic workloads aggressively, while the GPU-poor were stuck rationing capacity. But now the dynamics may change as infrastructure-smart providers – those that invested in custom silicon and composable data centers – begin to leverage their own accelerators for meaningful workloads. There is enough Trainium deployed inside AWS to run frontier models such as Anthropic for inference at scale. Training remains a different story, despite public commitments on both sides. Anthropic’s leadership has acknowledged that training on Nvidia would require far fewer chips, which explains why it negotiated a larger deal with Google to run on TPUs – even as AWS invested billions in the company. Still, TPU volume will remain limited. Google will not match Nvidia’s scale unless Nvidia falters. Nvidia sells to Google’s competitors. Neoclouds depend on Nvidia allocation and are unlikely to compromise it. Neither Amazon nor Microsoft is going to shift to TPUs. Volume determines trajectory, and Nvidia’s volume remains unmatched. Could TPUs create pricing pressure? Possibly. A credible competitor gives buyers negotiating leverage. Nvidia’s 70% margins may face some compression. But the software ecosystem, tooling, libraries, and developer familiarity remain heavily skewed toward Nvidia. The lesson from this week is that AWS is becoming more assertive about the GPU story because it believes its infrastructure – combined with Nitro, Trainium and rapidly improving Nvidia integration – positions it strongly for the next phase of AI infrastructure. But the industry-wide GPU story is more complicated than energy constraints and data center buildouts. It includes an unspoken constraint in that high GPU failure rates, massive CapEx tied up in underutilized infrastructure, and a rapidly maturing next-generation GPU cycle is reshuffling the hierarchy of who is GPU-rich and who is GPU-poor. The slide above tells the story of two worlds. On the left sits the pursuit of messiah-level AGI – the frontier labs chasing grand breakthroughs. On the right is the hard, unglamorous scaffolding required to make AI useful in enterprises. The contrast underscores a fundamental divide. The frontier narrative often centers around singular breakthroughs and personalities, while the enterprise ecosystem is focused on building practical systems. The hyperscalers, ISVs and large incumbents are constructing the heavy scaffolding at both the agent layer and the data layer. AgentCore represents the control and governance framework. But the other half of the equation is even more foundational – bringing together data and action in a consistent, governed system. Actions – meaning tools and callable workflows – must pair with data, which provides the context that guides what an agent should do. When those come together coherently, the result is a knowledge graph, and that “4D Map” becomes the system of intelligence. This is hard enterprise software work, and frontier LLM vendors are not database vendors or workflow vendors. They are a long way from building this substrate. Enterprises that operate at scale – Amazon.com, large banks such as JPMorgan, and major technology firms that include Dell – confirm that they must build this system of intelligence themselves. It does not exist out of the box. Our early work, such as the “Uber for All” model explored years ago, hinted at the idea of people, places, things, activities – drivers, riders, prices, locations – brought together into a unified digital representation of an enterprise. That remains the ambition today: a real-time, four-dimensional map of the business. It’s why the agentic era will take most of a decade to unfold, in our view. Analytics-oriented vendors can provide slices of this capability today, but only within confined analytic domains. Building the full operational twin of the enterprise – harmonized, contextualized and ready for agents – is a far larger undertaking. The slide above shows a camel covered in logos – more logos than a camel has fleas. The image captures the current frenzy. The market’s reaction to the word “agent” has resembled a Pixar moment when someone yells “squirrel,” and the dogs instantly lose focus. In this cycle, someone yells “agent,” and venture capital runs at full speed. The problem is that most of these agent startups are built on only the thinnest layer of scaffolding. Some domain agents – such as those in legal tech – carry embedded knowledge of workflows. But the vast majority lack the heavy lifting required for real enterprise value. They do not solve the integration challenge between data, action space, and governance. They do not provide the agent control apparatus. They do not offer the system of intelligence. The companies doing that work are the hyperscalers and the major software vendors. The differentiation will not come from shiny agent UIs or narrow features. It will come from the depth of integration with data systems, workflow systems and the governance and control planes that bind agents to enterprise policy and process. That’s why this era will be defined not by the number of agents a vendor can showcase, but by the scaffolding that underpins them. And that scaffolding is where the real enterprise value will accrue in our view. The final slide above ties the entire discussion together, showing how the emerging software stack will take shape and where different players fit. The center of gravity – the high-value real estate – is the system of intelligence layer. Companies such as Celonis and Palantir are furthest along, in our view, though they take different approaches. Palantir remains services-heavy but has made significant software advances. Other graph-centric and process-centric vendors such as ServiceNow Inc., SAP SE, Salesforce In. and essentially every SaaS company with embedded process logic, are now targeting this same layer. To participate meaningfully, these players must build out their data platforms and confront a major business-model transition. As they merge process logic with data and enable agents to take increasingly autonomous action, they weaken their traditional seat-based subscription models. This is an innovator’s dilemma in real time. For example a $50 billion dashboard-centric industry (BI) faces disruption. Efforts to introduce “talk to your data” interfaces are part of that response, but they do not change the underlying economics. Below the system-of-intelligence layer sit the data platforms: Snowflake, Databricks and the lakehouse constructs of SageMaker and S3. Above it sits the system of agency – Bedrock and the agent-control frameworks. And throughout the stack, governance is ubiquitous; every major player is adding governance layers to address the risks of agentic systems. Meanwhile, the software development lifecycle is shifting from a linear pre-gen AI workflow to one that is nonlinear, interactive and deeply agent-driven. As the hardware stack is redefined – compute, storage and networking – the entire software stack is being redefined with it. Zooming out from re:Invent 2025 and the broader move toward service-as-software, the momentum feels like early baby steps toward a decade-long transformation. Two major trends are emerging: The bubble is not bursting, but it is growing. There may be some deflation on the consumer side, particularly around OpenAI’s positioning, but enterprise activity is only beginning. Building worker-bee AGI beyond basic RPA 2.0 and microservices 2.0 is a long, challenging road. But the productivity gains across software development and operations tools will be large and immediate. Over time, those agentic capabilities will migrate into every enterprise process, creating the marginal-economics advantage that defines the service-as-software model. The broader market dynamics may feel bubblicious – echoing Ray Dalio’s comment that we’re “80% of the way into the bubble.” Whether that was macro commentary or a push for his preferred trades, the point stands in that bubbles don’t burst until something pricks them. We’re not there yet. History shows pullbacks of 10% or more can happen repeatedly during an expansion, as they did in the dot-com era. Recent market disruptions look more like early tremors than the hard correction that would unwind current valuations. The agentic era is coming. Its shape is becoming somewhat more clear. But the real transformation – the unified data foundation, the system of intelligence, the governed agent layer – will take the better part of a decade to mature. Support our mission to keep content open and free by engaging with theCUBE community. Join theCUBE’s Alumni Trust Network, where technology leaders connect, share intelligence and create opportunities. Founded by tech visionaries John Furrier and Dave Vellante, SiliconANGLE Media has built a dynamic ecosystem of industry-leading digital media brands that reach 15+ million elite tech professionals. Our new proprietary theCUBE AI Video Cloud is breaking ground in audience interaction, leveraging theCUBEai.com neural network to help technology companies make data-driven decisions and stay at the forefront of industry conversations. Worker-bee AGI: Why AWS is betting on practical agents, not 'messiah AGI' Major collaboration between AWS and Snowflake drives sales growth and AI product integrations On theCUBE Pod: Amazon’s AI play, exclusive insight from Jensen Huang and America's semiconductor woes Veza introduces AI Agent Security to tackle emerging agentic AI risks NinjaOne brings native remote access to its unified endpoint management platform Resemble AI hauls in $13M for its different approach to deepfake detection Worker-bee AGI: Why AWS is betting on practical agents, not 'messiah AGI' AI - BY GUEST AUTHOR . 5 MINS AGO Major collaboration between AWS and Snowflake drives sales growth and AI product integrations AI - BY MARK ALBERTSON . 1 HOUR AGO On theCUBE Pod: Amazon’s AI play, exclusive insight from Jensen Huang and America's semiconductor woes AI - BY DEVONY HOF . 1 HOUR AGO Veza introduces AI Agent Security to tackle emerging agentic AI risks SECURITY - BY DUNCAN RILEY . 3 HOURS AGO NinjaOne brings native remote access to its unified endpoint management platform SECURITY - BY DUNCAN RILEY . 3 HOURS AGO Resemble AI hauls in $13M for its different approach to deepfake detection SECURITY - BY PAUL GILLIN . 3 HOURS AGO
--------------------------------------------------

Title: The Kids are Alright
URL: https://www.mutualfundobserver.com/2025/12/the-kids-are-alright/
Time Published: 2025-12-07T20:21:40Z
Full Content:
MFO’s founding mission is to “write for the benefit of intellectually curious, serious investors— managers, advisers, and individuals—who need to go beyond marketing fluff, beyond computer-generated recommendations and beyond Morningstar’s coverage universe.” But one of our core precepts is “80% of all existing funds could disappear today with no loss to anyone, except possibly the managers who have to explain it to their spouses.” The goodriddance group includes two overlapping sorts of idiocy: (1) many are launched at the behest of an advisor’s marketing department or strategic team. Short version: “hey, we need at least one bond fund if we’re going to keep their money in-house. Why don’t you go make one for us?” Or “everything who’s anybody has a target-date retirement series. Why don’t we have a target-date retirement series, hmmmmm???” And (2) many are cynical ploys to play on human weakness. Short version: “look, the guys in my fantasy football league know Tesla better than Musk does, and they want a way to do a quick-pivot from doubling down on Tesla’s morning performance to double-shorting it in the afternoon, so let’s do this crazy thing!” Through November 1,087 new funds and ETFs were launched in 2025. Of those, over 300 were niche trading toys: ether, hedged bitcoin, crypto index, altcoin, onchain, Litecoin, bitcoin covered call, long bitcoin / short ether, hedera coin, double-short Palantir, leveraged long + income Palantir, selling put options on ETFs that are double-long Robinhood Markets stock … The mix included six new ways to play Tesla, up or down, and one that combines Tesla and Uber, which gives us a total of 13 Tesla-specific ETFs. Bad news: these are designed to suck the life out of you, while convincing you that you’re better at this than Warren Buffett ever was. Look at column #3, dear friends: losses of 50-75% before they reach their first birthday. They are invitations to play a trading game where your reaction time is measured in minutes and your opponents’ are measured in milliseconds. Good news: these are going to perish in droves because they’re a bad idea and they can’t convince enough people long enough that they aren’t. That was the fate of the flood of internet funds (remember Nothing But Net?), blockchain funds, the flood of “green funds,” the flood of alts-for-the-masses funds, the flood of emerging market consumers funds … And yet, each year also brings several dozen legitimately interesting opportunities: often experienced managers or teams exploring new asset classes or extending proven disciplines in interesting new ways. We want to suggest that you add 10 notable rookies to your year-end research list. What makes these funds rookies? Our sibling site, MFO Premium, has an amazing fund screener which does calculations inconceivable on any site charging less than $12,000 a year (looks toward Chicago). One function of the site allows you to screen funds by age (from “launched this year” to “rookies” to “over 90 years old”). The rookie screener selects for funds with between one and two years of operation: long enough to take a few hits, short enough to remain fresh and interesting. What makes these funds notable? We screened each of six broad baskets of rookie funds – US equity, global equity, international equity, mixed asset, alternatives, and bonds – for funds that met two performance criteria. First, they had to have downside deviation ratings that were average-to-excellent. “Deviation” is a fund’s bounciness. Standard deviation measures the bounces both up and down. Downside deviation recognizes that you don’t object to having your fund bounce higher; you’re only steamed when it bounces down. So downside deviation measures a fund’s return below the risk-free rate of return; that is, if you make less in a period than the 90-day T-bill, you’re generating downside, and we’re measuring it. Second, they had to have Ulcer Indexes that were average-to-excellent. The Ulcer Index captures two metrics: how far a fund falls and how long it stays down. The logic is simple: if your manager (or index) falls flat on their face and struggles to get up, you’re going to get an ulcer. Big fall, long time down = major ulcer, high Ulcer Index. Little stumble, up and dusted off = barely any ulcer at all. That gave us a list of funds that, so far, have resisted the impulse to implode. We then sorted by Sharpe ratio – the most common measure of risk-adjusted returns – and began with the fund atop the list. If that fund shows two further criteria – it’s available to the general public, and it does not evidently rely on financial engineering, blackbox strategies, or disciplines so complex that I couldn’t explain them to myself – then we shared them with you. After that, I scanned the top 10 list in each category, asking the question, “What looks interesting here?” Our answers follow. What can I say? The ETF tracks an index of large cap companies that (a) put a lot of money into research and development and (b) have increased that commitment in each of the past three years. It ranks them, invests in the top 50, and rebalances once a year. The target is finding companies that are reinvesting in their own growth. Here are the particulars from First Trust: The fund’s Investors Guide is pretty thin. The short summary: the world is changing fast, R&D is essential to keeping up, and we find the most R&D intensive large caps for you. Plausible, though not a lot of depth there. The premise that companies investing heavily in R&D will matter more than those coasting on yesterday’s patents isn’t new. What’s new is that ‘R&D’ in 2025 increasingly means AI compute clusters and model training, not better mousetraps. First Trust isn’t picking winners; they’re just betting that the companies willing to light billions on fire today are more likely to own tomorrow than those protecting margin today. Those interested in a more active approach to the same discipline might consider Guinness Atkinson Global Innovators Fund (IWIRX), a five-star actively managed fund that found life in the late 1990s as the Wireless (magazine) Index of innovative companies. Matthew and Ian do exceptional work. The $111 billion American Funds American Mutual Fund (AMRMX) annoys me. First, you’ve got this dumb reduplicative name. Second, they push it out in 19 distinct share classes. Third, it’s a whale: $111 billion, with low Active Share (58) and a 0.58% expense ratio on the “A” shares. That having been said, it’s also got $111 billion for a reason: it’s really good at delivering what it promises and has been so for a really long time. American Mutual does not specialize in raw outperformance – over the past 60 years, it has outperformed its peers by an average of just 0.3% per year – it specializes in getting you there with less trauma. MFO Premium tracks dozens of risk metrics, and AMRMX outperforms its peers on virtually every metric for virtually every trailing period. CGCV is the ETF version of that fund. While it is only 1% of the size of American Mutual, the ETF charges substantially less than the retail “A” shares of the fund for the same strategy and same management team. What you’re getting: Conservative Equity tries to balance current income, growth of capital, and principal protection. It typically holds about 90 stocks, primarily in well-established, dividend-paying US and Canadian companies with strong balance sheets. We checked 756 rolling three-year periods for American Mutual, dating back to 1960. The typical experience of an investor holding on for three years is a return of 11.0%. Its worst-ever three-year run was -11.0% and its worst-ever five-year span was -4.1% APR. The fund many people wished they were in is T. Rowe Price Capital Appreciation, but you can’t have it. The fund has been kicking butt, under three different managers, since the 1980s: for every trailing period from one to 40 years, it has higher total return, higher Sharpe, smaller maximum drawdown, and lower Ulcer Index than its peers. And it’s closed. The fact that the success spans manager tenures suggests it’s the process that works, and TRP has been rolling out a suite of funds that incorporate variations of the discipline. This version is a mixed‑asset conservative fund that seeks total return by pairing income‑oriented fixed income with a risk‑aware equity sleeve, typically keeping roughly half to two‑thirds of assets in bonds and other debt instruments and the balance in stocks. With a 12.5% APR that is about 1.9 percentage points ahead of its peer group and a Sharpe ratio of 1.52, it has delivered competitive results with a profile designed to feel more like a cautious “paycheck plus growth” vehicle than an aggressive balanced fund. What really sets PRCFX apart is that it extends the discipline, team, and “capital appreciation with downside defense” DNA of the long‑closed Capital Appreciation Fund into a more income‑tilted format, giving investors access to a seasoned, franchise‑level process that was previously hard to reach. SEI is a manager-of-managers (MOM?) advisor. We all know that within any asset class (US equities), there are many sensible investment approaches, but no one strategy (large-cap momentum) works all the time. One alternative is that you could own three or four complementary funds and then shift their weight in your portfolio as market conditions change. Or you could surrender that particular fantasy and adopt a new one: you’ll hire someone who will hire managers representing three or four complementary strategies and will rebalance them for you within the fund. That “someone” is SEI. For SEEM, SEI hired three fundamental EM managers—one focused on quality, one on momentum with a small-cap tilt, one on value with macro overlay—and then uses their own quant tools to decide how much each should control. The goal is a broadly diversified, all‑cap portfolio across Asia, Latin America, Africa, and other developing regions. The fund has had an unusually strong first year, with both higher returns (29% APR vs 24% for its peers) and lower volatility (measured by maximum drawdown, standard deviation, and downside deviation) than its peers, leading to substantially higher risk-adjusted returns metrics (Sharpe ratio and Ulcer Index are strikingly higher). The fund has drawn $320 million in assets and charges 0.60% after waivers, a noticeable bargain price. One caveat is that the MOM approach does not tend to generate star performance. Morningstar tries it with their nine house-branded funds, seven of which are three stars or below. Litman Gregory (which now bears the ugly name iMPG) made it the heart of their business model in the Masters funds, only two of which survive. SEI has done exceptionally well with the model, but the caveat remains. The other is that not a single one of the thirty-eleven managers, including SEI employees, has invested a penny of their own money in the fund. GMO International Value ETF (GMOI) is the retail incarnation of GMO International Opportunistic Value (GTMIX), an institutional fund that’s been around since 1998. The strategy there (and here), is to concentrate on what GMO calls “deep value” stocks in developed markets outside the U.S., seeking total return from a heavily contrarian, valuation‑driven discipline. Its record since inception is exceptional, though perhaps a tiny bit irrelevant. It has outperformed its peers over every trailing measurement period (3-, 5-, 10-, 20-, inception), generally by 100 – 250 bps. Its risk metrics (maximum drawdown, standard deviation, downside deviation) are generally in line with or better than its peers, and its risk-adjusted returns metrics (Sharpe ratio and Ulcer index) are consistently better. The three current managers arrived in May 2023, meaning this 27-year track record is largely someone else’s work, even if the new team has decades of GMO experience elsewhere and responsibility for implementing the strategy that others have piloted. (And two of the three have declined to invest in the ETF.) The ETF has done well since launch. Its 31.7% APR beats its peers by 620 bps, and its risk metrics have been pretty much in line with its peers. The fund has gathered $215 million in assets in just over a year. This rookie vehicle is part of the rising wave of ETF launches, which give the rest of us access to an institutional‑grade GMO discipline that has historically lived in separate accounts and mutual funds.​ Rockefeller Capital Management launched a Global Equity Strategy in 1991. Marketed primarily for institutional clients, intermediaries, high-net-worth individuals, and family offices, the strategy has accumulated $4.5 billion. There’s no public performance record that we can find. The Rockco.com website is among the world’s most annoying, offering a rich and slow-loading visual experience with virtually no content concerning its investment capabilities beyond the moral equivalent of “we cool. We cool!” Here’s what we do know. The firm talks a lot about the overemphasis on short-term metrics among most investors (it has its roots in 1882 so the bias is explicable), about its global scope and unconventional sources of insight (mostly unexplained). The firm has three equity and three muni bond ETFs. The two older equity ETFs (Climate Solutions and US Small Cap Core) are … okay. Climate Solutions is in a meaningless peer group (Specialty / Miscellaneous), and Small Cap mostly tracks its peers. In October 2024, the firm launched Rockefeller Global Equity ETF (RGEF) with approximately $700 million in assets. This actively managed ETF invests primarily in large‑cap stocks across developed and emerging markets, using a bottom‑up fundamental process to build a 45–75 stock portfolio of companies with durable competitive advantages and a long‑term earnings runway. It has done quite well, on both upside and downside measures, in its short life. It has an APR of 23.2% versus its peers’ 18.9%, with dramatically lower volatility and a dramatically higher Sharpe ratio. Whether the advisor’s opacity reflects confidence born of 33 years managing money for people who know them personally, or simply indifference, is unclear. What is clear: investors considering RGEF are being asked to trust the Rockefeller name more than any articulated investment philosophy. This is the ETF version of Fidelity Hedged Equity Fund (FEQHX), a $550 million, four-star fund whose two managers are responsible for about $1 billion in hedged equity products at Fido. At base, the managers construct an equity portfolio that looks like the S&P 500 and then buy puts on their holdings to buffer the effects of market declines. The puts can rise in value when markets fall, so they make a positive contribution at much less than the cost of shorting stocks as a hedge. We long ago stopped reading Fidelity’s annual reports and manager “interviews” because they are so templated and sanitized that you learn virtually nothing from them, and that’s the case here, too. A chatbot comes across as much human and thoughtful. That said, the fund’s performance numbers are solid. Relative to an unhedged peer group, the fund posted solid absolute returns with 15-20% less volatility. FHEQ is an actively managed global large‑cap core strategy that owns a diversified equity portfolio while using put options and related techniques to buffer downside, targeting a smoother ride through equity cycles. Its 19% APR, about 0.2 percentage points ahead of peers, and a 1.81 Sharpe ratio suggest that investors have been reasonably rewarded for accepting the complexity and costs of its options overlay. The fund charges 0.55%, the ETF charges 0.48%. It’s a fascinating insight into the changing dynamics of the industry: the fund with the exceptional public record has drawn fewer assets in 40 months ($550 million) than the ETF has in 20 months. ($620 million). Capital Group Global Equity ETF (CGGE) is a global large‑cap core ETF that mimics American Funds Global Insight (AGVHX). Same management team, same discipline. Global Insight is an actively managed global large‑cap equity fund that aims for prudent long‑term growth of capital while seeking to limit downside risk. It invests mainly in established companies across the U.S. and international markets, with meaningful exposure to sectors like industrials, technology, and financials. It has a far larger non-US stake than its peers (44% versus 34%), low turnover, low Active Share, and more industrials (21% versus 13% for peers) than more. So far, that has not triggered a noticeable performance difference with its peers – it trails by 0.9% annually with a little less downside, leading to comparable Sharpe ratios. The ETF has performed exceptionally well, but that translates to “the ETF has operated for its first 16 months in a market that favored it;” its longer-term performance is likely to be another verse of the Global Insight song, “stodgy, cheap, reliable me!” The argument for the ETF is that it offers a more tax‑ and fee‑efficient wrapper. The ETF charges 0.47% on $1.4 billion in assets, the fund’s retail “A” shares ring in at 0.86% on $19 billion in assets. Palmer Square Credit Opportunities ETF (PSQO) is an actively managed, flexible multi‑asset credit strategy that allocates across CLOs, corporate bonds, ABS, and bank loans, drawing on Palmer Square’s existing opportunistic multi‑asset credit strategies and funds. Palmer Square frames it in terms of the opportunistic, relative‑value credit approach they’ve been running across separate accounts, funds, and other vehicles … but it does not identify one specific mutual fund or listed fund that PSQO is meant to replicate. The fund has only been around a year, but has dramatically outperformed its Global Income peer group in that period. The main “red flag” is that PSQO is a complex, opportunistic credit vehicle whose risk may only show up under real stress; it belongs firmly in the adventurous side of a bond sleeve, not as a core bond replacement.​ It has attracted about $107 million in assets over its first year of operation and charges 0.52%. Palmer Square CLO Senior Debt ETF (PSQA) tracks the Palmer Square CLO Senior Debt Index. Senior debt sits atop the stack of debts to get paid in the case of a default. As a general matter, CLO senior debt has returns like intermediate bonds but responds to a different set of risk factors. It is not high-yield debt, Palmer Square screens for securities with the equivalent of AA or AAA ratings, but like high-yield debt. CLO senior debt is sensitive to default or impairment rates but not sensitive to rising interest rates. The index has returned 3.46% annually since 2012 and 4.75% annually over the past five years, which sort of looks like this: The ETF itself has returned 5.9% in its first year with far better risk metrics than the average “loan participation” fund, so that its Sharpe ratio is twice as large. This strikes us as a “know what you own” story: structurally safer than mezzanine CLO exposure, but far from a simple investment‑grade bond fund, and not something to hold without tolerance for complexity and episodic drawdowns even if backward‑looking Sharpe ratios look excellent.​ Let’s start at Square One: I’m a fan of CrossingBridge. I’m amazed by the consistency with which David Sherman and his team have done exactly what they’ve promised: generated substantial upside with extremely well-managed downside in a collection of strategies that you can’t find elsewhere. I’m invested in two of their funds, Chip is invested in one, and MFO’s tiny “endowment” is, too. We wrote about CrossingBridge Nordic High Income Bond Fund (NRDCX) at its launch, and it has done well since. They seek high income and capital preservation while investing in bonds issued, originated, or underwritten in the Nordic countries. Part of the corporate DNA is a willingness to pursue small issues and event-driven ones that larger managers could not exploit. They see the Nordic markets as embodying a sort of gold standard for corporate governance and transparency, report that Nordic bonds represent better values than US high yield, and believe that the Nordic region has a distinctive market niche. For high-yield investors looking beyond the US, this is the quintessential “get this on your due diligence list” fund. Miller Market Neutral Income Fund (MMNIX) is a relative‑value, market‑neutral strategy that seeks positive total return with low correlation by emphasizing convertible and synthetic convertible structures, using long/short and hedging techniques to dampen broad equity and rate risk. To be clear, this isn’t the famous “Miller” and the CIO’s leadership of “Wellesley Asset Management” isn’t the Vanguard Wellesley. This Miller and this Wellesley are convertible bond specialists primarily serving an institutional clientele and managing about $2 billion in assets. At 9.8% APR, about 1.9 percentage points above its market‑neutral peers, and with a 3.80 Sharpe ratio, it fits our “alternatives with real risk‑adjusted payoff” preference, but (1) the 1.69% expense ratio is way high, and (2) it appears that it’s only available to institutional investors. I mention it here for the benefit of our professional readers who might have avenues to access a specialist shop’s flagship. SGI Enhanced Core ETF (USDX) is an “absolute‑return‑ish” bond and options hybrid that holds a diversified portfolio of high‑quality, short‑term money‑market instruments while running an actively traded put‑and‑call overlay on broad equity indices such as the S&P 500 to generate incremental income. Morningstar, by the way, likes no part of it. Or, more narrowly, Morningstar’s machine-learning analyst likes no part of it. That having been said, it’s posted pretty much top 1% returns since its launch about two years ago. The combination of very short‑duration fixed income and options‑driven yield is a sort of complexity trade: potentially smoother performance than long‑duration bonds, but with structural and behavioral risks that require some sophistication and tolerance for an expense ratio of 1.05% for a bond ETF. The advisor, Summit Global of Bountiful, Utah, manages about $760 million and advises five funds. Where to start, where to start? Hmmm … I really like the leadership of Bridgeway Capital, and once invited founder John Montgomery to speak to the students at the Institute for Leadership and Service at Augustana. That reflected two things: first, Bridgeway’s unswerving commitment to follow the evidence rather than the crowd, and their deep commitment to serving their community and their investors. John was obsessively cheap long before Vanguard and ETFs made it the vogue. Mr. Montgomery’s analysis of “the small company effect” led him to the conclusion that only the smallest of small companies – those in the so-called tenth decile – actually manifested it, and so their very first fund, Bridgeway Ultra-Small Company, which targeted companies so small that it had to have a hard close at just over $25 million. That having been said, the firm has seen relentless outflows and inconsistent performance over the past decade. So, here’s the story: Bridgeway Global Opportunities Fund (BRGOX) is trying to offer long-short “hedge fund” capabilities at mutual fund prices. It is an equity market‑neutral strategy that aims for long‑term positive absolute returns by running a roughly dollar‑neutral long/short portfolio in U.S. and foreign stocks. (Market-neutral and dollar-neutral translates to: our returns are independent of the stock market and currency fluctuations.) The key differentiator is Bridgeway’s work on “intangible capital” such as research & development spending. Accounting rules treat R&D as outflows, like the cost of buying coffee for the breakroom, not as investments. As a result, traditional metrics undervalue them. Here’s Bridgeway’s official description of what they do: Global Opportunities seeks consistent risk–adjusted absolute returns agnostic to market direction, with reduced volatility and granular diversification. Our systematic stock selection approach targets inefficiencies and opportunities in global markets. Innovations in accounting theory and financial analysis are employed to evaluate company fundamentals contextually, opening the opportunity to capitalize on slower price discovery in overlooked market segments. Limited discretion is applied when research assumptions do not hold. Our portfolio construction process is designed to emphasize idiosyncratic over systematic exposures. Bridgeway has published three peer-reviewed articles on the investment relevance of intangible capital, and the fund has done well so far. Bridgeway’s well‑documented commitment to donating a large share of profits to charity, its quantitative research ethos, and its history of sometimes brilliant but inconsistent funds make BRGOX feel like a high‑conviction expression of a very distinctive culture—one that investors may admire for its mission and process even if they should be cautious about extrapolating early‑stage performance.​ Final note, the fund charges a lot, 1.63% on assets of $34 million, if you think of it as a mutual fund, and not much at all if you think of it as a hedge fund. Your call! The flood of crypto derivatives and leveraged trading toys will wash out as it always does, leaving behind a small cohort of genuinely interesting opportunities. The lowest-risk rookies are precisely what MFO has always hunted for: experienced managers with solid, verifiable track records who are now available in new forms, whether that’s Capital Group’s franchise strategies wrapped in lower-cost ETFs, GMO’s institutional disciplines accessible to retail investors, or T. Rowe Price’s closed-to-new-money process extended into a complementary vehicle. These aren’t experiments or marketing plays. They’re proven managers bringing tested disciplines to investors who couldn’t previously access them. The question isn’t whether these strategies work, many have decades of demonstrating they do, but whether the new wrapper fits your portfolio. For serious investors willing to look past the noise, that’s a far more promising starting point than whatever Tesla-leveraged monstrosity launches next month. David Snowball, PhD (Massachusetts). Cofounder, lead writer. David is a Professor of Communication Studies at Augustana College, Rock Island, Illinois, a nationally-recognized college of the liberal arts and sciences, founded in 1860. For a quarter century, David competed in academic debate and coached college debate teams to over 1500 individual victories and 50 tournament championships. When he retired from that research-intensive endeavor, his interest turned to researching fund investing and fund communication strategies. He served as the closing moderator of Brill’s Mutual Funds Interactive (a Forbes “Best of the Web” site), was the Senior Fund Analyst at FundAlarm and author of over 120 fund profiles. Find an unparalleled array of risk metrics, fund screeners and correlation matrices at MFO Premium
--------------------------------------------------

Title: The accelerator is on the floor for autonomous vehicles | TechCrunch
URL: https://techcrunch.com/2025/12/07/the-accelerator-is-on-the-floor-for-autonomous-vehicles/
Time Published: 2025-12-07T17:01:10Z
Full Content:
Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us Welcome back to TechCrunch Mobility — your central hub for news and insights on the future of transportation. To get this in your inbox, sign up here for free — just click TechCrunch Mobility! Another week, another round of announcements about robotaxis either launching or planning to in cities. Let’s take stock. Waymo started testing its autonomous vehicles (with a safety monitor) in Philadelphia and will start manual driving to collect data in Baltimore, St. Louis, and Pittsburgh; Uber and Avride launched a robotaxi service in Dallas that will initially include a human safety operator behind the wheel; and the California Department of Motor Vehicles released revised rules that would allow companies to test and eventually deploy self-driving trucks on public highways in the state. Autonomous vehicle tech is scaling and the pace is quickening. But should it? As autonomous vehicle tech percolates into the cityscape, so has the criticism and challenges. A couple of recent incidents illustrate this point. The National Highway Traffic Safety Administration has asked Waymo for more information about its self-driving system and operations following reports from the Austin School District that its robotaxis illegally passed school buses 19 times this year. The agency already opened an investigation into Waymo’s performance around school buses. Then there is KitKat, the bodega cat that died after a Waymo robotaxi ran him over on October 27. The company was already facing criticism over the event. And now it might escalate thanks to new video. The NYT tracked down surveillance video that shows a woman crouching beside the Waymo trying to lure KitKat to safety before the vehicle suddenly pulled away. A lot of changes have been happening at Lucid Motors recently, according to some little birds. As many of you already know, the company has lost a number of top executives, including former CEO and CTO Peter Rawlinson and most recently, chief designer Eric Bach. Lucid, which is in the middle of ramping up production of its Gravity SUV, has patched some of these vacancies with a mix of internal promotions and outside hires. And the changes keep coming. A few little birdies told us this week that a handful or more of top managers on its software and electrical teams were let go, including two senior directors who started with Lucid around a decade ago. Got a tip for us? Email Kirsten Korosec at kirsten.korosec@techcrunch.com or my Signal at kkorosec.07, or email Sean O’Kane at sean.okane@techcrunch.com. Electric aircraft maker Beta Technologies, which went public last month, is carving out a nice little supplier business for itself. Which is fitting since the Vermont-based company is aiming to be an OEM to the aviation sector. The company locked in a deal to supply air taxi company Eve Air Mobility with its electric pusher motors. Beta says the agreement is a potential 10-year opportunity valued at $1 billion. Of course, “potential” is an important hedge. That $1 billion is not guaranteed, even if shareholders translated it as such (stocks popped 8% following the news). Still, Beta is finding a near-term revenue path as it continues to work toward the commercial certification of its electric aircraft with the Federal Aviation Administration. The company also reported its third-quarter earnings this week. Beta saw its revenue more than double to $8.9 million from the same quarter last year. Its net losses have also grown. Beta reported net losses of $452 million in the third quarter, a more than fivefold increase from the same year-ago period. Other deals that got my attention … Autolane, a Palo Alto-based startup developing the “air traffic control” for autonomous vehicles, raised $7.4 million in a round led by VC firms Draper Associates and Hyperplane. Element Fleet Management, an automotive fleet manager, acquired San Francisco-based connected vehicle payments company Car IQ. The terms weren’t disclosed, but sources with information on the deal told TechCrunch the acquisition price was $80 million. History lesson: back in 2024, Canada-based Element Fleet Management acquired fleet optimization software startup Autofleet for $110 million. ExploMar, a China-based developer of electric propulsion systems for boats, raised $10 million in a Series A round. The investment was jointly led by private equity funds and a listed company in China (not disclosed), with existing shareholder DCM Ventures continuing to participate. Heven AeroTech, a startup developing hydrogen-powered drones, raised $100 million in a Series B round led by American quantum computing company IonQ. The company’s post-money valuation is now more than $1 billion. Texas Venture Partners also participated. Wayve, the buzzy U.K. self-driving startup backed by Microsoft, Nvidia, and SoftBank Group, acquired German startup Quality Match, which analyzes data used to train AI models for automated driving. Terms weren’t disclosed. Amazon is considering ending its long-standing contract with the United States Postal Service and building out its own competing nationwide delivery network. Tesla owners can text and drive with the latest version of the company’s Full Self-Driving (Supervised) driver-assistance software, despite the fact that it’s illegal to do so in most states. Grand Theft Auto Online has added robotaxis from a fictional-yet-familiar company dubbed “KnoWay,” whose sole purpose appears to be wreaking havoc. Nvidia announced Alpamayo-R1, an open reasoning vision language model for autonomous driving research. TechCrunch’s Europe-based reporter Anna Heim gives an inside look at a drone delivery partnership in Finland. The Trump administration said it will lower fuel economy standards for cars and light trucks sold in the United States, arguing it will make vehicles more affordable. There’s a trade-off, though. Consumers could end up paying more for gas. The reduction essentially brings vehicles below what they’re achieving already. The proposal would roll fleet-wide fuel economy to 34.5 miles per gallon for 2031 model-year cars. The previous fuel economy standard, set under the Biden administration, mandated fuel economy of 50.4 mpg by 2031. In 2024, automakers had to average 30.1 mpg across their fleets, which they beat, delivering 35.4 mpg, according to CAFE calculations. Back before Thanksgiving, we did a poll in the Mobility newsletter asking, “When do you expect robotaxis to reach a tipping point of mass adoption that will affect how people move from Point A to Point B?” Most readers picked “before the end of the decade,” which received 47.2% of the vote, followed by the “2030s.” Based on your votes, there appears to be low confidence that 2026 will be the year of the tipping point. Sign up for the Mobility newsletter to participate in our polls! Topics Transportation Editor Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates. Claude Code is coming to Slack, and that’s a bigger deal than it sounds Creator IShowSpeed sued for allegedly punching, choking viral humanoid Rizzbot SpaceX reportedly in talks for secondary sale at $800B valuation, which would make it America’s most valuable private company Meta acquires AI device startup Limitless Andy Jassy says Amazon’s Nvidia competitor chip is already a multibillion-dollar business ‘End-to-end encrypted’ smart toilet camera is not actually end-to-end encrypted Company backed by Donald Trump Jr.’s firm nabs $620M government contract © 2025 TechCrunch Media LLC.
--------------------------------------------------

Title: The AI Wildfire Is Coming. It's Going to Be Painful and Healthy
URL: https://ceodinner.substack.com/p/the-ai-wildfire-is-coming-its-going
Time Published: 2025-12-07T16:43:38Z
Description: AI won’t crash—it will burn. Like every tech cycle, the fire will clear the brush, redistribute talent, and leave infrastructure to power what comes next. The question is: what kind of plant are you?
--------------------------------------------------

Title: Kroger CEO has a harsh solution to rising prices in stores
URL: https://www.thestreet.com/retail/kroger-ceo-has-a-harsh-solution-to-rising-prices-in-stores
Time Published: 2025-12-07T16:07:00Z
Description: Over the past few months, Kroger has seen a slight decrease in consumer demand amid recent economic uncertainty and heightened competition. During the third ...
--------------------------------------------------

Title: 'Get all that Hermes stuff now': Netflix director accused of $11 million fraud rushed to buy luxury goods, texts show
URL: https://www.businessinsider.com/carl-rinsch-netflix-fraud-trial-hermes-hastens-mattress-2025-12
Time Published: 2025-12-05T21:06:02Z
Full Content:
Every time Jacob publishes a story, you’ll get an alert straight to your inbox! Enter your email By clicking “Sign up”, you agree to receive emails from Business Insider. In addition, you accept Insider’s Terms of Service and Privacy Policy. After Carl Rinsch got an infusion of $11 million from Netflix to finish his passion project — a futuristic television series — he could sleep well at night. That's partly because he bought a $439,000 handmade mattress on what prosecutors say was on Netflix's dime. At Rinsch's criminal fraud trial in Manhattan federal court on Friday, jurors heard more about the director's spending spree from some of the people who witnessed it firsthand. His former personal assistant testified that he compared himself to a character in a movie who had 30 days to spend $30 million — or lose it all. Prosecutors also called to the stand a salesman who waxed on about the handmade Swedish mattress he sold Rinsch, complete with a "sleep doctor" to massage it for him. Rinsch liked the Hästens Grand Vividus mattress so much that he decided to buy a second one, the salesperson testified Friday. Prosecutors in the US Attorney's Office for the Southern District of New York allege Rinsch defrauded Netflix by misusing funds for the production of "White Horse" — a show about artificial beings who create their own society on Earth after a schism with humankind. Rinsch filmed portions of "White Horse," but went over budget and never finished a single episode. On Friday, jurors heard more testimony from Maria Skotnikova, who worked as a personal assistant for Rinsch and made logistical arrangements for the filming of "White Horse." Skotnikova said Rinsch made multiple luxury purchases after Netflix gave him an additional $11 million in March 2020 to finish the project, including a rush to buy Hermes goods. "Get all that Hermes stuff now," Rinsch told Skotnikova in one August 2021 text message sent to the jury. "This is your job," he texted her a short while later. "We have to do this. Or else the money goes bye-bye. Get it." According to Skotnikova, Rinsch compared his situation to "Brewster's Millions" — the 1985 movie about a man who learns he received a $30 million windfall from a family member but must spend it all within 30 days. Skotnikova also testified Thursday about driving to meetings in Ferraris and Rolls-Royces, vehicles an FBI forensic accountant said Rinsch purchased using money that originally came from Netflix. Skotnikova said Friday that Rinsch tried to purchase a large amount of furniture from the French designer Jacques Adnet, which he considered "interesting and underappreciated." Rinsch, known for directing "Ronin 47" with Keanu Reeves, wanted to have a "monopoly" on the designer's furniture pieces so he could "control the price," Skotnikova testified. The spending spree also included over 480 food takeout orders on Postmates and Uber Eats in a six-month span in 2022. The FBI forensic accountant previously testified that Rinsch moved the funds from Netflix through different accounts, invested a portion of it in the stock market and cryptocurrency, and spent other amounts on what appeared to be personal uses. Later Friday, jurors heard from Johan Ericsson, who served as the top Hästens salesperson on the West Coast of the US. He said he met Rinsch in 2021, when the director went to the brand's Los Angeles store. Rinsch purchased four mattresses for a total of $617,610.66, records show. He received a discount because he bought floor models rather than having them individually handmade in Sweden, Ericsson said. The highlight was the Grand Vividus in the "black shadow" colorway. It was the top-of-the-line model that took over 700 hours to make, Ericsson said. The Grand Vividus is not just a mattress, but a "sleep instrument" that includes a base and leather headboard, and comes with a "bed doctor" who visits your house to massage the mattress, according to Ericsson. Rinsch was so pleased with it that he later modified his order to get an additional Grand Vividus mattress rather than three lesser Hästens models, according to Ericsson. "These are two very special beds," Ericsson said. US District Judge Jed Rakoff, who is overseeing the trial, chastised prosecutors for allowing Ericsson to spend so much time on the witness stand waxing lyrical about the qualities of Hästens mattresses. "I was going to call it a sales pitch, but he obviously deeply believes in the brilliance of these mattresses," Rakoff said. Ericsson said that Rinsch never spoke with him about using the mattresses for the production of "White Horse." Rinsch's defense lawyers say he's innocent, and the case is really about a "creative genius" who was overwhelmed by the challenges of the project and didn't get the support he needed from Netflix. In a deposition for a separate legal proceeding, which was entered into evidence in the criminal trial, Rinsch was asked why he purchased "a mattress that costs $450,000 for this production." "Because it retains value," Rinsch said. "And a mattress that you spend $30,000 on is worth zilch, but a mattress that you spend $450,000 on — guess what? It's worth a hundred grand more now. So hey, what are you gonna do?" Prosecutors told Rakoff they expect to finish presenting their case on Monday. Rinsch — an engaged and jittery presence in the courtroom — hasn't said whether he will take the witness stand while his lawyers present his defense case. Jump to
--------------------------------------------------

Title: This Startup Makes Ammonia By Turning The Planet Into A Chemical Reactor
URL: https://www.forbes.com/sites/the-prototype/2025/12/05/this-startup-makes-ammonia-by-turning-the-planet-into-a-chemical-reactor/
Time Published: 2025-12-05T16:23:03Z
Full Content:
ByAlex Knapp, Forbes Staff. In this week’s edition of The Prototype, we look at a cleaner way to make ammonia, some of the brightest young scientists in North America, magnetically charging your care, and more. To get The Prototype in your inbox, sign up here. Ammonia is a crucial ingredient for the planet’s food supply—more than two-thirds of it is used to produce fertilizer. It’s also increasingly being seen as a potential clean energy source, with startups like Amogy using it to produce power for maritime and industrial applications. But while burning ammonia for fuel may be clean, making it isn’t—it relies on a fossil fuel dependent chemical reaction called the Haber-Bosch process, which accounts for nearly 2% of carbon emissions annually. That’s where Addis Energy comes in. Cofounded by Michael Alexander (CEO), Charlie Mitchell (COO), Iwnetim Abate (chief science officer and Yet-Ming Chiang (chief strategy officer and an alum of the Forbes Sustainability Leaders list), the company aims to use the Earth itself as a chemical reactor to make ammonia in a cleaner way. Here’s how it works—first, they identify rocky formations underground with large amounts of iron. Then they inject those rocks with water, nitrogen and a chemical catalyst. That causes the oxygen in the water to bind with the iron in the rocks—making rust—freeing the hydrogen, which reacts with nitrogen to form ammonia. The advantage of this, Alexander and Mitchell told me, is that once they’re able to achieve this reaction at scale, it will produce ammonia at one-third the cost of the conventional process, which requires natural gas subjected to high temperatures and pressure. On Thursday, the company announced an $8.3 million seed round, led by At One Ventures, bringing its total raised to over $17 million. Existing investors Engine Ventures and Pillar VC also participated. The company plans to use the capital to continue development of the technology and perform its first pilot operation in the field. Astronauts are among the most highly trained people in the world. Most of them have advanced degrees, not to mention years of experience in highly demanding military or technical fields. Sending them to the International Space Station is expensive—it costs around $130,000 an hour to keep its crew in orbit. But despite all this expertise and expense, astronauts spend a great deal of time doing menial, tedious work such as routine maintenance or moving and organizing cargo. Ethan Barajas, 22, and Jamie Palmer, 25, want to fix that. Their company, Icarus Robotics, is developing robots that can do the grunt work so that the station crew “can focus on the groundbreaking discoveries that only astronauts can do,” he says. Barajas and Palmer are just two of the innovators on this year’s 30 Under 30 Science list, which highlights some of the hottest young scientists, engineers and deep tech entrepreneurs. Read more about the list here, and check out the complete 30 Under 30 Science list here. Magnetic charging of phones has become commonplace—and your electric car may not be far behind. A team of researchers at the Swiss Federal Laboratories for Materials Science and Technology developed a magnetic plate that transfers energy to a receiver in the car. When tested under real world conditions, it showed the same efficiency as a cable, and can get started as soon as the car is correctly parked. In addition to co-editing the 30 Under 30 Science list, I also co-edited the Forbes 30 Under 30 Healthcare list, which you can read more about here. In my other newsletter, InnovationRx, Amy Feldman and I wrote about price cuts for blockbuster weight-loss drugs, a new gene-editing partnership, the coming barriers to getting vaccines, and more. Rideshare giant Uber launched robotaxi service in Dallas this week, where rival Waymo plans to bring its service next year. Jeff Bezos’ space company Blue Origin is planning on using its planned Moon missions to gain a competitive advantage over rival SpaceX. Satellite company Spire (cofounded by Forbes 30 Under 30 Science alumnus Jeroen Cappaert) is teaming up with Deloitte to build a constellation of satellites designed to detect and prevent cyberattacks against spacecraft in orbit. A team of MIT researchers (led by Forbes 30 Under 30 Science alumnus Ritu Raman) has developed artificial tendons that can be used to make robots more capable. Next time you have a presentation coming up at work, think about how you’ll use your hands to emphasize your points. At least, that’s what a recent paper suggests. The researcher behind the study used analysis of TED talks plus controlled study where individuals evaluated someone pitching a product. In both cases, they found that people who used their hands to illustrate their point—like spreading them out when discussing something far away—were more persuasive than people who didn’t. I’ve been listening to the Sharp Pins’ new album Balloon Balloon Balloon on repeat this week. This fantastic work of music is the brainchild of 21-year-old Kai Slater (who also plays guitar for the punk band Lifeguard). It somehow simultaneously sounds fresh, and also like someone at the record store put on a lost gem from 1967 while going on and on about how it’s too bad the band never made it. If you like lo-fi indie rock, or psychedelic ’60s rock, then this is for you. Check it out.
--------------------------------------------------

Title: TRIP REPORT: Random Food Low-Effort around Chicago – New Aircraft, Old Friends
URL: https://economyclassandbeyond.boardingarea.com/2025/12/05/trip-report-random-food-low-effort-around-chicago-new-aircraft-old-friends/
Time Published: 2025-12-05T10:31:31Z
Description: Random Low-Effort Food Around Chicago New Aircraft, Old Friends Why yes, I’m trying to avoid writing something else. Or is it booking something else? So, a quick food adventure before I get back to booking something… In this Trip Report: Well, this year has b…
--------------------------------------------------