List of news related to Uber stock price UBER:

Title: The Graduate: A Slick BMW Boxer Bobber Built From R65 and R100 Parts
URL: https://www.bikeexif.com/bmw-boxer-bobber
Time Published: 2025-07-04T17:01:01Z
Full Content:
You might not know Sam Clercx’s name, but you’ve seen his work. He launched his career at the tender age of 15 as an intern at Ironwood Motorcycles, under the guidance of Arjan van den Boom. He’s had a hand in many of the amazing machines that have graced our pages—and he’s learned a thing or two, judging by this beautifully executed BMW boxer bobber. “I was there with Arjan when he built the Mutant, and most of the other BMWs that put Ironwood on the map,” Sam tells us. “It was an extremely exciting time for me, as you can imagine. Most of my friends had jobs in supermarkets or cafés and I was helping build these amazing-looking and sounding custom bikes.” The niggles associated with classic motorcycles are partly why meneer van den Boom hit pause on Ironwood a few years ago. But Sam still has an affinity for the beloved BMW boxer motor. So he built up this R65 basket case as a side project, while completing another internship—this time at Motoism in Munich. “After Arjan closed up his shop and stopped building his boxers, I got a chance to buy a 1979 BMW R65 in parts, for cheap,” says Sam. “Thanks, in part, to Arjan and other people building wonderful machines out of these old R-series BMWs, the prices rose significantly, putting a nice riding rolling base out of my price range. I grabbed the opportunity and slowly started envisioning my perfect twin-valve custom.” “With a tight budget, but plenty of time, I picked up the neglected R65 in boxes. The short R65 frame and swingarm, paired with R100 cylinders, pistons, and heads, offered an affordable path to the quick, agile airhead I always wanted.” In stock form, the R100 makes about 25 hp more than the R65—so rebuilding the engine with R100 parts was a good call on Sam’s part. He also added BMW R100RS badges to the engine block to tease the engine’s true capacity, and adorned the heads with classic peanut covers. The airbox was swapped for pod filters, and the space it left behind was filled with a 3D-printed cover, housing a NOCO NLP9 battery. Sam scalped more R100 parts for the front end, fitting the lowered forks and twin Brembo brakes from a BMW R100RS. The R65 retains its drum brake and snowflake rims, which are now shod with Shinko E-270 tires. “It was a great help throughout the build to have a lot of spare parts from Arjan sitting in my garage,” he adds. “Small stuff like seals, throttle cables, and a lot of wiring—but also some nice bling parts.” A pair of aftermarket shocks props up the rear, connected to a custom-made stepped subframe. Lower down, the unsightly brackets that normally hold the mufflers and passenger pegs were trimmed down, leaving just enough space for the latter. “While style was obviously important, I didn’t want to sacrifice function,” Sam adds. “There are, of course, more practical bikes out there, but I set out to strike a balance between function and form: keeping it a two-seater and asking the talented Tom Hurley to make the seat as comfortable and waterproof as possible, while keeping it slim; adding tie-down points under the seat for my luggage; and fitting modern LEDs for good visibility at night, along with reliable electronics. I’m a rider first and a builder second.” Keeping with this philosophy, Sam fabricated a pair of short fenders for the bike and protected the fork stanchions with fresh rubber boots. A chromed LED headlight sits out front, nailing the mix of classic style and modern reliability that Sam was after. The headlight is neatly tucked into a 3D-printed fairing that was inspired by the plug-and-play fork covers that Motoism produces. It includes integrated Motoism turn signals, with a tidy housing for a slim Motogadget Motoscope Mini speedo up top. Other Motogadget bits include the bike’s keyless RFID ignition, and the company’s mo.unit blue module, around which the whole bike was rewired. The fairing also helps to route the cockpit’s cables and houses, making for an uber-neat setup. Wide handlebars sport vintage-style grips, a MessnerMoto throttle, and modern push-buttons with internal wiring. Tarozzi foot controls round out the control package. Motoism’s influence is clear in the BMW’s rear lighting too. Sam designed and 3D-printed his own taillight housing, equipping it with powerful LED internals. The rear turn signals are Motoism parts too, but the bracket that holds them is a one-off. The boxer’s glorious two-into-one exhaust headers were created by Sam’s good friend Chiel Nipius (of Nius Moto). They’re matched to a Spark silencer to create an appropriately throaty rumble. The most striking thing about this BMW boxer bobber is how well judged every last part and finish is—from the refinished motor to the period-correct pin striping and blacked-out tank roundels. “The color scheme was inspired by a picture of a classic Porsche 356 convertible I found—black leather, chrome silver, and this stunning blue,” explains Sam. “It was perfectly executed by Royal Kustom Works on the tank, fenders, and front fairing.” Now that his BMW R65/R100 is complete, Sam plans to take it on a few trips before selling it to make way for the next project. But first, it’s being exhibited as his official graduation project at the Utrecht School of the Arts. If it were up to us, we’d give him full marks. Sam Clercx Instagram | Images by Paul van Mondfrans Lindén GET THE WORLD'S BEST CUSTOMS DELIVERED TO YOUR INBOX. COPYRIGHT © 2008- | COLE PUBLISHING | ALL RIGHTS RESERVED
--------------------------------------------------

Title: I’m a retiree with $900k cash but no home. How do I make it last? - Mary Holm
URL: https://www.nzherald.co.nz/business/personal-finance/im-a-retiree-with-900k-cash-but-no-home-how-do-i-make-it-last-mary-holm/ZA75E4TTEJFALEKTRRCY7PKOQA/
Time Published: 2025-07-04T17:00:00Z
Full Content:
Reminder, this is a Premium article and requires a subscription to read. There's no need for your 80s to be sad. Photo / 123RF Q: I am a twice-married woman of 70. I have not come out of either marriage settlement well. For six years now, I’ve been living with a friend in a large, comfortable home. However, it is not a great situation and I really need to be out of it. My problem is that I have three children with families who all live in the Auckland area, and I would like to be located so that I can see them easily. They all lived offshore for a long time and now they are all here. I am so lucky. I have all up around $1 million, although $100,000 is on loan to my daughter to enable her to buy a home. My only income is the pension (I guess you’ve heard this all before!), but I am hopeful of living these next few years as I would like to live. Clearly, my 80s look sad. I am English-born, lived in Australia and met my Kiwi husband and moved to NZ. My 20-year marriage ended, and five years later I met my second husband. We had a business together which was successful, but he mismanaged our funds (he being the only director) and then left to live a nomadic life! My circumstances need to be addressed. I do not know if renting is wise as I’d hate to continually move, and my money would only allow me to buy something tiny anywhere near my only family in NZ. Is there any solution to this? I have been harbouring this problem for far too long, and I must move on. A: Let’s set you on a more positive path – not just for now but for your future. There’s no need for your 80s or beyond to be sad. I think renting, rather than tying up your savings in a small property that doesn’t appeal to you, is the way to go. You’ve got $900,000 available now. If you plan to live on that from now until you’re 90, you could spend $45,000 a year – in addition to NZ Super - even if you were earning no return on the savings. But if you earn 3% a year, after fees and tax, you could spend $60,000 a year – or $5000 a month - according to an online regular withdrawal calculator. What about when you’re 90? Many people report they can live comfortably on just NZ Super at that stage – although they tend to be homeowners. But by then, it would surely be reasonable for your daughter to repay your $100,000 loan, which you could use to supplement your Super. There are a few issues to consider here: If you prefer to just put the lot in bank deposits, your return would probably average above 2% a year after tax, and you could spend $4500 a month. You can make this work! Footnote 1: Cash-poor retired homeowners might want to consider selling their homes and renting in much the same way. Many people wouldn’t dream of doing that. But they would have considerably more spending money. Footnote 2: In your story, there is a message for other women whose husbands run the money side of a joint business: Be involved. Please. Q: I write regarding last week’s letter about landlords being charitable for too long and needing to raise rents. Landlords need to remember that their market is individuals with limits on what they can pay in rent. These individuals are not a charity to support indigent landlords. Of course, landlords can raise rents, but they may not find tenants. I see this in the apartment block where I own my home. Rents range from $500 per week for a studio to $750 for a two-bedroom. Lovely tenants moved out because the landlord raised the rent at lease renewal time. Apartments have been vacant for weeks until landlords got more realistic and reduced the asking price, in at least one case to below the previous rent. My renting neighbours are professionals on good incomes, the only people who can afford to rent here. I am a single superannuitant and could not afford to rent an apartment in my building. As an owner, my outgoings are around $6500 per annum, which I can afford. Obviously, a landlord’s outgoings also include mortgage repayments. But with the substantial rents my neighbours pay, I am surprised that landlords can’t cover their costs, particularly now that interest is tax-deductible. Possibly some landlords didn’t look carefully at risks and returns and are too highly geared, but I don’t see why tenants should pay for landlords’ poor business decisions. A: Your observations are interesting. A key factor in how well a rental property investment works for the landlord is the size of their mortgage. With no mortgage, most rents would easily cover expenses, but with a large mortgage, the interest payments can kill the short-term profitability. On the other hand, the bigger the mortgage, the bigger the long-term return the landlord stands to gain on their original investment – as long as property values rise. That’s the risk highly geared property investors take. Usually it works, or certainly has in the past. But if property values fall or stagnate, landlords with big mortgages they are struggling to pay are sometimes forced to sell at a loss. Expecting tenants to rescue them by paying rent above market rates is unrealistic. Q: You get lots of letters from landlords that focus on the social service they are doing by having properties that people can rent. There is no question that we need a stock of rental properties, but there are two points that many seem to miss. The first is that landlords, when they purchase properties to rent out, add demand to a limited supply of properties, and help raise the price. Secondly, when they threaten to leave the market, they will argue that there will be fewer properties for people to rent. That’s not true if the property is bought by another landlord. And if it’s bought by someone moving from rental to home ownership, then there is also one less person looking to rent. Unless they decide to leave the property vacant - highly unlikely - the total number of houses does not change when a landlord exits the market. A: You’re quite right on both points. If someone wants to own more than one house – so they can rent one property out – that must push up demand, and therefore prices. Several other readers also made your second point. One added that, if a previous tenant is able to buy a house from a landlord who has left the market, “from an overall societal perspective, this is a very good thing”. Also, she says, “I understand that the new healthy homes regulations are persuading some landlords to sell. Brilliant.” More on landlords and tenants next week. Q: Many years ago, I would read your weekly NZ Herald Q&A commentary (back in the days when the paper was known as conservative Granny Herald). Your bias against residential rental property was evident. You pushed for a capital gains tax and now quite possibly want a wealth tax in NZ. I also recall that your underlying views appeared to be somewhat socialist. Beyond this, I appreciate that you were giving advice to those who were not as financially literate as yourself. Over the many years my rental properties have appreciated in value, and now that, at retirement, I am mortgage-free, I have plenty of income and the benefit of capital gains. Also excellent long-term tenants and nicely renovated properties. Landlords have been particularly demonised in the last 10 or so years, and a culture of envy has developed against those who work to get ahead. We now have so many on a benefit (including NZ Super) that we have become unproductive as a nation. So the few work hard to support those who either don’t want to work or who can’t. I chanced upon an item online from your column back on February 24 last year asking the question, “Should we, the uber-rich and ‘chauffeured’!, be retiring ... at 85!” - whilst I was researching how I can financially help family by setting up a super fund for them, here and in Oz. Surely you are taking the mickey and invented this story? Otherwise, the couple must have dementia or cognitive impairment to write this nonsense to you. If, by some stretch of the imagination, there was some truth to what this couple wrote, the only purpose in publishing it was to engender envy and hatred, or dismay at best. It is great to stir the pot of green envy in NZ, as the left need the support of their “besties”, the media, including columns like yours, to further their agenda. Also, no wonder trust in the media, as revealed in recent polls, is at an all-time low, including distrust of our institutions and politicians, who also introduce legislation by stealth. Not to mention experts whose comments are all “politicised” today, and a left-biased judiciary and universities. Constant cherry-picking, an unbalanced distortion of the facts, running to their own narrative and pushing their agenda. There are still more than a few of us who are immune to all the propaganda and were educated in free thought. I do fear many will be departing our shores, though, given the push to greater socialism and redistribution of wealth in this country, and the racial divisions and subsequent erosion of democracy. A: Gosh. It must be hard being unhappy with beneficiaries, people who get NZ Super, the media, institutions and politicians, the judiciary and universities. You’ve well and truly broken the 200-word limit for letters, but you raise some interesting points. My comments: You acknowledge that some people can’t work. Along with setting up financial help for your family, it would be wonderful if you donated to charities that support these people. It might make you happier – I mean that sincerely. * Mary Holm, ONZM, is a freelance journalist, a seminar presenter and a bestselling author on personal finance. She is a director of Financial Services Complaints Ltd (FSCL) and a former director of the Financial Markets Authority. Her opinions do not reflect the position of any organisation in which she holds office. Mary’s advice is of a general nature, and she is not responsible for any loss that any reader may suffer from following it. Send questions to mary@maryholm.com. Letters should not exceed 200 words. We won’t publish your name. Please provide a (preferably daytime) phone number. Unfortunately, Mary cannot answer all questions, correspond directly with readers, or give financial advice. Reminder, this is a Premium article and requires a subscription to read. OPINION: Buying your first home? Here's how to get there faster, without the strings.
--------------------------------------------------

Title: Ultimate Alexa Command Guide: 200+ Voice Commands to Take Control of Your Echo Devices
URL: https://www.cnet.com/home/smart-home/ultimate-alexa-command-guide-200-voice-commands-to-take-control-of-your-echo-devices/
Time Published: 2025-07-03T20:00:07Z
Full Content:
Our expert, award-winning staff selects the products we cover and rigorously researches and tests our top picks. If you buy through our links, we may get a commission. Reviews ethics statement Your Echo device is more versatile than you think. These Alexa commands can save you time and make daily life more manageable. Make the most of your Echo devices with these Alexa commands. Since its arrival in 2014, Alexa has changed drastically from the voice assistant that was originally released. Instead of being an easier way to trigger music, or add to your to-do list, it's now an effective tool for managing all the different parts of your busy life. With the addition of new AI-powered features from Alexa Plus, your favorite voice assistant is more capable than ever. From organizing your schedule to controlling smart devices, Alexa can help simplify your daily routine and bring a new level of convenience to your space. Whether you want to automate chores, manage your Fire TV, or just streamline your mornings, these advanced voice commands make Alexa a compelling tool in any connected home. If you haven't explored what it can do lately, now's a good time to see how much more useful it's become with AI-powered features now available. Though a recent CNET survey found that 73% of US adults using home voice assistants have privacy concerns about AI integrations, Alexa was the most trusted voice assistant among respondents. Want to unlock Alexa's full potential? You just need to learn the right commands. If you have an Echo device at home, here's a complete guide to all the voice commands worth trying. Amazon recently launched Alexa Plus, a major AI-powered upgrade to its voice assistant. This new version brings significantly improved conversational abilities and smart home control. The upgrade costs $19.99 monthly but is free for Amazon Prime subscribers. The upgraded system, first demoed back in 2023, can handle more complex requests, remember personal details and perform multiple actions through natural conversation. With these spring cleaning and organization features, Alexa+ aims to make managing your home more intuitive than ever. Notable new commands include: Prior to that, Amazon had announced new hardware products while also talking up a few new additions to the already vast Alexa commands library, including: By default, Amazon's connected speakers all have the same wake word. To cue up a request, just say, "Alexa." You can change the wake word to something else if, say, your own name is Alexa, or you'd just prefer an alternative. You can also trigger your smart assistant with Amazon, Echo or Computer. To change it, in the Alexa app go to Settings then Device Settings then select the Echo device you'd like to change the wake word on (you have to change each device's settings individually). If you have an Amazon Tap, Dash Wand or the Amazon Fire TV voice remote, you'll need to press a button to wake Alexa. Amazon updated the Tap with a hands-free mode that you must enable in the settings. The only wake word available to the Amazon Tap is Alexa. There's also a feature called Follow-Up Mode that makes it easier and faster to issue multiple commands to Alexa without having to keep repeating the wake word, if you enable it. When you do, Alexa will continue to listen for another command after it's completed your first request. You can keep issuing more commands until you're done or you say, "Stop." Amazon has also built on this a multiple commands feature by allowing you to string two related commands into one. You can say something like, "Alexa, play folk music at volume six," or, "Alexa, add bread, milk and eggs to my shopping list." Your Echo device can be convenient in the kitchen, the living room or anywhere for that matter. While the most obvious or natural way to use Alexa may be through an Echo speaker from Amazon, it's not the only way you can call up Amazon's digital assistant. In fact, there are more and more ways to access Alexa being created all the time, and you don't even need any specialized devices. Here are some of the most prominent ways to use Alexa with the devices you already have: You can enable the mobile apps to listen for Alexa when they're open (this will, however, disable your phone from listening for its native digital assistant's wake word -- i.e. "Hey, Siri" or "Hey, Google" won't work while you have the Alexa app open). Otherwise, you can tap the Alexa icon to call up the assistant. On an updated Windows computer, you can summon Cortana and say, "Open Alexa." After the initial connection is made, saying this will cue up Amazon's assistant through Cortana. Alexa Echo Auto allows you to connect your phone to Alexa in your car. The Echo Auto is capable of carrying out many of the same commands and features as your home device, but with some restrictions (it won't unlock your doors, for example). The list of Alexa commands is expansive and grows with every new service or device it supports. Alexa isn't perfect, but it's pretty great at understanding natural language, so you don't always have to speak the commands exactly as you see them below. Many commands work when worded several different ways or even with words omitted. When you consider the possible third-party commands through Skills -- essentially the apps of Amazon's Alexa -- the list goes on even further. To learn what individual skills are capable of, visit the skill's page from the Amazon Alexa app or alexa.amazon.com. Here are all the native Alexa commands. The Echo Show devices and Echo Spot are the only Echo speakers with touchscreen displays. This means you can tell them to show you things. You can ask your Echo show to show you things using voice commands. You can now use compatible Echo devices (Echo, Echo Dot, Echo Look, Echo Show and Amazon Tap) to control your Fire TV and Fire TV Sticks. Amazon also builds its Fire TV operating system into televisions like the Element EL4KAMZ17 series. All of the commands above work on those too, in addition to a few TV-specific commands below. Alexa commands also work with Fire TV products. You can make calls and leave voicemails to other Echo users, as well as "Drop In" to your own echo devices, either to voice or video chat with whoever's in the room (or just to monitor the space like a security camera). If you have an Android, you can send text messages with Alexa. Control purchases, shopping lists and notifications with your Echo device. To turn on notifications, open the Alexa app and select to Settings, then Notifications, then Shopping Notifications and toggle it on. Your Echo speakers will light up yellow when you have new notifications. Alexa can answer all of your music and movie-related questions. Kids can ask Alexa to play parent-approved music and stories with the Echo Dot Kids Edition. Alexa can integrate with loads of smart home platforms, such as SmartThings, Philips Hue, Wink, Insteon, Lutron, Belkin WeMo and many more. Some require you to enable skills, and some don't. Here is a selection of the commands you can use for controlling your smart home, although there are dozens more. Alexa can integrate with loads of smart home platforms and devices. Skills are third-party applications for Alexa speakers. They allow you to connect third-party software and hardware to your speaker, as well as play games and add different news sources to your Flash Briefing. Originally, they had to be enabled before you could use them, but Amazon has since made that process automatic (just ask for the Skill and it will enable when it's used). Microsoft's Cortana is available as a skill -- but rather than just being a skill, it opens the door to a completely separate digital assistant through your Alexa speakers. Once you've added the skill, enabled permissions and connected your Microsoft and Amazon accounts, just say, "Alexa, open Cortana." When you're speaking to Cortana you can check your emails, ask for the next event on your calendar or add items to your to-do list. For now, the Cortana skill is limited because it's a public preview of what the full integration will be in the future. Ring in the holiday season -- or the spooky season -- using you Echo devices. Alexa comes chock-full of Easter eggs and jokes -- the list is long. We cover the strange world of Alexa Easter eggs here, noting some of the more popular or prominent commands that prompt a snarky or humorous response. For even more, check out this Reddit thread dedicated to Alexa Easter eggs.
--------------------------------------------------

Title: AI #123: Moratorium Moratorium
URL: https://www.lesswrong.com/posts/9bbu9nebdSfXa8cKa/ai-123-moratorium-moratorium
Time Published: 2025-07-03T15:40:03Z
Description: Published on July 3, 2025 3:40 PM GMTThe big AI story this week was the battle over the insane AI regulatory moratorium, which came dangerously close to passing. Ultimately, after Senator Blackburn realized her deal was no good and backed out of it, the dam b…
--------------------------------------------------

Title: Uber Eyes Pony.ai’s U.S. Unit in Potential Deal Backing Founder Travis Kalanick
URL: https://finance.yahoo.com/news/uber-eyes-pony-ai-u-183155844.html
Time Published: 2025-07-02T18:31:55Z
Description: Uber Technologies, Inc. (NYSE:UBER) ranks among the best FAANG stocks to buy according to hedge funds. Bernstein maintained its $95 price target and...
--------------------------------------------------

Title: Nykaa's early investor to exit; VC funding rebounds in 2025
URL: https://economictimes.indiatimes.com/tech/newsletters/tech-top-5/nykaas-early-investor-to-exit-vc-funding-rebounds-in-2025/articleshow/122207847.cms
Time Published: 2025-07-02T13:58:41Z
Full Content:
Want this newsletter delivered to your inbox? Updated On Jul 02, 2025, 08:02 PM IST Want this newsletter delivered to your inbox? Thank you for subscribing to Daily Top 5We'll soon meet in your inbox. Hot on Web In Case you missed it Top Searched Companies Top Calculators Top Definitions Top Commodities Top Prime Articles Top Slideshow Top Story Listing Top Market Pages Latest News Follow us on:
--------------------------------------------------

Title: Animal Spirits: The Top 10 Risks to the Stock Market
URL: https://awealthofcommonsense.com/2025/07/animal-spirits-the-top-10-risks-to-the-stock-market/
Time Published: 2025-07-02T11:15:45Z
Full Content:
A Wealth of Common Sense Posted July 2, 2025 by Ben Carlson This episode is sponsored by Vanguard. Learn more at: https://vgi.vg/3GbOsYM The dollar is off to its worst start to a year since Bretton Woods ended in 1973 pic.twitter.com/k1G2eVQEv1 — Jake (@EconomPic) June 30, 2025 Interesting split: Growth sectors are outperforming in the US, while Value sectors are leading the rest of the world pic.twitter.com/ftgZwFEe1z — Mike Zaccardi, CFA, CMT 🍖 (@MikeZaccardi) June 25, 2025 Israel $EIS has been the best performing country ETF in our asset class matrix in the second quarter. Up 24.7%. 🔥 pic.twitter.com/fCuvmrpIvj — Bespoke (@bespokeinvest) June 30, 2025 "At year-end 2024, Individual Retirement Accounts (IRAs) and 401(k) plans accounted for 58% of the $44 trillion of total US retirement market assets" – GS pic.twitter.com/Tdt42U60hy — Sam Ro 📈 (@SamRo) June 23, 2025 Counter #'s The average college graduate is now 24 years old, up from 22 in the 1980s and 40%+ of graduates now go on to graduate school, compared to roughly 20 to 25% in the 1980s. Thus, the applicable bucket is 25-29 year olds where unemployment is near a record low. https://t.co/SQ2Wqr3MPK pic.twitter.com/fIZeqaWS3Z — Jake (@EconomPic) June 26, 2025 loan underwriters at freddie mac determining if an unemployed teenager has enough fartcoin to secure a mortgage. pic.twitter.com/8tRin6krYU — Dip Wheeler (@DipWheeler) June 25, 2025 Just released Q1 2025 NMDB data reveals: – 20.7% of mortgaged homes have a rate <3%– 32.7% have a rate 3.0 – 3.99%– 17.9% have a rate 4.0 – 4.99%– 9.9% have a rate 5.0 – 5.99%– 18.8% have a rate >= 6% 81% of mortgaged homes have a rate below 6%, that's down from the peak of… pic.twitter.com/3kCJZyL76P — Odeta Kushi (@odetakushi) June 30, 2025 Ever wonder if you should be tipping your Uber driver after a ride? Tipping on Uber rides is entirely optional, says CEO Dara Khosrowshahi, who addresses the growing question. While just over 20% of riders currently tip, that number is rising. Khosrowshahi emphasizes it’s a… pic.twitter.com/AYE9YKUlu3 — CBS Sunday Morning 🌞 (@CBSSunday) June 27, 2025 'THE SOCIAL NETWORK 2' is officially in the works Aaron Sorkin is returning to write, and also direct (via: Deadline) pic.twitter.com/8ggDWoVQAi — ScreenTime (@screentime) June 25, 2025 Follow us on Facebook, Instagram, and YouTube. Check out our t-shirts, coffee mugs, and other swag here. Subscribe here: Nothing in this blog constitutes investment advice, performance data or any recommendation that any particular security, portfolio of securities, transaction or investment strategy is suitable for any specific person. Any mention of a particular security and related performance data is not a recommendation to buy or sell that security. Any opinions expressed herein do not constitute or imply endorsement, sponsorship, or recommendation by Ritholtz Wealth Management or its employees. The Compound, Inc., an affiliate of Ritholtz Wealth Management, received compensation from the sponsor of this advertisement. Inclusion of such advertisements does not constitute or imply endorsement, sponsorship or recommendation thereof, or any affiliation therewith, by the Content Creator or by Ritholtz Wealth Management or any of its employees. Investing in speculative securities involves the risk of loss. Nothing on this website should be construed as, and may not be used in connection with, an offer to sell, or a solicitation of an offer to buy or hold, an interest in any security or investment product This content, which contains security-related opinions and/or information, is provided for informational purposes only and should not be relied upon in any manner as professional advice, or an endorsement of any practices, products or services. There can be no guarantees or assurances that the views expressed here will be applicable for any particular facts or circumstances, and should not be relied upon in any manner. You should consult your own advisers as to legal, business, tax, and other related matters concerning any investment. The commentary in this “post” (including any related blog, podcasts, videos, and social media) reflects the personal opinions, viewpoints, and analyses of the Ritholtz Wealth Management employees providing such comments, and should not be regarded the views of Ritholtz Wealth Management LLC. or its respective affiliates or as a description of advisory services provided by Ritholtz Wealth Management or performance returns of any Ritholtz Wealth Management Investments client. References to any securities or digital assets, or performance data, are for illustrative purposes only and do not constitute an investment recommendation or offer to provide investment advisory services. Charts and graphs provided within are for informational purposes solely and should not be relied upon when making any investment decision. Past performance is not indicative of future results. The content speaks only as of the date indicated. Any projections, estimates, forecasts, targets, prospects, and/or opinions expressed in these materials are subject to change without notice and may differ or be contrary to opinions expressed by others. The Compound Media, Inc., an affiliate of Ritholtz Wealth Management, receives payment from various entities for advertisements in affiliated podcasts, blogs and emails. Inclusion of such advertisements does not constitute or imply endorsement, sponsorship or recommendation thereof, or any affiliation therewith, by the Content Creator or by Ritholtz Wealth Management or any of its employees. Investments in securities involve the risk of loss. For additional advertisement disclaimers see here: https://www.ritholtzwealth.com/advertising-disclaimers Please see disclosures here. A Wealth of Common Sense is a blog that focuses on wealth management, investments, financial markets and investor psychology. I manage portfolios for institutions and individuals at Ritholtz Wealth Management LLC. More about me here. For disclosure information please see here. Email address: © 2025 A Wealth of Common Sense. Every month you'll receive 3-4 book suggestions--chosen by hand from more than 1,000 books. You'll also receive an extensive curriculum (books, articles, papers, videos) in PDF form right away.
--------------------------------------------------

Title: Ripple CTO Drops Bombshell On Pre-IPO Shares As Linqto Meltdown Explodes
URL: https://bitcoinist.com/ripple-cto-bombshell-pre-ipo-shares-linqto/
Time Published: 2025-07-01T17:30:03Z
Full Content:
Linqto’s once-celebrated promise to “democratize” (Ripple) pre-IPO investing is collapsing under the weight of federal probes, a looming bankruptcy filing and a furious customer base that now numbers roughly 13,000. According to an internal review first detailed by The Wall Street Journal, investigators for the Securities and Exchange Commission and the US Department of Justice are examining allegations that former chief executive William Sarris secretly marked up Ripple shares by more than 60 percent, sold customer stock without permission and promoted deals to thousands of investors who failed to meet accredited-investor standards. New management concedes that client accounts have been frozen since February and warns that a Chapter 11 filing could leave many investors as unsecured creditors. A March 14 press release from the company’s new leadership confirmed “pervasive securities-law violations,” the pausing of all trading and the dismissal of nearly half the staff while Linqto “explores all options to preserve value,” including court-supervised restructuring. The same statement insists that the special-purpose vehicles (SPVs) holding customers’ assets remain on issuer cap tables, but concedes that an independent forensic review is under way to verify that claim. Into that vacuum stepped attorney John E. Deaton, who told his X followers that the situation is a “total clusterfuck” and that roughly 11,500 Linqto users bought units in SPVs that, in turn, were supposed to own Ripple shares. Deaton says as many as 5,000 of those investors are non-accredited, creating “a regulatory compliance nightmare” now squarely on the SEC’s radar. He plans to host a live session at 3 p.m. EST today to detail what he calls a “heavily involved” enforcement action and to explain why simply refunding principal would strip investors of six- and seven-figure gains booked on private-share price appreciation. Ripple’s chief technology officer David Schwartz—better known online as “JoelKatz”—added fuel to the blaze by reminding holders that they never owned Ripple equity outright. “You don’t own the shares directly,” Schwartz wrote, “but you own a portion of a legal entity that owns the shares.” He elaborated, saying: “So if you ‘bought’ Z shares, you own X fraction of a legal entity with Y shares where X×Y=100. This generally lets you buy ‘shares’ more easily and in smaller quantities, but the equivalent per-share price is usually higher.” This clarification dismantled a key misconception among many Linqto clients who believed they were holding Ripple stock directly. The implications are now being examined not only by the SEC but also by customers who fear their indirect ownership could be rendered illiquid or encumbered in bankruptcy court. When pressed about whether those SPVs could be affected by Linqto’s financial collapse, Schwartz responded: “The legal entity that owns the shares that you own part of should not have exposure to Linqto going bankrupt. So a direct encumbrance on the shares to cover Linqto’s debts shouldn’t happen. But the entity may face operational challenges depending on exactly how it’s structured.” That operational risk is precisely what has many investors on edge. If trustees, custodians, or record-keepers tied to those SPVs are forced to restructure, change providers, or liquidate assets, investors may find themselves in prolonged legal limbo with no access to their holdings—even if the shares remain technically intact on the cap table. Complicating perceptions further, Schwartz addressed a separate thread linking billionaire George Soros to Ripple. He clarified that Soros Fund Management backed PolySign—another private company in which many Linqto users invested—during its 2022 acquisition of fund administrator MG Stover, but said he was “not aware of any Soros connection to Ripple.” Initially, Schwartz wrote: “It wouldn’t surprise me very much since his funds own bits of almost everything (Salesforce, Amazon, Google, JP Morgan, Goldman, Uber, FedEx, and many more), but I couldn’t find any actual connection.” However, after further reflection, he corrected himself: “Oh, wait, I remember now. Yes, Soros’ fund did invest in PolySign to help finance the acquisition of MG Stover! No connection to Ripple AFAICT though.” The deeper regulatory concern is structural. Linqto created more than 500 SPVs, each designed to pool hundreds of retail investors while keeping the underlying issuer’s shareholder count below the 2,000-owner threshold that triggers public-reporting obligations. Internal emails obtained by investigators show former executives exhorting staff to “take no prisoners” in sales campaigns—at times buying back Ripple shares from customers at $55 each, only to flip them to Ripple for $61, banking an $8 million spread. If those shares never made it into the SPVs—as suggested in confidential memos cited by investigators—questions of beneficial ownership, tax liability and voting rights could embroil Ripple itself in discovery. What happens next will hinge on three converging clocks: Linqto’s restructuring timetable, the SEC’s enforcement calendar and the pace at which SPV trustees can—or cannot—demonstrate clean title to almost half a billion dollars’ worth of private-company shares. Until then, thousands of would-be Ripple shareholders remain locked out of their accounts, watching from the sidelines as a legal and regulatory cyclone decides whether their “pre-IPO dream” survives or is wiped out in a courtroom ledger. At press time, XRP traded at $2.20. For updates and exclusive offers enter your email. Jake Simmons has been a Bitcoin enthusiast since 2016. Ever since he heard about Bitcoin, he has been studying the topic every day and trying to share his knowledge with others. His goal is to contribute to Bitcoin's financial revolution, which will replace the fiat money system. Besides BTC and crypto, Jake studied Business Informatics at a university. After graduation in 2017, he has been working in the blockchain and crypto sector. You can follow Jake on Twitter at @realJakeSimmons. Bitcoin news portal providing breaking news, guides, price analysis about decentralized digital money & blockchain technology. © 2025 Bitcoinist. All Rights Reserved.
--------------------------------------------------

Title: Coffee Break: OpenAI as The Money Pit
URL: https://www.nakedcapitalism.com/2025/06/open-ai-chatgpt-money-pit.html
Time Published: 2025-06-30T18:00:30Z
Full Content:
OpenAI has fatally flawed finances which reveal a company that presents no serious threat to any of the tech incumbents, including Google. In the (excellent) comments to my post last Monday on Google’s inexplicable-to-me decision to risk their search monopoly by going all-in on LLM AI one from Hickory exposed that I had failed to make a key point: ChatGPT is not a threat to replace Google as the leader in search because OpenAI loses money on every ChatGPT prompt and is trying to make it up in volume. Let’s put aside the claims about LLMs having reasoning ability for now and focus on the bullish business case for ChatGPT as a killer app that threatens Google search. Cal Newport lays out that case: The application that has… leaped ahead to become the most exciting and popular use of these tools is smart search. If you have a question, instead of turning to Google you can query a new version of ChatGPT or Claude. These models can search the web to gather information, but unlike a traditional search engine, they can also process the information they find and summarize for you only what you care about. Want the information presented in a particular format, like a spreadsheet or a chart? A high-end model like GPT-4o can do this for you as well, saving even more extra steps. Smart search has become the first killer app of the generative AI era because, like any good killer app, it takes an activity most people already do all the time — typing search queries into web sites — and provides a substantially, almost magically better experience. This feels similar to electronic spreadsheets conquering paper ledger books or email immediately replacing voice mail and fax. I would estimate that around 90% of the examples I see online right now from people exclaiming over the potential of AI are people conducting smart searches. This behavioral shift is appearing in the data. A recent survey conducted by Future found that 27% of US-based respondents had used AI tools such as ChatGPT instead of a traditional search engine. From an economic perspective, this shift matters. Earlier this month, the stock price for Alphabet, the parent company for Google, fell after an Apple executive revealed that Google searches through the Safari web browser had decreased over the previous two months, likely due to the increased use of AI tools. Keep in mind, web search is a massive business, with Google earning over $175 billion from search ads in 2023 alone. In my opinion, becoming the new Google Search is likely the best bet for a company like OpenAI to achieve profitability… That’s a seemingly reasonable claim, but doesn’t hold up after a look into OpenAI’s business plans for ChatGPT. Despite their seeming threat to Google search, OpenAI is the kind of self-defeating competition no monopolist should fear, much less destroy its proven business model to compete with. The New York Times put it pretty well last September: pic.twitter.com/As1hKPAqtB — Nat Wilson Turner (@natwilsonturner) June 30, 2025 Morningstar summed up the NYT’s reporting well: Financial documents reviewed by The New York Times reveal a company burning through cash at an alarming rate, raising questions about the sustainability of its current trajectory and the potential risks of prioritizing break-neck expansion over responsible AI development. Let’s discuss some of the key points from the New York Times report, which was published last week before the funding announcement: — OpenAI’s monthly revenue hit $300 million in August 2024, a 1,700% increase since early 2023. — The company expects to generate around $3.7 billion in annual sales this year and anticipates revenue ballooning to $11.6 billion in 2025. — Despite rising revenues, OpenAI predicts a loss of about $5 billion. this year due to high operational costs, biggest of which is the cost of computing power it gets through its partnership with Microsoft. — OpenAI predicts its revenue will hit $100 billion in 2029. The Times report raises serious questions about OpenAI’s sustainability and realistic goals. The company’s monthly revenue growth from early 2023 to August 2024 is nothing short of explosive; however, the long-term projection of $100 billion in revenue by 2029 appears unrealistic. This figure would require sustaining an average annual growth rate of more than 90% for five consecutive years (93.3% to be precise, from an expected $3.7 billion in 2024 to $100 billion in 2029), a feat rarely achieved in the tech industry, especially for a company already operating at such a large scale. While impressive on paper, said projections may be masking underlying financial challenges and setting expectations that could be difficult, if not impossible, to meet. Financial challenges become even more apparent given the current expense structure in relation to projected growth. It’s crucial to note that, even if it reaches the projected revenue targets, OpenAI is not merely failing to break even in 2024 – it’s losing significantly more money than it’s generating. This means that before OpenAI can even consider achieving its ambitious growth targets, it must first find a way to become profitable, or at the very least, break even. Bryan McMahon pointed out the massive financial risk posed by the stock market bubble driven by faith in LLMs or as he calls it Generative AI: Venture capital (VC) funds, drunk on a decade of “growth at all costs,” have poured about $200 billion into generative AI. Making matters worse, the stock market’s bull run is deeply dependent on the growth of the Big Tech companies fueling the AI bubble. In 2023, 71 percent of the total gains in the S&P 500 were attributable to the “Magnificent Seven”—Apple, Nvidia, Tesla, Alphabet, Meta, Amazon, and Microsoft—all of which are among the biggest spenders on AI. Just four—Microsoft, Alphabet, Amazon, and Meta—combined for $246 billion of capital expenditure in 2024 to support the AI build-out. Goldman Sachs expects Big Tech to spend over $1 trillion on chips and data centers to power AI over the next five years. Yet OpenAI, the current market leader, expects to lose $5 billion this year, and its annual losses to swell to $11 billion by 2026. If the AI bubble bursts, it not only threatens to wipe out VC firms in the Valley but also blow a gaping hole in the public markets and cause an economy-wide meltdown. But wait it gets worse, per Ed Zitron: It seems, from even a cursory glance, that OpenAI’s costs are increasing dramatically. The Information reported earlier in the year that OpenAI projects to spend $13 billion on compute with Microsoft alone in 2025, nearly tripling what it spent in total on compute in 2024 ($5 billion). This suggests that OpenAI’s costs are skyrocketing, and that was before the launch of its new image generator which led to multiple complaints from Altman about a lack of available GPUs, leading to OpenAI’s CEO saying to expect “stuff to break” and delays in new products. Nevertheless, even if we assume OpenAI factored in the compute increases into its projections, it still expects to pay Microsoft $13 billion for compute this year. This number, however, doesn’t include the $12.9 billion five-year-long compute deal signed with CoreWeave, a deal that was a result of Microsoft declining to pick up the option to buy said compute itself. Payments for this deal, according to The Information, start in October 2025, and assuming that it’s evenly paid (the terms of these contracts are generally secret, even in the case of public companies), this would still amount to roughly $2.38 billion a year. I’ll let the Entertainment Strategy Guy nail the profitability coffin shut: By all accounts, right now, OpenAI is losing money. Like literally billions of dollars. The energy costs of LLMs are enormous. If they’re pricing their services below market value, trying to gain market share, then we don’t know if AI can make money for the service it’s providing right now. Two factors are driving these costs. First, the memory an AI program uses (either the more data it stores as it thinks or the longer it thinks about a problem/answer), the more it costs the AI companies in compute. Second, the AI companies are racing to build next-generation models that will require even more training, which means higher costs. And the salaries for top AI engineers/scientists are also sky-rocketing up. This is why I’m somewhat skeptical about the sorts of things that OpenAI is promising that AI can do (like become your universal assistant that remembers everything about you); it seems like an absolute memory boondoggle of monumental proportions. How much energy will it take for AI to analyze my whole life if it’s already too taxing for an LLM to remember how to format links properly? But wait, there’s even more bad news that just dropped. OpenAI is now in a bidding war for talent with some of the stupidest money out there, Mark Zuckerberg of Meta: …competition for top AI researchers is heating up in Silicon Valley. Zuckerberg has been particularly aggressive in his approach, offering $100 million signing bonuses to some OpenAI staffers, according to comments Altman made on a podcast with his brother, Jack Altman. Multiple sources at OpenAI with direct knowledge of the offers confirmed the number. The Meta CEO has also been personally reaching out to potential recruits, according to the Wall Street Journal. “Over the past month, Meta has been aggressively building out their new AI effort, and has repeatedly (and mostly unsuccessfully) tried to recruit some of our strongest talent with comp-focused packages,” Chen wrote on Slack. And speaking of dumb money and OpenAI, Softbank is involved, although maybe not as much as reported: (In April) OpenAI closed “the largest private tech funding round in history,” where it “raised” an astonishing “$40 billion,” and the reason that I’ve put quotation marks around it is that OpenAI has only raised $10 billion of the $40 billion, with the rest arriving by “the end of the year.” The remaining $30 billion — $20 billion of which will (allegedly) be provided by SoftBank — is partially contingent on OpenAI’s conversion from a non-profit to a for-profit by the end of 2025, and if it fails, SoftBank will only give OpenAI a further $20 billion. The round also valued OpenAI at $300 billion. And things might not be going so well with Softbank because OpenAI is now talking to even dumber, and much more dangerous, money: Saudi Arabia. And if you’ve ever paid attention to the actual words coming out of OpenAI CEO Sam Altman’s mouth, you’ll realize Altman attracting dumb money is just a case of birds of a feather flocking together. Ed Zitron chronicles some of the stupid in his latest newsletter: Here is but one of the trenchant insights from Sam Altman in his agonizing 37-minute-long podcast conversation with his brother Jack Altman from last week: “I think there will be incredible other products. There will be crazy new social experiences. There will be, like, Google Docs style AI workflows that are just way more productive. You’ll start to see, you’ll have these virtual employees, but the thing that I think will be most impactful on that five to ten year timeframe is AI will actually discover new science.” When asked why he believes AI will “discover new science,” Altman says that “I think we’ve cracked reasoning in the models,” adding that “we’ve a long way to go,” and that he “think[s] we know what to do,” adding that OpenAI’s o3 model “is already pretty smart,” and that he’s heard people say “wow, this is like a good PHD.” That’s the entire answer! It’s complete nonsense! Sam Altman, the CEO of OpenAI, a company allegedly worth $300 billion to venture capitalists and SoftBank, kind of sounds like a huge idiot! Ed also roasts Alphabet/Google’s Sundar Pichai: Sundar Pichai, when asked one of Nilay Patel’s patented 100-word-plus-questions about Jony Ive and Sam Altman’s new (and likely heavily delayed) hardware startup: I think AI is going to be bigger than the internet. There are going to be companies, products, and categories created that we aren’t aware of today. I think the future looks exciting. I think there’s a lot of opportunity to innovate around hardware form factors at this moment with this platform shift. I’m looking forward to seeing what they do. We are going to be doing a lot as well. I think it’s an exciting time to be a consumer, it’s an exciting time to be a developer. I’m looking forward to it. The fuck are you on about, Sundar? Your answer to a question about whether you anticipate more competition is to say “yeah I think people are gonna make shit we haven’t come up with and uhh, hardware, can’t wait!” While I think Pichai is likely a little smarter than Altman, in the same way that Satya Nadella is a little smarter than Pichai, and in the same way that a golden retriever is smarter than a chihuahua. That said, none of these men are superintelligences, nor, when pressed, do they ever seem to have any actual answers. If ChatGPT were such an existential threat to Google’s search monopoly that Alphabet’s only option was risking the empire to beat OpenAI in the LLM race, it would be profitable or at least have a plausible path to profitability. Sam Altman being a blithering idiot isn’t really the disadvantage it should be since he’s going up against competition like Mark Zuckerberg, Elon Musk, and Sundar Pichai. This isn’t like Uber vs. the local taxi incumbents in the 2010s where despite Uber’s never going to be profitable business model they were able to take over in many markets because OpenAI does not have a huge cash advantage over Alphabet and never will. Next week we’ll look at at Meta, the absolute stupidest tech money around — a company that put Dana White of the Ultimate Fighting Championship on its board. And because I promised I’d get around to this, regarding LLMs ability to “reason” it was thoroughly debunked last October by six researchers from Apple in a paper called “GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models.” When the paper was released the senior author, Mehrdad Farajtabar, tweeted that, ““we found no evidence of formal reasoning in language models …. Their behavior is better explained by sophisticated pattern matching—so fragile, in fact, that changing names can alter results by ~10%!” Veteran political operative and corporate media professional. One of the Ed Zitron pieces you cited: https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/ while quite long, goes deep into the details of OpenAI’s present and future financing and how they expect to meet their financial commitments over the next two or three years. It left me in a funk for several days, not because I care a whit about OpenAI, but because the business press has now apparently become so delusional and dishonest that it’s hard to believe anything or even see how things can go on. After reading this, I have to conclude that OpenAI/Softbank is definitely, positively going to go out of business in the next two or three years. How much of the rest of the economy they take down with it is perhaps more worrisome. This is the same business press that covered Uber and Lyft breathlessly for 15 years as Uber burnt through money.. because they wanted the businesses to succeed. The will do the same thing with OpenAI until they magically find profit. Kurtismayfield, yea but I don’t think the overall economy has the runway that Uber had in the 2010s. Gonna be some reality checks sooner rather than later. Yea, the LLM bubble popping might be the end of the “Everything Bubble” that George Soros wrote a whole book about 20 years ago As a complement to this piece, I recommend this lengthy interview with technology journalist Karen Hao about her recent book “Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI”. thanks! I will check it out. Agreed. It was excellent. I’m not so sure that taking over search or even making money are the real goals of these people. We had a story in Links today about LLMs ability to ensnare the lonely or unhappy into “relationships” that seem quite real to the victims. That could prove a handy tool if you’re a tech billionaire trying to take over the world or even a government seeking to disable potential dissidents. One emerging dystopia is a world where tech billionaires use AIs to battle each other for world control. The LLMs would be useful for “converting” people to their cause, while another type of AI could control huge drone swarms that attack opponents’ data centers. Philip K. Dick could make a fun novel out of that possibility. excellent point. I’m always missing the story because I’m busy arguing the rational explanation. Like trying to evaluate today’s stonk market based on business fundamentals or betting on professional wrestling based on the athleticism of the performers. LLM’s ability to persuade might indeed be the killer app. What dark magick! That is in fact VULCAN’S HAMMER from 1959, or damned close to it, IIRC. It’s almost universally agreed to be Dick’s worst novel, for completions only. but Dick’s visionary abilities make even his least essential work of interest. It certainly wasn’t his mastery of prose. Apologies, I read the post before I saw your comment which I duplicated below. Karen Hao has substantial insights into the broader questions. “Second, the AI companies are racing to build next-generation models that will require even more training, which means higher costs.” “Training” Data mining that amounts to wealth transfers and even more opportunities for surveillance and control of the flow of information are going to be the main outcome. Yea Gary Marcus is saying surveillance is where OpenAI is headed, I’ll get into that in a future post although even there Palintir is way ahead of them and is infamously using AI widely in Gaza and everywhere else. There is a lot to be said for local inference. “Fast” and “easy” are not usually among them. I will say that the installation process is slowly getting easier for the suitably equipped general user, month by month. Consider also the possibility of OpenAI or other chatbot providers being a regulatory arbitrage bid with broader ambitions, sort of like Uber. The anti-AI partisans, supplied with scary developments by researchers, are helping create the conditions for the enclosure of local private computation, with the economic and surveillance effects you’d imagine. The “Singapore Consensus on Global AI Safety Research Priorities” only hints at this eventuality. It does speak plainly to the general desire for surveillance among the participants, and utters some other uncomfortably guild-like noises. yikes. It’s easy to dismiss some of the “OMG AI is totes going to take over the world” crap as the opposite side of the coin of the hype but you’re right. There are a lot of very scary possibilities being worked toward even as the business idiots defraud believers for billions. Of course that’s scary too as they’re risking yet another financial collapse. I love dooming with this community! Everyone here is smarter than me and I’m learning a ton in these comment sections. Such a pleasant change from the various ridiculous and highly toxic electorates, “targets” and fandoms I’ve been writing for these last 28 years. To see where all this AI stuff may be headed, a viewing of “Forbidden Planet” might be predictive. Their version ruined it’s creators, the Krell,. I haven’t seen that since I was a kid and I didn’t have a clue what it was about. will give it a shot now Seconded. Not only is it a beautiful movie with stunning hand-painted sets, credible spacecraft and a great robot, but also the issues it addresses are more relevant now than when the movie was made. Human hubris and the human subconscious make for a dangerous pairing. Transhumanist dreams become nightmares. And Anne Francis is smokin’ hot. ok then, my friend’s documentary is going to have to wait As a complete ignoramus in these matters, I have long assumed the most likely financiers of AI are going to to be the US and Chinese militaries. I imagine no self-respecting general is going to want to fight a war of the future without feeling he has the superior AI. Am I missing something? Palintir has certainly used AI as a “killer app” in Gaza. But I don’t know much about what type of AI — if it’s machine learning or LLMs or what. I suspect it’s some of all types. No intelligent general would depend on AI because LLM based AIs are always very convincing but one out of three times they are flat out wrong. These mistakes are sometimes called “hallucinations.” I was not thinking of LLMs, but other forms of AI. Palantir and the IDF don’t care about hallucinations or wrong data, they don’t view their targets as human so they don’t care if they get a few extra victims while they’re targeting a doctor or journalist’s family for a synchronized multi-site assassination. for genocidal purposes hallucinations are a feature, not a bug “one out of three times they are flat out wrong.” Seems like better results than those delivered by our present intelligence agencies (the surveillance and control bureaucracies). So we can guarantee about 100% of generals will buy into it. Especially once a the hint of post military career board positions are offered. A young man our family knew when he was a high school student in Ljubljana desperate to come to America and work on AI now, nearly 20 years later, has a Silicon Valley start-up working on voice recognition and mimicry. Wonder who’s interested in that. all kinds of fun people, I’m sure. From MI6 to the Sinaloa Cartel… I think you are right for two reasons: 1. Drones with target matching that can take over in case of broken communication would make one main anti-drone defence on the battlefield in Ukraine much less useful. (Machine learning, not a chatbot) 2. Accountability sink. When the need comes to massacre civilians or POWs, it’s useful if the machine kills and can be blamed. Also it saves on PTSD treatment for the soldiers. See Gaza. Don’t know the business aspects, but ISTM that building the models and running the models are two different things. I have a couple of open source Hugging Face-type models here locally that I run in the open source Python environment on NVidia cuda with 6 Gb VRAM, though you need 12 or even 18 Gb to really be productive. As far as online, I’ve found I’m using Google-AI from their search where I might have used Stack Overflow in the past for simple programming solutions. Don’t see any monetization opportunities for Google from my usage. On a large open source project I work on, one dev has a MS CoPilot account and runs all the commits through it prior to merging. I don’t see any earth-shaking insights from it but it does in the main offer useful ideas. You haven’t seen CoPilot producing hallucinations? Oddly, I’ve found for basic Python, OpenAI’s Codex and its GitHub integration work surprisingly well. It’s still clearly a very early product and you can’t for example independently push to a PR branch and get Codex to update its working branch, but whatever. I was only using it for pretty straightforward personal things. Some of us are so old we can remember twenty five years ago when the web was considered a libertarian alternative to traditional media and the open source movement an ultimate expression of this. I still regard it that way and about half my searches go to information aggregator Wikipedia which is produced by humans if not always trustworthy humans. But whatever it’s flaws, I’d say Wiki is a lot more trustworthy than a money making robot run by investor sharks. If AI isn’t about surveillance then what else could this impractical technology possibly be about? True, from the above, it sounds like it is merely about suckering stock buyers. Balzac said behind every great fortune is a great crime and then W.C. Fields said you can’t cheat an honest man. Welcome to our world. Wiki (and Reddit) has been heavily manipulated by the worst actors on Earth for decades now. See Who’s Editing Wikipedia – Diebold, the CIA, a Campaign — Wired 2007 There’s also the rumor that Ghislaine Maxwell was a huge moderator on Reddit which has never been confirmed, but this Vice article “debunking” it has many of the tropes of other “debunkings” (see Vox.com’s 2020 covid coverage, the suppression of the NY Post’s 2020 election eve Hunter Biden laptop story or MSNBC on Russiagate to this day). Use of terms like “incoherent and evidence-free conspiracy theory”, “The ‘evidence’ shared by conspiracy theorists”….sets off alerts in the part of my brain that triggers PTSD when the phrase “unprovoked invasion of Ukraine” is encountered. Counterpoint, the theory was pushed hard by this Utah MAGA Senate candidate who at a glance is walking the anti-Zionist/anti-Semite line a little to closely for my comfort. Like others I don’t get much out of Reddit. And of course we all know about how Wales is not to be trusted and how Wikipedia is manipulated by the spooks. But also of course there are countless topics on Wikipedia that have nothing to do with the spooks. Everything is manipulated now to some degree but some formats are less susceptible than others. Walter Cronkite once said he picked all the stories for the evening news from that day’s NY Times. Now the Times is a joke https://www.moonofalabama.org/2025/06/nyt-guessing-about-iran-with-experts-who-lack-knowledge-of-it.html and we webians have to become our own gatekeepers and editors rather than rely on that dubious “first draft of history” (which I too once read avidly). Computers are a tool. You control them or they control you. my difficulty is dealing with normies who don’t become their own gatekeepers. watching the democrats go blue maga in the 2016-2024 era was pretty awful since that was my closest family and friends my GOP family and friends were always at a bit of an arm’s remove, cousins not siblings I think you’ll find the full-fat version is “Vladimir Putin’s brutal, unprovoked invasion of Ukraine”. Extra points for later references to Putin’s Chef, Putin’s Banker, Putin’s Thinker and other variations on his imagined menagerie of stock villain characters. Karen Hao, in an interview with Novara Media UK offers substantial information on the AI situation. Silicon Valley Insider Exposes Cult Like AI Companies As Artificial Intelligence begins to fundamentally alter the way normal people live their lives, it’s often talked about in terms of boom and doom, which makes a nuanced examination difficult. The problem with AI is that the understanding required to scrutinise the technology is rare and even if one does have that understanding, the ability to clearly communicate it is even rarer. This week’s guest has been both a worker in, and reporter on the tech industry and is uniquely poised to present a nuanced and informed analysis of this rapidly expanding industry. In her new book, ‘Empire of AI’, Karen Hao debunks myths that surround AI and exposes us to the full breadth of this global industry, from it’s cult-leader like CEOs to the workers that power the technology. She sat down with Aaron to talk about Sam Altman’s origin story, the traumatising nature of content moderation work and the striking similarities between Open AI and the British East India Company. IMO there is a case for LLMs becoming profitable but it involves injecting ads/propaganda directly into the answers. I’m sure companies and governments would pay large amounts of money to make sure that a model is biased in a way that directly benefits them. Of course, it requires getting to the point where people don’t have any alternatives to go back to. This makes Google’s destruction of the open web make sense on multiple levels The Sam Altman and Sundar Pichai quotes reminded me of this NewsRadio clip from the 90s: https://www.youtube.com/watch?v=lE1bS-Mn2Mk It would be funny if they weren’t running some of the biggest and most powerful companies in the world. I mean it’s easy to beat Google search these days because it’s been completely enshittified. I use Kagi – paying $100/year but I will never get a single ad. It’s like Google when Google was actually good. Well worth it. I’m doing the same, although on the monthly plan and never switched to annual. Worth noting unlike Neeva, Kagi doesn’t spider itself and just uses feeds from Google, Microsoft Bing, and a few others I think. Nonetheless, not being the product is worth paying $10 a month for. The specific survival of OpenAI isn’t of any particular interest to me personally, but DeepThink’s achievement of a 30x improvement in cost for training an effective model showed that the link between performance improvement and cost for such a new technology is not something that should be projected forward with any confidence. Whether that will save OpenAI itself, again, to me, who cares, but it seems likely to be relevant to the future ubiquity of the technology itself. DeepThink or DeepSeek? DeepSeek! Thank you Just clarifying because they’re very different animals. Very hard to tell how much of the claims made by DeepSeek are true. There is a true fog of propaganda war over that topic at the moment. It seems likely they did achieve significant efficiencies. It also seems entirely plausible that they did take advantage of OpenAI and others’ training data so it might not be replicable. This was my first thought. Just because chatgpt is unprofitable and expensive to operate now doesn’t mean that’s baked in to LLMs or “AI”. anyone who wants to evaluate whether it is wise for google to adopt LLMs in search needs to look at best-in-class in terms of cost like deepseek. Someone recently said the cost of AI converges to the cost of electricity over time. Deepseek’s improvements likely will be adopted by google eventually. What does the profitability look like at this point? I agree with many of the points in this article, but pointing out chatgpt’s unprofitability isn’t convincing. It’s very early stages and Chinese firms clearly show there’s massive room for cost savings. I saw one estimate that deepseek query costs are 3% of Chatgpt’s, so I think google’s decision should be judged with that future efficiency rate. also, whether or not chatgpt is a threat to google isn’t the issue. It’s whether LLMs and related ai tech is a threat, especially with 97% reduced query costs, and I think the answer is obviously yes. Natural language queries and responses are far more intuitive for most users and use cases than inputting a phrase and browsing links. Compare with asking “where is the nearest home depot” and being given the answer. It would be good to be skeptical of the reported cost advantages of Deepseek. I looked at it for my applications, which relate to cyber security for industrial control systems, and I was astounded by its ability to “reason.” (I’m going to sidestep here why I put quotes around “reason,” except to say the capability is valuable, even if it is not what humans do.) Back in February, my firm expectation was that every other engine would acquire the same reasoning capabilities within weeks or months. The fact that they have come nowhere close is suggestive that the cost advantages of Deepseek are not what they were claimed to be. A chunk of LLM API requests get redirected from places where money is real to OpenAI where the charges are on the order of 1/6 the price. Setting up your own compute to run your own models locally is pretty pricey, so if OpenAI craters it’s going to cause some pain in certain products currently subsidized by the magic of Silicon Valley. built in lack of resilience to the industry. OpenAI collapsing could be a singularity that pulls a lot of peripheral companies down into a black hole with it. “oops not the singularity we promised, does a minsky moment count?” Great post this and reading it, I can see a future direction that they will go in. That they will want the user to talk to the AI instead of just hammering on keys. That, come to think of it, was featured in the 2013 film “Her” which had a computer AI- https://en.wikipedia.org/wiki/Her_(2013_film)#Plot They say that they want more training sets to make their AI better but where will those come from? They have ransacked the internet now and slurped it all up. They haven’t even set up standards for AI yet and we are still in the bananas stage- https://www.theregister.com/2025/06/27/bofh_2025_episode_12/ that’s one of the reasons Gary Marcus has known all along that the mass compute/big money/big scale approach wouldn’t work. they’re out of content to train on and the more the LLM generated content gets mixed in the worse the output gets There is lots of content left to train on. But it isn’t openly accessible stuff. Think of all the NHS data palantir will now get it’s hands on. All the data that various governments store. All the data corporations store. Hell even think about all the messages that get sent in Whatsapp and similar every day. All of that data is out that and not currently accesible. But it will be. and private phone conversations! I suspect Palintir, Meta, Alphabet, Amazon and others are grabbing “training data” that would shock and appall even the most jaded of us Oh, the Dems love “labor,” because the honchos give them (dues) money to run their campaigns during which they mouth platitudes about “working families.” But as far as supporting actual rank and file workers, not at all. You see these union politicians like Sean Fain (yes, he is for all intents and purposes a Dem Party neoliberal politician). The Dems co-opted the unions, and deal almost exclusively with high- and medium-level hacks like Fain, who think like they do. Please do not leave off topic comments. The place for this is Links. This is called thread-jacking and is a violation of our written site Policies. And there is this: Potemkin Understanding in Large Language Models As a search engine it’s OK at best, but in other regards it’s really not very reliable. this persuading people to believe crazy nonsense might be the killer app I failed to see when I did the initial post. very scary but as someone who’s spent decades in the “get attention > attempt to persuade” field I can see where that’s a high margin business provided they can cut way way down on the compute costs and energy burn. but I’m not sure the lack of need for high quality content relates to any technical cost savings. Anyone know? People already believe crazy nonsense Who needs AI? Well per MIT Technology Review “AI can do a better job of persuading people than we do: OpenAI’s GPT-4 is much better at getting people to accept its point of view during an argument than humans are—but there’s a catch.” There is a huge market to be able to control exactly what crazy nonsense specific individuals believe. This could replace advertising completely — provided they can dramatically reduce cost and energy use. Big provisions. Re tweet that the behavior of LLMs is best explained as “sophisticated pattern matching.” I agree with that, but I think a better and more incisive way of explaining LLMs is to simply say that they are all about mimicry. They are consummate con artists. They can sound just like a doctor without knowing medicine. They can sound just like a PhD without even knowing how to reason or think. Is that some huge human achievement, that we have developed a computer program that can mimic doctors and PhDs without actually knowing anything? To me, the answer is no. It’s not much of an achievement at all to develop automated con artists. Why do we need automated con artists that sound convincing but know nothing and have no value other than how convincing they sound? Several years back i overheard a senior enginer explaining to a junior one that “the key to being s consultant isn’t knowing more than the client, it’s bullshitting them that you know more”. Perhaps AI is kust a reflection of where society has already gone. it might be an achievement along the lines of Dr Frankenstein’s. I don’t pay any attention to the AI “features” in Google search, though that’s getting more and more difficult over time, because I don’t trust it not to make stuff up. I’m surprised more people aren’t likewise leery of it. word is getting out but reptition is the most powerful form of persuasion according to some and the whole tech industry is pushing this stuff on us over and over and over and over “The energy costs of LLMs are enormous.” Amongst all their BS and hype I can’t look past the energy aspect. Where will the affordable energy come from to power all of the data centres as they store increasing amounts of data, and the more data AI has to interrogate the more it consumes energy to ‘think’ (just consumes an increasingly larger amount of energy as it learns and grows)? The more I listen to energy experts discuss energy demand and affordable clean energy (is anything really clean considering the resources we dig up to build solar/wind capture infrastructure) the more I think AI will be limited by (clean/cleanish) energy availability. Based on current trends, humans will be limited by energy availability because AI has priority. Your email address will not be published. Required fields are marked * Comment * Name * Email *
--------------------------------------------------

Title: Google Stock Is a High-Growth Story With Room to Run in 2025
URL: https://www.barchart.com/story/news/33126272/google-stock-is-a-high-growth-story-with-room-to-run-in-2025
Time Published: 2025-06-30T17:29:31Z
Description: This trillion-dollar company is still considered a growth story.
--------------------------------------------------

Title: Make Fun of Them
URL: https://www.wheresyoured.at/make-fun-of-them/
Time Published: 2025-06-30T15:25:03Z
Full Content:
Have you ever heard Sam Altman speak? I’m serious, have you ever heard this man say words from his mouth? Here is but one of the trenchant insights from Sam Altman in his agonizing 37-minute-long podcast conversation with his brother Jack Altman from last week: When asked why he believes AI will “discover new science,” Altman says that “I think we’ve cracked reasoning in the models,” adding that “we’ve a long way to go,” and that he “think[s] we know what to do,” adding that OpenAI’s o3 model “is already pretty smart,” and that he’s heard people say “wow, this is like a good PHD.” That’s the entire answer! It’s complete nonsense! Sam Altman, the CEO of OpenAI, a company allegedly worth $300 billion to venture capitalists and SoftBank, kind of sounds like a huge idiot! “But Ed!” you cry. “You can’t just call Sam Altman an idiot! He isn’t stupid! He runs a big company, and he’s super successful!” My counter to that is, first, yes I can, I’m doing it right now. Second, if Altman didn’t want to be called stupid, he wouldn’t say stupid shit with a straight face to a massive global audience. My favourite part of the interview is near the beginning: This is a nonsensical conversation, and both of them sound very, very stupid. “So, is this going to make new science or make science faster?” “Yeah, I hear scientists are using AI to go faster [CITATION NEEDED], but if a human scientist goes three times faster [CITATION NEEDED] using my model that would be good. Also I heard from a guy that he heard a guy who did biology who said ‘this helped.’” Phenomenal! Give this guy $40 billion or more dollars every year until he creates a superintelligence, that’ll fucking work. Here are some other incredible quotes from the genius mind of Sam Altman: This is gobbledygook, nonsense, bullshit peddled by a guy who has only the most tangential understanding of the technology his company is building. Every single interview with Sam Altman is like this, every single one, ever since he became a prominent tech investor and founder. Without fail. And the sad part is that Altman isn’t alone in this. Sundar Pichai, when asked one of Nilay Patel’s patented 100-word-plus-questions about Jony Ive and Sam Altman’s new (and likely heavily delayed) hardware startup: The fuck are you on about, Sundar? Your answer to a question about whether you anticipate more competition is to say “yeah I think people are gonna make shit we haven’t come up with and uhh, hardware, can’t wait!” While I think Pichai is likely a little smarter than Altman, in the same way that Satya Nadella is a little smarter than Pichai, and in the same way that a golden retriever is smarter than a chihuahua. That said, none of these men are superintelligences, nor, when pressed, do they ever seem to have any actual answers. Let’s see what Satya Nadella of Microsoft answered when asked about how exactly it’s going to get to (and I paraphrase Dwarkesh Patel’s mealy-mouthed question) $130 billion in AI revenue “through AGI”: This quote has been used as a means of suggesting that Nadella is saying that “generative AI is generating basically no value,” which, while somewhat true, obfuscates its true meaning: Satya Nadella isn’t saying a fucking thing. The question was “how do you get Microsoft to $130 billion in revenue,” and Satya Nadella’s answer was to say “uhhh, abundance, uhhh, explosion, uhhhhh, GDP! Growth! Industrial revolution! Inflation-adjusted! Percentages! The winners will be the people who do stuff, and then productivity will go up!” This is fucking nonsense, and it’s time to stop idolizing these speciously-informed goobers. While kinder souls or Zitron-haters may read this and say “ahh, actually, what Nadella was saying was…” stop. I want to stop you there and suggest that perhaps a smart person should be able to speak clearly enough that their intent is obvious. It’s tempting to believe that there is some sort of intellectual barrier between you and the powerful — that the confusing and obtuse way that they speak is the sound of genius, rather than somebody who has learned a lot of smart-sounding words without ever learning what they mean. “But Ed, they’re trained to do this!” As someone who has media trained hundreds of people, there is only so much you can do to steer someone’s language. You cannot say to Sundar Pichai “hey man, can you sound more confusing?” You can, however, tell them what not to talk about and hope for the best. Sure, you can make them practice, sure, you can give them feedback, but people past a certain stage of power or popularity are going to talk however they want, and if they’re a big stupid idiot pretending to be smart, they’re going to sound exactly like this. Why? Because nobody in the media ever asks them to explain themselves. When you’ve spent your entire career being asked friendly-or-friendly-adjacent questions and never having someone say “wait, what does that mean?” you will continue to mutate in a pseudo-communicator that spits out information-adjacent bullshit. I am, to be clear, being very specific about that question. Powerful CEOs and founders never, ever get asked to explain what they’re saying, even when what they’re saying barely resembles an actual answer. Pichai, Altman and Nadella have always given this kind of empty-brained intellectual slop in response to questions because the media coddles them. These people are product managers and/or management consultants — and in Altman’s case, a savvy negotiator and manipulator known for “an absenteeism that rankled his peers and some of the startups he was supposed to nurture” as an investor at yCombinator, according to the Washington Post. By “coddle,” I mean these people are deliberately engaging in a combination of detective work and amnesia, where the reader or the listener is forced to simultaneously try and divine the meaning of their answer, while also not thinking too hard about the question the interviewer asked. Look at most modern business interviews. They involve a journalist asking a question, somebody giving an answer, and the journalist saying “okay!” and moving onto the next question, occasionally saying “but what about this?” when the appropriate response to many of the answers is to ask them to simplify them so that their meaning is clearer. A common response to all of this is to say that “interviewers can’t be antagonistic,” and I don’t think a lot of people understand what that means. It isn’t “antagonistic” to ask somebody to clearly articulate what they’re saying, nor is it “antagonistic” to say that you don’t understand, or that they didn’t answer the question you asked. If this is “antagonistic” to you, you are, intellectually-speaking, a giant fucking coward, because what you’re suggesting is that somebody cannot ask somebody to explain themselves, which is what an interview is. And I imagine nobody really wants to do this, because if you actually put these people on the spot, you’d realize the dark truth that I spoke of a few weeks ago: that the reason the powerful sound like idiots is because, well, they’re idiots. They sound like Business Idiots and create products to sell to Business Idiots, because Business Idiots run most companies and buy solutions based on what the last Business Idiot told them. To quote the excellent Nik Suresh: I know some of you might read this and say “these people can’t be stupid! These people run companies! They make huge deals! They read all these books!” and my answer is that some of the stupidest people I’ve ever met have read more books than you or I will read in a lifetime. While they might be smart when it comes to corporate chess moves or saying “this product category should do this,” none of these men — not Altman, Pichai or Nadella — actually has a hand in the design or creation of any of the things their companies make, and they never, ever have. Regardless, I have a larger point: it’s time to start mocking these people and tearing down their legends as geniuses of industry. They are not better than us, nor are they responsible for anything that their companies build other than the share price (which is a meaningless figure) and the accumulation of power and resources. These men are neither smart nor intellectually superior, and it’s time to start treating them as such. These people are powerful because they have names that are protected by the press. They are powerful because it is seen as unseemly to mock them because they are rich and “running a company,” a kind of corporate fealty that I find deeply unbecoming of an adult. We are, at most, customers. We do not “owe them” anything. We are long past the point when any of the people running these companies actually invented anything they sell. iIf anything, they owe us something, because they are selling us a product, even if said product is free and monetised by advertising. While reporters — as anyone — should have some degree of professionalism in interviews or covering subjects, there is no reason to treat these people as special, even if they have managed to raise a lot of money or their product is popular, because if that were the case we’d have far more coverage of defense contractor Lockheed Martin. It made $1.71 billion in profit last quarter, and hasn’t had a single quarter under a billion dollars in the last year. I’m being a little glib, but the logic behind covering OpenAI is, at this point, “it makes a lot of money and its product is popular,” which is also a fitting description of Lockheed Martin. The difference is that OpenAI has a consumer product that loses billions of dollars, and Lockheed Martin has products that makes billions of dollars by removing consumers from the Earth. Both of them are environmentally destructive. Covering OpenAI sure doesn’t seem to be about the tech, because if you looked at the tech you’d have to understand the tech, you’d see that the user numbers weren’t there outside of the 500 million people using ChatGPT, of which very few are actually paying for the product, and that the term “user” encompasses everything from the most occasional users who log in out of curiosity, to people who are actually using it as part of their daily lives. If covering OpenAI was about the tech, you’d read about how the tech itself doesn’t seem to have a ton of mass-market use cases, and those use cases aren’t really the kind of things that you’d pay for. If they did, there’d be articles that definitively discussed them versus articles in the New York Times about “everybody using AI” that boil down to “I use ChatGPT as search now” and “I heard a guy who asked it to teach him about modern art.” Yet men like Dario Amodei and Sam Altman continue to be elevated because they are “building the future,” even if they don’t seem to have built it yet, or have the ability to clearly articulate what that future actually looks like. Anthropic has now put out multiple stories suggesting that its generative AI will “blackmail” people as a means of stopping a user from turning off the system, something which is so obviously the company prompting its models to do so. Every member of the media covering this uncritically should feel ashamed of themselves. Sadly, this is all a result of the halo effect of being a Guy Who Raised Money or Guy Who Runs Big Company. We must, as human beings, assume that these people are smart, and that they’d never mislead us, because if we accept that they aren’t smart and that they willingly mislead us, we’d have to accept that the powerful are, well, bad and possibly unremarkable. And if they’re untrustworthy people that don’t seem that smart, we have to accept that the world is deeply unfair, and caters to people like them far more than it caters to people like us. We do not owe Satya Nadella any respect because he’s the CEO of Microsoft. If anything, we should show him outright scorn for the state of Microsoft products. Microsoft Teams is an insulting mess that only sometimes works, leaving workers spending 57% of their time either in Teams Chat, Teams Meetings or sending emails according to a Microsoft study. MSN.com is an abomination read by hundreds of millions of people a month, bloated with intrusive advertisements, attempts to trick you into downloading an app, and quasi-content that may or may not be AI generated. There are few products on the modern internet that show more contempt for the user -- other than, of course, Skype, a product that Microsoft let languish for more than a decade, the product so thoroughly engorged with spam that leaving it unattended for more than a month left you with a hundred unread messages from Eastern European romance scammers. Microsoft finally killed it in May. Products like Word and Excel don’t need improving, but that doesn’t stop Microsoft from trying, bloating them with odd user interface choices and forcing users to fight with popups to use an AI-powered Copilot that most of them hate. Why, exactly, are we meant to show these people respect? Because they run a company that provides a continually-disintegrating service? Because that service has such a powerful monopoly that it’s difficult to leave it if you’re interacting with other people or businesses? I think it’s because we live in Hell. The modern tech ecosystem is so utterly vile. Every single day our tech breaks in new and inventive ways, our iPhones resetting at random, random apps not accepting button presses, our Bluetooth disconnecting, our word processors harassing us to “try and use AI” while no longer offering us suggestions for typos, and our useful products replaced with useless shit, like how Google’s previously-functional assistants were replaced with generative AI that makes them tangibly worse so that Google can claim it has 350 million monthly active Gemini users. Yet the tech and business media acts as if everything is fine. It isn’t fine! It’s all really fucked! You can call me a cynic or a pessimist or every name under the sun, but the stakes have never been higher, and the damage never more wide-spread. Everything feels broken, and covering these companies as if it isn’t is insulting to your readers and your own intelligence. Look at the state of your computer or phone and tell me anything feels congruent or intentional rather than an endless battle of incentives. Look at the notifications on your phone and count the number of them that have absolutely nothing to do with information you actively need. As we speak, I have a notification from Adobe Lightroom, an app I use occasionally to edit photos, that tells me “Elevate any scene - now enhance people, sky, water and more with Quick Actions.” Zerocam, an app that brands itself “the first anti-AI camera app” where you “capture moments, not megapixels,” gave me a notification asking if I took a photo today. Amazon notified me that there is a deal picked just for me — a battery pack that I bought several months ago. Every single company that sends notifications like these should be mocked, but we have accepted such vile conditions as the norm. Apple should be tarred and feathered for allowing companies to send spam notifications, and yet it isn’t because, by and large, Apple is less vile and less exploitative than Microsoft, Google or Amazon. If you are reading this as a member of the tech press, seriously, please look at your daily experience with tech. Count the number of times that your day or a task is interrupted by poorly-designed software or hardware (such as the many, many times Zoom or Teams has a problem with Bluetooth, or a website just doesn’t load, or you type something into your browser and it just doesn’t do anything), or when the software you use either actively impedes you (hey, did you want to use AI? No? You sure?) or refuses to work in a logical way (see: Google Drive). There are tens of thousands of stories like this every day, and if you talked to people, you’d see how widespread it is…or maybe, I dunno, see that it’s happening to you too? There are people responsible, and the tech media writes about them every day. I realize it seems weird to constantly write that a company is releasing broken, convoluted software, but hey, if we can write 300,000 stories about how crime-ridden New York City is, why can’t we write three of them about how fucked Microsoft Office or Google Search have become? And why can’t we talk to the people in power about it? Is it because the questions are too hard to ask? Is it because it feels icky to interrupt Satya Nadella as he waffles on about using Copilot all the time by saying “hey man, Microsoft Teams is broken, tons of people feel this way, why?” or “why have you let MSN.com turn into a hub of AI slop and outright disinformation?” Oh no! You won’t get your access! Wahh! Who cares? Write a story about how Microsoft has become so unbelievably profitable as its products get worse, and talk about how weird and bad that is for the world! Ask Nadella those tough questions, or publish that Microsoft’s PR wouldn’t let you! These people are neither articulate nor wise, and whatever “intelligence” they may claim to have doesn’t seem to manifest in good products or intelligent statements. So why treat them like they’re smart? Why show them deference or pleasantries? These people have crapped up our digital lives at scale, and they deserve contempt, or at the very least a stern fucking reception. I realize I’m repeating points I’ve made again and again, but why is there such a halo around these fucking bozos? I’m serious! Why are we so protective of these guys? We’re more than happy to criticise celebrities, musicians, professional sports players, and politicians (fucking barely), but the business class is somehow protected outside of the occasional willingness to say that Elon Musk might have sort have done something wrong. I’m not denying there are critics. We have Molly White, Edward Ongweso Jr, Brian Merchant and — at a major outlet like CNN, no less! — one of the greatest living business writers in Allison Morrow. I believe that tech criticism is a barely-explored and hugely-profitable industry if we treated tech journalism less like the society pages and more like a force to hold the most powerful people in the world accountable as they continually harm billions of people in subtle ways. People are angry, and they aren’t stupid, and they want to see that anger reflected in the stories they read — and the meek deference we show to dumb fucking tech leaders is the opposite of that. As I’ve said before: we live in an era of digital tinnitus, nagged by notifications, warring with software ostensibly built for us that acts as if we’re the enemy. And if we’re the enemy, we should treat those building this software as the enemy in return. We are their customers, and they have failed us. The entire approach to business owners, especially in tech, is ridiculous. These people are selling us a product and the product fucking stinks! Put aside however you feel about generative AI for a second and face one very simple point: it doesn’t do enough, it’s really not cool at all, and we’re being forced to use it. I realize that some of you may want them to succeed, or want to be the person who tells everybody that they did so. I get that there are rewards for you — promotions, new positions, TV appearances repeating exactly what the powerful did and why they did it, or a plush role as that company’s head of communications — but I am telling you, your readers and viewers are waking up to it, and they feel like you have contempt for them and contempt for the truth. It’s easy — and common! — to try and dismiss my work as some sort of hater’s screed, a “cynical” approach to a tech industry that’s trying “brave new things” or whatever. In my opinion, there’s nothing more cynical than watching billions of people get shipped increasingly-shitty and expensive solutions and then get defensive of the people shipping them, and hostile to the people who are complaining that the products they use suck. I am angry at these companies because they have, at scale, torn down a tech industry that allowed me to be who I am today, and their intentional and disgraceful moves fill me full of disgust. I have watched the tech media move away from covering “technology” and more toward covering the people behind it, to the point that the actual outputs — the software and hardware we use every day — have taken a backseat to stories about whether Elon Musk does or doesn’t use a computer, which is meaningless, empty gossip journalism built to be shared by peers and nothing else. And please, please do not talk about optimism. If you are blindly saying that everything OpenAI does is cool and awesome and interesting, you aren’t being optimistic — you’re telling other people to be optimistic about a company’s success. It isn’t “optimistic” to believe that a company is going to build powerful AI despite it failing to do so. It’s propaganda, and yes, this is also the case if you simply don’t do the research to form a real opinion. I am not a pessimist because I criticize these companies, and framing me as one is cowardly and ignorant. If you are so weak-willed and speciously-informed that you can’t see somebody criticise a company without outright dismissing them as “a hater” or “pessimist,” you are an insult to journalism or analysis, and you know it in your wretched little heart. My heart sings with a firm belief in the things I think, founded on rigorous structures of knowledge that I’ve gained from reading things and talking to people, because something in me is incapable of being swayed by something just because everybody else is. You are assuming people are right because it is inconvenient and uncomfortable to accept they may not be, because doing so requires you to reckon with a market-wide hysteria founded on desperation and a lack of hyper-growth markets left in the tech industry. Worse still, in engaging with faux-optimism, you are failing to protect your readers and the general public. And if that’s what you want to do, ask yourself why! Why do you want these companies to win? What is it you want them to win? Do you want them to be rich? Do you want to be the person that told people they would be first? What is the world you want, and what does it look like, and how does doing your job in this way work toward creating that world? This isn’t optimism — it’s horse-trading, or strategic alignment behind powerful entities. It is choosing a side, because your side isn’t with the reader or the truth. If it was — even if you believed generative AI was powerful and that they simply didn’t understand — your duty would be to educate the reader in a clear-set and obvious way, and if you can’t find a way to do so, acknowledging that and explaining why. True optimism requires you to have a deep, meaningful understanding of things so that you can engage in real hope — a magical feeling, one that can buoy you in the most challenging times. What many claim is “optimism” is actually blind faith, the likes of which you’ll see at a roulette table. Or, of course, knowingly peddling propaganda. Let’s even take a different tact: say you actually want these companies to “build powerful AI,” and believe they’re smart enough to do so. Say that, somehow, looking at their decaying finances, the lack of revenue, the lack of growth, and the remarkable lack of use cases, you still come out of it saying “sure, I think they’re going to do this!” How? Why haven’t they done it yet? Why, three years in, are we still unable to describe what ChatGPT actually does, and why we need it? Take away how much money OpenAI makes for a second (and, indeed, how much it loses). Does this product actually really inspire anything in you? What is it that’s magical about this? And, on a business level, what is it I’m meant to be impressed by, exactly? OpenAI has — allegedly — hit “$10 billion in annualized revenue” (essentially the biggest month it can find, multiplied by 12), which is…not that much, really, considering it’s the most prominent company in the software world, with the biggest brand, and with the attention of the entirety of the world’s media. It has, allegedly, 500 million weekly active users — and, by the last count, only 15.5 million paying subscribers, an absolutely putrid conversion rate even before you realize that the actual conversion rate would be monthly active subscribers. That’s how any real software company actually defines its metrics, by the fucking way. Why is this impressive? Because it grew fast? It literally had more PR and more marketing and more attention and more opportunities to sell to more people than any company has ever had in the history of anything. Every single industry has been told to think about AI for three years, and they’ve been told to do so because of a company called OpenAI. There isn’t a single god damn product since Google or Facebook that has had this level of media pressure, and both of those companies launched without the massive amount of media (and social media) that we have today. Having literally everybody talking about your product all the time for years is pretty useful! Why isn’t it making more money? Why are we taking any of these people seriously? Mark Zuckerberg paid $14.3 billion for Scale AI, an AI data company, as a means of hiring its CEO Alexandr Wang to run his “superintelligence” team, has been offering random OpenAI employees $100 million to join Meta, thought about buying both AI search company Perplexity and generative video company Runway and even tried to buy OpenAI co-founder Ilya Sutskever’s pre-product “$32bn valuation” non-company Safe Superintelligence, settling instead on hiring its CEO Daniel Gross and buying his venture fund for some fucking reason. When you put aside the big numbers, these are the actions of a desperate dimwit with a failing product trying to buy his way to making generative AI into a “superintelligence,” something that Meta’s own Chief AI scientist Yan LeCun says isn’t going to work. By assuming that there is some sort of grand strategy behind these moves beyond “if we get enough smart people together something will happen,” you help boost the powerful’s messaging and buoy their stock valuations. You are not educating anybody by humouring these goofballs. In fact, the right way to approach this would be to ask why Meta, a multi-trillion dollar market cap company with a near-monopoly over all social media, is spending billions of dollars in what appears to be a totally irresponsible way. Instead, people are suggesting this is Mark Zuckerberg’s genius at work. Anyway, putting that aside, what exactly is the impressive part of generative AI again? The fucking code? Enough about the code, I’m tired of hearing about the code, I swear to god you people think that being a software engineer is only coding and that it’s fine if you ship “mediocre code,” as if bad code can’t bring down entire organizations. What do you think a software engineer does? Is all they do code? If you think the answer is yes, you are wrong! Human beings may make mistakes in writing code, but they at least know what a mistake looks like, which a generative AI does not, because a generative AI doesn’t know what anything is, or anything at all, because it is a probabilistic model. Congratulations! You made another way in which software engineers can automate parts of their jobs — stop being so fucking excited about the idea that people are going to lose their livelihoods! It’s nasty, and founded on absolutely nothing other than your adulation for the powerful! These models are dangerous and chaotic, built with little intention or regard for the future, just like the rest of big tech’s products. ChatGPT would’ve been a much smaller deal if Google had any interest in turning Google Search into a product that truly answered a query (as opposed to generating more of them to show more impressions to advertisers) — a nuanced search engine that took a user’s query and spat out a series of websites that might help answer said question rather than just summarising a few of them for an answer. And if you ever need proof that Google just doesn’t know how to fucking innovate anymore, look at AI Summaries, a product that both misunderstands search and why people use ChatGPT as a search replacement. While OpenAI may “summarise” stuff to give an answer, it at the very least gives something approximating a true answer, rather than a summary that feels like an absentee parent trying to get rid of you and then throwing you $20 in the hopes you’ll leave them alone. If Google Search truly evolved, ChatGPT wouldn’t really matter, because the idea of a machine that can theoretically answer a question is kind of why people used fucking Google in the fucking first place. Again, why are we not describing this company as the business equivalent of a banana republic? It’s actively making its shit worse to juice growth, and it’s really obvious how badly it sucks. Why doesn’t the state of Google dominate tech news, just like how random ketamine-fuelled tweets from Elon Musk do? Why aren’t we, collectively, repulsed by Google as a company? Why aren’t we, collectively, repulsed by OpenAI? No matter how big ChatGPT is, the fact that there’s a product out there with hundreds of millions of users that constantly gets answers wrong is a genuinely worrying thing for society, and that’s before you get to the environmental damage, the fact it trained its models on millions of people’s art and writing, and oh, I dunno, the fact it plans to lose over a hundred billions of dollars before becoming profitable? Why are we not more horrified? Why are we not more forlorn that this is where hundreds of billions of dollars are being forced? The most prominent company in the tech industry is an unstable monolith with a vague product that can only make $10 billion a year (revenue, not profit) as the very fabric of its existence is shoved down the throat of every executive in the world at once. Also, if it’s not fed $20 billion to $40 billion a year, it will die. Give me a fucking break. I don’t know, I sound pretty ornery, I get accused of being a hater or missing the grand mystery of this bullshit every few minutes by somebody with an AI avatar of a guy who looks like he’s banned from multiple branches of Best Buy, I understand there’s things that people do with Large Language Models, I am aware, but none of it matters because the way they’re being discussed is like we’re two steps from digitally replacing hundreds of millions of people. The reality is far simpler: we have an industry that has spent nearly half a trillion dollars between its capital expenditures and venture capital funding to create another industry with the combined revenue of the fucking smartwatch industry. What I’m writing isn’t inflammatory — in fact, it’s far more deeply rooted in reality than those claiming that OpenAI is building the future. Let’s do some fucking mathematics! Projected Big Tech Capital Expenditures in 2025 and revenue from AI: That’s $327 billion this year, with a total revenue of…what, $18 billion of revenue? And that’s not profit! And that’s if we include OpenAI’s spend on Azure. Even if every single one of these companies was making $18 billion in revenue a year from this it wouldn’t be great, but it’s more than likely that these chunderfucks can’t even pull together the projected revenue ($32 billion) of the global smartwatch industry! What a joke! “Wuhh, but what about OpenAI?” What about OpenAI? I’ve written about this so much. So what, OpenAI makes $12.7 billion this year, but loses $14 billion, what does that mean to you, exactly? What’re you going to say? The cost of inference is coming down? No, the cost that people are being charged is going down, we have no firm data on the actual costs because the companies don’t want to talk about it, and yes, it will absolutely lower prices to compete with other companies. The Information just reported that OpenAI was doing this to compete with Microsoft last week! Hey, quick question — wasn’t SoftBank meant to spend $3 billion annually on OpenAI’s software? Did that happen? Anyway, even if we add OpenAI’s revenue to the pot, we are at $30.7 billion. If we add the supposed $1 billion in revenue from training data startup Surge, $300 million in “annualized revenue” from Turing, optimistically assume that Perplexity will have $100 million (up from $34 million in 2024, where it burned $65 million) in revenue in 2025, and assume that Anysphere’s (which makes Cursor) $200 million run rate stays consistent through 2025, we are at…$32.3 billion. But I'm not being fair, am I? I didn’t include many of the names from The Information’s generative AI database. Prepare yourself, this is gonna be annoying! So let's add some more. We’ve got $3 billion from Anthropic, $870 million from Scale (now part of Meta), another alleged $300 million for Anysphere (The Information claims $500 million in ARR), we consider Neo4j’s “>$200 million ARR” to mean “$200 million,” Midjourney’s “>$200 million ARR” to mean $200m, Ironclad’s “>$150 million ARR” to mean $150 million ARR, Glean’s $103 million ARR, Together AI’s $100 million ARR, Moveworks’ $100 million ARR, Abridge’s $100 million ARR, Synthesia’s $100 million ARR, WEKA’s “>$100 million ARR” to mean $100m ARR, Windsurf’s $100m ARR, Runway’s $84 million ARR, Elevenlabs’ “>$100m ARR” to mean $100m ARR, Cohere’s $70m ARR, Jasper’s “>$60m ARR” to mean $60m, Harvey’s $50m ARR, Ada’s “>$50m ARR” to mean $50m, Photoroom’s $50m ARR…and then assumed the combined ARR of the remainders are somewhere in the region of a very generous $200m, we get… Less than $39 billion dollars of total revenue in the entire generative AI industry. Jesus fucking christ! According to The Information, generative AI companies have raised more than $18.8 billion in the first quarter of 2025, after investing $21 billion in Q4 2024 and $4 billion in Q3 2024 for a grand total of $43.8 billion, or a total of $370.8 billion of investment and capital expenditures for an industry that, despite being the single-most talked about thing on the planet, cannot even create a tenth of the dollars it requires to make it work. These companies are predominantly unprofitable, perpetually searching for product-market fit, and even when they find it, seem incapable of generating revenue numbers that remotely justify their valuations. If I’m honest, I think the truly radical position here is the one taken by most tech reporters that would rather take the lazy position of “well Uber lost a lot of money!” than think for two seconds about whether we’re all being sold a line of shit. What we’re watching is a mountain of waste perpetuated by the least-charming failsons of our generation. Nobody should be giving Satya Nadella or Sam Altman a glossy profile — they should be asking direct, brutal questions, much like Joanna Stern just did of Apple’s Craig Federighi, who had absolutely fucking nothing to share because he has never been pushed like this. Put aside the money for a second and be honest: these men are pathetic, unimpressive, uninventive, and dreadfully, dreadfully boring. Anthropic’s Wario (Sorry, Dario) Amodei and OpenAI’s Sam Altman have far more in common with televangelist Joel Olstein than they’ll ever have with Steve Jobs or any number of people that have actually invented things, and they got that way because we took them seriously instead of saying “wait, what do you mean?” To a single one of their wrongheaded, oafish and dim-witted hype-burps. It’s boring! I’m terribly, horribly bored, and if you’re interested in this shit I am genuinely curious why, especially if you’re a reporter, because right now the “innovation” happening in AI is, at best, further mutations of the Software As A Service business model, providing far less value than previous innovations at a calamitous cost. Reasoning models don’t even reason, as proven by an Apple paper released a few weeks ago, and agents as a concept are fucked because large language models are inherently unreliable — and yes, a study out of fucking Salesforce found that agents began to break down when given multi-step tasks, such as “any task you’d want to have an agent automate.” So, here’s my radical suggestion: start making fun of these people. They are not charming. They are not building anything. They have scooted along amassing billions of dollars promising the world and delivering you a hill of dirt. They deserve our derision — or, at the very least, our deep, unerring suspicion, if not for what they’ve done, but for what they’ve not done. Sam Altman is nowhere near delivering a functioning agent, let alone anything approaching intelligence, and really only has one skill: making other companies risk a bunch of money on his stupid ideas. No, really! He convinced Oracle to buy $40 billion of NVIDIA chips to put in the Abilene Texas “Stargate” data center, despite the fact that the Stargate organization has yet to be formed (as reported by The Information). SoftBank and Microsoft pay all of OpenAI’s bills, and the media does his marketing for him. OpenAI is, as I said, quite literally a banana republic. It requires the media and the markets to make up why it has to exist, it requires other companies to pump it full of money and build its infrastructure, and it doesn’t even make products that matter, with Sam Altman constantly talking about all the exciting shit other people will build. You can keep honking about how “it built the API that will power the future,” but if that’s the case, where’s the fucking future, exactly? Where is it? What am I looking at here? Where’s the economic activity? Where’s the productivity? The returns suck! The costs are too high! Why am I the radical person for saying this? This entire situation is absolutely god damn ridiculous, an incomparable waste even if it somehow went in the green. For the horrendous amounts of capital invested in generative AI to make sense, the industry would have to have revenue that dwarfed the smartphone and enterprise SaaS market combined, rather than less than half of that of the mobile gaming industry. Satya Nadella, Sam Altman, Wario Amodei, Tim Cook, Andy Jassy — they deserve to be laughed at, mocked, or at the very least interrogated vigorously, because their combined might has produced no exciting or interesting products outside of, at best, what will amount to a productivity upgrade for integrated development environments and faster ways to throw out code that may or may not be reliable. These things aren’t nothing, but they’re nowhere near the something that we’re being promised. So I put it to you, dear reader: why are we taking them seriously? What is there to take seriously other than their ability to force stuff on people? And I’ll leave you with a question: how do they manage to keep doing this, exactly? They always seem to find new growth, every single quarter, without fail? Is it because they keep coming up with new ideas? Or is it because they come up with new ideas to get more money, a vastly different choice that involves increasing the prices of products or making them worse so that they can show you more advertisements. My positions are not radical, and if you believe they are, your deference to the powerful disgusts me. In any case, I want to end this with something inspirational, because I believe that things change when regular people feel stronger and more capable. I want you to know that you are fully capable of understanding all of this. I don’t care if you “aren’t a numbers person” or “don’t get business.’ I don’t have a single iota of economics training, and everything you’ve ever read me write has been something I’ve had to learn. I was a layperson right up until I learned the stuff, then I became a stuff-knower, just like you can be. The tech industry, the finance industry, the entire mechanisms of capitalism want you to believe that everything they do is magical and complex, when it’s all far more obvious than you’d believe. You don’t have to understand the entire fundamentals of finance to know how venture capital works — they buy percentages of companies at a valuation that they hope is much lower than the company would be worth in the future. You don’t need to be technical to know that Large Language Models generate a response based on billions of pieces of training data, and by guessing at what the next bit of text in a line should be based on what it’s seen previously. These people love to say “ah, but didn’t you see-” and present an anecdote, when no anecdote will ever defeat the basics of “your business doesn’t make any money, the software doesn’t do the things you claim it’s meant to, and you have no path to profitability.” They can yammer at you all they want about “lots of people using ChatGPT,” but that doesn’t change the fact that ChatGPT just isn’t that revolutionary, and their only play here is to make you feel stupid rather than actually showing you why it’s so fucking revolutionary. This is the argument of a manipulator and a coward, and you are above such things. You don’t really have to be a specialist in anything to pry this shit apart, which is why so much of my work is either engaging to those who learn something from it or frustrating to those that intentionally deceive others through gobbledygook hype-schpiel. I will sit here and explain every fucking part of this horrid chain of freaks, and break it down into whatever pieces it takes to educate as many people as I have to to make things change. I also must be clear that I am nobody. I started writing this newsletter with 300 subscribers and no reason other than the fact I wanted to, and four years later I have nearly 64,000 subscribers and an award-winning podcast. I have no economics training, no special access, no deep sources, just the ability to look at things that are happening and say stuff. I taught myself everything I know about this industry, and there is nothing stopping you from doing the same. I was convinced I was stupid until around two years ago, though if I’m honest it might have been last year. I have felt othered the majority of my life, convinced by people that I am incapable or unwelcome, and as I’ve become more articulate and confident in who I am and what I believe in, I have noticed that the only people that seek to degrade or suppress are those of weak minds and weaker wills — Business Idiots in different forms and flavors. I have learned to accept who I am — that I am not like most people — and people conflate my passion and vigor with anger or hate, when what they’re experiencing is somebody different who deeply resents what the powerful have done to the computer. And while I complain about the state of media, what I’ve seen in the last year is that there are many, many people like me — both readers and peers — that resent things in the same way. I conflated being different with being alone, and I couldn’t be more wrong. For those of you that don’t wish to lick the boots of the people fucking up every tech product, the tent is large, it’s a big club, and you’re absolutely in it. A better tech industry is one where the people writing about it hold it accountable, pushing it toward creating the experiences and connectivity that truly change the world rather than repeating and reinforcing the status quo. Don’t watch the mouth, watch the hands. These companies will tell you that they’re amazing as many times as they want, but you don’t need to prove that — they do. I don’t care if you tell a single human soul about my work, but if it helps you understand these people better, use it to teach other people. These people may seem all-powerful, but they’ve built the Rot Economy on a combination of anonymity and a placant press, but pressure against them starts with you and those you know understanding how their businesses work, and trusting that you can understand because you absolutely can. Millions of people understanding how these people run their companies and how poorly they’ve built their software will stop people like Sundar Pichai from being able to quietly burn Google Search to the ground. People like Sam Altman are gambling that you are easily-confused, easily-defeated and incurious, when you could be writing thousands of words on a newsletter that you never, ever edit for brevity. You can understand every fucking part of their business — the economics of OpenAI, the flimsy promises of Salesforce, the destruction of Google Search — and you can tell everybody you know about it, and suddenly it won’t be so easy for these wretched creeps to continue thriving. I know it sounds small, and like your role is even smaller, but the reason they’ve grown so rapaciously is driven by the sense that the work they do is some sort of black magic, when it’s really fucking stupid and boring finance stapled onto a tech industry that’s run out of ideas. You are more than capable of understanding this entire world — including the technology, along with the finances that ultimately decide what technology gets made next. These people have got rich and famous and escaped all blame by casting themselves as somehow above us, when if I’m honest, I’ve never looked down on somebody quite as much as I do the current gaggle of management consultant fucks that have driven Silicon Valley into the ground. Subscribe today. It's free. Please. Great! You’ve successfully signed up. Welcome back! You've successfully signed in. You've successfully subscribed to Ed Zitron's Where's Your Ed At. Your link has expired. Success! Check your email for magic link to sign-in. Success! Your billing info has been updated. Your billing was not updated.
--------------------------------------------------

Title: FOMO-Driven Call Buying Soars as Traders Chase S&P 500’s Furious Run
URL: https://financialpost.com/pmn/business-pmn/fomo-driven-call-buying-soars-as-traders-chase-sp-500s-furious-run
Time Published: 2025-06-30T09:54:46Z
Description: Traders keen to seize on further gains after the S&P 500 Index hit its first record since February are betting on stock-market darlings that they expect will surpass the index’s ascent.
--------------------------------------------------

Title: FOMO-Driven Call Buying Soars as Traders Chase S&P 500’s Furious Run
URL: https://finance.yahoo.com/news/fomo-driven-call-buying-soars-093000519.html
Time Published: 2025-06-30T09:30:00Z
Description: (Bloomberg) -- Traders keen to seize on further gains after the S&P 500 Index hit its first record since February are betting on stock-market darlings that...
--------------------------------------------------