List of news related to Advanced Micro Devices stock price AMD:

Title: Nvidia resets the economics of AI factories, again
URL: https://siliconangle.com/2026/01/10/nvidia-resets-economics-ai-factories/
Time Published: 2026-01-10T21:58:15Z
Full Content:
UPDATED 16:58 EST / JANUARY 10 2026 BREAKING ANALYSIS by David Vellante and David Floyer At CES 2026, Nvidia Corp. Chief Executive Jensen Huang once again reset the economics of artificial intelligence factories. In particular, despite recent industry narratives that Nvidia’s moat is eroding, our assessment is the company has further solidified its position as the hardware and software standard for the next generation of computing. In the same way Intel Corp. and Microsoft Corp. dominated the Moore’s Law era, we believe Nvidia will be the mainspring of tech innovation for the foreseeable future. Importantly, the previous era saw a doubling of performance every two years. Today Nvidia is driving annual performance improvements of five times, throughput of 10 times, and driving token demand of 15 times via Jevons Paradox. The bottom line is that ecosystem players and customers must align with this new paradigm or risk a fate similar to that of Sisyphus, the beleaguered figure who perpetually pushed a rock up the mountain. In this Breaking Analysis, we build on our prior work from Episode 300 with an update to our thinking. We begin with an historical view, examining the fate of companies that challenged Intel during the personal computer era and the characteristics that allowed a small number of them to survive and ultimately succeed. From there, we turn to the announcements Huang (pictured) made at CES and explain why they materially change the economics of AI factories. In our view, these developments are critical to understanding the evolving demand dynamics around performance, throughput and utilization in large-scale AI infrastructure. We close by examining the implications across the ecosystem. What does this mean for competitors such as Intel, Broadcom Inc., Advanced Micro Devices Inc. and other silicon specialists? How should hyperscalers, leading AI research labs, original equipment manufacturers and enterprise customers think about AI strategy, capital allocation and spending priorities in light of these shifts? Let’s begin with a historical view, looking back at the companies that challenged Intel during the 1980s and 1990s. IBM was the dominant force early on, but it was far from the only player that attempted to compete at the silicon level. A long list of RISC vendors and alternative architectures emerged during that period – including Sun Microsystems Inc. – many of which are now footnotes in computing history. The slide above highlights this reality. The companies shown in green are the ones that managed to make it through the knothole. The rest did not. The central reason comes down to the fact that Intel delivered relentless consistency with predictable, sustained improvement in performance and price-performance, roughly doubling every two years. Intel never took its foot off the pedal. It executed Moore’s Law as an operational discipline as well as a technology roadmap. As a result, competitors simply could not keep pace. Even strong architectural ideas from industry leaders were overwhelmed by Intel’s scale, manufacturing advantage, volume economics and cadence. One point worth noting. Apple, while not always viewed as a direct silicon competitor during that era, ultimately won by controlling its system architecture and, later, by vertically integrating its silicon strategy. The broader takeaway is fundamental in our assumptions for the rest of this analysis. Specifically, in platform markets driven by learning curves, volume and compounding economics, dominance is not just about having a great product. Success requires sustained momentum over long periods of time, while competitors exhaust themselves trying to catch up. Let’s now double down on the companies that actually survived the Intel-dominated PC era. The list below is instructive in our view. AMD, Acorn (the original Arm), Apple Inc., Taiwan Semiconductor Manufacturing Co. Intel and Nvidia. Each followed a different path, but they share a common underlying characteristic which is volume. AMD’s survival traces directly back to IBM’s original PC strategy. IBM mandated a second-source supplier, forcing Intel to share its instruction sets. AMD became that second source, and no other company gained comparable access. That structural advantage persisted for decades and allowed AMD to remain viable long after other x86 challengers disappeared. ARM, TSMC and Apple fundamentally changed the prevailing belief – stated by AMD CEO Jerry Sanders— that “real men own fabs.” These companies proved that separating design from manufacturing could be a winning strategy. Apple brought massive system-level volume. TSMC rode that volume to drive down costs, ultimately achieving manufacturing economics that we estimate to be roughly 30% lower than Intel’s. Nvidia followed a similar fabless path, pairing architectural leadership with accelerating demand. Intel itself was the original volume powerhouse, benefiting from the virtuous cycle created by the Wintel combination. That volume allowed Intel to outlast RISC competitors and dominate the PC era. But in the current cycle, Intel has lost ground to Arm-based designs, Nvidia and TSMC – each of which now rides on steeper learning curves. The takeaway is that volume is volume is fundamental to dominance. Not just volume in a single narrow segment, but volume across adjacent and synergistic markets that feed the same learning curves. AMD’s volume was initially forced by IBM’s PC division mandating a second source to Intel. Apple’s volume is consumer-driven. TSMC’s volume is manufacturing-led. Nvidia’s volume is now accelerating faster than any of them in this era. In our view, Nvidia is positioned to be the dominant volume leader of the AI era by a wide margin. And as history shows, once volume leadership is established at scale, it becomes extraordinarily difficult for competitors to catch up without other factors affecting the outcome (e.g. self-inflicted wounds or things out of the leader’s control such as geopolitical shifts). Nvidia’s CES announcements were visionary and focused largely on the emerging robotics market. In this analysis, however, we focused in on the core of Nvidia’s systems business. In our view, what Nvidia announced in this regard exceeded even our optimistic expectations. As we’ve stressed often, Nvidia is remarkable, not only because of a single chip, but because of the scope of what it delivers. Specifically, Huang led this part of his keynote with a six-chip, full-system redesign built around what Huang consistently refers to as extreme co-design. The chart above shows the next generation innovations from Nvidia, including Vera Rubin, named in homage to the astronomer whose work on galactic rotation curves led to the discovery of dark matter. Vera is the CPU. Rubin is the GPU. But focusing only on those two components misses the broader story. Nvidia simultaneously advanced every major silicon element in the system including NVLink based on InfiniBand, ConnectX nics and Spectrum-X for Ethernet, BlueField DPUs and Spectrum-X Ethernet with co-packaged optics. A few years ago, the prevailing narrative suggested that Ethernet would undercut Nvidia’s proprietary networking position, the underpinning which was Infiniband (via the Covid-era Mellanox acquisition). Nvidia was undeterred and responded by building Spectrum-X. Today, Jensen Huang argues that Nvidia is the largest networking company in the world by revenue, and the claim appears credible. What’s striking is not the line extension itself, but the speed and completeness with which Nvidia executed it. The deeper point lies in how Nvidia defines co-design. While the company works closely with customers such as OpenAI Group PBC, Google LLC with Gemini and xAI Corp., the co-design begins internally – across Nvidia’s own portfolio. This generation represents a ground-up redesign of the entire machine. Every major chip has been enhanced in coordination, not in isolation. The performance metrics are astounding. The GPU delivers roughly a fivefold performance improvement. The CPUs see substantial gains as well. But equally important are the advances in networking – both within the rack and across racks. Each subsystem was redesigned together to maximize end-to-end throughput rather than optimize any single component in isolation. The result is multiplicative, not additive. While individual elements show performance gains on the order of five times, the system-level throughput improvement is closer to an order of magnitude. That is the payoff of extreme co-design – aligning compute, networking, memory and software to minimize single bottlenecks that limit the overall system. In our view, this marks a decisive shift in how AI infrastructure is built. For quite some time we’ve acknowledged that Nvidia is no longer shipping chips. It is delivering tightly integrated systems engineered to maximize throughput, utilization, and economic efficiency at the scale required for AI factories. That distinction is profound as competitors attempt to match not just component performance, but the learning-curve advantages that emerge when volume, architecture and system-level design reinforce each other. While Jensen has pointed out that Nvidia is a full systems player, the point is often lost on investors and market watchers. This announcement further underscores the importance of this design philosophy and further differentiates Nvidia from any competitor. A critical point that becomes more clear from Nvidia’s announcements is the chip is not the correct unit of measurement. The system is. More precisely, the rack – and ultimately the token output per rack – is what defines performance, economics, and value. Each rack integrates 72 GPUs along with CPUs and high-speed interconnects that bind the system together. Compute density is critical, but so is the ability to move data with minimal jitter and maximum consistency – within the rack, across racks, and across entire frames. Nvidia has dramatically increased memory capacity into the terabytes, enabling GPUs to operate in tight coordination without stalling. The result is coherent execution at massive scale. These systems are designed to scale up, scale out, and scale across. When deployed at full factory scale, they operate not in dozens or hundreds of GPUs, but in hundreds of thousands – eventually up to a million GPUs working together. As scale increases, so does throughput. And as throughput increases, the economic value of the tokens generated accelerates. This is where the numbers compound to create the flywheel effect. Roughly five times performance improvement at the component level combines with roughly ten times throughput at the system level. Together, they drive what we believe is an estimated 15-times increase in demand, as lower cost per token unlocks entirely new classes of workloads. This is Moore’s Law on triple steroids – and it explains why annual value creation rises so sharply. The Jevons Paradox applies here. As the efficiency of token generation improves, total consumption rises. As we’ve stressed, the value shifts away from static measures of chip performance, toward dynamic measures of system utilization and output economics. The faster tokens can be generated, the more economically viable it becomes to deploy AI at scale, and the more demand expands. Networking is central to this equation. Nvidia’s long-term investment in Mellanox – once dismissed by many as a bet on a dying technology – now looks prescient. InfiniBand continues to grow rapidly, even as Ethernet demand also accelerates. Far from being a bottleneck, networking has become a core enabler of system-level performance. The takeaway is that AI infrastructure economics are now defined at the rack and factory level, not at the chip level. Nvidia’s advantage lies in designing systems where compute, memory, networking and software operate as a single, tightly coordinated machine. That is where throughput is maximized, token economics are transformed, and the next phase of AI factory value is being created. Huang presented three critical metrics on a single slide to show training throughput, AI factory token throughput and token cost. Together, they tell a story about where AI infrastructure economics are headed. For clarity, we break this into two parts as shown below: training on the left, factory and inference throughput on the right. The training chart shows time-to-train measured in months for a next-generation, ultra-large model. The takeaway is eye opening. The Rubin platform reaches the same training throughput as Blackwell using roughly one quarter of the GPUs. As we pointed out earlier, this is not simply about faster chips. It reflects dramatic gains in efficiency at scale – reduced synchronization overhead, fewer memory stalls, lower fabric contention, and shorter training cycles overall. The implications are notable. Capital required per model run drops materially. Customers can run more experiments per year and iterate faster. Training velocity becomes a competitive advantage in itself, not just a cost consideration. In our view, this is one of the most under-appreciated dynamics in the current AI race. The factory throughput chart above on the right, tells an equally important story. As workloads shift from batch inference toward interactive, agent-driven use cases, throughput characteristics change dramatically. Tokens per query increase. Latency sensitivity rises. Under these conditions, Blackwell’s throughput collapses as shown. Meanwhile, Rubin sustains performance far more effectively and delivers approximately 10 times more tokens per month at the factory level. This is the future workload profile of AI factories – real-time, interactive, agentic and highly variable — not static batch inference. Rubin is designed for this moment. The value is not just in peak performance, but in sustained throughput under real-world conditions. Taken together, these charts explain why Nvidia’s advantage continues to widen. Training and inference are converging in economic importance. Faster training reduces capital intensity and accelerates innovation. Higher factory throughput lowers token costs while expanding demand. This combination resets expectations for performance, efficiency and scalability. In our view, many observers continue to underestimate both the pace at which Nvidia is moving and the magnitude of the gap it is creating. Comparisons to alternative accelerators – whether Google TPUs, AWS Trainium or others – miss the system-level reality being demonstrated by Nvidia. The new standard is not raw compute. It is training velocity, sustained factory throughput and token economics at scale. And on those dimensions, Nvidia is setting the bar. The final piece of the equation that we’ll dig into is cost. And this is where the implications become overwhelming. In our view, it’s what matters most. The combination of higher throughput and system-level efficiency drives cost per token down by roughly an order of magnitude. Huang framed it in his keynote saying these systems may consume more power, but they do vastly more work. When throughput rises by 10 times and cost per token falls to one-10th, the economic profile of AI factories fundamentally resets. What’s striking is the pace. This is not the 18- to 24-month cadence historically associated with Moore’s Law. These gains are occurring on a 12-month cycle. Moore’s Law transformed the computing industry for decades, lifting productivity across silicon, software, storage, infrastructure and applications. What we are seeing now is an even more aggressive curve – orders-of-magnitude improvement compressed into a single year. There are real pressures behind this progress. Demand for advanced chips, memory and interconnects is intense, pushing up component costs. Nvidia has secured premium access across that supply chain. But from the perspective of an AI factory operator, the math dominates everything else. If cost per token falls while throughput rises dramatically, the earning power of the factory increases materially. This is especially critical in a power-constrained world as we described last August when we explored the “New Jensen’s Law.” Hyperscalers and neoclouds alike are limited by available power, not just capital. Under those constraints, Jensen’s tongue-in-cheek “law” applies – buy more, make more; or buy more, save more. The ability to extract significantly more work from the same infrastructure — or achieve the same output with far less — translates directly into financial operating leverage. The example Jensen cited makes the point concrete. In a $50 billion, gigawatt-scale data center, improving utilization by 10% produces an enormous $5 billion benefit that flows straight to the income statement. That is why networking, in this context, becomes economically “free.” The incremental cost is dwarfed by the utilization gains it enables. This is ultimately why Nvidia’s position is so strong. The advantage is not just technical – it’s economic. Nvidia is operating on a steep learning curve, reinforced by volume, system-level co-design and accelerating efficiency gains. When cost per token collapses at this rate, demand expands, utilization rises and the economics compound. That dynamic is what defines leadership in this era. We’ll close by translating the CES announcements into competitive implications across multiple classes of players, including vendors that are simultaneously customers. The common theme is that the unit of competition has shifted from chips to systems, racks and ultimately token economics. That shift changes the survivability economics for incumbents, the opportunity for specialists, and the urgency of customer strategies. In our view, it’s effectively game over for Intel’s historical monopoly and leadership position. The more interesting question is whether Intel can remain a meaningful CPU provider in an AI factory world – and the Nvidia/Intel interoperability move is notable in that context. The historical context is relevant. Nvidia has wanted deeper access to x86 since the late 1990s but was never allowed. The new arrangement changes the structure and it enables a configuration where Intel CPUs and Nvidia GPUs can operate within the same frame. It’s not a fully unified architecture, but it is sufficient for most of the work, and it creates a practical path for Intel CPUs to remain present in these systems. It also gives Intel a meaningful level of access to CUDA-based environments – short of “full access,” but still consequential. The net effect should improve Intel connectivity in these deployments, keep Intel in the CPU game for this cycle, and increase the volume of Nvidia systems available to the market. In other words, it can act as a viable bridge from the old to the new, which is good for customers. We do want to flag a key risk to any optimistic Nvidia scenario – a Taiwan geopolitical disruption. If China takes over Taiwan, there are multiple potential outcomes – from continuity with a new lever for China, to a more disruptive scenario if that lever is pulled. Either would ripple through sentiment around Nvidia and could increase perceived strategic value for Intel. But the hard reality is Intel still has to close the manufacturing and execution gap with TSMC, and that is not something any company can leapfrog overnight. AMD has executed well against Intel in x86. But the competitive target has shifted. x86 is mature and its curve has flattened, which made the timing right for AMD’s ascdendency and for hyperscalers to pursue alternatives such as AWS’ Graviton. AMD is now taking on a very different animal – a leader moving on a steep learning curve with compounding system-level advantages. In our view, the core issue is speed. AMD will struggle to move fast enough to close a gap defined by 12-month cycles and system-level throughput economics. One practical implication is that AMD should pursue a deal structure similar to Intel’s – something that secures volume on one side – while focusing aggressively on the edge. Data center CPU revenue is meaningful for Intel and AMD, but expanding volume there will be difficult, and there is real risk of decline. The edge remains wide open, and that’s where focus should go in our opinion. At the same time, it’s important to recognize that Nvidia is also targeting the edge – autonomous vehicle libraries were highlighted and robotics were put on stage at CES and it’s a major focus of the company. The edge is open, but it won’t be uncontested. There is ample room for specialists that avoid direct, frontal competition with Nvidia. The AI factory buildout is forecast to be enormous – large enough that niche and adjacency strategies can still create meaningful businesses, particularly around factories and the edge. Two examples we cite: But the strategic point is that latency is a real lever in inference economics, and specialists that win on latency can matter – especially at the edge. Broadcom is best understood as a critical supplier to hyperscalers, OEM ecosystems, mobile players and virtually all forms of connectivity. Broadcom has a custom silicon engine that manages back-end execution with foundries and manufacturing partners. Its business is diversified and structurally important, and we do not view it as going away by any means. Broadcom has deep engineering talent and a diversified business with exceptional leadership. The more controversial question is whether hyperscalers should continue investing in alternative accelerators such as TPUs, Trainium and other ASIC strategies – as a long-term path to compete with Nvidia. Google has deep history and real technical credibility with TPUs. But the argument here is that this is now a different business environment. Google must protect search quality and accelerate Gemini. If internal platform choices limit developer access to CUDA and the best available hardware/software improvements, the risk is that Gemini’s development velocity slows. If model iteration takes multiples longer, that becomes strategically dangerous. Our view is that TPUs have reached a ceiling in this context – not because they can’t improve, but because they cannot match Nvidia’s volume-driven learning curve and system-level economics, particularly with networking as scale. A related point, made by Gavin Baker using a simplified economics example is if Google’s TPU program represents a $30 billion business, and it sends a large portion of value to Broadcom (about $15 billion), one might argue for vertical integration. The counterargument here is that even if it’s financially possible, it may be strategically irrational if it slows Gemini’s iteration speed. The core thesis is that Google should prioritize model velocity over accelerator self-sufficiency. The same logic extends to Trainium. AWS’ Graviton playbook worked because it targeted a mature, flattening x86 curve. That is not the environment in accelerators today. The pace is too fast, the curves are too steep, and the system complexity is too high. Will AWS, Google and even Microsoft continue to fund alternatives to Nvidia? Probably as use cases will emerge for more cost effective platforms. But the real strategic advantage for hyperscalers in our view lies elsewhere, especially as they face increasing competition from neoclouds. We position four frontier labs as the primary contenders: OpenAI, Anthropic PBC, Google and xAI Corp.’sGrok, with Meta Platforms Inc.treated as a second tier (with the caveat that it’s unwise to count Zuckerberg out). Despite persistent negative narratives around OpenAI — especially around financing structure and commitments — our view is that pessimism may be misplaced. The reasoning is as follows: In short, we see the winners as OpenAI the most likely overall winner in the center, with Anthropic as the second player, and Grok highly likely to do well at the edge. Elon could also compete strongly at the edge while he backed away from the idea of building his own data center chips. An additional allocation nuance is labs aligned with Nvidia (OpenAI and X.ai) may have a better path to “latest and greatest” allocations than those pursuing tighter coupling with alternative accelerator strategies. For OEMs like Dell, HPE, Lenovo, and Supermicro, the opportunity is primarily executional. In other words, get the latest platforms, package them, deliver them, and keep them running reliably without thermal or integration failures. Demand is enormous, supply is constrained, and this is not a zero-sum game. For now they can all do well. The key point is that as long as the market remains supply-constrained, anything credible that can be produced will be consumed. That reality can justify multiple silicon suppliers from the ecosystem – even if the long-run competitive curve still favors Nvidia. On the customer side, we challenge a widely repeated narrative to “get your data house in order before you spend on AI.” The view here is that this sequencing can be backwards. Our modeling suggests that over a multi-year period (for example, five years), getting onto the AI learning curve earlier can generate substantially more value than delaying until data is “clean.” Even if data isn’t pristine, organizations can choose a dataset, apply AI to improve it, and compound learning rather than waiting. Two additional implications are highlighted below: Our strategy recommendation is to optimize for speed and learning. Put token capacity close to data (latency matters), use tokens to improve access and data quality, then iterate through AI projects quickly – one project, learn, then the next, building a flywheel. The emphasis should be on starting from value and using intelligence to improve the systems, rather than spending years trying to perfect data first. In our view, the defining lesson of this analysis is that AI is no longer a contest of individual chips, models, or even vendors – it is a contest of learning curves, systems and economics. History shows that in platform transitions, leadership accrues to those who achieve volume, sustain execution and convert efficiency gains into expanding demand. That dynamic shaped the PC era, and it is repeating at far greater speed in the AI factory era. What differentiates this cycle is the compression of time. Improvements that once unfolded over decades are now occurring in 12-month intervals, resetting cost structures and forcing strategic decisions faster than most organizations are accustomed to making them. The implications go across silicon providers, hyperscalers, AI labs, OEMs and enterprises alike. For customers, the message is value will accrue to those who get onto the AI learning curve early, focus on throughput and token economics, and build momentum through rapid iteration rather than waiting for perfect conditions. For vendors, survival will depend less on clever alternatives and more on whether they can stay on the steepest curves without slowing themselves down. This transition will not be linear, and it will not be evenly distributed. But the direction is clear in our view. AI factories are becoming the economic engine of the next computing era, and the winners will be those who treat AI not as a feature or experiment, but as the core operating model of their business. Support our mission to keep content open and free by engaging with theCUBE community. Join theCUBE’s Alumni Trust Network, where technology leaders connect, share intelligence and create opportunities. Founded by tech visionaries John Furrier and Dave Vellante, SiliconANGLE Media has built a dynamic ecosystem of industry-leading digital media brands that reach 15+ million elite tech professionals. Our new proprietary theCUBE AI Video Cloud is breaking ground in audience interaction, leveraging theCUBEai.com neural network to help technology companies make data-driven decisions and stay at the forefront of industry conversations. Nvidia resets the economics of AI factories, again Retail 2026: When AI becomes the operating system OpenAI invests $500M in SoftBank’s SB Energy unit AI cloud provider Lambda reportedly raising $350M round Stablecoin payment card startup Rain reels in $250M Red Hat pledges day-zero support for Nvidia's newest GPUs Nvidia resets the economics of AI factories, again AI - BY GUEST AUTHOR . 1 MIN AGO Retail 2026: When AI becomes the operating system AI - BY JOHN FURRIER . 1 HOUR AGO OpenAI invests $500M in SoftBank’s SB Energy unit INFRA - BY MARIA DEUTSCHER . 21 HOURS AGO AI cloud provider Lambda reportedly raising $350M round AI - BY MARIA DEUTSCHER . 23 HOURS AGO Stablecoin payment card startup Rain reels in $250M BLOCKCHAIN - BY MARIA DEUTSCHER . 1 DAY AGO Red Hat pledges day-zero support for Nvidia's newest GPUs AI - BY PAUL GILLIN . 1 DAY AGO
--------------------------------------------------

Title: AI memory is sold out, causing an unprecedented surge in prices
URL: https://www.cnbc.com/2026/01/10/micron-ai-memory-shortage-hbm-nvidia-samsung.html
Time Published: 2026-01-10T12:00:01Z
Description: Three primary memory vendors — Micron, SK Hynix and Samsung Electronics — make up nearly the entire RAM market, and they're benefitting from this shortage.
--------------------------------------------------

Title: Stocks Settle Mixed on Sector Rotation
URL: https://www.barchart.com/story/news/36957434/stocks-settle-mixed-on-sector-rotation
Time Published: 2026-01-08T21:39:02Z
Description: The S&P 500 Index ($SPX ) (SPY ) on Thursday closed up +0.01%, the Dow Jones Industrials Index ($DOWI ) (DIA ) closed up +0.55%, and the Nasdaq 100 Index...
--------------------------------------------------

Title: Penguin Solutions: The Deep-Value AI Play You’ve Been Looking For
URL: https://www.marketbeat.com/originals/penguin-solutions-the-deep-value-ai-play-youve-been-looking-for/?utm_source=yahoofinance&amp;utm_medium=yahoofinance
Time Published: 2026-01-08T20:43:00Z
Description: Penguin Solutions is well-positioned to deliver accelerating growth as enterprises shift into the inference phase of AI. 30% upside is a minimum target.del
--------------------------------------------------

Title: Dear Taiwan Semi Stock Fans, Mark Your Calendars for January 15
URL: https://www.barchart.com/story/news/36954952/dear-taiwan-semi-stock-fans-mark-your-calendars-for-january-15
Time Published: 2026-01-08T19:22:59Z
Description: With TSMC gearing up to release Q4 earnings this month, now is the perfect time to take a deeper dive into this chipmaking giant.
--------------------------------------------------

Title: Best of CES 2026: Android Authority’s top products from the show!
URL: https://www.androidauthority.com/best-of-ces-2026-awards-3631032/
Time Published: 2026-01-08T18:31:24Z
Full Content:
Affiliate links on Android Authority may earn us a commission. Learn more. January 8, 2026 A new year means a fresh CES, and once again Las Vegas turned into tech central for CES 2026. Our team spent the week on the ground, walking the show floors, chasing down announcements, and getting hands-on with as many products as humanly possible. Nobody can see everything at CES, since the show is massive, but we focused on the gear that genuinely stood out. This year brought big upgrades in smart home tech, plenty of creative ideas in mobile and wearables, smarter displays, and a few products that simply put a smile on our faces. So let’s get into it. Here are the Android Authority Best of CES 2026 Award winners. Samsung’s boldest foldable yet made its public debut at CES 2026. The Galaxy Z TriFold immediately feels like both a glimpse of what’s next and a reminder of how hard that future is to reach. This is Samsung’s first phone that folds twice, opening from a standard cover display into a full 10-inch AMOLED tablet. The TriFold finally delivers on the long-promised idea of a tablet that actually fits in your pocket. Internally, the Galaxy Z TriFold shares a lot with the Galaxy Z Fold 7, including the Snapdragon 8 Elite chip and the same camera setup, but adds a larger 5,400mAh battery to help power the much bigger screen. Where the TriFold really separates itself is software. One UI 8 on Android 16 enables true three-app multitasking, splitting the screen into equal thirds without crushing app layouts. Samsung DeX can also run directly on the device, turning the inner display into a full desktop workspace without an external monitor. The Galaxy Z TriFold is an engineering statement more than a mass-market product, but as a Best of CES pick, it shows just how far Samsung is willing to push form factors. SPONSORED ARZOPA is known for its innovative, affordable digital display technology, designed to elevate how we work, play, and connect. And while Christmas might be behind us, you don’t need special occasions to give your family gifts, especially when it’s something as thoughtful and bound to bring a whole lot of joy as the ARZOPA D14 Digital Photo Frame. While you might be away from your family, the D14 digital photo frame lets you still share beautiful moments and memories instantly. With just a tap, you can send photos and videos to any D14 photo frame anywhere in the world, so every update becomes a shared moment, with share-anytime-anywhere convenience. Of course, multiple family members can send photos and videos directly to the frame, keeping you instantly connected to your family, even if you’re thousands of miles apart. With a gorgeous 14-inch IPS anti-glare display with a Full HD resolution, every photo and video stands out in beautiful detail. It connects to Wi-Fi, so pictures and videos are uploaded and available instantly, and you can even send 2-minute video messages through the frame. With 32GB of built-in storage, microSD card support, and free and unlimited cloud storage, you can share plenty of memories for years; no subscriptions or fees to worry about. It’s easy to set up and use, and is designed to blend seamlessly into any space around your or your family’s home. Whether it’s for your parents, grandparents, siblings, or your own household, the ARZOPA D14 Digital Photo Frame is a gift that grows more and more meaningful the more you share. TCL doubled down on eye comfort at CES 2026 with the NXTPAPER 70 Pro, a phone built for people who spend a lot of time staring at their screens. Using NXTPAPER 4.0, the 6.9-inch FHD+ 120Hz display has a matte, paper-like finish that cuts glare and reflections without sacrificing smoothness. It feels closer to reading on paper than a normal display and that difference is obvious the moment you pick it up. The dedicated NXTPAPER button returns, letting you switch between display modes, including a high-contrast monochrome option that is ideal for reading. TCL also improved the anti-flicker tech, which not only reduces eye strain but makes the screen easier to film without visible banding, a small touch that shows how much thought went into real-world use. Under the hood, the NXTPAPER 70 Pro keeps things sensible. You get a 50MP main camera with optical stabilization and TCL’s MuseFilm processing, a Dimensity 7300 chip, and a 5,200mAh battery. Performance is not chasing flagships, but that is not the point here. Optional T-Pen support and built-in AI translation features add to the phone’s practical appeal. Priced from around $400, the TCL NXTPAPER 70 Pro stands out by offering a genuinely different smartphone experience. SPONSORED DREO is known for its intuitive, efficient, powerful, and elegantly designed home appliances. From tower fans and ceiling fans to portable ACs, humidifiers, heaters, and more, DREO offers a massive portfolio of performance-focused, user-centric products that make your home life easier. And the brand is bringing all that expertise to its latest product showcase at CES 2026 – the TurboCool™ Misting Fan 765S. As its name suggests, the Misting Fan 765S delivers faster, stronger cooling you can feel immediately. It’s dramatically cooler from the get-go, beyond anything you’d get from traditional fans and evaporative coolers, with lab tests showing a massive ambient temperature drop of up to 10°F. When used as a misting fan or humidifier, it’s designed for mess-free indoor use. The device produces ultrafine 17 μm mist that evaporates rapidly without condensing, even at the highest mist output levels. A dedicated internal blower system and an advanced dual-channel flow system separate air and mist paths, preventing the formation of large droplets. You won’t have to worry about damp floors or furniture when using the fan in Mist or Humidifier modes. Its HyperSilent™ operation, going as low as 20 db, makes it ideal for bedrooms, nurseries, and close-range use. Whether you’re working, watching TV, or sleeping, the Misting Fan 765S won’t be a distraction. And finally, the Misting Fan 765S is easy to manage and maintain. Its pump-free architecture eliminates mold and bacteria buildup, and it’s easy to remove, clean, and refill the 6L tank. The large tank provides up to 7 hours of Turbo cooling, or up to 30 hours in lower settings. You get independent wind and mist adjustments, 12 fan speeds, and integrated temperature and humidity sensors so you can find the perfect balance. Everything is easy to set up and control, via the app, using your voice (compatible with Alexa and Google Assistant), or with a remote. The DREO TurboCool™ Misting Fan 765S is priced at $179.99 and will be available from April 2026. SPONSORED We see lots of smart lighting showcased at events like CES, and this year is no different. One that truly stands out from the crowd is the Linkind SP6 Smart Solar Pathway Light. Designed for backyards and lawns with pathways, the SP6 is ideal for anyone looking to upgrade their pathway lighting, bringing not only safety but also a touch of style and elegance to your home’s outdoor areas. What makes the SP6 pathway light special is the inclusion of five interchangeable projection lenses that let you create patterns like Ripple, Concentric, Radial, Circular, and Lozenge. The best part? It’s all managed and controlled through the AiDot app; no tools required, and you don’t have to swap lenses manually to change the projection pattern. With 60 lumens of output and tunable white and full-spectrum RGB color adjustment, the possibilities for your outdoor decor are endless. The SP6 Smart Pathway Lights are easy to install and durable, and are powered by an advanced MPPT system that optimizes solar charging, especially in low-light conditions. A full charge gives you 12 hours of brightness, and there’s also an Eco Mode for extended running. And if solar power isn’t enough, say, during poor weather, you can also charge the lights via the built-in USB-C port. With multiple lights, you can turn your walkway into a personal lighting experience. With Bluetooth Mesh, you get automatic syncing across connected devices without a hub or Wi-Fi. And through the app, you also get 43 preset modes, music-sync capability, and scheduling for seamless, coordinated lighting effects. If you’re looking to enhance your outdoor pathway lighting, the Linkind SP6 Smart Solar Pathway Lights offer the convenience and ease of use like no other and are a great way to improve your outdoor safety and ambiance. Roborock went big at CES 2026 with the Saros Rover, a robot vacuum that rethinks mobility in a way we have not seen before. Instead of trying to work around obstacles, the Rover deals with them head-on. It uses a pair of hinged wheel-legs that let it balance, lift itself, and move over uneven surfaces, including stairs. Yes, it can climb stairs, and it can clean them while doing so. Unlike earlier stair solutions that simply carry a vacuum from one floor to another, the Saros Rover stays active the entire time. As it climbs, one leg remains planted on the step below to keep the body stable, while the other moves forward. That lets the Rover clean each step individually on the way up or down. Roborock says the system also works on curved staircases and ramps, which makes it far more flexible than past attempts at vertical cleaning. The Rover is still a preview rather than a finished product, and Roborock is not ready to talk pricing or launch timing yet. Even so, seeing it operate in person makes one thing clear. This is a strong attempt to solve one of the last major problems in robotic cleaning, and it hints at a future where no part of your home is off-limits to a robot vacuum. Motorola made its biggest foldable leap yet at CES 2026 with the Razr Fold, the company’s first book-style foldable and a clear signal that the Razr brand is no longer limited to clamshells. Built around an 8.1-inch inner display and a tall outer screen, the Razr Fold feels immediately familiar if you have used other large foldables. But it still carries Motorola’s design DNA, from its clean software look to its signature materials and finishes. In hand, the Razr Fold strikes a balance between size and comfort. It opens into a spacious tablet-like canvas that feels well-suited for any task. Meanwhile, the outer display remains useful enough to handle quick tasks without unfolding. Motorola’s hardware confidence shows here. The hinge feels solid, the displays are bright and smooth, and the overall design feels well thought out. Motorola’s software approach also plays to its strengths. The experience stays close to stock Android, with light customization and thoughtful touches carried over from the Razr flip lineup. Even in early hands-on time, the interface feels calm and approachable on a large screen, which is not always a given with foldables. The Razr Fold marks Motorola’s entry into large foldables with a clear focus on design, usability, and brand identity. If Motorola can follow through on polish and long-term support, the Razr Fold has the potential to become a compelling alternative for people who want an approachable large foldable. XGIMI surprised us at CES 2026 by stepping away from projectors and into wearable tech with the Memo One, the lead product under its new MemoMind brand. These AI glasses actually look and feel wearable, weighing just 28.9g and designed for all-day use without calling attention to themselves. In person, the Memo One feels closer to normal eyewear than most smart glasses we have seen so far. The Memo One uses dual-eye displays paired with built-in speakers to deliver information discreetly. The system focuses on short, relevant interactions, such as live translation, summaries, reminders, note-taking, and contextual guidance. Powering all of this is a hybrid AI system that dynamically selects the best model for each task, pulling from multiple major AI platforms in the background. Comfort and personalization are clearly a priority. XGIMI offers multiple frame styles and interchangeable temples, along with full prescription lens support. Battery life is also handled sensibly, with all-day use from the glasses themselves and a charging case that can stretch total runtime close to a full week. At around $599, the MemoMind Memo One are not cheap, but they feel thoughtfully positioned. If AI glasses are going to move beyond novelty, this is the kind of approach that gives them a real shot. Lenovo brought a more focused handheld experience to CES 2026 with the SteamOS version of the Legion Go 2. It is the same second-generation hardware as the Windows model, but paired with Valve’s controller-first operating system for players who want their handheld to feel closer to a console than a tiny PC. The pitch is simple and effective. SteamOS handles quick suspend and resume, native Steam library access, cloud saves, and a UI built around buttons and sticks rather than menus and windows. Lenovo says this is its most powerful handheld to ship natively with SteamOS. You get an 8.8-inch OLED display with a 144Hz refresh rate, an AMD Ryzen Z2 Extreme chip, up to 32GB of LPDDR5X memory, and up to 2TB of storage with microSD expansion. What makes this model appealing is choice. Windows is there for flexibility and broad compatibility, while SteamOS is for players who want a cleaner, more predictable gaming experience without desktop friction. That mirrors what Lenovo already did with the Legion Go S, and it feels like a smart continuation of that strategy. Starting at $1,199 and launching around June 2026, the SteamOS Legion Go 2 is clearly positioned above the Steam Deck on price. Lenovo is aiming at players who want top-tier handheld hardware and prefer SteamOS to do exactly one thing well: play games. Dreame returned to CES 2026 with a clear goal: refine its flagship robot vacuum without making compromises. The X60 Max Ultra builds on last year’s stair-climbing concept and pushes it further, letting the robot roll over obstacles up to 8.8cm high. That still will not handle a full staircase, but it is enough to deal with raised thresholds, room dividers, and other problem spots that usually stop a robot in its tracks. Dreame really managed to slim things down with this new model. The X60 Max Ultra measures just 7.95cm tall, making it the company’s lowest-profile robot yet. To pull that off, Dreame uses a retracting LiDAR system that lowers itself when the robot moves under furniture, then pops back up to maintain full mapping accuracy. Paired with the latest OmniSight navigation system, Dreame claims significantly faster path planning and more confident object recognition. Mobility is handled by the new FlexiAdapt system, which uses retractable legs and swinging arms ahead of the wheels to lift the robot over raised surfaces instead of avoiding them. Combined with strong suction and a full mopping setup, the X60 is designed to clean more of your home in a single pass, rather than asking you to prep the space first. The high-end dock rounds things out with hot-water mop washing at 100°C, cutting down on odors and manual maintenance. Priced at $1,699, the Dreame X60 Max Ultra is firmly in flagship territory, but it earns that spot by tackling multiple real-world pain points all at once. Beatbot used CES 2026 to show just how far robotic pool care has progressed, and the AquaSense X is the clearest example yet. AquaSense is a system designed to make pool maintenance feel close to self-managing, from cleaning to post-cycle upkeep. The standout feature is the AstroRinse Cleaning Station, a self-cleaning dock that automatically rinses the robot’s internal filter, flushes debris into a sealed bag, and starts recharging once a cycle is finished. For pool owners, this removes one of the most annoying parts of robotic cleaning. No more handling wet filters or rinsing debris by hand after every run. The large-capacity debris bag is built to last weeks between emptying, even with frequent cleaning. Beatbot AI 2.0 and HybridSense AI Vision combine cameras with infrared and ultrasonic sensors to identify dozens of debris types across the pool floor, walls, waterline, and surface. Navigation adapts dynamically to pool shape and depth, allowing a single cycle to handle areas that often require separate passes on other robots, including shallow ledges and surface debris. At $4,250, the Beatbot AquaSense X is a premium product. But by addressing both cleaning and the maintenance that follows, it can conceivably take care of the pool in the background, which feels like the real next step for this category. TCL went all-in on premium TV performance at CES 2026 with the X11L Series, a flagship Mini LED TV that is clearly aimed at ending the usual OLED versus LED debate. The X11L combines extreme brightness, deep black levels, and unusually accurate color in a well-rounded package. At the core of the X11L is TCL’s new SQD-Mini LED display system, built around Super Quantum Dots, a new UltraColor filter, and advanced color processing. Users get BT.2020 color coverage with far more consistency than we usually see from Mini LED panels. TCL pairs that color performance with up to 20,000 dimming zones and peak brightness hitting 10,000 nits. This combo of features should translate into intense highlights, strong contrast, and minimal blooming even in difficult scenes. TCL’s upgraded Halo Control System and new 26-bit backlight controller allow for tighter light control and cleaner shadow detail, while the TSR AI Processor handles motion, upscaling, clarity, and sound tuning. The panel itself is ultra-thin, just 0.8 inches (20mm) deep, with a flat back designed to sit flush on a wall, reinforced by an Art Mode that helps it blend into a living space when not in use. Audio is similarly ambitious. Bang and Olufsen tuning is built in, with the option to expand into a full wireless Dolby Atmos setup over time, including a subwoofer and surround speakers. Starting at $6,999 for the 75-inch model, the TCL X11L SQD-Mini LED sets its own bar for what a no-compromise premium TV should look like in 2026. Razer brought one of the more unexpected ideas to CES with Project Motoko, a concept that asks a simple question: what if smart glasses worked just as well without sitting on your face. Instead of lenses, Motoko builds its AI experience into a pair of over-ear headphones that look and feel like regular wireless cans. The trick is a pair of forward-facing cameras embedded into the headphones, capturing a first-person view of the world around you. Motoko delivers the same kind of contextual help we have come to expect from smart glasses. Live translation, object recognition, price comparisons, directions, and weather updates all worked smoothly in demos. The system is not locked to a single assistant either, with support for platforms like Gemini, ChatGPT, and others depending on what you prefer. What makes Motoko stand out is the form factor. Unlike smart glasses, these headphones blend in. On the head, they feel like normal everyday headphones, and visually, nothing about them signals experimental tech. For people who like the idea of ambient AI help but do not want a visible wearable, that matters a lot. Project Motoko is still a concept, with no pricing or release details yet. If Razer decides to take this further, smart headphones could end up being a far more natural home for everyday AI than glasses ever were. LG Display showed off one of the most extreme gaming panels we’ve seen with a 27-inch OLED monitor panel built for pure speed. This is a QHD display that pushes refresh rates far beyond what most gamers have ever seen, topping out at a staggering 720Hz. The headline feature is Dynamic Frequency and Resolution, or DFR. This lets players choose what matters most in the moment. In Performance Mode, the panel runs at a full 720Hz for the smoothest possible motion. Switch to Resolution Mode, and it delivers QHD clarity at 540Hz, still far beyond today’s mainstream gaming monitors. Paired with a 0.02ms gray-to-gray response time, motion blur and latency are pushed to levels that LCD panels simply cannot match. Because this is OLED, image quality keeps up with the speed. The panel delivers perfect blacks, up to 1,500 nits of peak brightness, and near-complete DCI-P3 coverage with strong BT.2020 support. Color depth and contrast remain intact even at extreme refresh rates, which is not something high-speed panels have always managed in the past. LG Display also leaned into comfort, with flicker-free operation, reduced glare, and low blue light output to support longer play sessions. As a technology showcase, this 720Hz OLED panel sets a new ceiling for competitive gaming displays and signals where the very top end of esports hardware is heading next. Samsung expanded its PC ambitions at CES with the Galaxy Book 6 lineup, pairing Intel’s newest Panther Lake processors with a clearer performance hierarchy and the return of the Ultra model. The series includes the Galaxy Book 6, Book 6 Pro, and the Galaxy Book 6 Ultra, covering everything from thin-and-light productivity to heavy creative and gaming workloads. All models are built around Intel Core Ultra Series 3 chips, delivering a sizable jump in performance and efficiency. The base and Pro models rely on Intel Arc integrated graphics, while the Galaxy Book 6 Ultra stands apart by offering NVIDIA RTX 50 series GPUs. The Ultra can also be configured with up to 64GB of memory, reinforcing its position as the most powerful Galaxy Book yet. Displays remain a strong point. The Pro and Ultra feature Samsung’s latest Dynamic AMOLED panels with high resolution, dynamic 120Hz refresh rates, strong brightness, and anti-reflective coatings. For battery, Samsung claims up to 30 hours of video playback on the Pro and Ultra. Design tweaks are subtle but intentional, including cleaner branding and a more uniform keyboard layout. Samsung has not yet announced pricing for the Galaxy Book 6 series. Availability begins later this month in select markets, with US sales expected to start in the spring. Lenovo continued its rollable push at CES 2026 with the Legion Pro Rollable Concept, a gaming laptop that takes the idea of an expanding display to an extreme. Built for esports and high-end gaming, this concept starts as a fairly normal 16-inch laptop and then unfurls into something much larger, turning into a desktop-style gaming screen on demand. The rollable PureSight OLED display can expand up to 24 inches in “Arena mode,” or stop at 21.5 inches in “Tactical mode” for setups where space is more limited. That flexibility is the real hook here. You can travel with a reasonably sized gaming laptop and still get a massive screen once you sit down to play. Lenovo uses a dual-motor system to extend the display smoothly, aiming to keep vibration and noise to a minimum during the transition. Under the hood, the concept is based on the Legion Pro 7i, which means top-tier hardware. Lenovo confirmed that the system is paired with Intel Core Ultra processors and an NVIDIA GeForce RTX 5090, making it clear this is not just a visual experiment. This is still very much a concept, and Lenovo has not said when or if it will reach production. Even so, it feels like a natural next step after the company’s first commercial rollable laptop. Pebble made an unexpected and welcome return to Las Vegas with the Pebble Round 2, a smartwatch that feels deliberately out of step with modern wearables, in the best way possible. It is a spiritual follow-up to the Pebble Time Round, keeping the same ultra-thin, lightweight circular design while fixing its biggest flaw with a much larger, edge-to-edge display. The new 1.3-inch e-paper screen completely changes how the watch feels day to day. Notifications are easier to read, watch faces finally have room to breathe, and visibility in bright light is excellent without relying on a backlight. Pebble sticking with e-paper is a clear statement that this watch prioritizes readability and battery life over flashy visuals. Comfort is where the Pebble Round 2 really stands apart. The case is extremely thin and light, to the point where it almost disappears on your wrist. For people with smaller wrists, or anyone tired of bulky smartwatches, this is refreshing. It feels closer to wearing a traditional watch than a mini computer. There are obvious omissions. No heart rate sensor, GPS, NFC, speaker, or fitness tracking. That is intentional. The Pebble Round 2 is designed to be a notification-first smartwatch with up to 14 days of battery life, nothing more. Pebble Round 2 costs $199 and is expected to start shipping in May. A collaboration between XREAL and ASUS, the ROG XREAL R1 is a gaming-first take on AR glasses that puts a high-refresh display directly in front of your eyes. This is not positioned as a general-purpose wearable. It is designed to function like a portable gaming monitor, and the hardware reflects that focus. Each lens features a 1080p micro-OLED display running at up to 240Hz, with latency rated at just three milliseconds. That combination makes fast motion feel smooth and responsive, closer to what you would expect from a dedicated gaming display than from a wearable. A wider 57-degree field of view helps the virtual screen feel more immersive without dominating your entire vision. The R1 fits neatly into ASUS’ gaming ecosystem. It connects over USB-C for simple plug-and-play use and pairs especially well with devices like the ROG Ally. A dedicated dock lets you switch between multiple inputs, while built-in head tracking allows the display to stay anchored in space as you move. Audio is handled through Bose-tuned speakers built into the arms, keeping the setup self-contained. Automatic electrochromic lens tinting adjusts to ambient light, making the glasses easier to wear across different environments. Pricing has not been announced yet, but availability is expected in the first half of 2026. Our annual Best of CES awards highlight products that stand out at the very top of the show. But the event has always been about more than established names and headline launches. It is also a proving ground for smaller teams and newer brands looking to break through with fresh ideas. To recognize that side of the show, we created the Best of CES 2026: Breakthrough Awards. The products below may not come from the biggest players, but each one brings something new to the table and shows real potential. Here are the 10 Best of CES 2026 Breakthrough Award winners. Keep an eye on them, as any of these could shape where tech goes next. Which of these products is your favorite? Let us know the top Best of CES 2026 award winner in the comments below, and stay tuned for more! Thank you for being part of our community. Read our Comment Policy before posting.
--------------------------------------------------

Title: Stocks Settle Mostly Lower as Early Rally Fades
URL: https://www.barchart.com/story/news/36936097/stocks-settle-mostly-lower-as-early-rally-fades
Time Published: 2026-01-07T21:37:36Z
Description: The S&P 500 Index ($SPX ) (SPY ) on Wednesday closed down -0.34%, the Dow Jones Industrials Index ($DOWI ) (DIA ) closed down -0.94%, and the Nasdaq 100...
--------------------------------------------------

Title: Intel Is Doubling Back Down on Gaming. Does That Make INTC Stock a Buy Here?
URL: https://www.barchart.com/story/news/36934753/intel-is-doubling-back-down-on-gaming-does-that-make-intc-stock-a-buy-here
Time Published: 2026-01-07T20:43:07Z
Description: Intel stock soars as the company unveils new processors at CES 2026. Here’s what makes INTC shares worth owning at current levels.
--------------------------------------------------

Title: Stocks Supported by Lower Bond Yields
URL: https://www.barchart.com/story/news/36929069/stocks-supported-by-lower-bond-yields
Time Published: 2026-01-07T15:07:34Z
Description: The S&P 500 Index ($SPX ) (SPY ) today is up +0.13%, the Dow Jones Industrials Index ($DOWI ) (DIA ) is down -0.10%, and the Nasdaq 100 Index ($IUXX ) (QQQ )...
--------------------------------------------------