List of news related to Advanced Micro Devices stock price AMD:

Title: The Relentless Rise of Jensen Huang
URL: https://www.theatlantic.com/magazine/archive/2025/05/thinking-machine-jensen-huang-nvidia-book-review/682122/
Time Published: 2025-04-08T11:00:00Z
Full Content:
How Jensen Huang built Nvidia into a nearly $3 trillion business Listen to more stories on hark Another day, another new AI large language model that’s supposedly better than all previous ones. When I began writing this story, Elon Musk’s xAI had just released Grok 3, which the company says performs better than its competitors against a wide range of benchmarks. As I was revising the article, Anthropic released Claude 3.7 Sonnet, which it says outperforms Grok 3. And by the time you read this, who knows? Maybe an entirely new LLM will have appeared. In January, after all, the AI world was temporarily rocked by the release of a low-cost, high-performance LLM from China called DeepSeek-R1. A month later, people were already wondering when DeepSeek-R2 would come out. Check out more from this issue and find your next story to read. The competition among LLMs may be hard to keep track of, but for Nvidia, the company that designs the computer chips—or graphics-processing units (GPUs)—that many of these large language models have been trained on, it’s also enormously lucrative. Nvidia, which, as of this writing, is the third-most-valuable company in the world (after Apple and Microsoft), was started three decades ago by engineers who wanted to make graphics cards for gamers. How it evolved into the company that is providing almost all the picks and shovels for the AI gold rush is the story at the core of Stephen Witt’s The Thinking Machine. Framed as a biography of Jensen Huang, the only CEO Nvidia has ever had, the book is also something more interesting and revealing: a window onto the intellectual, cultural, and economic ecosystem that has led to the emergence of superpowerful AI. James Surowiecki: DeepSeek’s chatbot has an important message That ecosystem’s center, of course, is Silicon Valley, where Huang has spent most of his adult life. He was born in Taiwan, the son of a chemical engineer and a teacher. The family moved to Thailand when he was 5, and a few years later, his parents sent him and his older brother to the United States to escape political unrest. Eventually, his parents relocated to the U.S. as well, and Huang grew up in the suburbs of Portland, Oregon. In the early 1980s, after majoring in electrical engineering at Oregon State (which at the time didn’t offer a computer-science major), he got a job at Advanced Micro Devices. The company—then the poor cousin of the chip giant Intel—was headquartered in Sunnyvale, California, near US 101, the highway that runs from San Jose to Stanford. Since then, Huang’s career has unfolded within a five-mile radius of that office. Huang soon left AMD for a firm called LSI Logic Corporation, which built software-design tools for chip architects, and then left LSI in 1993 to start Nvidia with the chip designers Curtis Priem and Chris Malachowsky: He was right on target “to run something by the age of thirty,” as he’d told them he aimed to do. The company was entering a crowded marketplace for developing graphics cards, the computer hardware that’s used to render images and videos. Nvidia didn’t have a real business plan, but Huang’s boss at LSI recommended him to Sequoia Capital. One of the Valley’s most important venture-capital firms, Sequoia helped the company get off the ground. The graphics-card business was built on a perpetual upgrade cycle that forced developers into a never-ending game of performance improvement: A company was only as good as its last card. At various points in those early years, Nvidia was one misstep away from bankruptcy, and its unofficial motto became “Our company is thirty days from going out of business.” One gets the impression that Huang liked it that way. He says his heart rate goes down under pressure, and to call him a relentless worker is to understate matters. “I should make sure that I’m sufficiently exhausted from working that no one can keep me up at night,” he once said. His reading diet features business books (which he devours). He has no obvious politics (or at least never discusses them). He’s not a gaudy philanthropist. Though devoted to his family, he’s also honest: “Lori,” he says of his wife, “did ninety percent of the parenting” of their two children. For the past 30 years, his life has clearly revolved around Nvidia. Huang’s reluctance to talk about himself makes him a challenging subject for Witt to bring to life. But Nvidia’s employees, who almost all refer to Huang by his first name, are effusive. They “worship him—I believe they would follow him out of the window of a skyscraper if he saw a market opportunity there,” Witt writes. He later adds that they see Huang “not just as a leader but as a prophet. Jensen was a prophet who made predictions about things. And then those things came true.” He has a ferocious temper—referred to in the company as “the Wrath of Huang”—and is notorious for publicly reprimanding, at length, workers who have made mistakes or failed to deliver. But he rarely fires people and, in fact, inspires intense devotion. One of his key subordinates says, “I’ve been afraid of Jensen sometimes. But I also know that he loves me.” Read: Jensen Huang is tech’s new alpha dog Huang’s greatest strength as a CEO has been his willingness to make big, risky bets when opportunities present themselves. The first of those came when he changed the architecture of Nvidia’s chips from serial processing to parallel processing. Witt calls this move “a radical gamble,” because up to that point, no company had been able to make selling parallel-processing chips a viable business. Serial computing is the way your computer’s central processing unit works: It executes one instruction at a time, very, very fast. Witt likens it to telling one delivery van to drop off packages in sequence. By contrast, “Nvidia’s parallel GPU acts more like a fleet of motorcycles spreading out across a city,” with the drivers delivering each package at roughly the same time. The coding required to make parallel processing work was much more complex, but if you could do it, you had access to enormous amounts of computing power. Initially, all that power was used mainly to make computer games look and perform better. But then Huang took another big risk, remaking Nvidia’s GPUs so that they could also process massive data sets, of the kind scientists might use. As one Nvidia executive puts it, “You have a video game card on one side, but it has a switch on it. So you flick that switch, and turn the card over, and suddenly the card becomes a supercomputer.” The fascinating thing about this decision was that Huang didn’t know who might want to buy a supercomputer in the guise of a graphics card, or how many such people were out there. He was just betting that if you make powerful tools available to people, they will find a use for them, and at a scale to justify the billions in investment. That use—and it was big—turned out to be artificial intelligence, in particular neural-network technology. As Witt notes, just as parallel processing was revolutionizing computing, a similar revolution was happening in AI research—though no one at Nvidia was paying attention to it. AI had gone through a series of boom-and-bust cycles as researchers tried different techniques, all of which ultimately failed. One of those methods was neural networks, which tried to mimic the human brain and allow the AI to evolve new rules of learning on its own. When you train these networks on massive databases of images and text, they can, over time, identify patterns and become smarter. Neural networks had long been peripheral, partly because they’re black boxes (you can’t explain how the AI is learning, or why it’s doing what it’s doing), and partly because the computing power required to make a high-performance neural network operate was out of reach. Parallel-processing GPUs changed all that. Suddenly, AI researchers, if they could write software well enough to get the most out of the chips, had access to sufficient computing power to allow neural networks to evolve at an extraordinary pace. In 2009, Geoff Hinton, one of the godfathers of AI research, told a conference of machine-learning experts to go buy Nvidia cards. And in 2012, one of Hinton’s students, Alex Krizhevsky, strung together two Nvidia GPUs and built and trained SuperVision (which he later renamed AlexNet). It was an AI model that could, for the first time, identify images with startling accuracy, largely because, in Witt’s words, “the GPU produced in half a minute what would have taken an Intel machine an hour and what would have taken biology a hundred thousand years.” Huang did not immediately recognize the importance of what had happened. When he spoke at Nvidia’s annual GPU Technology Conference in 2013, he never mentioned neural networks, talking instead about weather modeling and computer graphics. But a few months later, after an Nvidia researcher named Bryan Catanzaro made a direct pitch to him about the importance of AI, Huang had what Witt calls a “Damascene epiphany”: He placed another big bet, essentially transforming Nvidia from a graphics company into an AI company over the course of a weekend. This bet was less risky than his earlier ones, because even though Nvidia had competitors who also built GPUs, none of them had really designed theirs to be used as supercomputers. Still, going all in was prescient—developments such as large language models had yet to take off—and is what has turned Nvidia into a nearly $3 trillion company. Read: The lifeblood of the AI boom That weekend feels as if it were the compressed culmination of Nvidia’s story, which isn’t empirically true. The 12 years that followed have been incredibly eventful, and incredibly profitable, as the company has kept improving its chips, servicing the insatiable appetite for computing power created by the emergence of LLMs, and fending off competitors (many of whom are Nvidia’s customers, now building their own chips). But the foundations for that pivot, and all that ensued, were already in place when Huang decided to act on his AI insight. Those foundations, The Thinking Machine makes clear, were not laid by Nvidia alone. Indeed, among Witt’s key contributions is to show that Nvidia’s success can’t be understood apart from the culture and economy of Silicon Valley (and of tech more generally). Take the simple fact of free labor markets. One catalyst of the Valley’s success, as the scholar AnnaLee Saxenian has famously argued, was a freewheeling, risk-taking culture that encouraged workers to leave companies for competitors or to start their own firms. And that depended, in part, on the fact that noncompete clauses were unenforceable in California. Nvidia’s history exemplifies this: not just Huang’s mobility, but that of his early hires as well. Later, one of the company’s favorite tactics was to poach its competitors’ best engineers and coders—bad form, perhaps, but a good business tactic. Nvidia also benefited from the research investments made by the government and universities. One of the crucial breakthroughs in unlocking the power of parallel computing, for instance, was an open-source programming language called Brook, which a gamer and Stanford graduate student named Ian Buck developed with a group of researchers in 2003, relying on a Defense Department grant. Alex Krizhevsky and his partner Ilya Sutskever (who later helped start OpenAI) were grad students at the University of Toronto when Krizhevsky devised AlexNet. The contest in which the model demonstrated its accuracy, the ImageNet challenge, was designed by a Stanford computer scientist named Fei-Fei Li. And as that lineup demonstrates (Krizhevsky and Sutskever were born in the Soviet Union, Li in China), immigration has been central to the history of not just Nvidia but AI generally. Practical economic features of the ecosystem mattered as well. The most important was the rise of independent chip foundries: factories that serve many different companies and make chips on order. Nvidia’s partnership with Taiwan Semiconductor Manufacturing Company, the best-known of these factories, allowed it to become a dominant player by focusing on designing and writing software for its chips; Nvidia didn’t have to invest in actual production, which would have required prohibitive amounts of capital. From the September 2023 issue: Does Sam Altman know what he’s creating? Finally, Nvidia benefited from patience, and its board’s willingness to put long-term thinking ahead of short-term profits. Because of the gaming market, Nvidia was almost always a profitable company, but its stock price dropped nearly 90 percent two different times; it didn’t appreciate for a full 10 years after the dot-com bubble burst, while the company was spending billions turning its graphics cards into supercomputers. One familiar indictment of American capitalism is that it’s too short-term-focused. In the tech industry, at least, the trajectory of Nvidia (and many other companies) suggests that’s a bum rap. To be sure, Huang himself was central to Nvidia’s success: He has run the company essentially on his own (as Witt puts it, he has had “no right-hand man or woman, no majordomo, no second-in-command”), and he’s made the bold moves. What’s more, he seems to have done so without a trace of doubt. Lots of people in the AI industry—including the people training LLMs—have raised concerns about AI’s dangers, but Huang is not one of them. For him, Witt writes, “AI is a pure force for progress.” Huang does not fret that it may eat all of our jobs, or replace artists, or go rogue and decide to wipe out humanity. In fact, when Witt, stricken with existential anxiety about how AI will change the world, asks Huang whether some of these concerns might be worth pondering, he is subjected to one of his legendary tirades: You could write this off as an example of Upton Sinclair’s adage “It is difficult to get a man to understand something, when his salary depends upon his not understanding it!” But the fact that Huang talks about AI in terms of its impact on “marginal costs” shouldn’t be reduced to mere opportunism: It fits right in with the single-minded focus on performance that has driven him from Nvidia’s beginning. Witt at one point calls Huang a “visionary inventor.” The vision Huang has been in thrall to, though, seems to be less about grand future goals, and more about tools—about making the fastest, most powerful chips as efficiently as possible. “Existential risk” has no place in that vision. Huang’s unapologetic stance on AI is bracing in its way, especially in contrast with the public hand-wringing of many AI chieftains, fretting about the dangers of their LLMs while continuing to develop them. But he is in effect making the biggest, riskiest bet ever—not just for Nvidia, but for all of us. Let’s hope he’s right. This article appears in the May 2025 print edition with the headline “The New King of Tech.” ​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.
--------------------------------------------------

Title: Is Nvidia Stock Worth Buying The Dip?
URL: https://www.forbes.com/sites/investor-hub/article/is-nvidia-nvda-stock-worth-buying-the-dip/
Time Published: 2025-04-07T20:29:22Z
Full Content:
ByCatherine Brock ByCatherine Brock, Contributor. Nvidia has continued AI growth, plus opportunities in robotics, PC gaming and autonomous driving ... More that make it an attractive buy at the current valuation.&nbsp; You can buy Nvidia stock on the cheap right now, but should you? That’s the question many investors have been asking since the once-unstoppable NVDA stock fell to its lowest P/E ratio since early 2019. Get your answer now with this look at what happened to Nvidia, factors that could spark a rebound and risks ahead for the company. Nvidia stock gained 168% in the first 10 months of 2024 as investors bought up shares to get their piece of the AI boom. The stock price rally peaked in early November and then turned south when investors got nervous about lingering high interest rates. The negative trend for Nvidia deepened in 2025 as a series of headlines prompted many to question the chip designer’s growth outlook: January through early April, Nvidia stock is down almost 30%. The AI buildout has driven Nvidia's growth in recent years. Nvidia's AI data center sales are still increasing, but the pace has slowed and competition could become a factor soon. A full Nvidia rebound will likely require a different kind of breakthrough. Three opportunity areas to watch are robotics, PC gaming and autonomous driving. Huang recently valued the opportunity in AI-powered robotics and automation at $50 trillion. The CEO says these technologies will "transform manufacturing, logistics, healthcare and other industries." Nvidia has two platforms, Isaac and Cosmos, that support robotics and other types of physical AI. Nvidia’s GeForce Now service uses the cloud to upgrade the gaming experience on any PC. Gamers connect their PC gaming accounts at Steam, Epic Games Store or Ubisoft Connect to GeForce Now for added hardware support—essentially turning any device into a gaming PC. Nvidia announced expanded GeForce Now device support and capabilities at the 2025 CES trade show. Nvidia’s automotive line-up includes a platform for in-vehicle computing plus solutions for training AI driving models and simulating environments for testing. In 2025, the company announced automotive AI partnerships with Toyota, Aurora, Continental, GM, Gatik and Torc. Nvidia expects its automotive business to deliver fiscal 2026 revenue of $5 billion, up from $1.7 billion in fiscal 2025. Alongside these opportunities, Nvidia faces some challenges. Regulatory changes, cheaper AI solutions and in-house chip development top the list. Changing Trump administration policies could pressure Nvidia’s stock price. Reciprocal tariffs, even with semiconductors excluded, could raise input costs and reduce margins. While Huang seems unbothered by the trade war developments, he also said he could move manufacturing to the U.S. if needed. That is a long-term solution. Unfortunately, growth investors are not known for their patience. A transition to domestic manufacturing would impact the NVDA stock price. More concerning than tariffs is the potential for export bans to China and import bans by China. Reports indicate Trump has considered tighter limits on chip sales to China. Meanwhile, Chinese regulators are discouraging sales of Nvidia's H20 chip—a product designed for export to China—because it doesn't meet efficiency standards, according to the Financial Times. The rollout of DeepSeek caused angst for Nvidia shareholders. At issue was the $5.6 million total investment quoted by the AI app’s creator. The price tag seems tiny next to, say, Microsoft's $80 billion AI budget for fiscal 2025. The discrepancy prompted questions about Nvidia's growth outlook. If DeepSeek can do it, why can't big tech spend far less on Nvidia's AI hardware for the same results? Some experts have said the $5.6 million number from DeepSeek is misleading. Still, there will be a time when cost-efficiency enters the AI fray. That could create space for competitors to chip away at Nvidia's AI dominance. Big tech companies don’t want Nvidia to be the only AI chip game in town. It's too risky. They are mitigating that risk by developing in-house solutions. Alphabet (GOOG) recently introduced a collection of lightweight open-source AI models, Meta (META) is testing an AI chip and OpenAI has nearly finalized the design of its AI chip. These solutions will reduce Nvidia's business with existing customers over time. Nvidia will have to improve on performance and price as a result. Nvidia is an attractive, long-term buy right now despite regulatory and competitive challenges. The stock may not return to its pre-Trump growth rates, but it is an innovative, healthy company with a forward-thinking leader—and those qualities usually create shareholder value over time. Like many growth stocks, NVDA is volatile. Its per-share price can fall as quickly as it rises. You can see that dynamic in play for NVDA stock since it went public in 1999. So this stock is best suited for hardy, patient investors and those who already own NVDA and want to reduce their average cost basis. If you don't feel quite ready for NVDA, see this list of best stocks for 2025 for more investing ideas. Bottom Line Nvidia is down nearly 30% this year as investors worry about tariffs, trade bans and lower-cost AI models. But the chip designer is not down for the count. Nvidia has continued AI growth, plus opportunities in robotics, PC gaming and autonomous driving that make it an attractive buy at the current valuation. After the recent downturn, Nvidia’s P/E ratio is about 32. That compares favorably to other semiconductor companies, including Advanced Micro Devices (AMD), Broadcom (AVGO) and Arm Holdings (ARM). Nvidia is a well-run company that can navigate financial downturns and industry shifts. Relative to its history, the company's current valuation is appealing. If you don't mind volatility and believe in the AI promise as well as Nvidia CEO Jensen Huang, now is a good time to buy Nvidia stock. The biggest risks for Nvidia are margin degradation from tariffs, the global impact of tariffs, import and export bans and waning demand if others can replicate DeepSeek's low-power AI model.
--------------------------------------------------

Title: Vulnerability Summary for the Week of March 31, 2025
URL: https://www.cisa.gov/news-events/bulletins/sb25-097
Time Published: 2025-04-07T13:26:40Z
Full Content:
An official website of the United States government Here’s how you know Official websites use .gov A .gov website belongs to an official government organization in the United States. Secure .gov websites use HTTPS A lock (LockA locked padlock) or https:// means you’ve safely connected to the .gov website. Share sensitive information only on official, secure websites. Free Cyber ServicesSecure by design Secure Our WorldShields UpReport A Cyber Issue Search Free Cyber ServicesSecure by design Secure Our WorldShields UpReport A Cyber Issue The CISA Vulnerability Bulletin provides a summary of new vulnerabilities that have been recorded in the past week. In some cases, the vulnerabilities in the bulletin may not yet have assigned CVSS scores. Vulnerabilities are based on the Common Vulnerabilities and Exposures (CVE) vulnerability naming standard and are organized according to severity, determined by the Common Vulnerability Scoring System (CVSS) standard. The division of high, medium, and low severities correspond to the following scores: Entries may include additional information provided by organizations and efforts sponsored by CISA. This information may include identifying information, values, definitions, and related links. Patch information is provided when available. Please note that some of the information in the bulletin is compiled from external, open-source reports and is not a direct result of CISA analysis. Back to top Back to top Back to top Back to top We recently updated our anonymous product survey; we’d welcome your feedback.
--------------------------------------------------